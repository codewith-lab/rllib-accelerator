{"epoch": 1, "reward_mean": 21.445652173913043, "student_loss": null, "teacher_policy_loss": -12.296149253845215, "teacher_value_loss": 275.0354309082031, "teacher_entropy": 0.5925091505050659, "total_time": 1.749969482421875, "rollout_time": 0.4375641345977783, "train_time": 1.2264702320098877, "student_train_time": 0.08553409576416016, "throughput": 1142.8770730516367, "inference_time": 0.053526132502383916, "env_time": 0.3840380020953944, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 2, "reward_mean": 20.412371134020617, "student_loss": null, "teacher_policy_loss": -12.316801071166992, "teacher_value_loss": 135.41952514648438, "teacher_entropy": 0.6676086187362671, "total_time": 1.3191092014312744, "rollout_time": 0.4475715160369873, "train_time": 0.8579001426696777, "student_train_time": 0.012953758239746094, "throughput": 1516.1747017077419, "inference_time": 0.05895023224582019, "env_time": 0.3886212837911671, "samples": 2000, "teacher_eval_reward": 9.2}
{"epoch": 3, "reward_mean": 20.711340206185568, "student_loss": null, "teacher_policy_loss": -10.782022476196289, "teacher_value_loss": 132.1959991455078, "teacher_entropy": 0.5622909665107727, "total_time": 1.1482701301574707, "rollout_time": 0.42566585540771484, "train_time": 0.7166979312896729, "student_train_time": 0.005482673645019531, "throughput": 1741.7504361327638, "inference_time": 0.054517988002089623, "env_time": 0.3711478674056252, "samples": 2000, "teacher_eval_reward": 49.8}
{"epoch": 4, "reward_mean": 21.75, "student_loss": null, "teacher_policy_loss": -12.650280952453613, "teacher_value_loss": 134.3413543701172, "teacher_entropy": 0.6746163964271545, "total_time": 1.1387372016906738, "rollout_time": 0.4208536148071289, "train_time": 0.707528829574585, "student_train_time": 0.010007143020629883, "throughput": 1756.3314845871516, "inference_time": 0.05250594725021074, "env_time": 0.36834766755691817, "samples": 2000, "teacher_eval_reward": 12.5}
{"epoch": 5, "reward_mean": 21.725274725274726, "student_loss": null, "teacher_policy_loss": -11.4496488571167, "teacher_value_loss": 98.50224304199219, "teacher_entropy": 0.6489948630332947, "total_time": 1.273254156112671, "rollout_time": 0.4136481285095215, "train_time": 0.8454596996307373, "student_train_time": 0.0137939453125, "throughput": 1570.7783009372868, "inference_time": 0.05226785325066885, "env_time": 0.36138027525885263, "samples": 2000, "teacher_eval_reward": 94.1}
{"epoch": 6, "reward_mean": 21.236559139784948, "student_loss": null, "teacher_policy_loss": -13.0419340133667, "teacher_value_loss": 114.73914337158203, "teacher_entropy": 0.6830673217773438, "total_time": 1.2095584869384766, "rollout_time": 0.44202566146850586, "train_time": 0.7620813846588135, "student_train_time": 0.005095243453979492, "throughput": 1653.4959008573587, "inference_time": 0.05599758649566411, "env_time": 0.38602807497284175, "samples": 2000, "teacher_eval_reward": 102.1}
{"epoch": 7, "reward_mean": 20.897959183673468, "student_loss": null, "teacher_policy_loss": -12.461447715759277, "teacher_value_loss": 90.921875, "teacher_entropy": 0.6813761591911316, "total_time": 1.1256799697875977, "rollout_time": 0.41214537620544434, "train_time": 0.7059342861175537, "student_train_time": 0.007246255874633789, "throughput": 1776.7039066861748, "inference_time": 0.051765703252499407, "env_time": 0.36037967295294493, "samples": 2000, "teacher_eval_reward": 73.6}
{"epoch": 8, "reward_mean": 23.103448275862068, "student_loss": null, "teacher_policy_loss": -13.386922836303711, "teacher_value_loss": 87.39883422851562, "teacher_entropy": 0.6838552951812744, "total_time": -0.3373110294342041, "rollout_time": 0.4198901653289795, "train_time": -0.7670614719390869, "student_train_time": 0.009502887725830078, "throughput": 200000000000.0, "inference_time": 0.05208656225045161, "env_time": 0.3678036030785279, "samples": 2000, "teacher_eval_reward": 9.2}
{"epoch": 9, "reward_mean": 20.80851063829787, "student_loss": null, "teacher_policy_loss": -12.074080467224121, "teacher_value_loss": 64.35352325439453, "teacher_entropy": 0.6719456911087036, "total_time": 1.2190866470336914, "rollout_time": 0.41548585891723633, "train_time": 0.7921736240386963, "student_train_time": 0.011067867279052734, "throughput": 1640.5724768345583, "inference_time": 0.05296934125090047, "env_time": 0.36251651766633586, "samples": 2000, "teacher_eval_reward": 9.6}
{"epoch": 10, "reward_mean": 23.193181818181817, "student_loss": null, "teacher_policy_loss": -11.85099983215332, "teacher_value_loss": 68.139404296875, "teacher_entropy": 0.6189448833465576, "total_time": 1.2477107048034668, "rollout_time": 0.423443078994751, "train_time": 0.8150091171264648, "student_train_time": 0.008838891983032227, "throughput": 1602.935674351716, "inference_time": 0.05341758325198498, "env_time": 0.370025495742766, "samples": 2000, "teacher_eval_reward": 9.4}
{"epoch": 11, "reward_mean": 20.96875, "student_loss": null, "teacher_policy_loss": -11.843998908996582, "teacher_value_loss": 53.519615173339844, "teacher_entropy": 0.6904832720756531, "total_time": 1.118760108947754, "rollout_time": 0.4177720546722412, "train_time": 0.6957645416259766, "student_train_time": 0.004826545715332031, "throughput": 1787.6933437330845, "inference_time": 0.053077949502608135, "env_time": 0.3646941051696331, "samples": 2000, "teacher_eval_reward": 9.3}
{"epoch": 12, "reward_mean": 21.60674157303371, "student_loss": null, "teacher_policy_loss": -12.625418663024902, "teacher_value_loss": 57.62724304199219, "teacher_entropy": 0.6769385933876038, "total_time": 1.330932855606079, "rollout_time": 0.407611608505249, "train_time": 0.9147343635559082, "student_train_time": 0.008243322372436523, "throughput": 1502.7054081471613, "inference_time": 0.051152256000364105, "env_time": 0.3564593525048849, "samples": 2000, "teacher_eval_reward": 9.1}
{"epoch": 13, "reward_mean": 22.98876404494382, "student_loss": null, "teacher_policy_loss": -12.411587715148926, "teacher_value_loss": 70.47014617919922, "teacher_entropy": 0.6534900069236755, "total_time": 1.1347403526306152, "rollout_time": 0.40743160247802734, "train_time": 0.7085647583007812, "student_train_time": 0.018314599990844727, "throughput": 1762.51773840905, "inference_time": 0.05083709449922935, "env_time": 0.356594507978798, "samples": 2000, "teacher_eval_reward": 12.9}
{"epoch": 14, "reward_mean": 21.19148936170213, "student_loss": null, "teacher_policy_loss": -11.853468894958496, "teacher_value_loss": 47.31600570678711, "teacher_entropy": 0.675760805606842, "total_time": 1.3076395988464355, "rollout_time": 0.40721631050109863, "train_time": 0.8690664768218994, "student_train_time": 0.030924081802368164, "throughput": 1529.4734128305276, "inference_time": 0.05203895950205606, "env_time": 0.3551773509990426, "samples": 2000, "teacher_eval_reward": 9.5}
{"epoch": 15, "reward_mean": 23.325581395348838, "student_loss": null, "teacher_policy_loss": -11.99848461151123, "teacher_value_loss": 83.52330017089844, "teacher_entropy": 0.5734224915504456, "total_time": 1.3798668384552002, "rollout_time": 0.41453075408935547, "train_time": 0.9582412242889404, "student_train_time": 0.006693840026855469, "throughput": 1449.4152220072601, "inference_time": 0.051011028255175006, "env_time": 0.36351972583418046, "samples": 2000, "teacher_eval_reward": 9.6}
{"epoch": 16, "reward_mean": 20.95876288659794, "student_loss": null, "teacher_policy_loss": -9.36693286895752, "teacher_value_loss": 46.021263122558594, "teacher_entropy": 0.5284988880157471, "total_time": 1.2916662693023682, "rollout_time": 0.4320716857910156, "train_time": 0.848675012588501, "student_train_time": 0.010376930236816406, "throughput": 1548.3875731153098, "inference_time": 0.0524031767491806, "env_time": 0.379668509041835, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 17, "reward_mean": 21.829545454545453, "student_loss": null, "teacher_policy_loss": -12.496225357055664, "teacher_value_loss": 67.1890869140625, "teacher_entropy": 0.6230254769325256, "total_time": 1.1727571487426758, "rollout_time": 0.4151592254638672, "train_time": 0.747795581817627, "student_train_time": 0.009414196014404297, "throughput": 1705.3829108133932, "inference_time": 0.054183349247978185, "env_time": 0.360975876215889, "samples": 2000, "teacher_eval_reward": 13.2}
{"epoch": 18, "reward_mean": 21.375, "student_loss": null, "teacher_policy_loss": -10.688826560974121, "teacher_value_loss": 52.153438568115234, "teacher_entropy": 0.6149635910987854, "total_time": 1.2706859111785889, "rollout_time": 0.44645166397094727, "train_time": 0.8118748664855957, "student_train_time": 0.012012004852294922, "throughput": 1573.9530771573257, "inference_time": 0.056390449752939276, "env_time": 0.390061214218008, "samples": 2000, "teacher_eval_reward": 12.3}
{"epoch": 19, "reward_mean": 21.258064516129032, "student_loss": null, "teacher_policy_loss": -9.903204917907715, "teacher_value_loss": 53.956478118896484, "teacher_entropy": 0.5277685523033142, "total_time": 1.3900108337402344, "rollout_time": 0.5854871273040771, "train_time": 0.7969748973846436, "student_train_time": 0.0071468353271484375, "throughput": 1438.8377064791716, "inference_time": 0.06552590249896184, "env_time": 0.5199612248051153, "samples": 2000, "teacher_eval_reward": 17.8}
{"epoch": 20, "reward_mean": 21.09375, "student_loss": null, "teacher_policy_loss": -10.907779693603516, "teacher_value_loss": 54.73754119873047, "teacher_entropy": 0.6136674880981445, "total_time": 1.1548945903778076, "rollout_time": 0.4176962375640869, "train_time": 0.7292358875274658, "student_train_time": 0.007538557052612305, "throughput": 1731.7597784796342, "inference_time": 0.050778346499782856, "env_time": 0.36691789106430406, "samples": 2000, "teacher_eval_reward": 19.8}
{"epoch": 21, "reward_mean": 22.471910112359552, "student_loss": null, "teacher_policy_loss": -11.987082481384277, "teacher_value_loss": 51.41192626953125, "teacher_entropy": 0.6319051384925842, "total_time": 1.3156709671020508, "rollout_time": 0.45099830627441406, "train_time": 0.8492152690887451, "student_train_time": 0.015108823776245117, "throughput": 1520.1369111346125, "inference_time": 0.055675153500146735, "env_time": 0.39532315277426733, "samples": 2000, "teacher_eval_reward": 9.1}
{"epoch": 22, "reward_mean": 21.791208791208792, "student_loss": null, "teacher_policy_loss": -11.211247444152832, "teacher_value_loss": 53.088050842285156, "teacher_entropy": 0.5771244168281555, "total_time": 1.231997013092041, "rollout_time": 0.4374666213989258, "train_time": 0.7887873649597168, "student_train_time": 0.005383491516113281, "throughput": 1623.3805591625915, "inference_time": 0.05467839625248416, "env_time": 0.3827882251464416, "samples": 2000, "teacher_eval_reward": 118.9}
{"epoch": 23, "reward_mean": 22.379310344827587, "student_loss": null, "teacher_policy_loss": -13.45722484588623, "teacher_value_loss": 76.99363708496094, "teacher_entropy": 0.6544478535652161, "total_time": 1.2435426712036133, "rollout_time": 0.4129760265350342, "train_time": 0.8231217861175537, "student_train_time": 0.006842613220214844, "throughput": 1608.3083004013195, "inference_time": 0.05087349650057149, "env_time": 0.3621025300344627, "samples": 2000, "teacher_eval_reward": 11.4}
{"epoch": 24, "reward_mean": 24.988095238095237, "student_loss": null, "teacher_policy_loss": -12.243274688720703, "teacher_value_loss": 95.25135040283203, "teacher_entropy": 0.5405741930007935, "total_time": -0.3128814697265625, "rollout_time": -1.1197359561920166, "train_time": 0.7978515625, "student_train_time": 0.008651256561279297, "throughput": 200000000000.0, "inference_time": 0.05472368424909746, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 10.5}
{"epoch": 25, "reward_mean": 23.523809523809526, "student_loss": null, "teacher_policy_loss": -10.654556274414062, "teacher_value_loss": 76.16476440429688, "teacher_entropy": 0.48451367020606995, "total_time": 1.2387409210205078, "rollout_time": 0.417006254196167, "train_time": 0.8140907287597656, "student_train_time": 0.007249355316162109, "throughput": 1614.5426102112997, "inference_time": 0.0520434567454231, "env_time": 0.3649627974507439, "samples": 2000, "teacher_eval_reward": 10.2}
{"epoch": 26, "reward_mean": 25.0875, "student_loss": null, "teacher_policy_loss": -11.57060718536377, "teacher_value_loss": 85.77359008789062, "teacher_entropy": 0.4994441270828247, "total_time": 1.2683827877044678, "rollout_time": 0.4377403259277344, "train_time": 0.8181324005126953, "student_train_time": 0.012155294418334961, "throughput": 1576.8110537195325, "inference_time": 0.056120935504054614, "env_time": 0.38161939042367976, "samples": 2000, "teacher_eval_reward": 13.7}
{"epoch": 27, "reward_mean": 22.772727272727273, "student_loss": null, "teacher_policy_loss": -13.189348220825195, "teacher_value_loss": 113.25397491455078, "teacher_entropy": 0.6196841597557068, "total_time": 1.21113920211792, "rollout_time": 0.4182009696960449, "train_time": 0.7764480113983154, "student_train_time": 0.016089916229248047, "throughput": 1651.3378449831355, "inference_time": 0.05260419724993426, "env_time": 0.36559677244611066, "samples": 2000, "teacher_eval_reward": 15.3}
{"epoch": 28, "reward_mean": 24.72151898734177, "student_loss": null, "teacher_policy_loss": -12.509855270385742, "teacher_value_loss": 63.012393951416016, "teacher_entropy": 0.617881715297699, "total_time": 1.3441967964172363, "rollout_time": 0.41487789154052734, "train_time": 0.9225902557373047, "student_train_time": 0.006109714508056641, "throughput": 1487.8773743031622, "inference_time": 0.05228459400132124, "env_time": 0.3625932975392061, "samples": 2000, "teacher_eval_reward": 13.7}
{"epoch": 29, "reward_mean": 23.49411764705882, "student_loss": null, "teacher_policy_loss": -11.244852066040039, "teacher_value_loss": 56.6840705871582, "teacher_entropy": 0.5801074504852295, "total_time": 1.2601451873779297, "rollout_time": 0.42314767837524414, "train_time": 0.8274555206298828, "student_train_time": 0.009186506271362305, "throughput": 1587.1187066639018, "inference_time": 0.05332093450294906, "env_time": 0.3698267438722951, "samples": 2000, "teacher_eval_reward": 29.4}
{"epoch": 30, "reward_mean": 23.847058823529412, "student_loss": null, "teacher_policy_loss": -13.073001861572266, "teacher_value_loss": 72.35615539550781, "teacher_entropy": 0.639442503452301, "total_time": 1.2741353511810303, "rollout_time": 0.446336030960083, "train_time": 0.8054094314575195, "student_train_time": 0.022014379501342773, "throughput": 1569.69194689257, "inference_time": 0.05749608625035307, "env_time": 0.38883994470972993, "samples": 2000, "teacher_eval_reward": 26.1}
{"epoch": 31, "reward_mean": 22.337078651685392, "student_loss": null, "teacher_policy_loss": -12.126880645751953, "teacher_value_loss": 48.15514373779297, "teacher_entropy": 0.6422967314720154, "total_time": 1.2129342555999756, "rollout_time": 0.42310595512390137, "train_time": 0.7756531238555908, "student_train_time": 0.013677597045898438, "throughput": 1648.8939864351541, "inference_time": 0.05250045074978971, "env_time": 0.37060550437411166, "samples": 2000, "teacher_eval_reward": 13.1}
{"epoch": 32, "reward_mean": 24.253012048192772, "student_loss": null, "teacher_policy_loss": -13.409825325012207, "teacher_value_loss": 85.33348846435547, "teacher_entropy": 0.6248698830604553, "total_time": 1.2125911712646484, "rollout_time": 0.4308457374572754, "train_time": 0.7681281566619873, "student_train_time": 0.013264179229736328, "throughput": 1649.3605160543423, "inference_time": 0.05562978899797599, "env_time": 0.3752159484592994, "samples": 2000, "teacher_eval_reward": 38.8}
{"epoch": 33, "reward_mean": 23.67058823529412, "student_loss": null, "teacher_policy_loss": -14.373947143554688, "teacher_value_loss": 96.30268859863281, "teacher_entropy": 0.6531463861465454, "total_time": 1.259274959564209, "rollout_time": 0.41793036460876465, "train_time": 0.8287034034729004, "student_train_time": 0.012274026870727539, "throughput": 1588.2154924228225, "inference_time": 0.05436135649904372, "env_time": 0.3635690081097209, "samples": 2000, "teacher_eval_reward": 18.2}
{"epoch": 34, "reward_mean": 23.542168674698797, "student_loss": null, "teacher_policy_loss": -13.074447631835938, "teacher_value_loss": 76.98009490966797, "teacher_entropy": 0.6286784410476685, "total_time": 1.1849620342254639, "rollout_time": 0.4182572364807129, "train_time": 0.759037971496582, "student_train_time": 0.0073239803314208984, "throughput": 1687.817788446932, "inference_time": 0.051451337751927895, "env_time": 0.366805898728785, "samples": 2000, "teacher_eval_reward": 12.7}
{"epoch": 35, "reward_mean": 24.378048780487806, "student_loss": null, "teacher_policy_loss": -12.079619407653809, "teacher_value_loss": 89.2541732788086, "teacher_entropy": 0.5647304058074951, "total_time": 1.1843600273132324, "rollout_time": 0.42960619926452637, "train_time": 0.733210563659668, "student_train_time": 0.02118825912475586, "throughput": 1688.6757015407545, "inference_time": 0.05319971174742477, "env_time": 0.3764064875171016, "samples": 2000, "teacher_eval_reward": 12.5}
{"epoch": 36, "reward_mean": 22.813953488372093, "student_loss": null, "teacher_policy_loss": -11.54887866973877, "teacher_value_loss": 74.79039001464844, "teacher_entropy": 0.5751722455024719, "total_time": 1.3118617534637451, "rollout_time": 0.4200475215911865, "train_time": 0.8735208511352539, "student_train_time": 0.017810583114624023, "throughput": 1524.550887103267, "inference_time": 0.0537872440022511, "env_time": 0.3662602775889354, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 37, "reward_mean": 24.423529411764704, "student_loss": null, "teacher_policy_loss": -11.933270454406738, "teacher_value_loss": 56.70644760131836, "teacher_entropy": 0.6262550950050354, "total_time": 1.1250267028808594, "rollout_time": 0.4230506420135498, "train_time": 0.6942152976989746, "student_train_time": 0.007371187210083008, "throughput": 1777.7355816342792, "inference_time": 0.05421942125099122, "env_time": 0.3688312207625586, "samples": 2000, "teacher_eval_reward": 230.9}
{"epoch": 38, "reward_mean": 23.764705882352942, "student_loss": null, "teacher_policy_loss": -15.094646453857422, "teacher_value_loss": 148.9213104248047, "teacher_entropy": 0.6709035634994507, "total_time": 1.2919895648956299, "rollout_time": 0.42940664291381836, "train_time": 0.8480856418609619, "student_train_time": 0.014070272445678711, "throughput": 1548.0001188411804, "inference_time": 0.05305901524855017, "env_time": 0.3763476276652682, "samples": 2000, "teacher_eval_reward": 14.5}
{"epoch": 39, "reward_mean": 26.01388888888889, "student_loss": null, "teacher_policy_loss": -15.147398948669434, "teacher_value_loss": 119.59526062011719, "teacher_entropy": 0.6339369416236877, "total_time": 1.145036220550537, "rollout_time": 0.42171239852905273, "train_time": 0.7180531024932861, "student_train_time": 0.004918575286865234, "throughput": 1746.6696372612505, "inference_time": 0.05302016300106516, "env_time": 0.3686922355279876, "samples": 2000, "teacher_eval_reward": 15.3}
{"epoch": 40, "reward_mean": 26.3875, "student_loss": null, "teacher_policy_loss": -13.655624389648438, "teacher_value_loss": 103.76591491699219, "teacher_entropy": 0.621854841709137, "total_time": 1.2222316265106201, "rollout_time": 0.44602060317993164, "train_time": 0.7577588558197021, "student_train_time": 0.018072128295898438, "throughput": 1636.3510455950566, "inference_time": 0.054003741499172975, "env_time": 0.39201686168075867, "samples": 2000, "teacher_eval_reward": 127.7}
{"epoch": 41, "reward_mean": 23.488095238095237, "student_loss": null, "teacher_policy_loss": -13.230232238769531, "teacher_value_loss": 72.27505493164062, "teacher_entropy": 0.6608283519744873, "total_time": 1.202951192855835, "rollout_time": 0.44165754318237305, "train_time": 0.7500388622283936, "student_train_time": 0.010837554931640625, "throughput": 1662.5778434551048, "inference_time": 0.0548141370011308, "env_time": 0.38684340618124224, "samples": 2000, "teacher_eval_reward": 22.3}
{"epoch": 42, "reward_mean": 24.78048780487805, "student_loss": null, "teacher_policy_loss": -13.779213905334473, "teacher_value_loss": 80.85640716552734, "teacher_entropy": 0.6420044898986816, "total_time": 1.279294490814209, "rollout_time": 0.4541208744049072, "train_time": 0.8147666454315186, "student_train_time": 0.010002851486206055, "throughput": 1563.3616922145086, "inference_time": 0.05282504699880519, "env_time": 0.40129582740610203, "samples": 2000, "teacher_eval_reward": 30.8}
{"epoch": 43, "reward_mean": 24.658227848101266, "student_loss": null, "teacher_policy_loss": -13.95206069946289, "teacher_value_loss": 75.61561584472656, "teacher_entropy": 0.6460400223731995, "total_time": 1.164839267730713, "rollout_time": 0.4106159210205078, "train_time": 0.7475078105926514, "student_train_time": 0.006376028060913086, "throughput": 1716.9750843790744, "inference_time": 0.052339244501467874, "env_time": 0.35827667651903994, "samples": 2000, "teacher_eval_reward": 52.9}
{"epoch": 44, "reward_mean": 26.0126582278481, "student_loss": null, "teacher_policy_loss": -14.545382499694824, "teacher_value_loss": 113.29793548583984, "teacher_entropy": 0.6536770462989807, "total_time": 1.22784423828125, "rollout_time": 0.4217512607574463, "train_time": 0.7950305938720703, "student_train_time": 0.010708808898925781, "throughput": 1628.871104041358, "inference_time": 0.05407729774890413, "env_time": 0.36767396300854216, "samples": 2000, "teacher_eval_reward": 30.7}
{"epoch": 45, "reward_mean": 24.5625, "student_loss": null, "teacher_policy_loss": -14.396717071533203, "teacher_value_loss": 81.35047149658203, "teacher_entropy": 0.6541556119918823, "total_time": 1.1522705554962158, "rollout_time": 0.4083244800567627, "train_time": 0.7249307632446289, "student_train_time": 0.018618106842041016, "throughput": 1735.7034686516974, "inference_time": 0.05250360575234936, "env_time": 0.35582087430441334, "samples": 2000, "teacher_eval_reward": 68.4}
{"epoch": 46, "reward_mean": 26.584415584415584, "student_loss": null, "teacher_policy_loss": -14.988344192504883, "teacher_value_loss": 95.57939910888672, "teacher_entropy": 0.6593227982521057, "total_time": 1.262444019317627, "rollout_time": 0.41112852096557617, "train_time": 0.8290529251098633, "student_train_time": 0.021913766860961914, "throughput": 1584.2286623378634, "inference_time": 0.05278868174957552, "env_time": 0.35833983921600066, "samples": 2000, "teacher_eval_reward": 100.7}
{"epoch": 47, "reward_mean": 24.271604938271604, "student_loss": null, "teacher_policy_loss": -14.01311206817627, "teacher_value_loss": 75.09129333496094, "teacher_entropy": 0.6616087555885315, "total_time": 1.1956520080566406, "rollout_time": 0.4140467643737793, "train_time": 0.7721481323242188, "student_train_time": 0.009120941162109375, "throughput": 1672.7275047617832, "inference_time": 0.0512434087498832, "env_time": 0.3628033556238961, "samples": 2000, "teacher_eval_reward": 33.9}
{"epoch": 48, "reward_mean": 24.035714285714285, "student_loss": null, "teacher_policy_loss": -12.673806190490723, "teacher_value_loss": 44.623329162597656, "teacher_entropy": 0.6617276668548584, "total_time": 1.1766891479492188, "rollout_time": 0.44548821449279785, "train_time": 0.7228376865386963, "student_train_time": 0.00800466537475586, "throughput": 1699.6842398739552, "inference_time": 0.05426666949983883, "env_time": 0.391221544992959, "samples": 2000, "teacher_eval_reward": 14.5}
{"epoch": 49, "reward_mean": 25.94736842105263, "student_loss": null, "teacher_policy_loss": -14.071029663085938, "teacher_value_loss": 89.38417053222656, "teacher_entropy": 0.6367124319076538, "total_time": 1.2427785396575928, "rollout_time": 0.4181959629058838, "train_time": 0.8126335144042969, "student_train_time": 0.011564254760742188, "throughput": 1609.2971806151681, "inference_time": 0.05222065674820442, "env_time": 0.36597530615767937, "samples": 2000, "teacher_eval_reward": 17.6}
{"epoch": 50, "reward_mean": 25.78205128205128, "student_loss": null, "teacher_policy_loss": -14.131462097167969, "teacher_value_loss": 86.15728759765625, "teacher_entropy": 0.6529633402824402, "total_time": 1.1945042610168457, "rollout_time": 0.4055027961730957, "train_time": 0.7788829803466797, "student_train_time": 0.009778976440429688, "throughput": 1674.3347556562585, "inference_time": 0.05113437349632477, "env_time": 0.35436842267677093, "samples": 2000, "teacher_eval_reward": 104.5}
{"epoch": 51, "reward_mean": 26.466666666666665, "student_loss": null, "teacher_policy_loss": -14.710042953491211, "teacher_value_loss": 81.78630065917969, "teacher_entropy": 0.671590268611908, "total_time": 1.2507474422454834, "rollout_time": 0.4386625289916992, "train_time": 0.7984073162078857, "student_train_time": 0.013321161270141602, "throughput": 1599.0438456618976, "inference_time": 0.054342477250656884, "env_time": 0.38432005174104233, "samples": 2000, "teacher_eval_reward": 119.6}
{"epoch": 52, "reward_mean": 24.0, "student_loss": null, "teacher_policy_loss": -12.702820777893066, "teacher_value_loss": 45.905155181884766, "teacher_entropy": 0.6719294786453247, "total_time": 1.1107192039489746, "rollout_time": 0.4105055332183838, "train_time": 0.6896514892578125, "student_train_time": 0.010211706161499023, "throughput": 1800.635113617679, "inference_time": 0.05243324024741014, "env_time": 0.35807229297097365, "samples": 2000, "teacher_eval_reward": 28.0}
{"epoch": 53, "reward_mean": 23.625, "student_loss": null, "teacher_policy_loss": -12.412256240844727, "teacher_value_loss": 54.88378143310547, "teacher_entropy": 0.6500500440597534, "total_time": 1.1811320781707764, "rollout_time": 0.42693185806274414, "train_time": 0.7427563667297363, "student_train_time": 0.011087894439697266, "throughput": 1693.2907309548373, "inference_time": 0.05500452400417544, "env_time": 0.3719273340585687, "samples": 2000, "teacher_eval_reward": 165.3}
{"epoch": 54, "reward_mean": 24.9873417721519, "student_loss": null, "teacher_policy_loss": -14.234726905822754, "teacher_value_loss": 71.46034240722656, "teacher_entropy": 0.6601787209510803, "total_time": -0.3410830497741699, "rollout_time": -1.1494910717010498, "train_time": 0.803058385848999, "student_train_time": 0.005005359649658203, "throughput": 200000000000.0, "inference_time": 0.05192455974929544, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 56.1}
{"epoch": 55, "reward_mean": 26.106666666666666, "student_loss": null, "teacher_policy_loss": -14.471636772155762, "teacher_value_loss": 68.07662963867188, "teacher_entropy": 0.6510680317878723, "total_time": 1.3136322498321533, "rollout_time": 0.4218733310699463, "train_time": 0.8806140422821045, "student_train_time": 0.010793685913085938, "throughput": 1522.496117353655, "inference_time": 0.05334035324983688, "env_time": 0.3685329778201094, "samples": 2000, "teacher_eval_reward": 341.3}
{"epoch": 56, "reward_mean": 27.84722222222222, "student_loss": null, "teacher_policy_loss": -16.42571449279785, "teacher_value_loss": 111.91255950927734, "teacher_entropy": 0.6468912959098816, "total_time": 1.2911722660064697, "rollout_time": 0.40122032165527344, "train_time": 0.8774669170379639, "student_train_time": 0.012133121490478516, "throughput": 1548.9799871444718, "inference_time": 0.050493324498461334, "env_time": 0.3507269971568121, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 57, "reward_mean": 28.535211267605632, "student_loss": null, "teacher_policy_loss": -15.184844970703125, "teacher_value_loss": 79.61814880371094, "teacher_entropy": 0.6358376741409302, "total_time": 1.3373312950134277, "rollout_time": 0.42798733711242676, "train_time": 0.8909885883331299, "student_train_time": 0.017971277236938477, "throughput": 1495.5157390375125, "inference_time": 0.05389955250473122, "env_time": 0.37408778460769554, "samples": 2000, "teacher_eval_reward": 149.3}
{"epoch": 58, "reward_mean": 27.65753424657534, "student_loss": null, "teacher_policy_loss": -15.740226745605469, "teacher_value_loss": 110.69412231445312, "teacher_entropy": 0.6352943181991577, "total_time": 1.3653085231781006, "rollout_time": 0.590374231338501, "train_time": 0.7543437480926514, "student_train_time": 0.02017688751220703, "throughput": 1464.8703688925157, "inference_time": 0.05083868275016812, "env_time": 0.5395355485883329, "samples": 2000, "teacher_eval_reward": 273.1}
{"epoch": 59, "reward_mean": 24.634146341463413, "student_loss": null, "teacher_policy_loss": -13.714412689208984, "teacher_value_loss": 75.9112548828125, "teacher_entropy": 0.6296232342720032, "total_time": 1.513596534729004, "rollout_time": 0.6153435707092285, "train_time": 0.8930037021636963, "student_train_time": 0.004897117614746094, "throughput": 1321.3560906824368, "inference_time": 0.05428382725051506, "env_time": 0.5610597434587135, "samples": 2000, "teacher_eval_reward": 126.2}
{"epoch": 60, "reward_mean": 25.03846153846154, "student_loss": null, "teacher_policy_loss": -13.424402236938477, "teacher_value_loss": 51.53868865966797, "teacher_entropy": 0.6310436725616455, "total_time": 1.180417537689209, "rollout_time": 0.41202330589294434, "train_time": 0.7632060050964355, "student_train_time": 0.004775047302246094, "throughput": 1694.315728242406, "inference_time": 0.052653484252573435, "env_time": 0.3593698216403709, "samples": 2000, "teacher_eval_reward": 150.4}
{"epoch": 61, "reward_mean": 26.931506849315067, "student_loss": null, "teacher_policy_loss": -15.751564025878906, "teacher_value_loss": 110.77559661865234, "teacher_entropy": 0.6386328339576721, "total_time": 1.2920482158660889, "rollout_time": 0.43489694595336914, "train_time": 0.8427200317382812, "student_train_time": 0.014073848724365234, "throughput": 1547.9298492427818, "inference_time": 0.0541594042502993, "env_time": 0.38073754170306984, "samples": 2000, "teacher_eval_reward": 105.2}
{"epoch": 62, "reward_mean": 25.949367088607595, "student_loss": null, "teacher_policy_loss": -13.663820266723633, "teacher_value_loss": 75.75659942626953, "teacher_entropy": 0.64545738697052, "total_time": 1.2513682842254639, "rollout_time": 0.4177560806274414, "train_time": 0.8240911960601807, "student_train_time": 0.009170055389404297, "throughput": 1598.2505112297158, "inference_time": 0.05671355924971522, "env_time": 0.3610425213777262, "samples": 2000, "teacher_eval_reward": 100.1}
{"epoch": 63, "reward_mean": 25.636363636363637, "student_loss": null, "teacher_policy_loss": -13.903480529785156, "teacher_value_loss": 68.07891845703125, "teacher_entropy": 0.6581423878669739, "total_time": 1.346724510192871, "rollout_time": 0.41597867012023926, "train_time": 0.9248523712158203, "student_train_time": 0.005483388900756836, "throughput": 1485.084725838672, "inference_time": 0.051440081751934486, "env_time": 0.3645385883683048, "samples": 2000, "teacher_eval_reward": 75.9}
{"epoch": 64, "reward_mean": 25.074074074074073, "student_loss": null, "teacher_policy_loss": -13.835274696350098, "teacher_value_loss": 70.13782501220703, "teacher_entropy": 0.6550224423408508, "total_time": 1.2052485942840576, "rollout_time": 0.4123051166534424, "train_time": 0.7785396575927734, "student_train_time": 0.014027118682861328, "throughput": 1659.4086974961717, "inference_time": 0.053065785495846285, "env_time": 0.3592393311575961, "samples": 2000, "teacher_eval_reward": 75.3}
{"epoch": 65, "reward_mean": 24.308641975308642, "student_loss": null, "teacher_policy_loss": -13.645797729492188, "teacher_value_loss": 64.76447296142578, "teacher_entropy": 0.6643772125244141, "total_time": 1.1349081993103027, "rollout_time": 0.423673152923584, "train_time": 0.701648473739624, "student_train_time": 0.009244203567504883, "throughput": 1762.257071730933, "inference_time": 0.05248465549686898, "env_time": 0.371188497426715, "samples": 2000, "teacher_eval_reward": 107.4}
{"epoch": 66, "reward_mean": 24.4875, "student_loss": null, "teacher_policy_loss": -13.77278995513916, "teacher_value_loss": 64.68938446044922, "teacher_entropy": 0.6612879633903503, "total_time": 1.198836326599121, "rollout_time": 0.425900936126709, "train_time": 0.763049840927124, "student_train_time": 0.00946664810180664, "throughput": 1668.2844485315468, "inference_time": 0.05460370999992392, "env_time": 0.37129722612678506, "samples": 2000, "teacher_eval_reward": 207.4}
{"epoch": 67, "reward_mean": 26.948051948051948, "student_loss": null, "teacher_policy_loss": -14.934243202209473, "teacher_value_loss": 86.84124755859375, "teacher_entropy": 0.6616293787956238, "total_time": -0.44855499267578125, "rollout_time": -1.1756703853607178, "train_time": 0.7202205657958984, "student_train_time": 0.006540775299072266, "throughput": 200000000000.0, "inference_time": 0.04968229824930859, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 268.1}
{"epoch": 68, "reward_mean": 26.52, "student_loss": null, "teacher_policy_loss": -14.541604995727539, "teacher_value_loss": 69.83688354492188, "teacher_entropy": 0.654063880443573, "total_time": 1.1443090438842773, "rollout_time": 0.4060051441192627, "train_time": 0.7331068515777588, "student_train_time": 0.0048520565032958984, "throughput": 1747.7795973814375, "inference_time": 0.05054746499490648, "env_time": 0.3554576791243562, "samples": 2000, "teacher_eval_reward": 70.0}
{"epoch": 69, "reward_mean": 29.060606060606062, "student_loss": null, "teacher_policy_loss": -15.538721084594727, "teacher_value_loss": 68.55026245117188, "teacher_entropy": 0.6415618658065796, "total_time": 1.1831815242767334, "rollout_time": 0.39884138107299805, "train_time": 0.7737960815429688, "student_train_time": 0.010144472122192383, "throughput": 1690.3576999502077, "inference_time": 0.05151304799460377, "env_time": 0.3473283330783943, "samples": 2000, "teacher_eval_reward": 67.2}
{"epoch": 70, "reward_mean": 29.3, "student_loss": null, "teacher_policy_loss": -16.18215560913086, "teacher_value_loss": 107.68499755859375, "teacher_entropy": 0.6298599243164062, "total_time": 1.2866556644439697, "rollout_time": 0.420351505279541, "train_time": 0.8561580181121826, "student_train_time": 0.009753704071044922, "throughput": 1554.417436823941, "inference_time": 0.052939876001119046, "env_time": 0.36741162927842197, "samples": 2000, "teacher_eval_reward": 134.5}
{"epoch": 71, "reward_mean": 29.10144927536232, "student_loss": null, "teacher_policy_loss": -16.99319076538086, "teacher_value_loss": 146.32923889160156, "teacher_entropy": 0.6296026110649109, "total_time": 1.236532211303711, "rollout_time": 0.4288210868835449, "train_time": 0.7991065979003906, "student_train_time": 0.008165597915649414, "throughput": 1617.4265269574687, "inference_time": 0.051613485248481084, "env_time": 0.37720760163506384, "samples": 2000, "teacher_eval_reward": 136.6}
{"epoch": 72, "reward_mean": 26.89041095890411, "student_loss": null, "teacher_policy_loss": -14.655598640441895, "teacher_value_loss": 83.50629425048828, "teacher_entropy": 0.6268576979637146, "total_time": 1.0985121726989746, "rollout_time": 0.4074363708496094, "train_time": 0.6799819469451904, "student_train_time": 0.010750770568847656, "throughput": 1820.6443676323831, "inference_time": 0.05076982825039522, "env_time": 0.35666654259921415, "samples": 2000, "teacher_eval_reward": 72.2}
{"epoch": 73, "reward_mean": 25.9875, "student_loss": null, "teacher_policy_loss": -13.07229995727539, "teacher_value_loss": 75.93589782714844, "teacher_entropy": 0.6128675937652588, "total_time": 1.177290916442871, "rollout_time": 0.40630531311035156, "train_time": 0.7384545803070068, "student_train_time": 0.03218245506286621, "throughput": 1698.815451700677, "inference_time": 0.05241706950153002, "env_time": 0.35388824360882154, "samples": 2000, "teacher_eval_reward": 68.9}
{"epoch": 74, "reward_mean": 26.794520547945204, "student_loss": null, "teacher_policy_loss": -14.640730857849121, "teacher_value_loss": 100.97075653076172, "teacher_entropy": 0.6160380840301514, "total_time": 1.2732594013214111, "rollout_time": 0.4326155185699463, "train_time": 0.8303689956665039, "student_train_time": 0.00980377197265625, "throughput": 1570.771830095552, "inference_time": 0.05548711425183228, "env_time": 0.377128404318114, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 75, "reward_mean": 28.083333333333332, "student_loss": null, "teacher_policy_loss": -14.760200500488281, "teacher_value_loss": 68.29082489013672, "teacher_entropy": 0.6229747533798218, "total_time": 1.2515556812286377, "rollout_time": 0.41552138328552246, "train_time": 0.8290431499481201, "student_train_time": 0.006592988967895508, "throughput": 1598.011203174455, "inference_time": 0.05218041875036761, "env_time": 0.36334096453515485, "samples": 2000, "teacher_eval_reward": 95.8}
{"epoch": 76, "reward_mean": 29.515151515151516, "student_loss": null, "teacher_policy_loss": -17.421384811401367, "teacher_value_loss": 131.00531005859375, "teacher_entropy": 0.6310775279998779, "total_time": 1.3781867027282715, "rollout_time": 0.40683722496032715, "train_time": 0.9616923332214355, "student_train_time": 0.009309768676757812, "throughput": 1451.1821918182645, "inference_time": 0.05284915850086236, "env_time": 0.3539880664594648, "samples": 2000, "teacher_eval_reward": 51.3}
{"epoch": 77, "reward_mean": 29.134328358208954, "student_loss": null, "teacher_policy_loss": -16.770816802978516, "teacher_value_loss": 142.42904663085938, "teacher_entropy": 0.6198651194572449, "total_time": 1.236368179321289, "rollout_time": 0.4080545902252197, "train_time": 0.8193433284759521, "student_train_time": 0.008611440658569336, "throughput": 1617.6411148804482, "inference_time": 0.05101460824869264, "env_time": 0.3570399819765271, "samples": 2000, "teacher_eval_reward": 39.9}
{"epoch": 78, "reward_mean": 31.757575757575758, "student_loss": null, "teacher_policy_loss": -16.93138313293457, "teacher_value_loss": 157.38023376464844, "teacher_entropy": 0.618722140789032, "total_time": 1.2612192630767822, "rollout_time": 0.42635560035705566, "train_time": 0.8227741718292236, "student_train_time": 0.011736869812011719, "throughput": 1585.7670894757348, "inference_time": 0.053399028001081206, "env_time": 0.37295657235597446, "samples": 2000, "teacher_eval_reward": 49.3}
{"epoch": 79, "reward_mean": 28.281690140845072, "student_loss": null, "teacher_policy_loss": -15.400278091430664, "teacher_value_loss": 90.92754364013672, "teacher_entropy": 0.6220952868461609, "total_time": -0.4797635078430176, "rollout_time": -1.2526819705963135, "train_time": 0.7638256549835205, "student_train_time": 0.008739709854125977, "throughput": 200000000000.0, "inference_time": 0.0534008467499234, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 126.8}
{"epoch": 80, "reward_mean": 27.16216216216216, "student_loss": null, "teacher_policy_loss": -14.82116985321045, "teacher_value_loss": 71.31669616699219, "teacher_entropy": 0.641265332698822, "total_time": 1.2619233131408691, "rollout_time": 0.4130258560180664, "train_time": 0.8412539958953857, "student_train_time": 0.007293224334716797, "throughput": 1584.882361054169, "inference_time": 0.05245770175076814, "env_time": 0.36056815426729827, "samples": 2000, "teacher_eval_reward": 40.7}
{"epoch": 81, "reward_mean": 29.28358208955224, "student_loss": null, "teacher_policy_loss": -15.953896522521973, "teacher_value_loss": 100.95012664794922, "teacher_entropy": 0.6365841031074524, "total_time": 1.2387537956237793, "rollout_time": 0.4041769504547119, "train_time": 0.8048520088195801, "student_train_time": 0.029375553131103516, "throughput": 1614.5258299635661, "inference_time": 0.05163617650248398, "env_time": 0.35254077395222794, "samples": 2000, "teacher_eval_reward": 71.5}
{"epoch": 82, "reward_mean": 26.746666666666666, "student_loss": null, "teacher_policy_loss": -14.93429946899414, "teacher_value_loss": 83.429931640625, "teacher_entropy": 0.6475674510002136, "total_time": 1.283637523651123, "rollout_time": 0.4771597385406494, "train_time": 0.7756409645080566, "student_train_time": 0.03046584129333496, "throughput": 1558.0722463700552, "inference_time": 0.06315658899870868, "env_time": 0.41400314954194073, "samples": 2000, "teacher_eval_reward": 125.5}
{"epoch": 83, "reward_mean": 31.41269841269841, "student_loss": null, "teacher_policy_loss": -17.847034454345703, "teacher_value_loss": 162.66567993164062, "teacher_entropy": 0.6542760133743286, "total_time": 1.1915936470031738, "rollout_time": 0.42372679710388184, "train_time": 0.7573316097259521, "student_train_time": 0.010118961334228516, "throughput": 1678.424524190731, "inference_time": 0.05411042700325197, "env_time": 0.36961637010062987, "samples": 2000, "teacher_eval_reward": 53.8}
{"epoch": 84, "reward_mean": 32.11290322580645, "student_loss": null, "teacher_policy_loss": -17.53453254699707, "teacher_value_loss": 113.75422668457031, "teacher_entropy": 0.6515941023826599, "total_time": 1.3847935199737549, "rollout_time": 0.46602487564086914, "train_time": 0.9011077880859375, "student_train_time": 0.017296791076660156, "throughput": 1444.258635784131, "inference_time": 0.06142122499750258, "env_time": 0.40460365064336656, "samples": 2000, "teacher_eval_reward": 39.8}
{"epoch": 85, "reward_mean": 29.971014492753625, "student_loss": null, "teacher_policy_loss": -15.680234909057617, "teacher_value_loss": 92.78167724609375, "teacher_entropy": 0.6377190351486206, "total_time": 1.164597988128662, "rollout_time": 0.40538978576660156, "train_time": 0.7481276988983154, "student_train_time": 0.0107269287109375, "throughput": 1717.3308046098432, "inference_time": 0.051962579751375415, "env_time": 0.35342720601522615, "samples": 2000, "teacher_eval_reward": 156.6}
{"epoch": 86, "reward_mean": 28.014285714285716, "student_loss": null, "teacher_policy_loss": -15.541647911071777, "teacher_value_loss": 81.52857208251953, "teacher_entropy": 0.6584274172782898, "total_time": 1.3044013977050781, "rollout_time": 0.41527771949768066, "train_time": 0.8532125949859619, "student_train_time": 0.03555774688720703, "throughput": 1533.2703595064645, "inference_time": 0.05233373775070049, "env_time": 0.36294398174698017, "samples": 2000, "teacher_eval_reward": 32.9}
{"epoch": 87, "reward_mean": 30.1875, "student_loss": null, "teacher_policy_loss": -17.61586570739746, "teacher_value_loss": 151.75730895996094, "teacher_entropy": 0.6370046138763428, "total_time": 1.164780855178833, "rollout_time": 0.4080023765563965, "train_time": 0.7473864555358887, "student_train_time": 0.008927583694458008, "throughput": 1717.061188898862, "inference_time": 0.05052807900085554, "env_time": 0.35747429755554094, "samples": 2000, "teacher_eval_reward": 35.0}
{"epoch": 88, "reward_mean": 33.096774193548384, "student_loss": null, "teacher_policy_loss": -16.721954345703125, "teacher_value_loss": 102.22726440429688, "teacher_entropy": 0.6433703899383545, "total_time": 1.1853587627410889, "rollout_time": 0.42343640327453613, "train_time": 0.7493958473205566, "student_train_time": 0.012116670608520508, "throughput": 1687.2528915845612, "inference_time": 0.05498887225053295, "env_time": 0.3684475310240032, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 89, "reward_mean": 33.31666666666667, "student_loss": null, "teacher_policy_loss": -18.838220596313477, "teacher_value_loss": 165.8406982421875, "teacher_entropy": 0.6486485004425049, "total_time": 1.2270607948303223, "rollout_time": 0.4093291759490967, "train_time": 0.8043134212493896, "student_train_time": 0.013019084930419922, "throughput": 1629.9110919573952, "inference_time": 0.051320551001026615, "env_time": 0.35800862494807006, "samples": 2000, "teacher_eval_reward": 27.3}
{"epoch": 90, "reward_mean": 28.985714285714284, "student_loss": null, "teacher_policy_loss": -14.070588111877441, "teacher_value_loss": 85.5380859375, "teacher_entropy": 0.6118633151054382, "total_time": 1.2279713153839111, "rollout_time": 0.41011524200439453, "train_time": 0.8101322650909424, "student_train_time": 0.00731348991394043, "throughput": 1628.7025396637405, "inference_time": 0.05226094025101702, "env_time": 0.3578543017533775, "samples": 2000, "teacher_eval_reward": 22.4}
{"epoch": 91, "reward_mean": 30.593220338983052, "student_loss": null, "teacher_policy_loss": -18.545738220214844, "teacher_value_loss": 237.45223999023438, "teacher_entropy": 0.5830580592155457, "total_time": 1.1886556148529053, "rollout_time": 0.42957448959350586, "train_time": 0.7538151741027832, "student_train_time": 0.004805088043212891, "throughput": 1682.5731313669835, "inference_time": 0.054009995995784266, "env_time": 0.3755644935977216, "samples": 2000, "teacher_eval_reward": 37.5}
{"epoch": 92, "reward_mean": 34.453125, "student_loss": null, "teacher_policy_loss": -16.372861862182617, "teacher_value_loss": 111.68306732177734, "teacher_entropy": 0.609913170337677, "total_time": 1.232750415802002, "rollout_time": 0.41974639892578125, "train_time": 0.8015720844268799, "student_train_time": 0.011076927185058594, "throughput": 1622.3884205294235, "inference_time": 0.054327083246903385, "env_time": 0.36541931567887787, "samples": 2000, "teacher_eval_reward": 152.4}
{"epoch": 93, "reward_mean": 30.12121212121212, "student_loss": null, "teacher_policy_loss": -15.29318904876709, "teacher_value_loss": 80.94033813476562, "teacher_entropy": 0.6383978128433228, "total_time": 1.2487609386444092, "rollout_time": 0.4048893451690674, "train_time": 0.8361692428588867, "student_train_time": 0.007364034652709961, "throughput": 1601.5875722146607, "inference_time": 0.05119778450330159, "env_time": 0.3536915606657658, "samples": 2000, "teacher_eval_reward": 28.9}
{"epoch": 94, "reward_mean": 30.6875, "student_loss": null, "teacher_policy_loss": -15.512179374694824, "teacher_value_loss": 96.84351348876953, "teacher_entropy": 0.5906723737716675, "total_time": 1.1578545570373535, "rollout_time": 0.41382884979248047, "train_time": 0.7310729026794434, "student_train_time": 0.012612104415893555, "throughput": 1727.3326669953055, "inference_time": 0.05196488799947474, "env_time": 0.36186396179300573, "samples": 2000, "teacher_eval_reward": 28.8}
{"epoch": 95, "reward_mean": 32.36842105263158, "student_loss": null, "teacher_policy_loss": -17.418102264404297, "teacher_value_loss": 150.07318115234375, "teacher_entropy": 0.5933586955070496, "total_time": 1.1942884922027588, "rollout_time": 0.42977023124694824, "train_time": 0.759307861328125, "student_train_time": 0.0048024654388427734, "throughput": 1674.637253107227, "inference_time": 0.054039852254504694, "env_time": 0.37573037899244355, "samples": 2000, "teacher_eval_reward": 44.9}
{"epoch": 96, "reward_mean": 31.347826086956523, "student_loss": null, "teacher_policy_loss": -15.181431770324707, "teacher_value_loss": 86.43611145019531, "teacher_entropy": 0.6088787317276001, "total_time": 1.1403441429138184, "rollout_time": 0.4166250228881836, "train_time": 0.7109487056732178, "student_train_time": 0.012360095977783203, "throughput": 1753.856511148977, "inference_time": 0.050841378000200166, "env_time": 0.36578364488798343, "samples": 2000, "teacher_eval_reward": 64.5}
{"epoch": 97, "reward_mean": 30.074626865671643, "student_loss": null, "teacher_policy_loss": -15.987414360046387, "teacher_value_loss": 83.16893005371094, "teacher_entropy": 0.6140261888504028, "total_time": 1.1587622165679932, "rollout_time": 0.41015148162841797, "train_time": 0.7364354133605957, "student_train_time": 0.011835098266601562, "throughput": 1725.9796456977808, "inference_time": 0.051753803250676356, "env_time": 0.3583976783777416, "samples": 2000, "teacher_eval_reward": 39.2}
{"epoch": 98, "reward_mean": 36.924528301886795, "student_loss": null, "teacher_policy_loss": -19.79340934753418, "teacher_value_loss": 194.1316680908203, "teacher_entropy": 0.6046532988548279, "total_time": 1.1810481548309326, "rollout_time": 0.4135580062866211, "train_time": 0.7601418495178223, "student_train_time": 0.007006645202636719, "throughput": 1693.4110534098422, "inference_time": 0.05299267000270902, "env_time": 0.3605653362839121, "samples": 2000, "teacher_eval_reward": 33.1}
{"epoch": 99, "reward_mean": 30.742424242424242, "student_loss": null, "teacher_policy_loss": -15.236686706542969, "teacher_value_loss": 106.19403076171875, "teacher_entropy": 0.5886111855506897, "total_time": 1.1824913024902344, "rollout_time": 0.45531344413757324, "train_time": 0.7142596244812012, "student_train_time": 0.012546539306640625, "throughput": 1691.3443640457704, "inference_time": 0.05663457975094843, "env_time": 0.3986788643866248, "samples": 2000, "teacher_eval_reward": 64.3}
{"epoch": 100, "reward_mean": 33.46666666666667, "student_loss": null, "teacher_policy_loss": -18.53089141845703, "teacher_value_loss": 118.0339126586914, "teacher_entropy": 0.6213718056678772, "total_time": 1.13545560836792, "rollout_time": 0.401975154876709, "train_time": 0.7266607284545898, "student_train_time": 0.006469011306762695, "throughput": 1761.4074784260022, "inference_time": 0.05277150725135016, "env_time": 0.3492036476253588, "samples": 2000, "teacher_eval_reward": 49.2}
{"epoch": 101, "reward_mean": 31.984375, "student_loss": null, "teacher_policy_loss": -16.046239852905273, "teacher_value_loss": 109.67028045654297, "teacher_entropy": 0.613340437412262, "total_time": 1.1252732276916504, "rollout_time": 0.4030184745788574, "train_time": 0.7120757102966309, "student_train_time": 0.009835958480834961, "throughput": 1777.3461153987785, "inference_time": 0.048800243504274476, "env_time": 0.35421823107458295, "samples": 2000, "teacher_eval_reward": 23.4}
{"epoch": 102, "reward_mean": 32.43333333333333, "student_loss": null, "teacher_policy_loss": -17.200149536132812, "teacher_value_loss": 161.17196655273438, "teacher_entropy": 0.5726104974746704, "total_time": 1.1968975067138672, "rollout_time": 0.4074287414550781, "train_time": 0.7813794612884521, "student_train_time": 0.006665945053100586, "throughput": 1670.9868545812956, "inference_time": 0.05314189525074653, "env_time": 0.3542868462043316, "samples": 2000, "teacher_eval_reward": 30.1}
{"epoch": 103, "reward_mean": 34.3, "student_loss": null, "teacher_policy_loss": -16.850467681884766, "teacher_value_loss": 125.3661117553711, "teacher_entropy": 0.5785551071166992, "total_time": 1.2682230472564697, "rollout_time": 0.43930625915527344, "train_time": 0.823176383972168, "student_train_time": 0.005344390869140625, "throughput": 1577.0096627139633, "inference_time": 0.052606105995550934, "env_time": 0.3867001531597225, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 104, "reward_mean": 33.50847457627118, "student_loss": null, "teacher_policy_loss": -18.47151756286621, "teacher_value_loss": 147.82174682617188, "teacher_entropy": 0.6259751319885254, "total_time": 1.3676435947418213, "rollout_time": 0.40688061714172363, "train_time": 0.9470441341400146, "student_train_time": 0.013365983963012695, "throughput": 1462.369295399327, "inference_time": 0.05125571325140754, "env_time": 0.3556249038903161, "samples": 2000, "teacher_eval_reward": 69.8}
{"epoch": 105, "reward_mean": 29.432835820895523, "student_loss": null, "teacher_policy_loss": -16.020734786987305, "teacher_value_loss": 109.88052368164062, "teacher_entropy": 0.605991780757904, "total_time": 1.2266931533813477, "rollout_time": 0.4305262565612793, "train_time": 0.787118673324585, "student_train_time": 0.008708477020263672, "throughput": 1630.3995783192008, "inference_time": 0.05544933424926057, "env_time": 0.3750769223120187, "samples": 2000, "teacher_eval_reward": 66.3}
{"epoch": 106, "reward_mean": 30.646153846153847, "student_loss": null, "teacher_policy_loss": -15.833290100097656, "teacher_value_loss": 104.75196838378906, "teacher_entropy": 0.5991206169128418, "total_time": 1.1307027339935303, "rollout_time": 0.39507079124450684, "train_time": 0.7245347499847412, "student_train_time": 0.010721683502197266, "throughput": 1768.811500911648, "inference_time": 0.05012851800120188, "env_time": 0.34494227324330495, "samples": 2000, "teacher_eval_reward": 102.8}
{"epoch": 107, "reward_mean": 35.56363636363636, "student_loss": null, "teacher_policy_loss": -19.292757034301758, "teacher_value_loss": 150.43783569335938, "teacher_entropy": 0.6222066879272461, "total_time": 1.2372422218322754, "rollout_time": 0.42853832244873047, "train_time": 0.7975451946258545, "student_train_time": 0.010801553726196289, "throughput": 1616.4983418025695, "inference_time": 0.054052036751158994, "env_time": 0.3744862856975715, "samples": 2000, "teacher_eval_reward": 262.0}
{"epoch": 108, "reward_mean": 36.45614035087719, "student_loss": null, "teacher_policy_loss": -18.54568099975586, "teacher_value_loss": 112.14557647705078, "teacher_entropy": 0.6254297494888306, "total_time": 1.4250781536102295, "rollout_time": 0.40355491638183594, "train_time": 1.013582468032837, "student_train_time": 0.0075893402099609375, "throughput": 1403.4318012196659, "inference_time": 0.052162077002321894, "env_time": 0.35139283937951404, "samples": 2000, "teacher_eval_reward": 139.7}
{"epoch": 109, "reward_mean": 32.68852459016394, "student_loss": null, "teacher_policy_loss": -17.740543365478516, "teacher_value_loss": 115.28012084960938, "teacher_entropy": 0.6156695485115051, "total_time": -0.38764357566833496, "rollout_time": 0.44582509994506836, "train_time": -0.848701000213623, "student_train_time": 0.014858007431030273, "throughput": 200000000000.0, "inference_time": 0.053159238498778905, "env_time": 0.39266586144628945, "samples": 2000, "teacher_eval_reward": 232.1}
{"epoch": 110, "reward_mean": 36.94117647058823, "student_loss": null, "teacher_policy_loss": -21.503969192504883, "teacher_value_loss": 183.23451232910156, "teacher_entropy": 0.6252577900886536, "total_time": 1.1976025104522705, "rollout_time": 0.40543627738952637, "train_time": 0.7748522758483887, "student_train_time": 0.016965866088867188, "throughput": 1670.003179305884, "inference_time": 0.05102613524911703, "env_time": 0.35441014214040933, "samples": 2000, "teacher_eval_reward": 204.3}
{"epoch": 111, "reward_mean": 37.875, "student_loss": null, "teacher_policy_loss": -18.793865203857422, "teacher_value_loss": 146.89930725097656, "teacher_entropy": 0.624742329120636, "total_time": 1.2527103424072266, "rollout_time": 0.40374183654785156, "train_time": 0.842721700668335, "student_train_time": 0.005839347839355469, "throughput": 1596.5382677026284, "inference_time": 0.0525492989987697, "env_time": 0.35119253754908186, "samples": 2000, "teacher_eval_reward": 257.8}
{"epoch": 112, "reward_mean": 34.625, "student_loss": null, "teacher_policy_loss": -17.77064323425293, "teacher_value_loss": 140.1973876953125, "teacher_entropy": 0.6175615191459656, "total_time": -0.48611927032470703, "rollout_time": -1.2672717571258545, "train_time": 0.7716464996337891, "student_train_time": 0.009141683578491211, "throughput": 200000000000.0, "inference_time": 0.050764707752591676, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 152.2}
{"epoch": 113, "reward_mean": 35.5, "student_loss": null, "teacher_policy_loss": -17.975366592407227, "teacher_value_loss": 166.30279541015625, "teacher_entropy": 0.6201586723327637, "total_time": 1.1398100852966309, "rollout_time": 0.4142906665802002, "train_time": 0.7178924083709717, "student_train_time": 0.007269144058227539, "throughput": 1754.6782800044346, "inference_time": 0.05170934850150388, "env_time": 0.3625813180786963, "samples": 2000, "teacher_eval_reward": 117.8}
{"epoch": 114, "reward_mean": 40.326530612244895, "student_loss": null, "teacher_policy_loss": -20.27528953552246, "teacher_value_loss": 141.29364013671875, "teacher_entropy": 0.6205106377601624, "total_time": 1.186403512954712, "rollout_time": 0.40973806381225586, "train_time": 0.7706770896911621, "student_train_time": 0.005630970001220703, "throughput": 1685.767092023391, "inference_time": 0.05280006475027221, "env_time": 0.35693799906198365, "samples": 2000, "teacher_eval_reward": 106.9}
{"epoch": 115, "reward_mean": 34.310344827586206, "student_loss": null, "teacher_policy_loss": -18.86788558959961, "teacher_value_loss": 148.79042053222656, "teacher_entropy": 0.6104477643966675, "total_time": 1.272904396057129, "rollout_time": 0.4184119701385498, "train_time": 0.8374655246734619, "student_train_time": 0.016651153564453125, "throughput": 1571.209908768544, "inference_time": 0.05496807725182862, "env_time": 0.3634438928867212, "samples": 2000, "teacher_eval_reward": 102.6}
{"epoch": 116, "reward_mean": 35.10526315789474, "student_loss": null, "teacher_policy_loss": -18.984439849853516, "teacher_value_loss": 139.88783264160156, "teacher_entropy": 0.6049863696098328, "total_time": 1.3706748485565186, "rollout_time": 0.4073338508605957, "train_time": 0.9578065872192383, "student_train_time": 0.005175352096557617, "throughput": 1459.1352588881562, "inference_time": 0.05101495724727556, "env_time": 0.35631889361332014, "samples": 2000, "teacher_eval_reward": 204.5}
{"epoch": 117, "reward_mean": 39.11764705882353, "student_loss": null, "teacher_policy_loss": -20.24167823791504, "teacher_value_loss": 142.35215759277344, "teacher_entropy": 0.6154751181602478, "total_time": 1.3424489498138428, "rollout_time": 0.4124150276184082, "train_time": 0.924354076385498, "student_train_time": 0.005273342132568359, "throughput": 1489.8145663396285, "inference_time": 0.05159916949946819, "env_time": 0.36081585811894, "samples": 2000, "teacher_eval_reward": 74.7}
{"epoch": 118, "reward_mean": 34.932203389830505, "student_loss": null, "teacher_policy_loss": -17.747953414916992, "teacher_value_loss": 118.8547592163086, "teacher_entropy": 0.5987424850463867, "total_time": 1.2825391292572021, "rollout_time": 0.4154951572418213, "train_time": 0.8387584686279297, "student_train_time": 0.02793264389038086, "throughput": 1559.4066133158244, "inference_time": 0.05363589625108034, "env_time": 0.36185926099074095, "samples": 2000, "teacher_eval_reward": 53.2}
{"epoch": 119, "reward_mean": 34.30357142857143, "student_loss": null, "teacher_policy_loss": -18.534988403320312, "teacher_value_loss": 162.66453552246094, "teacher_entropy": 0.5823569297790527, "total_time": 1.3537266254425049, "rollout_time": 0.4317035675048828, "train_time": 0.9153194427490234, "student_train_time": 0.006315469741821289, "throughput": 1477.4031642808545, "inference_time": 0.05335654225007147, "env_time": 0.37834702525481134, "samples": 2000, "teacher_eval_reward": 48.9}
{"epoch": 120, "reward_mean": 44.391304347826086, "student_loss": null, "teacher_policy_loss": -22.134218215942383, "teacher_value_loss": 240.14564514160156, "teacher_entropy": 0.5933824777603149, "total_time": 1.206007719039917, "rollout_time": 0.41255712509155273, "train_time": 0.7828090190887451, "student_train_time": 0.010233640670776367, "throughput": 1658.3641782924633, "inference_time": 0.05253982799968071, "env_time": 0.360017297091872, "samples": 2000, "teacher_eval_reward": 52.7}
