{"epoch": 1, "reward_mean": 20.4020618556701, "student_loss": null, "teacher_policy_loss": -9.567138671875, "teacher_value_loss": 215.43345642089844, "teacher_entropy": 0.4952771067619324, "total_time": 1.5540618896484375, "rollout_time": 0.43193674087524414, "train_time": 1.0245742797851562, "student_train_time": 0.09716367721557617, "throughput": 1286.950032892476, "inference_time": 0.054408682499229144, "env_time": 0.377528058376015, "samples": 2000, "teacher_eval_reward": 23.0}
{"epoch": 2, "reward_mean": 20.94736842105263, "student_loss": null, "teacher_policy_loss": -12.914548873901367, "teacher_value_loss": 149.24781799316406, "teacher_entropy": 0.6785946488380432, "total_time": 1.2521286010742188, "rollout_time": 0.4377765655517578, "train_time": 0.7953934669494629, "student_train_time": 0.01856541633605957, "throughput": 1597.2800224227542, "inference_time": 0.05526793250123774, "env_time": 0.3825086330505201, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 3, "reward_mean": 19.12621359223301, "student_loss": null, "teacher_policy_loss": -10.368339538574219, "teacher_value_loss": 151.5111846923828, "teacher_entropy": 0.5373576879501343, "total_time": 1.170250415802002, "rollout_time": 0.41933465003967285, "train_time": 0.7374475002288818, "student_train_time": 0.01311635971069336, "throughput": 1709.035923417596, "inference_time": 0.05251833949932916, "env_time": 0.3668163105403437, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 4, "reward_mean": 19.23076923076923, "student_loss": null, "teacher_policy_loss": -10.74559497833252, "teacher_value_loss": 121.04454803466797, "teacher_entropy": 0.6891853213310242, "total_time": 1.243833065032959, "rollout_time": 0.4356985092163086, "train_time": 0.7970414161682129, "student_train_time": 0.010642528533935547, "throughput": 1607.9328136746421, "inference_time": 0.0545766489971129, "env_time": 0.3811218602191957, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 5, "reward_mean": 20.635416666666668, "student_loss": null, "teacher_policy_loss": -10.796152114868164, "teacher_value_loss": 88.76885986328125, "teacher_entropy": 0.6563234925270081, "total_time": 1.184645414352417, "rollout_time": 0.4326024055480957, "train_time": 0.7386176586151123, "student_train_time": 0.013000011444091797, "throughput": 1688.268891070071, "inference_time": 0.055477340748893766, "env_time": 0.37712506479920194, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 6, "reward_mean": 20.616161616161616, "student_loss": null, "teacher_policy_loss": -11.086459159851074, "teacher_value_loss": 70.3372802734375, "teacher_entropy": 0.6532490253448486, "total_time": 1.284803867340088, "rollout_time": 0.43045663833618164, "train_time": 0.8476674556732178, "student_train_time": 0.006284236907958984, "throughput": 1556.657829914984, "inference_time": 0.05267950899906282, "env_time": 0.3777771293371188, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 7, "reward_mean": 22.122222222222224, "student_loss": null, "teacher_policy_loss": -13.195090293884277, "teacher_value_loss": 182.85887145996094, "teacher_entropy": 0.6187275052070618, "total_time": 1.200239658355713, "rollout_time": 0.4550151824951172, "train_time": 0.7384505271911621, "student_train_time": 0.006413698196411133, "throughput": 1666.3338743030133, "inference_time": 0.05803111374984837, "env_time": 0.3969840687452688, "samples": 2000, "teacher_eval_reward": 53.0}
{"epoch": 8, "reward_mean": 20.21, "student_loss": null, "teacher_policy_loss": -11.95112419128418, "teacher_value_loss": 91.255126953125, "teacher_entropy": 0.6914992928504944, "total_time": 1.1845929622650146, "rollout_time": 0.42676472663879395, "train_time": 0.7477498054504395, "student_train_time": 0.00967264175415039, "throughput": 1688.3436452094709, "inference_time": 0.05187018449976222, "env_time": 0.37489454213903173, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 9, "reward_mean": 20.91304347826087, "student_loss": null, "teacher_policy_loss": -12.357346534729004, "teacher_value_loss": 107.23361206054688, "teacher_entropy": 0.6602333188056946, "total_time": 1.2540102005004883, "rollout_time": 0.4199340343475342, "train_time": 0.7927465438842773, "student_train_time": 0.04095816612243652, "throughput": 1594.8833583664468, "inference_time": 0.05189605499856498, "env_time": 0.3680379793489692, "samples": 2000, "teacher_eval_reward": 30.0}
{"epoch": 10, "reward_mean": 19.22222222222222, "student_loss": null, "teacher_policy_loss": -10.224361419677734, "teacher_value_loss": 41.489219665527344, "teacher_entropy": 0.6809036135673523, "total_time": 1.3100559711456299, "rollout_time": 0.4293806552886963, "train_time": 0.8692495822906494, "student_train_time": 0.010934591293334961, "throughput": 1526.6523294046906, "inference_time": 0.05482376325005589, "env_time": 0.3745568920386404, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 11, "reward_mean": 21.456521739130434, "student_loss": null, "teacher_policy_loss": -12.033720970153809, "teacher_value_loss": 83.07685852050781, "teacher_entropy": 0.6164290904998779, "total_time": 1.3263957500457764, "rollout_time": 0.43675708770751953, "train_time": 0.8683133125305176, "student_train_time": 0.020840883255004883, "throughput": 1507.845603343479, "inference_time": 0.054611600001521765, "env_time": 0.38214548770599777, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 12, "reward_mean": 21.408602150537636, "student_loss": null, "teacher_policy_loss": -11.802078247070312, "teacher_value_loss": 62.2262077331543, "teacher_entropy": 0.6229650974273682, "total_time": 1.1618237495422363, "rollout_time": 0.41863417625427246, "train_time": 0.7167682647705078, "student_train_time": 0.02599310874938965, "throughput": 1721.4315000773645, "inference_time": 0.052046778752469436, "env_time": 0.366587397501803, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 13, "reward_mean": 23.50602409638554, "student_loss": null, "teacher_policy_loss": -13.599234580993652, "teacher_value_loss": 89.71436309814453, "teacher_entropy": 0.6703110337257385, "total_time": 1.2596323490142822, "rollout_time": 0.42344188690185547, "train_time": 0.8248460292816162, "student_train_time": 0.010994434356689453, "throughput": 1587.7648756520805, "inference_time": 0.054489869749886566, "env_time": 0.3689520171519689, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 14, "reward_mean": 21.819148936170212, "student_loss": null, "teacher_policy_loss": -11.962757110595703, "teacher_value_loss": 62.913475036621094, "teacher_entropy": 0.6744912266731262, "total_time": 1.1725120544433594, "rollout_time": 0.42214179039001465, "train_time": 0.7424256801605225, "student_train_time": 0.00752711296081543, "throughput": 1705.739392973221, "inference_time": 0.05321412849889384, "env_time": 0.3689276618911208, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 15, "reward_mean": 21.53191489361702, "student_loss": null, "teacher_policy_loss": -12.553055763244629, "teacher_value_loss": 74.1763687133789, "teacher_entropy": 0.6734631061553955, "total_time": 1.176527738571167, "rollout_time": 0.4149210453033447, "train_time": 0.7513260841369629, "student_train_time": 0.009925127029418945, "throughput": 1699.917421776131, "inference_time": 0.05271783050113754, "env_time": 0.3622032148022072, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 16, "reward_mean": 20.78125, "student_loss": null, "teacher_policy_loss": -11.251168251037598, "teacher_value_loss": 46.07514953613281, "teacher_entropy": 0.630983829498291, "total_time": 1.3292572498321533, "rollout_time": 0.4541046619415283, "train_time": 0.8639316558837891, "student_train_time": 0.010794401168823242, "throughput": 1504.5996553733614, "inference_time": 0.05583331649779666, "env_time": 0.39827134544373166, "samples": 2000, "teacher_eval_reward": 13.0}
{"epoch": 17, "reward_mean": 21.29787234042553, "student_loss": null, "teacher_policy_loss": -12.653740882873535, "teacher_value_loss": 72.9571533203125, "teacher_entropy": 0.6854821443557739, "total_time": 1.1196420192718506, "rollout_time": 0.42177629470825195, "train_time": 0.6911559104919434, "student_train_time": 0.006340980529785156, "throughput": 1786.2852282917022, "inference_time": 0.05267177849850668, "env_time": 0.36910451620974527, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 18, "reward_mean": 22.790697674418606, "student_loss": null, "teacher_policy_loss": -11.7684326171875, "teacher_value_loss": 86.81487274169922, "teacher_entropy": 0.6099956035614014, "total_time": 1.2321534156799316, "rollout_time": 0.4152219295501709, "train_time": 0.8070695400238037, "student_train_time": 0.00951528549194336, "throughput": 1623.1744964131371, "inference_time": 0.053448558502054766, "env_time": 0.36177337104811613, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 19, "reward_mean": 22.420454545454547, "student_loss": null, "teacher_policy_loss": -11.20948600769043, "teacher_value_loss": 79.71190643310547, "teacher_entropy": 0.5737959146499634, "total_time": 1.2629570960998535, "rollout_time": 0.4469790458679199, "train_time": 0.8033010959625244, "student_train_time": 0.012320995330810547, "throughput": 1583.5850688643452, "inference_time": 0.05307615575145519, "env_time": 0.39390289011646473, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 20, "reward_mean": 22.9010989010989, "student_loss": null, "teacher_policy_loss": -11.523868560791016, "teacher_value_loss": 59.617942810058594, "teacher_entropy": 0.6253699064254761, "total_time": 1.2838661670684814, "rollout_time": 0.4193418025970459, "train_time": 0.8582649230957031, "student_train_time": 0.0058858394622802734, "throughput": 1557.7947696578876, "inference_time": 0.05146459624995714, "env_time": 0.36787720634708876, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 21, "reward_mean": 21.630434782608695, "student_loss": null, "teacher_policy_loss": -11.859894752502441, "teacher_value_loss": 49.776676177978516, "teacher_entropy": 0.6703367233276367, "total_time": 1.280742883682251, "rollout_time": 0.44344234466552734, "train_time": 0.8300271034240723, "student_train_time": 0.006914615631103516, "throughput": 1561.5936855724078, "inference_time": 0.055674559000863155, "env_time": 0.3877677856646642, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 22, "reward_mean": 22.850574712643677, "student_loss": null, "teacher_policy_loss": -11.76294994354248, "teacher_value_loss": 81.05723571777344, "teacher_entropy": 0.5699905157089233, "total_time": 1.2040367126464844, "rollout_time": 0.423734188079834, "train_time": 0.7739148139953613, "student_train_time": 0.00591588020324707, "throughput": 1661.078918103735, "inference_time": 0.056075093002277754, "env_time": 0.36765909507755623, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 23, "reward_mean": 23.8, "student_loss": null, "teacher_policy_loss": -12.880248069763184, "teacher_value_loss": 132.11875915527344, "teacher_entropy": 0.5635080337524414, "total_time": 1.31707763671875, "rollout_time": 0.4145979881286621, "train_time": 0.8757445812225342, "student_train_time": 0.026324748992919922, "throughput": 1518.5133694795866, "inference_time": 0.05291940724782762, "env_time": 0.3616785808808345, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 24, "reward_mean": 20.70967741935484, "student_loss": null, "teacher_policy_loss": -12.43315315246582, "teacher_value_loss": 67.75562286376953, "teacher_entropy": 0.6658205986022949, "total_time": 1.165609359741211, "rollout_time": 0.41701745986938477, "train_time": 0.7363207340240479, "student_train_time": 0.011927604675292969, "throughput": 1715.840717377253, "inference_time": 0.05122057724452134, "env_time": 0.36579688262486343, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 25, "reward_mean": 22.22826086956522, "student_loss": null, "teacher_policy_loss": -11.918811798095703, "teacher_value_loss": 76.29602813720703, "teacher_entropy": 0.614780604839325, "total_time": 1.2225754261016846, "rollout_time": 0.413593053817749, "train_time": 0.7981669902801514, "student_train_time": 0.010462760925292969, "throughput": 1635.8908884478553, "inference_time": 0.05431621124967023, "env_time": 0.3592768425680788, "samples": 2000, "teacher_eval_reward": 17.0}
{"epoch": 26, "reward_mean": 23.046511627906977, "student_loss": null, "teacher_policy_loss": -12.175063133239746, "teacher_value_loss": 66.24862670898438, "teacher_entropy": 0.6251529455184937, "total_time": 1.1672487258911133, "rollout_time": 0.42368102073669434, "train_time": 0.7291238307952881, "student_train_time": 0.014100313186645508, "throughput": 1713.4308700771028, "inference_time": 0.05474928474666285, "env_time": 0.3689317359900315, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 27, "reward_mean": 23.48235294117647, "student_loss": null, "teacher_policy_loss": -13.5149564743042, "teacher_value_loss": 70.41452026367188, "teacher_entropy": 0.6575952768325806, "total_time": 1.1239275932312012, "rollout_time": 0.4060039520263672, "train_time": 0.7111141681671143, "student_train_time": 0.006422519683837891, "throughput": 1779.4740622482284, "inference_time": 0.05196525224710058, "env_time": 0.3540386997792666, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 28, "reward_mean": 24.51219512195122, "student_loss": null, "teacher_policy_loss": -13.172295570373535, "teacher_value_loss": 71.12804412841797, "teacher_entropy": 0.629116952419281, "total_time": 1.2799975872039795, "rollout_time": 0.4383230209350586, "train_time": 0.8319230079650879, "student_train_time": 0.00934147834777832, "throughput": 1562.5029453131942, "inference_time": 0.05680590724591639, "env_time": 0.3815171136891422, "samples": 2000, "teacher_eval_reward": 39.0}
{"epoch": 29, "reward_mean": 23.337209302325583, "student_loss": null, "teacher_policy_loss": -12.884049415588379, "teacher_value_loss": 52.62840270996094, "teacher_entropy": 0.6594231128692627, "total_time": 1.1893482208251953, "rollout_time": 0.4269704818725586, "train_time": 0.752669095993042, "student_train_time": 0.009356498718261719, "throughput": 1681.593300414875, "inference_time": 0.05263524050212709, "env_time": 0.3743352413704315, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 30, "reward_mean": 24.463414634146343, "student_loss": null, "teacher_policy_loss": -12.724175453186035, "teacher_value_loss": 77.72042846679688, "teacher_entropy": 0.6274684071540833, "total_time": 1.2577061653137207, "rollout_time": 0.41684627532958984, "train_time": 0.8325009346008301, "student_train_time": 0.008004903793334961, "throughput": 1590.1965460280005, "inference_time": 0.0531505454988519, "env_time": 0.36369572983073795, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 31, "reward_mean": 23.63855421686747, "student_loss": null, "teacher_policy_loss": -13.019848823547363, "teacher_value_loss": 103.20355987548828, "teacher_entropy": 0.6059807538986206, "total_time": 1.1723778247833252, "rollout_time": 0.41252732276916504, "train_time": 0.7512862682342529, "student_train_time": 0.008167743682861328, "throughput": 1705.9346890748577, "inference_time": 0.05383642625224638, "env_time": 0.35869089651691866, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 32, "reward_mean": 25.125, "student_loss": null, "teacher_policy_loss": -14.859667778015137, "teacher_value_loss": 117.52322387695312, "teacher_entropy": 0.6746787428855896, "total_time": 1.2103376388549805, "rollout_time": 0.423447847366333, "train_time": 0.7758688926696777, "student_train_time": 0.01061558723449707, "throughput": 1652.431466885609, "inference_time": 0.05226444375239225, "env_time": 0.37118340361394075, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 33, "reward_mean": 24.011764705882353, "student_loss": null, "teacher_policy_loss": -11.95064926147461, "teacher_value_loss": 66.92423248291016, "teacher_entropy": 0.5885391235351562, "total_time": 1.2479774951934814, "rollout_time": 0.44350099563598633, "train_time": 0.7833940982818604, "student_train_time": 0.020701169967651367, "throughput": 1602.5930016389661, "inference_time": 0.056443323000962664, "env_time": 0.38705767263502366, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 34, "reward_mean": 23.63095238095238, "student_loss": null, "teacher_policy_loss": -10.118386268615723, "teacher_value_loss": 61.76081848144531, "teacher_entropy": 0.4766765534877777, "total_time": 1.1509175300598145, "rollout_time": 0.4182400703430176, "train_time": 0.7259268760681152, "student_train_time": 0.006410121917724609, "throughput": 1737.7439718865503, "inference_time": 0.05292995849868021, "env_time": 0.36531011184433737, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 35, "reward_mean": 24.024390243902438, "student_loss": null, "teacher_policy_loss": -10.393317222595215, "teacher_value_loss": 67.0032958984375, "teacher_entropy": 0.4573120176792145, "total_time": 1.275843620300293, "rollout_time": 0.4165799617767334, "train_time": 0.8498477935791016, "student_train_time": 0.00907754898071289, "throughput": 1567.5902345534037, "inference_time": 0.054737031250738255, "env_time": 0.36184293052599514, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 36, "reward_mean": 25.873417721518987, "student_loss": null, "teacher_policy_loss": -13.192792892456055, "teacher_value_loss": 121.87802124023438, "teacher_entropy": 0.5742142200469971, "total_time": 1.1537065505981445, "rollout_time": 0.413759708404541, "train_time": 0.732459306716919, "student_train_time": 0.007105350494384766, "throughput": 1733.543073811179, "inference_time": 0.05351188699864906, "env_time": 0.36024782140589195, "samples": 2000, "teacher_eval_reward": 36.0}
{"epoch": 37, "reward_mean": 22.423529411764704, "student_loss": null, "teacher_policy_loss": -13.441973686218262, "teacher_value_loss": 76.51475524902344, "teacher_entropy": 0.6788060665130615, "total_time": 1.2006940841674805, "rollout_time": 0.41978025436401367, "train_time": 0.7736687660217285, "student_train_time": 0.006848573684692383, "throughput": 1665.703218140473, "inference_time": 0.053126665247759775, "env_time": 0.3666535891162539, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 38, "reward_mean": 23.894117647058824, "student_loss": null, "teacher_policy_loss": -12.743827819824219, "teacher_value_loss": 72.03101348876953, "teacher_entropy": 0.6418064832687378, "total_time": 1.2242405414581299, "rollout_time": 0.4316444396972656, "train_time": 0.7854247093200684, "student_train_time": 0.006824016571044922, "throughput": 1633.6658787805727, "inference_time": 0.05399751674951858, "env_time": 0.37764692294774704, "samples": 2000, "teacher_eval_reward": 12.0}
{"epoch": 39, "reward_mean": 25.6625, "student_loss": null, "teacher_policy_loss": -13.393550872802734, "teacher_value_loss": 99.17554473876953, "teacher_entropy": 0.6157914996147156, "total_time": 1.123396635055542, "rollout_time": 0.4142117500305176, "train_time": 0.7019519805908203, "student_train_time": 0.006875753402709961, "throughput": 1780.3151065172256, "inference_time": 0.052593864748132546, "env_time": 0.36161788528238503, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 40, "reward_mean": 22.930232558139537, "student_loss": null, "teacher_policy_loss": -13.627340316772461, "teacher_value_loss": 86.99921417236328, "teacher_entropy": 0.6540615558624268, "total_time": 1.458383321762085, "rollout_time": 0.42358970642089844, "train_time": 1.0246233940124512, "student_train_time": 0.009825944900512695, "throughput": 1371.3815635134315, "inference_time": 0.05272749974983526, "env_time": 0.3708622066710632, "samples": 2000, "teacher_eval_reward": 23.0}
{"epoch": 41, "reward_mean": 26.96, "student_loss": null, "teacher_policy_loss": -14.557745933532715, "teacher_value_loss": 94.39636993408203, "teacher_entropy": 0.6346094608306885, "total_time": 1.1916263103485107, "rollout_time": 0.41185760498046875, "train_time": 0.7719714641571045, "student_train_time": 0.00739288330078125, "throughput": 1678.3785173516915, "inference_time": 0.05310913850030374, "env_time": 0.358748466480165, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 42, "reward_mean": 22.698795180722893, "student_loss": null, "teacher_policy_loss": -11.763474464416504, "teacher_value_loss": 55.37992477416992, "teacher_entropy": 0.6054372787475586, "total_time": 1.2750599384307861, "rollout_time": 0.4153010845184326, "train_time": 0.847567081451416, "student_train_time": 0.01169276237487793, "throughput": 1568.5537124328416, "inference_time": 0.053153444498661884, "env_time": 0.36214764001977073, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 43, "reward_mean": 25.223529411764705, "student_loss": null, "teacher_policy_loss": -13.055217742919922, "teacher_value_loss": 78.55610656738281, "teacher_entropy": 0.610366940498352, "total_time": 1.1985957622528076, "rollout_time": 0.4057481288909912, "train_time": 0.7851953506469727, "student_train_time": 0.007268667221069336, "throughput": 1668.6192818176846, "inference_time": 0.051225326500343726, "env_time": 0.3545228023906475, "samples": 2000, "teacher_eval_reward": 329.0}
{"epoch": 44, "reward_mean": 26.86111111111111, "student_loss": null, "teacher_policy_loss": -16.671934127807617, "teacher_value_loss": 149.7553253173828, "teacher_entropy": 0.6568592190742493, "total_time": 1.1770985126495361, "rollout_time": 0.4333763122558594, "train_time": 0.7293987274169922, "student_train_time": 0.013959169387817383, "throughput": 1699.093133248628, "inference_time": 0.05364260950420885, "env_time": 0.3797337027516505, "samples": 2000, "teacher_eval_reward": 25.0}
{"epoch": 45, "reward_mean": 22.0, "student_loss": null, "teacher_policy_loss": -11.623165130615234, "teacher_value_loss": 62.95132827758789, "teacher_entropy": 0.6233242750167847, "total_time": 1.1490733623504639, "rollout_time": 0.40235090255737305, "train_time": 0.7346293926239014, "student_train_time": 0.011749029159545898, "throughput": 1740.5329072366105, "inference_time": 0.051767180499155074, "env_time": 0.350583722058218, "samples": 2000, "teacher_eval_reward": 26.0}
{"epoch": 46, "reward_mean": 28.304347826086957, "student_loss": null, "teacher_policy_loss": -15.492395401000977, "teacher_value_loss": 114.75357055664062, "teacher_entropy": 0.6174573302268982, "total_time": 1.329148530960083, "rollout_time": 0.42133378982543945, "train_time": 0.9004340171813965, "student_train_time": 0.006981849670410156, "throughput": 1504.7227254243296, "inference_time": 0.05241188974923716, "env_time": 0.3689219000762023, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 47, "reward_mean": 26.355263157894736, "student_loss": null, "teacher_policy_loss": -14.770098686218262, "teacher_value_loss": 99.02027893066406, "teacher_entropy": 0.6441541910171509, "total_time": -0.47830629348754883, "rollout_time": 0.4092240333557129, "train_time": -0.9075319766998291, "student_train_time": 0.019641876220703125, "throughput": 200000000000.0, "inference_time": 0.052929804999848784, "env_time": 0.3562942283558641, "samples": 2000, "teacher_eval_reward": 60.0}
{"epoch": 48, "reward_mean": 27.65753424657534, "student_loss": null, "teacher_policy_loss": -15.986414909362793, "teacher_value_loss": 105.87911224365234, "teacher_entropy": 0.6563359498977661, "total_time": 1.231024980545044, "rollout_time": 0.4019804000854492, "train_time": 0.8046596050262451, "student_train_time": 0.024002790451049805, "throughput": 1624.6624005261758, "inference_time": 0.050448305752411216, "env_time": 0.351532094333038, "samples": 2000, "teacher_eval_reward": 20.0}
{"epoch": 49, "reward_mean": 27.18918918918919, "student_loss": null, "teacher_policy_loss": -15.024229049682617, "teacher_value_loss": 86.60363006591797, "teacher_entropy": 0.654566764831543, "total_time": 1.205507755279541, "rollout_time": 0.42853236198425293, "train_time": 0.7698888778686523, "student_train_time": 0.006705522537231445, "throughput": 1659.051956522857, "inference_time": 0.05421981174845314, "env_time": 0.3743125502357998, "samples": 2000, "teacher_eval_reward": 29.0}
{"epoch": 50, "reward_mean": 24.641025641025642, "student_loss": null, "teacher_policy_loss": -14.205440521240234, "teacher_value_loss": 85.53807830810547, "teacher_entropy": 0.6577175855636597, "total_time": 1.1988613605499268, "rollout_time": 0.4267606735229492, "train_time": 0.7642760276794434, "student_train_time": 0.007475614547729492, "throughput": 1668.2496123509936, "inference_time": 0.05592947574666596, "env_time": 0.37083119777628326, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 51, "reward_mean": 24.91566265060241, "student_loss": null, "teacher_policy_loss": -13.78739070892334, "teacher_value_loss": 84.5833969116211, "teacher_entropy": 0.6741169691085815, "total_time": 1.2000627517700195, "rollout_time": 0.41994738578796387, "train_time": 0.771369218826294, "student_train_time": 0.008399248123168945, "throughput": 1666.5795159879112, "inference_time": 0.05517600950361157, "env_time": 0.3647713762843523, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 52, "reward_mean": 28.718309859154928, "student_loss": null, "teacher_policy_loss": -16.79796028137207, "teacher_value_loss": 156.85244750976562, "teacher_entropy": 0.6759447455406189, "total_time": 1.1991539001464844, "rollout_time": 0.4446442127227783, "train_time": 0.7437176704406738, "student_train_time": 0.010442018508911133, "throughput": 1667.8426345072864, "inference_time": 0.052925730747801936, "env_time": 0.3917184819749764, "samples": 2000, "teacher_eval_reward": 116.0}
{"epoch": 53, "reward_mean": 26.884057971014492, "student_loss": null, "teacher_policy_loss": -16.214670181274414, "teacher_value_loss": 114.22647094726562, "teacher_entropy": 0.6756412982940674, "total_time": 1.2237801551818848, "rollout_time": 0.4176366329193115, "train_time": 0.7990527153015137, "student_train_time": 0.00666356086730957, "throughput": 1634.2804641269488, "inference_time": 0.052347430000395434, "env_time": 0.3652892029189161, "samples": 2000, "teacher_eval_reward": 25.0}
{"epoch": 54, "reward_mean": 28.506849315068493, "student_loss": null, "teacher_policy_loss": -15.649863243103027, "teacher_value_loss": 118.7363052368164, "teacher_entropy": 0.6530206203460693, "total_time": 1.2199482917785645, "rollout_time": 0.4308321475982666, "train_time": 0.7588136196136475, "student_train_time": 0.029900789260864258, "throughput": 1639.4137468598747, "inference_time": 0.0548114269981852, "env_time": 0.3760207206000814, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 55, "reward_mean": 29.424242424242426, "student_loss": null, "teacher_policy_loss": -15.963018417358398, "teacher_value_loss": 83.99415588378906, "teacher_entropy": 0.6689890027046204, "total_time": 1.2192270755767822, "rollout_time": 0.40943241119384766, "train_time": 0.7999269962310791, "student_train_time": 0.009472846984863281, "throughput": 1640.3835184301956, "inference_time": 0.05381681424682938, "env_time": 0.3556155969470183, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 56, "reward_mean": 27.18421052631579, "student_loss": null, "teacher_policy_loss": -16.355043411254883, "teacher_value_loss": 167.39596557617188, "teacher_entropy": 0.6504817605018616, "total_time": 1.4934606552124023, "rollout_time": 0.554570198059082, "train_time": 0.9309759140014648, "student_train_time": 0.007546424865722656, "throughput": 1339.171536270272, "inference_time": 0.08528751275036939, "env_time": 0.46928268530871264, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 57, "reward_mean": 30.953846153846154, "student_loss": null, "teacher_policy_loss": -18.050334930419922, "teacher_value_loss": 131.85397338867188, "teacher_entropy": 0.6451212167739868, "total_time": 1.3730065822601318, "rollout_time": 0.4101724624633789, "train_time": 0.9500808715820312, "student_train_time": 0.012311458587646484, "throughput": 1456.657255573941, "inference_time": 0.05181891800327776, "env_time": 0.35835354446010115, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 58, "reward_mean": 26.894736842105264, "student_loss": null, "teacher_policy_loss": -15.393402099609375, "teacher_value_loss": 97.04676818847656, "teacher_entropy": 0.6300042271614075, "total_time": 1.1826086044311523, "rollout_time": 0.42420387268066406, "train_time": 0.7492763996124268, "student_train_time": 0.008788585662841797, "throughput": 1691.1766010378572, "inference_time": 0.05562764249850716, "env_time": 0.3685762301821569, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 59, "reward_mean": 26.36, "student_loss": null, "teacher_policy_loss": -15.87927532196045, "teacher_value_loss": 108.26847839355469, "teacher_entropy": 0.6232282519340515, "total_time": 1.369992971420288, "rollout_time": 0.5350852012634277, "train_time": 0.8210444450378418, "student_train_time": 0.013448476791381836, "throughput": 1459.861504199234, "inference_time": 0.08316296974805937, "env_time": 0.45192223151536837, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 60, "reward_mean": 23.523809523809526, "student_loss": null, "teacher_policy_loss": -12.55911922454834, "teacher_value_loss": 57.898014068603516, "teacher_entropy": 0.6095123291015625, "total_time": 1.4366631507873535, "rollout_time": 0.5459933280944824, "train_time": 0.8831608295440674, "student_train_time": 0.007102012634277344, "throughput": 1392.1147757593096, "inference_time": 0.05254203600122764, "env_time": 0.4934512920932548, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 61, "reward_mean": 30.439393939393938, "student_loss": null, "teacher_policy_loss": -17.26795196533203, "teacher_value_loss": 131.93865966796875, "teacher_entropy": 0.6206871271133423, "total_time": 1.3213789463043213, "rollout_time": 0.5075352191925049, "train_time": 0.8081998825073242, "student_train_time": 0.0052204132080078125, "throughput": 1513.5703543587324, "inference_time": 0.07995619049961533, "env_time": 0.42757902869288955, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 62, "reward_mean": 29.83076923076923, "student_loss": null, "teacher_policy_loss": -17.07106590270996, "teacher_value_loss": 136.98011779785156, "teacher_entropy": 0.6127316355705261, "total_time": 1.212559700012207, "rollout_time": 0.42388343811035156, "train_time": 0.7801394462585449, "student_train_time": 0.008182764053344727, "throughput": 1649.4033242073488, "inference_time": 0.053656266500297534, "env_time": 0.37022717161005403, "samples": 2000, "teacher_eval_reward": 195.0}
{"epoch": 63, "reward_mean": 28.541666666666668, "student_loss": null, "teacher_policy_loss": -15.475434303283691, "teacher_value_loss": 77.18060302734375, "teacher_entropy": 0.6183635592460632, "total_time": 1.2110188007354736, "rollout_time": 0.438892126083374, "train_time": 0.762035608291626, "student_train_time": 0.009726285934448242, "throughput": 1651.5020235733448, "inference_time": 0.05355895950060585, "env_time": 0.38533316658276817, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 64, "reward_mean": 28.183098591549296, "student_loss": null, "teacher_policy_loss": -15.065677642822266, "teacher_value_loss": 71.60578155517578, "teacher_entropy": 0.6287145614624023, "total_time": -0.46503376960754395, "rollout_time": 0.41336894035339355, "train_time": -0.8865389823913574, "student_train_time": 0.007727146148681641, "throughput": 200000000000.0, "inference_time": 0.05320086150413772, "env_time": 0.36016807884925583, "samples": 2000, "teacher_eval_reward": 210.0}
{"epoch": 65, "reward_mean": 28.414285714285715, "student_loss": null, "teacher_policy_loss": -15.819095611572266, "teacher_value_loss": 76.81221771240234, "teacher_entropy": 0.6406347751617432, "total_time": 1.1706037521362305, "rollout_time": 0.44444823265075684, "train_time": 0.7147495746612549, "student_train_time": 0.011054039001464844, "throughput": 1708.5200661199037, "inference_time": 0.05494020050286963, "env_time": 0.3895080321478872, "samples": 2000, "teacher_eval_reward": 96.0}
{"epoch": 66, "reward_mean": 29.0, "student_loss": null, "teacher_policy_loss": -16.44964599609375, "teacher_value_loss": 96.13947296142578, "teacher_entropy": 0.6470731496810913, "total_time": 1.2191452980041504, "rollout_time": 0.40688085556030273, "train_time": 0.8053014278411865, "student_train_time": 0.0065765380859375, "throughput": 1640.493551731839, "inference_time": 0.052092606000996966, "env_time": 0.35478824955930577, "samples": 2000, "teacher_eval_reward": 162.0}
{"epoch": 67, "reward_mean": 30.873015873015873, "student_loss": null, "teacher_policy_loss": -19.082544326782227, "teacher_value_loss": 246.40211486816406, "teacher_entropy": 0.6579509377479553, "total_time": 1.1317663192749023, "rollout_time": 0.4090135097503662, "train_time": 0.7132778167724609, "student_train_time": 0.009070396423339844, "throughput": 1767.1492479837673, "inference_time": 0.05170596074799505, "env_time": 0.35730754900237116, "samples": 2000, "teacher_eval_reward": 60.0}
{"epoch": 68, "reward_mean": 30.25, "student_loss": null, "teacher_policy_loss": -15.59046459197998, "teacher_value_loss": 71.59556579589844, "teacher_entropy": 0.6595847606658936, "total_time": 1.2039785385131836, "rollout_time": 0.40727663040161133, "train_time": 0.78609299659729, "student_train_time": 0.01026773452758789, "throughput": 1661.1591785264202, "inference_time": 0.050717312249162205, "env_time": 0.3565593181524491, "samples": 2000, "teacher_eval_reward": 71.0}
{"epoch": 69, "reward_mean": 30.402985074626866, "student_loss": null, "teacher_policy_loss": -15.959421157836914, "teacher_value_loss": 86.32050323486328, "teacher_entropy": 0.6566469073295593, "total_time": 1.1637346744537354, "rollout_time": 0.41916537284851074, "train_time": 0.7368359565734863, "student_train_time": 0.007383108139038086, "throughput": 1718.6048021975569, "inference_time": 0.05110096625026017, "env_time": 0.36806440659825057, "samples": 2000, "teacher_eval_reward": 259.0}
{"epoch": 70, "reward_mean": 31.125, "student_loss": null, "teacher_policy_loss": -17.267948150634766, "teacher_value_loss": 100.58940887451172, "teacher_entropy": 0.6687880158424377, "total_time": 1.258507251739502, "rollout_time": 0.42342114448547363, "train_time": 0.8297116756439209, "student_train_time": 0.00498509407043457, "throughput": 1589.1843270951445, "inference_time": 0.0546050552492261, "env_time": 0.36881608923624754, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 71, "reward_mean": 31.28125, "student_loss": null, "teacher_policy_loss": -18.255462646484375, "teacher_value_loss": 164.5834197998047, "teacher_entropy": 0.66004478931427, "total_time": 1.3396339416503906, "rollout_time": 0.4275641441345215, "train_time": 0.9032506942749023, "student_train_time": 0.00840902328491211, "throughput": 1492.9451530140072, "inference_time": 0.05280847450035253, "env_time": 0.37475566963416895, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 72, "reward_mean": 29.96969696969697, "student_loss": null, "teacher_policy_loss": -16.914382934570312, "teacher_value_loss": 99.12763214111328, "teacher_entropy": 0.6478696465492249, "total_time": 1.2113304138183594, "rollout_time": 0.43593931198120117, "train_time": 0.7638499736785889, "student_train_time": 0.011178255081176758, "throughput": 1651.0771769492635, "inference_time": 0.05566759474959326, "env_time": 0.3802717172316079, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 73, "reward_mean": 27.21917808219178, "student_loss": null, "teacher_policy_loss": -15.678983688354492, "teacher_value_loss": 90.1915283203125, "teacher_entropy": 0.6376988887786865, "total_time": 1.213815450668335, "rollout_time": 0.4253556728363037, "train_time": 0.7802562713623047, "student_train_time": 0.007856369018554688, "throughput": 1647.6969368768428, "inference_time": 0.05328404375165974, "env_time": 0.372071629084644, "samples": 2000, "teacher_eval_reward": 57.0}
{"epoch": 74, "reward_mean": 29.58823529411765, "student_loss": null, "teacher_policy_loss": -17.021350860595703, "teacher_value_loss": 111.30371856689453, "teacher_entropy": 0.6294878125190735, "total_time": 1.3965375423431396, "rollout_time": 0.4543135166168213, "train_time": 0.9054770469665527, "student_train_time": 0.03639101982116699, "throughput": 1432.1133083499915, "inference_time": 0.05699362400105201, "env_time": 0.3973198926157693, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 75, "reward_mean": 31.015384615384615, "student_loss": null, "teacher_policy_loss": -17.761642456054688, "teacher_value_loss": 117.47232818603516, "teacher_entropy": 0.6411343812942505, "total_time": 1.2354395389556885, "rollout_time": 0.41579365730285645, "train_time": 0.809654951095581, "student_train_time": 0.009643077850341797, "throughput": 1618.8570439396744, "inference_time": 0.0545252347483256, "env_time": 0.36126842255453084, "samples": 2000, "teacher_eval_reward": 201.0}
{"epoch": 76, "reward_mean": 29.144927536231883, "student_loss": null, "teacher_policy_loss": -15.978338241577148, "teacher_value_loss": 85.26824951171875, "teacher_entropy": 0.6280932426452637, "total_time": 1.2247040271759033, "rollout_time": 0.4343128204345703, "train_time": 0.7644016742706299, "student_train_time": 0.02561044692993164, "throughput": 1633.047622625921, "inference_time": 0.05507791850141075, "env_time": 0.37923490193315956, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 77, "reward_mean": 29.893939393939394, "student_loss": null, "teacher_policy_loss": -16.956504821777344, "teacher_value_loss": 120.59032440185547, "teacher_entropy": 0.6343866586685181, "total_time": 1.4658465385437012, "rollout_time": 0.41586923599243164, "train_time": 1.040956735610962, "student_train_time": 0.00868082046508789, "throughput": 1364.3993060739995, "inference_time": 0.051620374000322045, "env_time": 0.3642488619921096, "samples": 2000, "teacher_eval_reward": 59.0}
{"epoch": 78, "reward_mean": 32.03174603174603, "student_loss": null, "teacher_policy_loss": -17.463747024536133, "teacher_value_loss": 127.88520050048828, "teacher_entropy": 0.619288444519043, "total_time": 1.205862283706665, "rollout_time": 0.4169318675994873, "train_time": 0.7811717987060547, "student_train_time": 0.007144927978515625, "throughput": 1658.564188484491, "inference_time": 0.053873278503601796, "env_time": 0.3630585890958855, "samples": 2000, "teacher_eval_reward": 431.0}
{"epoch": 79, "reward_mean": 27.208333333333332, "student_loss": null, "teacher_policy_loss": -14.804997444152832, "teacher_value_loss": 70.90672302246094, "teacher_entropy": 0.6320513486862183, "total_time": 1.4183425903320312, "rollout_time": 0.4674394130706787, "train_time": 0.8780252933502197, "student_train_time": 0.07251715660095215, "throughput": 1410.0965546919126, "inference_time": 0.055718524752478515, "env_time": 0.4117208883182002, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 80, "reward_mean": 33.85, "student_loss": null, "teacher_policy_loss": -19.014362335205078, "teacher_value_loss": 140.5108184814453, "teacher_entropy": 0.6322559714317322, "total_time": 1.2833797931671143, "rollout_time": 0.44768762588500977, "train_time": 0.8192048072814941, "student_train_time": 0.01613330841064453, "throughput": 1558.3851410535428, "inference_time": 0.05503391200193164, "env_time": 0.3926537138830781, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 81, "reward_mean": 34.42372881355932, "student_loss": null, "teacher_policy_loss": -18.765525817871094, "teacher_value_loss": 119.98649597167969, "teacher_entropy": 0.6364948749542236, "total_time": 1.192124605178833, "rollout_time": 0.4212338924407959, "train_time": 0.7624590396881104, "student_train_time": 0.008026361465454102, "throughput": 1677.6769737924972, "inference_time": 0.05239416250196882, "env_time": 0.3688397299388271, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 82, "reward_mean": 33.86206896551724, "student_loss": null, "teacher_policy_loss": -17.738967895507812, "teacher_value_loss": 84.22064971923828, "teacher_entropy": 0.6441683173179626, "total_time": 1.267714262008667, "rollout_time": 0.4246397018432617, "train_time": 0.8314223289489746, "student_train_time": 0.011232614517211914, "throughput": 1577.6425807745047, "inference_time": 0.05138581600067482, "env_time": 0.3732538858425869, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 83, "reward_mean": 29.235294117647058, "student_loss": null, "teacher_policy_loss": -16.24671745300293, "teacher_value_loss": 104.58799743652344, "teacher_entropy": 0.6398294568061829, "total_time": 1.171520471572876, "rollout_time": 0.41306567192077637, "train_time": 0.7462646961212158, "student_train_time": 0.011841297149658203, "throughput": 1707.1831423609804, "inference_time": 0.05243805474685814, "env_time": 0.3606276171739182, "samples": 2000, "teacher_eval_reward": 51.0}
{"epoch": 84, "reward_mean": 34.50847457627118, "student_loss": null, "teacher_policy_loss": -18.0223445892334, "teacher_value_loss": 115.78731536865234, "teacher_entropy": 0.6467821002006531, "total_time": 1.2702689170837402, "rollout_time": 0.4259939193725586, "train_time": 0.8380627632141113, "student_train_time": 0.005765438079833984, "throughput": 1574.4697623488755, "inference_time": 0.052713767502723385, "env_time": 0.3732801518698352, "samples": 2000, "teacher_eval_reward": 150.0}
{"epoch": 85, "reward_mean": 29.140625, "student_loss": null, "teacher_policy_loss": -17.445316314697266, "teacher_value_loss": 111.28754425048828, "teacher_entropy": 0.648015558719635, "total_time": 1.2839369773864746, "rollout_time": 0.43569111824035645, "train_time": 0.8376286029815674, "student_train_time": 0.01017904281616211, "throughput": 1557.708855828042, "inference_time": 0.05504368925028302, "env_time": 0.3806474289900734, "samples": 2000, "teacher_eval_reward": 181.0}
{"epoch": 86, "reward_mean": 36.68421052631579, "student_loss": null, "teacher_policy_loss": -19.438295364379883, "teacher_value_loss": 154.9927520751953, "teacher_entropy": 0.6450923681259155, "total_time": 1.2150037288665771, "rollout_time": 0.4221153259277344, "train_time": 0.7683188915252686, "student_train_time": 0.024205446243286133, "throughput": 1646.0854831002955, "inference_time": 0.0526195479993703, "env_time": 0.3694957779283641, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 87, "reward_mean": 32.68333333333333, "student_loss": null, "teacher_policy_loss": -17.972558975219727, "teacher_value_loss": 117.84339141845703, "teacher_entropy": 0.6326169371604919, "total_time": 1.2477726936340332, "rollout_time": 0.4135143756866455, "train_time": 0.8072218894958496, "student_train_time": 0.02663588523864746, "throughput": 1602.8560411713836, "inference_time": 0.05244051700083219, "env_time": 0.3610738586858133, "samples": 2000, "teacher_eval_reward": 200.0}
{"epoch": 88, "reward_mean": 34.6271186440678, "student_loss": null, "teacher_policy_loss": -19.91379165649414, "teacher_value_loss": 211.00787353515625, "teacher_entropy": 0.6358587741851807, "total_time": 1.1684958934783936, "rollout_time": 0.427980899810791, "train_time": 0.7334709167480469, "student_train_time": 0.006457805633544922, "throughput": 1711.6020785031383, "inference_time": 0.053210992250001254, "env_time": 0.37476990756078976, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 89, "reward_mean": 34.57627118644068, "student_loss": null, "teacher_policy_loss": -17.817453384399414, "teacher_value_loss": 115.6377182006836, "teacher_entropy": 0.6165695786476135, "total_time": 1.1973450183868408, "rollout_time": 0.4100327491760254, "train_time": 0.7819924354553223, "student_train_time": 0.004971504211425781, "throughput": 1670.3623177006743, "inference_time": 0.051269606504433796, "env_time": 0.3587631426715916, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 90, "reward_mean": 34.49122807017544, "student_loss": null, "teacher_policy_loss": -18.605985641479492, "teacher_value_loss": 148.76646423339844, "teacher_entropy": 0.6004395484924316, "total_time": 1.2211401462554932, "rollout_time": 0.42307090759277344, "train_time": 0.7845604419708252, "student_train_time": 0.013159751892089844, "throughput": 1637.8136499179102, "inference_time": 0.053898781750376656, "env_time": 0.3691721258423968, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 91, "reward_mean": 29.057142857142857, "student_loss": null, "teacher_policy_loss": -14.833863258361816, "teacher_value_loss": 69.78234100341797, "teacher_entropy": 0.6141510009765625, "total_time": 1.2638261318206787, "rollout_time": 0.418015718460083, "train_time": 0.8402965068817139, "student_train_time": 0.0051691532135009766, "throughput": 1582.496159593395, "inference_time": 0.052234872999747495, "env_time": 0.3657808454603355, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 92, "reward_mean": 33.69491525423729, "student_loss": null, "teacher_policy_loss": -19.32567596435547, "teacher_value_loss": 165.46104431152344, "teacher_entropy": 0.6148883104324341, "total_time": 1.2248477935791016, "rollout_time": 0.4280111789703369, "train_time": 0.7881100177764893, "student_train_time": 0.00837254524230957, "throughput": 1632.8559438033053, "inference_time": 0.05451999999763757, "env_time": 0.37349117897269934, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 93, "reward_mean": 36.94444444444444, "student_loss": null, "teacher_policy_loss": -19.93110466003418, "teacher_value_loss": 179.0211181640625, "teacher_entropy": 0.6120566129684448, "total_time": 1.292529821395874, "rollout_time": 0.40839457511901855, "train_time": 0.8590214252471924, "student_train_time": 0.02470684051513672, "throughput": 1547.3530799003847, "inference_time": 0.052582242498147025, "env_time": 0.35581233262087153, "samples": 2000, "teacher_eval_reward": 59.0}
{"epoch": 94, "reward_mean": 33.3, "student_loss": null, "teacher_policy_loss": -17.8973445892334, "teacher_value_loss": 130.6515350341797, "teacher_entropy": 0.6108582615852356, "total_time": 1.2015857696533203, "rollout_time": 0.4088449478149414, "train_time": 0.7804563045501709, "student_train_time": 0.011927604675292969, "throughput": 1664.4671154661203, "inference_time": 0.05175923975332353, "env_time": 0.3570857080616179, "samples": 2000, "teacher_eval_reward": 244.0}
{"epoch": 95, "reward_mean": 41.93617021276596, "student_loss": null, "teacher_policy_loss": -21.192218780517578, "teacher_value_loss": 134.9360809326172, "teacher_entropy": 0.6229647397994995, "total_time": 1.280365228652954, "rollout_time": 0.4495525360107422, "train_time": 0.820713996887207, "student_train_time": 0.009744882583618164, "throughput": 1562.0542914182063, "inference_time": 0.05686477274923618, "env_time": 0.392687763261506, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 96, "reward_mean": 32.583333333333336, "student_loss": null, "teacher_policy_loss": -18.13812828063965, "teacher_value_loss": 119.5296401977539, "teacher_entropy": 0.6097185015678406, "total_time": 1.240920066833496, "rollout_time": 0.4271111488342285, "train_time": 0.8014907836914062, "student_train_time": 0.011890888214111328, "throughput": 1611.7073560616016, "inference_time": 0.05532739049965585, "env_time": 0.37178375833457267, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 97, "reward_mean": 37.833333333333336, "student_loss": null, "teacher_policy_loss": -20.273542404174805, "teacher_value_loss": 144.35276794433594, "teacher_entropy": 0.6105338335037231, "total_time": 1.276986837387085, "rollout_time": 0.43125271797180176, "train_time": 0.8343920707702637, "student_train_time": 0.010990619659423828, "throughput": 1566.1868559994816, "inference_time": 0.05571646575174327, "env_time": 0.3755362522200585, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 98, "reward_mean": 31.634920634920636, "student_loss": null, "teacher_policy_loss": -16.12587547302246, "teacher_value_loss": 100.89730834960938, "teacher_entropy": 0.6178706884384155, "total_time": 1.2109107971191406, "rollout_time": 0.42339468002319336, "train_time": 0.7798521518707275, "student_train_time": 0.0072820186614990234, "throughput": 1651.6493244243668, "inference_time": 0.05236141074806255, "env_time": 0.3710332692751308, "samples": 2000, "teacher_eval_reward": 59.0}
{"epoch": 99, "reward_mean": 38.80769230769231, "student_loss": null, "teacher_policy_loss": -20.558656692504883, "teacher_value_loss": 132.92147827148438, "teacher_entropy": 0.6129672527313232, "total_time": 1.205531120300293, "rollout_time": 0.41341495513916016, "train_time": 0.7818088531494141, "student_train_time": 0.009951114654541016, "throughput": 1659.0198015807407, "inference_time": 0.05389350250152347, "env_time": 0.3595214526376367, "samples": 2000, "teacher_eval_reward": 465.0}
{"epoch": 100, "reward_mean": 35.36842105263158, "student_loss": null, "teacher_policy_loss": -18.249053955078125, "teacher_value_loss": 108.87359619140625, "teacher_entropy": 0.616563618183136, "total_time": -0.3568754196166992, "rollout_time": -1.154905080795288, "train_time": 0.7853446006774902, "student_train_time": 0.012264013290405273, "throughput": 200000000000.0, "inference_time": 0.05367367250255484, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 389.0}
{"epoch": 101, "reward_mean": 38.113207547169814, "student_loss": null, "teacher_policy_loss": -20.04749870300293, "teacher_value_loss": 137.7775421142578, "teacher_entropy": 0.6265824437141418, "total_time": 1.4414012432098389, "rollout_time": 0.4272124767303467, "train_time": 1.0057246685028076, "student_train_time": 0.008040189743041992, "throughput": 1387.5386950175125, "inference_time": 0.053833717248835455, "env_time": 0.3733787594815112, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 102, "reward_mean": 37.9, "student_loss": null, "teacher_policy_loss": -20.571317672729492, "teacher_value_loss": 160.34768676757812, "teacher_entropy": 0.617595911026001, "total_time": 1.2308464050292969, "rollout_time": 0.4181544780731201, "train_time": 0.7821028232574463, "student_train_time": 0.030240535736083984, "throughput": 1624.8981122485347, "inference_time": 0.055660339001292414, "env_time": 0.3624941390718277, "samples": 2000, "teacher_eval_reward": 78.0}
{"epoch": 103, "reward_mean": 34.91525423728814, "student_loss": null, "teacher_policy_loss": -17.77042579650879, "teacher_value_loss": 106.81370544433594, "teacher_entropy": 0.6170086860656738, "total_time": 1.2821109294891357, "rollout_time": 0.42487549781799316, "train_time": 0.8463211059570312, "student_train_time": 0.010540008544921875, "throughput": 1559.9274243742007, "inference_time": 0.05308683425334948, "env_time": 0.3717886635646437, "samples": 2000, "teacher_eval_reward": 258.0}
{"epoch": 104, "reward_mean": 35.293103448275865, "student_loss": null, "teacher_policy_loss": -17.891273498535156, "teacher_value_loss": 82.41034698486328, "teacher_entropy": 0.6232756972312927, "total_time": 1.2633311748504639, "rollout_time": 0.41995763778686523, "train_time": 0.8374311923980713, "student_train_time": 0.005590915679931641, "throughput": 1583.1161613159218, "inference_time": 0.05347482500053502, "env_time": 0.3664828127863302, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 105, "reward_mean": 38.01960784313726, "student_loss": null, "teacher_policy_loss": -21.680992126464844, "teacher_value_loss": 168.53353881835938, "teacher_entropy": 0.6234019994735718, "total_time": 1.2648096084594727, "rollout_time": 0.4329042434692383, "train_time": 0.815849781036377, "student_train_time": 0.015708208084106445, "throughput": 1581.2656597667558, "inference_time": 0.05511344075148372, "env_time": 0.37779080271775456, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 106, "reward_mean": 38.96078431372549, "student_loss": null, "teacher_policy_loss": -21.655488967895508, "teacher_value_loss": 200.10816955566406, "teacher_entropy": 0.6071010828018188, "total_time": 1.2349848747253418, "rollout_time": 0.41194677352905273, "train_time": 0.810643196105957, "student_train_time": 0.012037992477416992, "throughput": 1619.4530321230015, "inference_time": 0.05291204474838196, "env_time": 0.3590347287806708, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 107, "reward_mean": 36.78181818181818, "student_loss": null, "teacher_policy_loss": -18.451183319091797, "teacher_value_loss": 163.8236846923828, "teacher_entropy": 0.6232492923736572, "total_time": 1.1967756748199463, "rollout_time": 0.4151885509490967, "train_time": 0.7602591514587402, "student_train_time": 0.02098393440246582, "throughput": 1671.1569612249164, "inference_time": 0.05376376824960971, "env_time": 0.36142478269948697, "samples": 2000, "teacher_eval_reward": 39.0}
{"epoch": 108, "reward_mean": 36.57142857142857, "student_loss": null, "teacher_policy_loss": -19.720230102539062, "teacher_value_loss": 166.17739868164062, "teacher_entropy": 0.6090521216392517, "total_time": 1.2215533256530762, "rollout_time": 0.4158749580383301, "train_time": 0.7987000942230225, "student_train_time": 0.00603175163269043, "throughput": 1637.2596742190888, "inference_time": 0.054890057499619616, "env_time": 0.36098490053871046, "samples": 2000, "teacher_eval_reward": 35.0}
{"epoch": 109, "reward_mean": 36.53703703703704, "student_loss": null, "teacher_policy_loss": -19.558284759521484, "teacher_value_loss": 167.4273681640625, "teacher_entropy": 0.5813760757446289, "total_time": 1.276273250579834, "rollout_time": 0.4245645999908447, "train_time": 0.8437216281890869, "student_train_time": 0.0075719356536865234, "throughput": 1567.062538599288, "inference_time": 0.05482552624960135, "env_time": 0.3697390737412434, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 110, "reward_mean": 33.8, "student_loss": null, "teacher_policy_loss": -17.290874481201172, "teacher_value_loss": 124.83924102783203, "teacher_entropy": 0.5939950942993164, "total_time": 1.2313880920410156, "rollout_time": 0.41436195373535156, "train_time": 0.8110959529876709, "student_train_time": 0.005587577819824219, "throughput": 1624.1833203738527, "inference_time": 0.05207976699932715, "env_time": 0.3622821867360244, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 111, "reward_mean": 39.125, "student_loss": null, "teacher_policy_loss": -20.85573387145996, "teacher_value_loss": 133.65992736816406, "teacher_entropy": 0.6227630972862244, "total_time": 1.2071187496185303, "rollout_time": 0.43012213706970215, "train_time": 0.7648136615753174, "student_train_time": 0.011826276779174805, "throughput": 1656.837821988958, "inference_time": 0.0568302899991977, "env_time": 0.37329184707050445, "samples": 2000, "teacher_eval_reward": 294.0}
{"epoch": 112, "reward_mean": 34.16393442622951, "student_loss": null, "teacher_policy_loss": -16.694034576416016, "teacher_value_loss": 90.56613159179688, "teacher_entropy": 0.6079543828964233, "total_time": 1.261007308959961, "rollout_time": 0.4352853298187256, "train_time": 0.8178958892822266, "student_train_time": 0.007474660873413086, "throughput": 1586.0336302487706, "inference_time": 0.059297412252021786, "env_time": 0.3759879175667038, "samples": 2000, "teacher_eval_reward": 357.0}
{"epoch": 113, "reward_mean": 38.17307692307692, "student_loss": null, "teacher_policy_loss": -21.683353424072266, "teacher_value_loss": 206.26217651367188, "teacher_entropy": 0.609287440776825, "total_time": 1.300710916519165, "rollout_time": 0.41313886642456055, "train_time": 0.8774020671844482, "student_train_time": 0.009829521179199219, "throughput": 1537.6206769696405, "inference_time": 0.05260855499591344, "env_time": 0.3605303114286471, "samples": 2000, "teacher_eval_reward": 224.0}
{"epoch": 114, "reward_mean": 38.9375, "student_loss": null, "teacher_policy_loss": -23.02981185913086, "teacher_value_loss": 212.5428009033203, "teacher_entropy": 0.6073194742202759, "total_time": 1.1941442489624023, "rollout_time": 0.42508840560913086, "train_time": 0.763873815536499, "student_train_time": 0.004828691482543945, "throughput": 1674.839536126234, "inference_time": 0.05525994900119713, "env_time": 0.36982845660793373, "samples": 2000, "teacher_eval_reward": 416.0}
{"epoch": 115, "reward_mean": 39.833333333333336, "student_loss": null, "teacher_policy_loss": -20.269397735595703, "teacher_value_loss": 158.8657989501953, "teacher_entropy": 0.5971805453300476, "total_time": 1.2221870422363281, "rollout_time": 0.42147183418273926, "train_time": 0.7897846698760986, "student_train_time": 0.01047658920288086, "throughput": 1636.41073819638, "inference_time": 0.05233096600352383, "env_time": 0.36914086817921543, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 116, "reward_mean": 40.95918367346939, "student_loss": null, "teacher_policy_loss": -20.68234634399414, "teacher_value_loss": 123.60596466064453, "teacher_entropy": 0.6038346290588379, "total_time": 0.3150768280029297, "rollout_time": 0.43595242500305176, "train_time": -0.13566303253173828, "student_train_time": 0.014440774917602539, "throughput": 6347.6581653964195, "inference_time": 0.054666342248197, "env_time": 0.38128608275485476, "samples": 2000, "teacher_eval_reward": 180.0}
{"epoch": 117, "reward_mean": 37.925925925925924, "student_loss": null, "teacher_policy_loss": -19.217878341674805, "teacher_value_loss": 105.3088150024414, "teacher_entropy": 0.5981459021568298, "total_time": 2.328270435333252, "rollout_time": 0.4398219585418701, "train_time": 1.551330804824829, "student_train_time": 0.33676815032958984, "throughput": 859.0067415058398, "inference_time": 0.05941061650071333, "env_time": 0.3804113420411568, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 118, "reward_mean": 42.6, "student_loss": null, "teacher_policy_loss": -21.628999710083008, "teacher_value_loss": 126.326171875, "teacher_entropy": 0.5990266799926758, "total_time": 1.7289156913757324, "rollout_time": 0.4433414936065674, "train_time": 0.9000627994537354, "student_train_time": 0.38515162467956543, "throughput": 1156.7944058675066, "inference_time": 0.054765808751540135, "env_time": 0.38857568485502725, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 119, "reward_mean": 37.51923076923077, "student_loss": null, "teacher_policy_loss": -22.134239196777344, "teacher_value_loss": 205.63760375976562, "teacher_entropy": 0.5736251473426819, "total_time": 1.2473137378692627, "rollout_time": 0.41727685928344727, "train_time": 0.8169910907745361, "student_train_time": 0.012566566467285156, "throughput": 1603.4458206293164, "inference_time": 0.05264860649754155, "env_time": 0.3646282527859057, "samples": 2000, "teacher_eval_reward": 206.0}
{"epoch": 120, "reward_mean": 40.20754716981132, "student_loss": null, "teacher_policy_loss": -20.498193740844727, "teacher_value_loss": 135.50538635253906, "teacher_entropy": 0.572663426399231, "total_time": 1.2909438610076904, "rollout_time": 0.4348747730255127, "train_time": 0.8393313884735107, "student_train_time": 0.01638627052307129, "throughput": 1549.2540461355395, "inference_time": 0.054735696501438724, "env_time": 0.38013907652407397, "samples": 2000, "teacher_eval_reward": 327.0}
{"epoch": 121, "reward_mean": 35.29824561403509, "student_loss": null, "teacher_policy_loss": -18.766321182250977, "teacher_value_loss": 117.39329528808594, "teacher_entropy": 0.5776643753051758, "total_time": 1.2582709789276123, "rollout_time": 0.42909884452819824, "train_time": 0.8150196075439453, "student_train_time": 0.013434648513793945, "throughput": 1589.4827374184072, "inference_time": 0.05571003050363288, "env_time": 0.37338881402456536, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 122, "reward_mean": 41.255319148936174, "student_loss": null, "teacher_policy_loss": -23.157285690307617, "teacher_value_loss": 293.6884765625, "teacher_entropy": 0.5717553496360779, "total_time": 1.2331104278564453, "rollout_time": 0.4203968048095703, "train_time": 0.8055548667907715, "student_train_time": 0.0068089962005615234, "throughput": 1621.9147570397754, "inference_time": 0.052330593499846145, "env_time": 0.36806621130972417, "samples": 2000, "teacher_eval_reward": 99.0}
{"epoch": 123, "reward_mean": 40.72, "student_loss": null, "teacher_policy_loss": -19.97117042541504, "teacher_value_loss": 121.566650390625, "teacher_entropy": 0.5712614059448242, "total_time": 1.230405330657959, "rollout_time": 0.42506957054138184, "train_time": 0.7978556156158447, "student_train_time": 0.0071370601654052734, "throughput": 1625.4806039652806, "inference_time": 0.05388288100118643, "env_time": 0.3711866895401954, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 124, "reward_mean": 43.644444444444446, "student_loss": null, "teacher_policy_loss": -24.531230926513672, "teacher_value_loss": 278.5509338378906, "teacher_entropy": 0.5695582032203674, "total_time": 1.2809805870056152, "rollout_time": 0.4200093746185303, "train_time": 0.8488762378692627, "student_train_time": 0.01175546646118164, "throughput": 1561.3039106823194, "inference_time": 0.0562681957554787, "env_time": 0.3637411788630516, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 125, "reward_mean": 38.72549019607843, "student_loss": null, "teacher_policy_loss": -20.289987564086914, "teacher_value_loss": 147.55459594726562, "teacher_entropy": 0.5433657765388489, "total_time": 1.2340097427368164, "rollout_time": 0.4238858222961426, "train_time": 0.8008923530578613, "student_train_time": 0.008877038955688477, "throughput": 1620.7327468617484, "inference_time": 0.05387706025032912, "env_time": 0.37000876204581346, "samples": 2000, "teacher_eval_reward": 47.0}
{"epoch": 126, "reward_mean": 39.16326530612245, "student_loss": null, "teacher_policy_loss": -20.79311752319336, "teacher_value_loss": 173.75881958007812, "teacher_entropy": 0.5609751343727112, "total_time": 1.2011120319366455, "rollout_time": 0.41335606575012207, "train_time": 0.7818481922149658, "student_train_time": 0.0055408477783203125, "throughput": 1665.1236078080458, "inference_time": 0.05306263249872245, "env_time": 0.3602934332513996, "samples": 2000, "teacher_eval_reward": 130.0}
{"epoch": 127, "reward_mean": 43.714285714285715, "student_loss": null, "teacher_policy_loss": -20.662887573242188, "teacher_value_loss": 121.5671615600586, "teacher_entropy": 0.5721464157104492, "total_time": 1.2072288990020752, "rollout_time": 0.43161511421203613, "train_time": 0.7657530307769775, "student_train_time": 0.009513616561889648, "throughput": 1656.686649609903, "inference_time": 0.0548855557482284, "env_time": 0.37672955846380773, "samples": 2000, "teacher_eval_reward": 106.0}
{"epoch": 128, "reward_mean": 43.74418604651163, "student_loss": null, "teacher_policy_loss": -22.4066219329834, "teacher_value_loss": 135.896484375, "teacher_entropy": 0.5672397017478943, "total_time": 1.2362492084503174, "rollout_time": 0.4096338748931885, "train_time": 0.7998752593994141, "student_train_time": 0.02633213996887207, "throughput": 1617.7967891336987, "inference_time": 0.053010256999755256, "env_time": 0.3566236178934332, "samples": 2000, "teacher_eval_reward": 104.0}
{"epoch": 129, "reward_mean": 40.568627450980394, "student_loss": null, "teacher_policy_loss": -21.16865348815918, "teacher_value_loss": 173.71426391601562, "teacher_entropy": 0.5699465870857239, "total_time": 1.2180614471435547, "rollout_time": 0.4266965389251709, "train_time": 0.780411958694458, "student_train_time": 0.010524749755859375, "throughput": 1641.9532895406467, "inference_time": 0.054740864000564216, "env_time": 0.3719556749246067, "samples": 2000, "teacher_eval_reward": 401.0}
{"epoch": 130, "reward_mean": 44.91111111111111, "student_loss": null, "teacher_policy_loss": -21.300039291381836, "teacher_value_loss": 110.09832763671875, "teacher_entropy": 0.5910698175430298, "total_time": 1.2244763374328613, "rollout_time": 0.4245944023132324, "train_time": 0.7912671566009521, "student_train_time": 0.008263826370239258, "throughput": 1633.3512856549269, "inference_time": 0.053704938500686694, "env_time": 0.3708894638125457, "samples": 2000, "teacher_eval_reward": 59.0}
{"epoch": 131, "reward_mean": 41.53061224489796, "student_loss": null, "teacher_policy_loss": -20.268768310546875, "teacher_value_loss": 113.51204681396484, "teacher_entropy": 0.5846903920173645, "total_time": 1.2605631351470947, "rollout_time": 0.41137099266052246, "train_time": 0.8416562080383301, "student_train_time": 0.007174253463745117, "throughput": 1586.5924873065724, "inference_time": 0.0524083882502282, "env_time": 0.35896260441029426, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 132, "reward_mean": 47.02439024390244, "student_loss": null, "teacher_policy_loss": -22.8027286529541, "teacher_value_loss": 162.9985809326172, "teacher_entropy": 0.5961330533027649, "total_time": -0.44529247283935547, "rollout_time": 0.4241781234741211, "train_time": -0.8762896060943604, "student_train_time": 0.0064640045166015625, "throughput": 200000000000.0, "inference_time": 0.052523294251841435, "env_time": 0.37165482922227966, "samples": 2000, "teacher_eval_reward": 364.0}
{"epoch": 133, "reward_mean": 40.11764705882353, "student_loss": null, "teacher_policy_loss": -19.90386962890625, "teacher_value_loss": 111.55677795410156, "teacher_entropy": 0.597602903842926, "total_time": 1.2883236408233643, "rollout_time": 0.44837522506713867, "train_time": 0.8270306587219238, "student_train_time": 0.012571573257446289, "throughput": 1552.4049521607826, "inference_time": 0.059836550750787865, "env_time": 0.3885386743163508, "samples": 2000, "teacher_eval_reward": 242.0}
{"epoch": 134, "reward_mean": 55.65714285714286, "student_loss": null, "teacher_policy_loss": -26.904115676879883, "teacher_value_loss": 240.63058471679688, "teacher_entropy": 0.6103290915489197, "total_time": 1.2502689361572266, "rollout_time": 0.3975100517272949, "train_time": 0.841681957244873, "student_train_time": 0.01071786880493164, "throughput": 1599.6558357653155, "inference_time": 0.05200590075071432, "env_time": 0.3455041509765806, "samples": 2000, "teacher_eval_reward": 469.0}
{"epoch": 135, "reward_mean": 44.77777777777778, "student_loss": null, "teacher_policy_loss": -22.12192153930664, "teacher_value_loss": 167.2484130859375, "teacher_entropy": 0.5951808094978333, "total_time": 1.2570061683654785, "rollout_time": 0.42432641983032227, "train_time": 0.8200013637542725, "student_train_time": 0.012337446212768555, "throughput": 1591.0820888020446, "inference_time": 0.0547226922523123, "env_time": 0.36960372757800997, "samples": 2000, "teacher_eval_reward": 376.0}
{"epoch": 136, "reward_mean": 45.44444444444444, "student_loss": null, "teacher_policy_loss": -22.398361206054688, "teacher_value_loss": 143.5294647216797, "teacher_entropy": 0.5965191125869751, "total_time": 1.2397820949554443, "rollout_time": 0.4277818202972412, "train_time": 0.80287766456604, "student_train_time": 0.008768796920776367, "throughput": 1613.1867109049326, "inference_time": 0.052715987500164374, "env_time": 0.37506583279707684, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 137, "reward_mean": 44.86363636363637, "student_loss": null, "teacher_policy_loss": -23.579898834228516, "teacher_value_loss": 176.44088745117188, "teacher_entropy": 0.5962338447570801, "total_time": 1.3043956756591797, "rollout_time": 0.4162013530731201, "train_time": 0.8630492687225342, "student_train_time": 0.024731874465942383, "throughput": 1533.2770855663064, "inference_time": 0.05401215049846542, "env_time": 0.3621892025746547, "samples": 2000, "teacher_eval_reward": 303.0}
{"epoch": 138, "reward_mean": 45.609756097560975, "student_loss": null, "teacher_policy_loss": -23.5556697845459, "teacher_value_loss": 131.48780822753906, "teacher_entropy": 0.5911457538604736, "total_time": 1.140129566192627, "rollout_time": 0.4144601821899414, "train_time": 0.719080924987793, "student_train_time": 0.0060155391693115234, "throughput": 1754.1865936157087, "inference_time": 0.05406924500266541, "env_time": 0.360390937187276, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 139, "reward_mean": 53.38461538461539, "student_loss": null, "teacher_policy_loss": -25.171262741088867, "teacher_value_loss": 188.87632751464844, "teacher_entropy": 0.5978240966796875, "total_time": 1.329169511795044, "rollout_time": 0.43611764907836914, "train_time": 0.8577110767364502, "student_train_time": 0.03498530387878418, "throughput": 1504.698973495863, "inference_time": 0.0536296190007306, "env_time": 0.38248803007763854, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 140, "reward_mean": 48.26190476190476, "student_loss": null, "teacher_policy_loss": -25.87417221069336, "teacher_value_loss": 213.93190002441406, "teacher_entropy": 0.582205057144165, "total_time": 1.374643325805664, "rollout_time": 0.4122598171234131, "train_time": 0.9522037506103516, "student_train_time": 0.009632349014282227, "throughput": 1454.9228606830218, "inference_time": 0.05360559474638649, "env_time": 0.3586542223770266, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 141, "reward_mean": 51.973684210526315, "student_loss": null, "teacher_policy_loss": -25.603256225585938, "teacher_value_loss": 206.3224639892578, "teacher_entropy": 0.5892014503479004, "total_time": 1.2036261558532715, "rollout_time": 0.4356098175048828, "train_time": 0.7625722885131836, "student_train_time": 0.0050923824310302734, "throughput": 1661.6455120004975, "inference_time": 0.05608247825159651, "env_time": 0.3795273392532863, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 142, "reward_mean": 48.61904761904762, "student_loss": null, "teacher_policy_loss": -23.988183975219727, "teacher_value_loss": 208.52110290527344, "teacher_entropy": 0.575862467288971, "total_time": 1.1906940937042236, "rollout_time": 0.4070930480957031, "train_time": 0.7729806900024414, "student_train_time": 0.010236501693725586, "throughput": 1679.6925512396247, "inference_time": 0.052017894499385875, "env_time": 0.35507515359631725, "samples": 2000, "teacher_eval_reward": 382.0}
{"epoch": 143, "reward_mean": 46.75, "student_loss": null, "teacher_policy_loss": -23.10862922668457, "teacher_value_loss": 182.86964416503906, "teacher_entropy": 0.5668463706970215, "total_time": 1.143547534942627, "rollout_time": 0.41596269607543945, "train_time": 0.7217316627502441, "student_train_time": 0.005491495132446289, "throughput": 1748.9434753583218, "inference_time": 0.05186233724793965, "env_time": 0.3641003588274998, "samples": 2000, "teacher_eval_reward": 188.0}
{"epoch": 144, "reward_mean": 49.425, "student_loss": null, "teacher_policy_loss": -23.925281524658203, "teacher_value_loss": 139.86709594726562, "teacher_entropy": 0.5634199976921082, "total_time": 1.2491776943206787, "rollout_time": 0.4160633087158203, "train_time": 0.8252096176147461, "student_train_time": 0.007537126541137695, "throughput": 1601.053244140442, "inference_time": 0.052609136498290354, "env_time": 0.36345417221752996, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 145, "reward_mean": 51.02564102564103, "student_loss": null, "teacher_policy_loss": -24.999820709228516, "teacher_value_loss": 168.22828674316406, "teacher_entropy": 0.5736005902290344, "total_time": -0.43225765228271484, "rollout_time": 0.41788482666015625, "train_time": -0.8579974174499512, "student_train_time": 0.007466554641723633, "throughput": 200000000000.0, "inference_time": 0.052434068253546684, "env_time": 0.36545075840660957, "samples": 2000, "teacher_eval_reward": 90.0}
{"epoch": 146, "reward_mean": 46.35897435897436, "student_loss": null, "teacher_policy_loss": -22.89615249633789, "teacher_value_loss": 140.26278686523438, "teacher_entropy": 0.561407208442688, "total_time": 1.2494664192199707, "rollout_time": 0.41098713874816895, "train_time": 0.8301341533660889, "student_train_time": 0.007703304290771484, "throughput": 1600.683275064391, "inference_time": 0.05341944700091972, "env_time": 0.35756769174724923, "samples": 2000, "teacher_eval_reward": 178.0}
{"epoch": 147, "reward_mean": 53.9, "student_loss": null, "teacher_policy_loss": -23.22567367553711, "teacher_value_loss": 196.30967712402344, "teacher_entropy": 0.5615711808204651, "total_time": 1.1768426895141602, "rollout_time": 0.4108142852783203, "train_time": 0.7537119388580322, "student_train_time": 0.01194000244140625, "throughput": 1699.4624836609783, "inference_time": 0.054216529001564595, "env_time": 0.3565977562767557, "samples": 2000, "teacher_eval_reward": 133.0}
{"epoch": 148, "reward_mean": 45.93023255813954, "student_loss": null, "teacher_policy_loss": -21.737911224365234, "teacher_value_loss": 145.24847412109375, "teacher_entropy": 0.563468873500824, "total_time": 1.19512939453125, "rollout_time": 0.4149448871612549, "train_time": 0.7651901245117188, "student_train_time": 0.01457524299621582, "throughput": 1673.458965323528, "inference_time": 0.05233782199900361, "env_time": 0.3626070651622513, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 149, "reward_mean": 49.02439024390244, "student_loss": null, "teacher_policy_loss": -23.228851318359375, "teacher_value_loss": 169.3627471923828, "teacher_entropy": 0.5554350018501282, "total_time": 1.1742620468139648, "rollout_time": 0.40802693367004395, "train_time": 0.7573010921478271, "student_train_time": 0.00858163833618164, "throughput": 1703.1973446016132, "inference_time": 0.05209970150372101, "env_time": 0.35592723216632294, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 150, "reward_mean": 43.0, "student_loss": null, "teacher_policy_loss": -20.934751510620117, "teacher_value_loss": 125.24365997314453, "teacher_entropy": 0.552108883857727, "total_time": 1.180196762084961, "rollout_time": 0.4151790142059326, "train_time": 0.7540609836578369, "student_train_time": 0.010551214218139648, "throughput": 1694.632678424534, "inference_time": 0.054571944753092794, "env_time": 0.3606070694528398, "samples": 2000, "teacher_eval_reward": 228.0}
{"epoch": 151, "reward_mean": 49.21951219512195, "student_loss": null, "teacher_policy_loss": -23.128406524658203, "teacher_value_loss": 141.9962921142578, "teacher_entropy": 0.5688176155090332, "total_time": 1.248119592666626, "rollout_time": 0.40218281745910645, "train_time": 0.838822603225708, "student_train_time": 0.0067708492279052734, "throughput": 1602.4105476358802, "inference_time": 0.05150186824960201, "env_time": 0.35068094920950443, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 152, "reward_mean": 53.13157894736842, "student_loss": null, "teacher_policy_loss": -25.396116256713867, "teacher_value_loss": 171.917236328125, "teacher_entropy": 0.5681229829788208, "total_time": 1.2107601165771484, "rollout_time": 0.418506383895874, "train_time": 0.7821617126464844, "student_train_time": 0.009663820266723633, "throughput": 1651.8548741546376, "inference_time": 0.05196165124982599, "env_time": 0.36654473264604803, "samples": 2000, "teacher_eval_reward": 301.0}
{"epoch": 153, "reward_mean": 51.78947368421053, "student_loss": null, "teacher_policy_loss": -24.284833908081055, "teacher_value_loss": 179.1582794189453, "teacher_entropy": 0.5708999633789062, "total_time": 1.2000293731689453, "rollout_time": 0.4222118854522705, "train_time": 0.7705414295196533, "student_train_time": 0.0069255828857421875, "throughput": 1666.6258715972542, "inference_time": 0.05407935850030299, "env_time": 0.3681325269519675, "samples": 2000, "teacher_eval_reward": 208.0}
{"epoch": 154, "reward_mean": 55.189189189189186, "student_loss": null, "teacher_policy_loss": -26.56527328491211, "teacher_value_loss": 215.9617156982422, "teacher_entropy": 0.5744585394859314, "total_time": 1.4376649856567383, "rollout_time": 0.41163110733032227, "train_time": 1.020655632019043, "student_train_time": 0.004969120025634766, "throughput": 1391.1446824910895, "inference_time": 0.05223435549851274, "env_time": 0.3593967518318095, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 155, "reward_mean": 48.9, "student_loss": null, "teacher_policy_loss": -23.959148406982422, "teacher_value_loss": 164.17579650878906, "teacher_entropy": 0.5820043087005615, "total_time": 1.2545444965362549, "rollout_time": 0.4299607276916504, "train_time": 0.8140323162078857, "student_train_time": 0.00990915298461914, "throughput": 1594.204115933645, "inference_time": 0.053190196503464904, "env_time": 0.3767705311881855, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 156, "reward_mean": 44.55555555555556, "student_loss": null, "teacher_policy_loss": -21.326988220214844, "teacher_value_loss": 159.42665100097656, "teacher_entropy": 0.5616910457611084, "total_time": 1.2634036540985107, "rollout_time": 0.4280123710632324, "train_time": 0.8254921436309814, "student_train_time": 0.009482860565185547, "throughput": 1583.0253407230173, "inference_time": 0.05915146974609797, "env_time": 0.36886090131713445, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 157, "reward_mean": 51.64102564102564, "student_loss": null, "teacher_policy_loss": -23.77185821533203, "teacher_value_loss": 158.3472900390625, "teacher_entropy": 0.5755935311317444, "total_time": 1.3029944896697998, "rollout_time": 0.4200763702392578, "train_time": 0.8500716686248779, "student_train_time": 0.032474517822265625, "throughput": 1534.925907865376, "inference_time": 0.052521586500461126, "env_time": 0.3675547837387967, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 158, "reward_mean": 52.91891891891892, "student_loss": null, "teacher_policy_loss": -25.480911254882812, "teacher_value_loss": 167.6060333251953, "teacher_entropy": 0.5822280049324036, "total_time": 1.2095136642456055, "rollout_time": 0.42226409912109375, "train_time": 0.7625043392181396, "student_train_time": 0.02439570426940918, "throughput": 1653.5571768405234, "inference_time": 0.05432495774925883, "env_time": 0.3679391413718349, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 159, "reward_mean": 51.743589743589745, "student_loss": null, "teacher_policy_loss": -24.586851119995117, "teacher_value_loss": 188.44033813476562, "teacher_entropy": 0.5759028792381287, "total_time": 1.2364675998687744, "rollout_time": 0.41086411476135254, "train_time": 0.8169393539428711, "student_train_time": 0.00831913948059082, "throughput": 1617.5110453458374, "inference_time": 0.05247342500047125, "env_time": 0.3583906897608813, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 160, "reward_mean": 48.54761904761905, "student_loss": null, "teacher_policy_loss": -23.75967025756836, "teacher_value_loss": 166.0728759765625, "teacher_entropy": 0.5760961174964905, "total_time": 1.2219877243041992, "rollout_time": 0.4191734790802002, "train_time": 0.7939243316650391, "student_train_time": 0.00848078727722168, "throughput": 1636.6776525016253, "inference_time": 0.05256381550111655, "env_time": 0.36660966357908364, "samples": 2000, "teacher_eval_reward": 288.0}
{"epoch": 161, "reward_mean": 57.57142857142857, "student_loss": null, "teacher_policy_loss": -27.67438316345215, "teacher_value_loss": 252.1087646484375, "teacher_entropy": 0.5727400779724121, "total_time": 1.1259472370147705, "rollout_time": 0.4222116470336914, "train_time": 0.6917650699615479, "student_train_time": 0.011606693267822266, "throughput": 1776.282168694343, "inference_time": 0.05198815049914174, "env_time": 0.37022349653454967, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 162, "reward_mean": 53.94117647058823, "student_loss": null, "teacher_policy_loss": -28.697612762451172, "teacher_value_loss": 357.3725280761719, "teacher_entropy": 0.5671020746231079, "total_time": -0.418302059173584, "rollout_time": 0.4177227020263672, "train_time": -0.8570880889892578, "student_train_time": 0.020652055740356445, "throughput": 200000000000.0, "inference_time": 0.05215026474854767, "env_time": 0.3655724372778195, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 163, "reward_mean": 55.10526315789474, "student_loss": null, "teacher_policy_loss": -22.78201675415039, "teacher_value_loss": 134.15203857421875, "teacher_entropy": 0.5586685538291931, "total_time": 1.1938021183013916, "rollout_time": 0.4170207977294922, "train_time": 0.768831729888916, "student_train_time": 0.007545948028564453, "throughput": 1675.3195268623847, "inference_time": 0.05386579350181364, "env_time": 0.36315500422767855, "samples": 2000, "teacher_eval_reward": 101.0}
{"epoch": 164, "reward_mean": 62.21212121212121, "student_loss": null, "teacher_policy_loss": -27.219667434692383, "teacher_value_loss": 178.89344787597656, "teacher_entropy": 0.5814327597618103, "total_time": 1.178708791732788, "rollout_time": 0.41321754455566406, "train_time": 0.7455763816833496, "student_train_time": 0.019565582275390625, "throughput": 1696.771937248261, "inference_time": 0.05324671875075637, "env_time": 0.3599708258049077, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 165, "reward_mean": 57.44117647058823, "student_loss": null, "teacher_policy_loss": -25.54155921936035, "teacher_value_loss": 158.64756774902344, "teacher_entropy": 0.5744139552116394, "total_time": 1.1857497692108154, "rollout_time": 0.41359710693359375, "train_time": 0.76263427734375, "student_train_time": 0.009173154830932617, "throughput": 1686.6965121411029, "inference_time": 0.053134637499056225, "env_time": 0.3604624694345375, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 166, "reward_mean": 59.48571428571429, "student_loss": null, "teacher_policy_loss": -27.132518768310547, "teacher_value_loss": 224.36647033691406, "teacher_entropy": 0.5574598908424377, "total_time": 1.2182998657226562, "rollout_time": 0.4083845615386963, "train_time": 0.7955856323242188, "student_train_time": 0.01395106315612793, "throughput": 1641.6319629270126, "inference_time": 0.05152579649904965, "env_time": 0.35685876503964664, "samples": 2000, "teacher_eval_reward": 113.0}
{"epoch": 167, "reward_mean": 55.68571428571428, "student_loss": null, "teacher_policy_loss": -25.664901733398438, "teacher_value_loss": 207.17111206054688, "teacher_entropy": 0.5717305541038513, "total_time": 1.1753060817718506, "rollout_time": 0.41219091415405273, "train_time": 0.7549879550933838, "student_train_time": 0.007780551910400391, "throughput": 1701.684379089462, "inference_time": 0.052516780499786364, "env_time": 0.35967413365426637, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 168, "reward_mean": 51.61538461538461, "student_loss": null, "teacher_policy_loss": -25.397478103637695, "teacher_value_loss": 290.8919372558594, "teacher_entropy": 0.5704972743988037, "total_time": 1.2199013233184814, "rollout_time": 0.41124486923217773, "train_time": 0.8021700382232666, "student_train_time": 0.006142616271972656, "throughput": 1639.476867325159, "inference_time": 0.051150331250710224, "env_time": 0.3600945379814675, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 169, "reward_mean": 59.696969696969695, "student_loss": null, "teacher_policy_loss": -26.001352310180664, "teacher_value_loss": 175.3956756591797, "teacher_entropy": 0.5653584599494934, "total_time": 1.2527525424957275, "rollout_time": 0.4099709987640381, "train_time": 0.8359994888305664, "student_train_time": 0.005656242370605469, "throughput": 1596.4844868848636, "inference_time": 0.053200726745672, "env_time": 0.3567702720183661, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 170, "reward_mean": 59.90909090909091, "student_loss": null, "teacher_policy_loss": -26.43613052368164, "teacher_value_loss": 164.06494140625, "teacher_entropy": 0.5776753425598145, "total_time": 1.3208189010620117, "rollout_time": 0.4115488529205322, "train_time": 0.90071702003479, "student_train_time": 0.008202075958251953, "throughput": 1514.212128848163, "inference_time": 0.051333288249225006, "env_time": 0.3602155646713072, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 171, "reward_mean": 53.92307692307692, "student_loss": null, "teacher_policy_loss": -23.906007766723633, "teacher_value_loss": 128.61767578125, "teacher_entropy": 0.5702710747718811, "total_time": 1.1500349044799805, "rollout_time": 0.40392136573791504, "train_time": 0.7400119304656982, "student_train_time": 0.005689144134521484, "throughput": 1739.077650781699, "inference_time": 0.051666934999730074, "env_time": 0.35225443073818496, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 172, "reward_mean": 54.51428571428571, "student_loss": null, "teacher_policy_loss": -26.17176055908203, "teacher_value_loss": 147.52206420898438, "teacher_entropy": 0.5716098546981812, "total_time": 1.2155346870422363, "rollout_time": 0.4104297161102295, "train_time": 0.7994585037231445, "student_train_time": 0.005306243896484375, "throughput": 1645.3664558652827, "inference_time": 0.05218387224829257, "env_time": 0.3582458438619369, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 173, "reward_mean": 51.256410256410255, "student_loss": null, "teacher_policy_loss": -24.592897415161133, "teacher_value_loss": 239.47222900390625, "teacher_entropy": 0.5661340355873108, "total_time": 1.2444555759429932, "rollout_time": 0.4543037414550781, "train_time": 0.78285813331604, "student_train_time": 0.006695270538330078, "throughput": 1607.1284814522116, "inference_time": 0.06115527275073873, "env_time": 0.3931484687043394, "samples": 2000, "teacher_eval_reward": 131.0}
{"epoch": 174, "reward_mean": 57.638888888888886, "student_loss": null, "teacher_policy_loss": -27.286550521850586, "teacher_value_loss": 270.5213928222656, "teacher_entropy": 0.5760100483894348, "total_time": 1.3635878562927246, "rollout_time": 0.4208559989929199, "train_time": 0.9370851516723633, "student_train_time": 0.005300760269165039, "throughput": 1466.718840865546, "inference_time": 0.05565681425116509, "env_time": 0.36519918474175483, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 175, "reward_mean": 58.705882352941174, "student_loss": null, "teacher_policy_loss": -28.30295181274414, "teacher_value_loss": 269.5694274902344, "teacher_entropy": 0.5696096420288086, "total_time": 1.1516063213348389, "rollout_time": 0.40239834785461426, "train_time": 0.741581916809082, "student_train_time": 0.007276773452758789, "throughput": 1736.70460377621, "inference_time": 0.05186974074922546, "env_time": 0.3505286071053888, "samples": 2000, "teacher_eval_reward": 340.0}
{"epoch": 176, "reward_mean": 57.78787878787879, "student_loss": null, "teacher_policy_loss": -27.21407699584961, "teacher_value_loss": 162.9508819580078, "teacher_entropy": 0.5767033696174622, "total_time": 1.1513564586639404, "rollout_time": 0.40676355361938477, "train_time": 0.7306613922119141, "student_train_time": 0.01352834701538086, "throughput": 1737.0814963081411, "inference_time": 0.0538209605024349, "env_time": 0.35294259311694987, "samples": 2000, "teacher_eval_reward": 312.0}
{"epoch": 177, "reward_mean": 55.36842105263158, "student_loss": null, "teacher_policy_loss": -25.137210845947266, "teacher_value_loss": 214.8355255126953, "teacher_entropy": 0.5607119202613831, "total_time": 1.1522223949432373, "rollout_time": 0.41317152976989746, "train_time": 0.7307538986206055, "student_train_time": 0.007945775985717773, "throughput": 1735.7760175270048, "inference_time": 0.053753516001165735, "env_time": 0.3594180137687317, "samples": 2000, "teacher_eval_reward": 109.0}
{"epoch": 178, "reward_mean": 59.06060606060606, "student_loss": null, "teacher_policy_loss": -26.694780349731445, "teacher_value_loss": 211.55148315429688, "teacher_entropy": 0.5646417140960693, "total_time": 1.1431019306182861, "rollout_time": 0.42227959632873535, "train_time": 0.7114393711090088, "student_train_time": 0.009032011032104492, "throughput": 1749.6252490083984, "inference_time": 0.05403696500081878, "env_time": 0.36824263132791657, "samples": 2000, "teacher_eval_reward": 95.0}
{"epoch": 179, "reward_mean": 53.972972972972975, "student_loss": null, "teacher_policy_loss": -24.50902557373047, "teacher_value_loss": 220.38925170898438, "teacher_entropy": 0.5559011101722717, "total_time": 1.1669938564300537, "rollout_time": 0.41130852699279785, "train_time": 0.7442519664764404, "student_train_time": 0.011084318161010742, "throughput": 1713.8050804467746, "inference_time": 0.052227858750029554, "env_time": 0.3590806682427683, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 180, "reward_mean": 61.0, "student_loss": null, "teacher_policy_loss": -27.559213638305664, "teacher_value_loss": 189.35939025878906, "teacher_entropy": 0.5726162195205688, "total_time": 1.2373907566070557, "rollout_time": 0.4380767345428467, "train_time": 0.7895150184631348, "student_train_time": 0.00939488410949707, "throughput": 1616.304299447032, "inference_time": 0.058793460001425046, "env_time": 0.37928327454142163, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 181, "reward_mean": 51.38461538461539, "student_loss": null, "teacher_policy_loss": -26.275243759155273, "teacher_value_loss": 233.03860473632812, "teacher_entropy": 0.5520967841148376, "total_time": 1.1462197303771973, "rollout_time": 0.41954636573791504, "train_time": 0.7167818546295166, "student_train_time": 0.009415149688720703, "throughput": 1744.8661430228926, "inference_time": 0.052591410247146086, "env_time": 0.36695495549076895, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 182, "reward_mean": 71.10344827586206, "student_loss": null, "teacher_policy_loss": -30.059324264526367, "teacher_value_loss": 227.19622802734375, "teacher_entropy": 0.5675003528594971, "total_time": 1.1970195770263672, "rollout_time": 0.418698787689209, "train_time": 0.7668108940124512, "student_train_time": 0.01112675666809082, "throughput": 1670.8164497763642, "inference_time": 0.05414106525165607, "env_time": 0.3645577224375529, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 183, "reward_mean": 67.72413793103448, "student_loss": null, "teacher_policy_loss": -27.59246253967285, "teacher_value_loss": 180.0259246826172, "teacher_entropy": 0.5699496865272522, "total_time": 1.166039228439331, "rollout_time": 0.4095273017883301, "train_time": 0.7471563816070557, "student_train_time": 0.00900125503540039, "throughput": 1715.20816042945, "inference_time": 0.052459807255331725, "env_time": 0.35706749453299835, "samples": 2000, "teacher_eval_reward": 99.0}
{"epoch": 184, "reward_mean": 68.8076923076923, "student_loss": null, "teacher_policy_loss": -32.321014404296875, "teacher_value_loss": 346.1727294921875, "teacher_entropy": 0.5570886731147766, "total_time": 1.1535279750823975, "rollout_time": 0.41713595390319824, "train_time": 0.7204363346099854, "student_train_time": 0.015534162521362305, "throughput": 1733.8114403832628, "inference_time": 0.05475334775223928, "env_time": 0.36238260615095896, "samples": 2000, "teacher_eval_reward": 135.0}
{"epoch": 185, "reward_mean": 69.53125, "student_loss": null, "teacher_policy_loss": -30.214365005493164, "teacher_value_loss": 333.3891906738281, "teacher_entropy": 0.5482410192489624, "total_time": 1.2231557369232178, "rollout_time": 0.40901947021484375, "train_time": 0.8010134696960449, "student_train_time": 0.012786388397216797, "throughput": 1635.1147606361983, "inference_time": 0.05096166174814698, "env_time": 0.35805780846669677, "samples": 2000, "teacher_eval_reward": 118.0}
{"epoch": 186, "reward_mean": 62.86666666666667, "student_loss": null, "teacher_policy_loss": -31.625415802001953, "teacher_value_loss": 339.0731201171875, "teacher_entropy": 0.5465192794799805, "total_time": 1.175614833831787, "rollout_time": 0.4119744300842285, "train_time": 0.7524716854095459, "student_train_time": 0.010815858840942383, "throughput": 1701.2374652344427, "inference_time": 0.05445035150205513, "env_time": 0.3575240785821734, "samples": 2000, "teacher_eval_reward": 266.0}
{"epoch": 187, "reward_mean": 71.67857142857143, "student_loss": null, "teacher_policy_loss": -28.020252227783203, "teacher_value_loss": 118.33580780029297, "teacher_entropy": 0.5552201271057129, "total_time": 1.37184476852417, "rollout_time": 0.41998720169067383, "train_time": 0.9238080978393555, "student_train_time": 0.0276947021484375, "throughput": 1457.89089690636, "inference_time": 0.05648682824892148, "env_time": 0.36350037344175234, "samples": 2000, "teacher_eval_reward": 228.0}
{"epoch": 188, "reward_mean": 69.10714285714286, "student_loss": null, "teacher_policy_loss": -29.87445831298828, "teacher_value_loss": 194.12550354003906, "teacher_entropy": 0.5530256628990173, "total_time": 1.2131614685058594, "rollout_time": 0.4109337329864502, "train_time": 0.7968151569366455, "student_train_time": 0.005047798156738281, "throughput": 1648.585165223899, "inference_time": 0.05255469125017953, "env_time": 0.35837904173627066, "samples": 2000, "teacher_eval_reward": 332.0}
{"epoch": 189, "reward_mean": 72.85714285714286, "student_loss": null, "teacher_policy_loss": -32.246337890625, "teacher_value_loss": 323.2955627441406, "teacher_entropy": 0.5508614778518677, "total_time": 1.1548044681549072, "rollout_time": 0.40427398681640625, "train_time": 0.7391202449798584, "student_train_time": 0.011061906814575195, "throughput": 1731.894926935559, "inference_time": 0.05216548874568616, "env_time": 0.3521084980707201, "samples": 2000, "teacher_eval_reward": 223.0}
{"epoch": 190, "reward_mean": 63.64705882352941, "student_loss": null, "teacher_policy_loss": -28.629247665405273, "teacher_value_loss": 209.34942626953125, "teacher_entropy": 0.5410984754562378, "total_time": 1.229938268661499, "rollout_time": 0.4142277240753174, "train_time": 0.8101069927215576, "student_train_time": 0.0052051544189453125, "throughput": 1626.0978708927673, "inference_time": 0.05114075824917563, "env_time": 0.36308696582614175, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 191, "reward_mean": 67.67857142857143, "student_loss": null, "teacher_policy_loss": -31.678386688232422, "teacher_value_loss": 258.99774169921875, "teacher_entropy": 0.5493411421775818, "total_time": 1.228102445602417, "rollout_time": 0.4106152057647705, "train_time": 0.8089945316314697, "student_train_time": 0.008151531219482422, "throughput": 1628.528635507233, "inference_time": 0.052557443251430414, "env_time": 0.3580577625133401, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 192, "reward_mean": 68.96666666666667, "student_loss": null, "teacher_policy_loss": -29.939233779907227, "teacher_value_loss": 298.5616149902344, "teacher_entropy": 0.5162023901939392, "total_time": 1.2834815979003906, "rollout_time": 0.40869927406311035, "train_time": 0.8656609058380127, "student_train_time": 0.008719921112060547, "throughput": 1558.2615311912073, "inference_time": 0.05260538350034949, "env_time": 0.35609389056276086, "samples": 2000, "teacher_eval_reward": 122.0}
{"epoch": 193, "reward_mean": 62.733333333333334, "student_loss": null, "teacher_policy_loss": -28.269418716430664, "teacher_value_loss": 243.6411590576172, "teacher_entropy": 0.5289125442504883, "total_time": 1.197725772857666, "rollout_time": 0.41274166107177734, "train_time": 0.7786586284637451, "student_train_time": 0.005923032760620117, "throughput": 1669.831313079437, "inference_time": 0.05184654200013483, "env_time": 0.3608951190716425, "samples": 2000, "teacher_eval_reward": 462.0}
{"epoch": 194, "reward_mean": 67.5, "student_loss": null, "teacher_policy_loss": -27.407848358154297, "teacher_value_loss": 221.20245361328125, "teacher_entropy": 0.5343316793441772, "total_time": 1.178356409072876, "rollout_time": 0.4150378704071045, "train_time": 0.738572359085083, "student_train_time": 0.024355173110961914, "throughput": 1697.2793499494678, "inference_time": 0.05293108399985158, "env_time": 0.3621067864072529, "samples": 2000, "teacher_eval_reward": 150.0}
{"epoch": 195, "reward_mean": 76.92307692307692, "student_loss": null, "teacher_policy_loss": -33.06156921386719, "teacher_value_loss": 438.8047180175781, "teacher_entropy": 0.5510335564613342, "total_time": 1.2915880680084229, "rollout_time": 0.4166069030761719, "train_time": 0.8507223129272461, "student_train_time": 0.023829936981201172, "throughput": 1548.4813227517036, "inference_time": 0.05401210799823275, "env_time": 0.3625947950779391, "samples": 2000, "teacher_eval_reward": 105.0}
{"epoch": 196, "reward_mean": 71.70370370370371, "student_loss": null, "teacher_policy_loss": -30.649051666259766, "teacher_value_loss": 356.5386657714844, "teacher_entropy": 0.517197847366333, "total_time": 1.1694583892822266, "rollout_time": 0.4090583324432373, "train_time": 0.752032995223999, "student_train_time": 0.007909297943115234, "throughput": 1710.1933838172142, "inference_time": 0.052897438003583375, "env_time": 0.35616089443965393, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 197, "reward_mean": 75.85185185185185, "student_loss": null, "teacher_policy_loss": -32.339942932128906, "teacher_value_loss": 344.15167236328125, "teacher_entropy": 0.5337927341461182, "total_time": 1.1926255226135254, "rollout_time": 0.41085314750671387, "train_time": 0.7621622085571289, "student_train_time": 0.019159555435180664, "throughput": 1676.9723287635084, "inference_time": 0.05504852274964378, "env_time": 0.3558046247570701, "samples": 2000, "teacher_eval_reward": 104.0}
{"epoch": 198, "reward_mean": 70.44444444444444, "student_loss": null, "teacher_policy_loss": -30.206619262695312, "teacher_value_loss": 263.1781311035156, "teacher_entropy": 0.5379710793495178, "total_time": 1.1833877563476562, "rollout_time": 0.4059720039367676, "train_time": 0.7430028915405273, "student_train_time": 0.033952951431274414, "throughput": 1690.0631169048863, "inference_time": 0.05312378749658819, "env_time": 0.3528482164401794, "samples": 2000, "teacher_eval_reward": 167.0}
{"epoch": 199, "reward_mean": 65.13333333333334, "student_loss": null, "teacher_policy_loss": -26.994367599487305, "teacher_value_loss": 159.8191680908203, "teacher_entropy": 0.5449740886688232, "total_time": 1.1498308181762695, "rollout_time": 0.4068417549133301, "train_time": 0.7293720245361328, "student_train_time": 0.01326441764831543, "throughput": 1739.3863239569207, "inference_time": 0.053820624997797495, "env_time": 0.3530211299155326, "samples": 2000, "teacher_eval_reward": 266.0}
{"epoch": 200, "reward_mean": 69.03225806451613, "student_loss": null, "teacher_policy_loss": -29.80101776123047, "teacher_value_loss": 303.59051513671875, "teacher_entropy": 0.5248631834983826, "total_time": 1.259838581085205, "rollout_time": 0.42316722869873047, "train_time": 0.827491044998169, "student_train_time": 0.008766412734985352, "throughput": 1587.5049629590098, "inference_time": 0.054773458748513804, "env_time": 0.36839376995021667, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 201, "reward_mean": 76.76923076923077, "student_loss": null, "teacher_policy_loss": -34.22105026245117, "teacher_value_loss": 290.3740539550781, "teacher_entropy": 0.5350301861763, "total_time": 1.225895881652832, "rollout_time": 0.4101438522338867, "train_time": 0.7813241481781006, "student_train_time": 0.034064531326293945, "throughput": 1631.459922439311, "inference_time": 0.05314740849883037, "env_time": 0.35699644373505635, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 202, "reward_mean": 80.78260869565217, "student_loss": null, "teacher_policy_loss": -34.041587829589844, "teacher_value_loss": 228.51409912109375, "teacher_entropy": 0.5577428936958313, "total_time": 1.2006795406341553, "rollout_time": 0.413790225982666, "train_time": 0.7739319801330566, "student_train_time": 0.01256418228149414, "throughput": 1665.7233943902074, "inference_time": 0.05405700625158261, "env_time": 0.3597332197310834, "samples": 2000, "teacher_eval_reward": 107.0}
{"epoch": 203, "reward_mean": 77.38461538461539, "student_loss": null, "teacher_policy_loss": -31.672311782836914, "teacher_value_loss": 263.5596008300781, "teacher_entropy": 0.5429192185401917, "total_time": 1.1835229396820068, "rollout_time": 0.40827226638793945, "train_time": 0.7675695419311523, "student_train_time": 0.007334232330322266, "throughput": 1689.8700759761928, "inference_time": 0.0544564395040652, "env_time": 0.35381582688387425, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 204, "reward_mean": 81.23076923076923, "student_loss": null, "teacher_policy_loss": -31.673227310180664, "teacher_value_loss": 293.5426025390625, "teacher_entropy": 0.5465270280838013, "total_time": 1.317552089691162, "rollout_time": 0.5571343898773193, "train_time": 0.747164249420166, "student_train_time": 0.012876033782958984, "throughput": 1517.9665499743585, "inference_time": 0.06753231675304505, "env_time": 0.4896020731242743, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 205, "reward_mean": 70.25925925925925, "student_loss": null, "teacher_policy_loss": -32.37363052368164, "teacher_value_loss": 271.3545227050781, "teacher_entropy": 0.5546714067459106, "total_time": 1.1376900672912598, "rollout_time": 0.4152696132659912, "train_time": 0.7146735191345215, "student_train_time": 0.006621837615966797, "throughput": 1757.9480189730623, "inference_time": 0.053191697255101644, "env_time": 0.36207791601088957, "samples": 2000, "teacher_eval_reward": 156.0}
{"epoch": 206, "reward_mean": 73.3103448275862, "student_loss": null, "teacher_policy_loss": -30.991695404052734, "teacher_value_loss": 321.3760986328125, "teacher_entropy": 0.5471064448356628, "total_time": 1.2102243900299072, "rollout_time": 0.4264814853668213, "train_time": 0.7755985260009766, "student_train_time": 0.007704496383666992, "throughput": 1652.5860959971033, "inference_time": 0.05393218174958747, "env_time": 0.3725493036172338, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 207, "reward_mean": 89.85714285714286, "student_loss": null, "teacher_policy_loss": -35.98939895629883, "teacher_value_loss": 251.50411987304688, "teacher_entropy": 0.5618146657943726, "total_time": 1.3149878978729248, "rollout_time": 0.40966796875, "train_time": 0.8915762901306152, "student_train_time": 0.013401269912719727, "throughput": 1520.926544826097, "inference_time": 0.05198000925156521, "env_time": 0.3576879594984348, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 208, "reward_mean": 92.57142857142857, "student_loss": null, "teacher_policy_loss": -32.694393157958984, "teacher_value_loss": 255.9655303955078, "teacher_entropy": 0.5425958037376404, "total_time": 1.1730530261993408, "rollout_time": 0.40672922134399414, "train_time": 0.7579927444458008, "student_train_time": 0.007990360260009766, "throughput": 1704.9527645650805, "inference_time": 0.051605290999759745, "env_time": 0.3551239303442344, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 209, "reward_mean": 74.4074074074074, "student_loss": null, "teacher_policy_loss": -30.778079986572266, "teacher_value_loss": 240.4811248779297, "teacher_entropy": 0.5508327484130859, "total_time": 1.241274118423462, "rollout_time": 0.41893720626831055, "train_time": 0.8159694671630859, "student_train_time": 0.006028175354003906, "throughput": 1611.2476449119822, "inference_time": 0.05293621200269172, "env_time": 0.36600099426561883, "samples": 2000, "teacher_eval_reward": 141.0}
{"epoch": 210, "reward_mean": 78.74074074074075, "student_loss": null, "teacher_policy_loss": -33.167171478271484, "teacher_value_loss": 492.39093017578125, "teacher_entropy": 0.5524266362190247, "total_time": 1.1363911628723145, "rollout_time": 0.41572141647338867, "train_time": 0.713202953338623, "student_train_time": 0.007113218307495117, "throughput": 1759.9573679760488, "inference_time": 0.053186592253723575, "env_time": 0.3625348242196651, "samples": 2000, "teacher_eval_reward": 71.0}
{"epoch": 211, "reward_mean": 76.92, "student_loss": null, "teacher_policy_loss": -32.911190032958984, "teacher_value_loss": 311.2585754394531, "teacher_entropy": 0.5503065586090088, "total_time": -0.4098978042602539, "rollout_time": 0.4106326103210449, "train_time": -0.831484317779541, "student_train_time": 0.010608196258544922, "throughput": 200000000000.0, "inference_time": 0.054962743995588426, "env_time": 0.3556698663254565, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 212, "reward_mean": 80.76923076923077, "student_loss": null, "teacher_policy_loss": -31.673368453979492, "teacher_value_loss": 319.3486633300781, "teacher_entropy": 0.5566550493240356, "total_time": 1.154977560043335, "rollout_time": 0.4104006290435791, "train_time": 0.7378113269805908, "student_train_time": 0.006421327590942383, "throughput": 1731.635374738328, "inference_time": 0.053318321249662404, "env_time": 0.3570823077939167, "samples": 2000, "teacher_eval_reward": 131.0}
{"epoch": 213, "reward_mean": 94.78947368421052, "student_loss": null, "teacher_policy_loss": -37.73546600341797, "teacher_value_loss": 341.4452819824219, "teacher_entropy": 0.5595593452453613, "total_time": 1.2265253067016602, "rollout_time": 0.4193437099456787, "train_time": 0.797827959060669, "student_train_time": 0.009012937545776367, "throughput": 1630.622694103514, "inference_time": 0.05334194674776427, "env_time": 0.36600176319791444, "samples": 2000, "teacher_eval_reward": 144.0}
{"epoch": 214, "reward_mean": 85.56, "student_loss": null, "teacher_policy_loss": -34.120182037353516, "teacher_value_loss": 301.1138610839844, "teacher_entropy": 0.5536133646965027, "total_time": 1.2354156970977783, "rollout_time": 0.40992021560668945, "train_time": 0.8172640800476074, "student_train_time": 0.007881879806518555, "throughput": 1618.8882856987916, "inference_time": 0.052741668501994354, "env_time": 0.3571785471046951, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 215, "reward_mean": 84.0, "student_loss": null, "teacher_policy_loss": -35.272727966308594, "teacher_value_loss": 452.0251770019531, "teacher_entropy": 0.5530194044113159, "total_time": 1.2122802734375, "rollout_time": 0.4187650680541992, "train_time": 0.7854819297790527, "student_train_time": 0.0076138973236083984, "throughput": 1649.7835061927299, "inference_time": 0.05453276049706801, "env_time": 0.3642323075571312, "samples": 2000, "teacher_eval_reward": 143.0}
{"epoch": 216, "reward_mean": 93.27272727272727, "student_loss": null, "teacher_policy_loss": -33.31592559814453, "teacher_value_loss": 285.69708251953125, "teacher_entropy": 0.5540004968643188, "total_time": 1.2047042846679688, "rollout_time": 0.40273475646972656, "train_time": 0.7928900718688965, "student_train_time": 0.008730173110961914, "throughput": 1660.158451707694, "inference_time": 0.05387907975170947, "env_time": 0.3488556767180171, "samples": 2000, "teacher_eval_reward": 168.0}
{"epoch": 217, "reward_mean": 104.3, "student_loss": null, "teacher_policy_loss": -41.00590896606445, "teacher_value_loss": 498.8361511230469, "teacher_entropy": 0.558163583278656, "total_time": 1.1677055358886719, "rollout_time": 0.41027164459228516, "train_time": 0.7512567043304443, "student_train_time": 0.005827426910400391, "throughput": 1712.7605706501322, "inference_time": 0.05208549650058103, "env_time": 0.3581861480917041, "samples": 2000, "teacher_eval_reward": 191.0}
{"epoch": 218, "reward_mean": 80.65217391304348, "student_loss": null, "teacher_policy_loss": -33.83820343017578, "teacher_value_loss": 303.81585693359375, "teacher_entropy": 0.5546727180480957, "total_time": 1.1935391426086426, "rollout_time": 0.42492055892944336, "train_time": 0.7435314655303955, "student_train_time": 0.024665355682373047, "throughput": 1675.688654524331, "inference_time": 0.05482972674849407, "env_time": 0.3700908321809493, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 219, "reward_mean": 96.47619047619048, "student_loss": null, "teacher_policy_loss": -35.58316421508789, "teacher_value_loss": 276.4933166503906, "teacher_entropy": 0.5552818179130554, "total_time": 1.1664257049560547, "rollout_time": 0.4064757823944092, "train_time": 0.7494196891784668, "student_train_time": 0.010169029235839844, "throughput": 1714.6398536161807, "inference_time": 0.05277404450271206, "env_time": 0.3537017378916971, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 220, "reward_mean": 75.85185185185185, "student_loss": null, "teacher_policy_loss": -30.836496353149414, "teacher_value_loss": 245.69871520996094, "teacher_entropy": 0.5516017079353333, "total_time": 1.1990232467651367, "rollout_time": 0.41190028190612793, "train_time": 0.7813594341278076, "student_train_time": 0.005403757095336914, "throughput": 1668.0243735022075, "inference_time": 0.05134238624941645, "env_time": 0.3605578956567115, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 221, "reward_mean": 71.26923076923077, "student_loss": null, "teacher_policy_loss": -33.13682174682617, "teacher_value_loss": 376.842041015625, "teacher_entropy": 0.5405376553535461, "total_time": 1.1907985210418701, "rollout_time": 0.40808606147766113, "train_time": 0.7609667778015137, "student_train_time": 0.021344661712646484, "throughput": 1679.5452502327028, "inference_time": 0.05138467424797, "env_time": 0.35670138722969114, "samples": 2000, "teacher_eval_reward": 184.0}
{"epoch": 222, "reward_mean": 96.14285714285714, "student_loss": null, "teacher_policy_loss": -38.32224655151367, "teacher_value_loss": 360.5987548828125, "teacher_entropy": 0.5545932054519653, "total_time": 1.2796659469604492, "rollout_time": 0.41477513313293457, "train_time": 0.8501074314117432, "student_train_time": 0.014368057250976562, "throughput": 1562.9078860389602, "inference_time": 0.05516093149844892, "env_time": 0.35961420163448565, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 223, "reward_mean": 100.55, "student_loss": null, "teacher_policy_loss": -37.84597396850586, "teacher_value_loss": 391.0035705566406, "teacher_entropy": 0.5561411380767822, "total_time": 1.2372207641601562, "rollout_time": 0.4243927001953125, "train_time": 0.8062131404876709, "student_train_time": 0.006226062774658203, "throughput": 1616.5263774550613, "inference_time": 0.053202122749439695, "env_time": 0.3711905774458728, "samples": 2000, "teacher_eval_reward": 175.0}
{"epoch": 224, "reward_mean": 96.47619047619048, "student_loss": null, "teacher_policy_loss": -36.622276306152344, "teacher_value_loss": 313.8811950683594, "teacher_entropy": 0.5498130917549133, "total_time": 1.1188344955444336, "rollout_time": 0.40246009826660156, "train_time": 0.7098903656005859, "student_train_time": 0.00600886344909668, "throughput": 1787.574487526669, "inference_time": 0.05080102600129521, "env_time": 0.35165907226530635, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 225, "reward_mean": 94.5, "student_loss": null, "teacher_policy_loss": -45.77119445800781, "teacher_value_loss": 589.0487670898438, "teacher_entropy": 0.5495489239692688, "total_time": 1.1694374084472656, "rollout_time": 0.41686439514160156, "train_time": 0.7439541816711426, "student_train_time": 0.008272647857666016, "throughput": 1710.2240663359005, "inference_time": 0.054018307248952624, "env_time": 0.36284608789264894, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 226, "reward_mean": 124.14285714285714, "student_loss": null, "teacher_policy_loss": -38.834415435791016, "teacher_value_loss": 472.2498779296875, "teacher_entropy": 0.553761899471283, "total_time": 1.1659860610961914, "rollout_time": 0.40992069244384766, "train_time": 0.746098518371582, "student_train_time": 0.009541749954223633, "throughput": 1715.2863715366527, "inference_time": 0.050955566498146254, "env_time": 0.3589651259457014, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 227, "reward_mean": 84.34782608695652, "student_loss": null, "teacher_policy_loss": -34.839378356933594, "teacher_value_loss": 462.8229675292969, "teacher_entropy": 0.5483875870704651, "total_time": 1.1963553428649902, "rollout_time": 0.4150240421295166, "train_time": 0.7664568424224854, "student_train_time": 0.01433253288269043, "throughput": 1671.7441117540125, "inference_time": 0.05393469824662134, "env_time": 0.36108934388289526, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 228, "reward_mean": 99.05, "student_loss": null, "teacher_policy_loss": -38.155372619628906, "teacher_value_loss": 459.57342529296875, "teacher_entropy": 0.549803614616394, "total_time": 1.2181487083435059, "rollout_time": 0.4007599353790283, "train_time": 0.8116919994354248, "student_train_time": 0.005319118499755859, "throughput": 1641.8356694066451, "inference_time": 0.05267864024961, "env_time": 0.3480812951294183, "samples": 2000, "teacher_eval_reward": 128.0}
{"epoch": 229, "reward_mean": 93.86363636363636, "student_loss": null, "teacher_policy_loss": -38.15343475341797, "teacher_value_loss": 468.6967468261719, "teacher_entropy": 0.5272708535194397, "total_time": 1.2475268840789795, "rollout_time": 0.40200304985046387, "train_time": 0.840468168258667, "student_train_time": 0.0047016143798828125, "throughput": 1603.171863888572, "inference_time": 0.05138936025264229, "env_time": 0.3506136895978216, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 230, "reward_mean": 90.18181818181819, "student_loss": null, "teacher_policy_loss": -37.00764465332031, "teacher_value_loss": 361.1936950683594, "teacher_entropy": 0.5478807091712952, "total_time": 1.2887022495269775, "rollout_time": 0.4809248447418213, "train_time": 0.771376371383667, "student_train_time": 0.03602790832519531, "throughput": 1551.9488700621937, "inference_time": 0.06078341199804527, "env_time": 0.420141432743776, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 231, "reward_mean": 75.91304347826087, "student_loss": null, "teacher_policy_loss": -32.919944763183594, "teacher_value_loss": 324.4236755371094, "teacher_entropy": 0.5349767208099365, "total_time": 1.2587239742279053, "rollout_time": 0.43253183364868164, "train_time": 0.8055706024169922, "student_train_time": 0.020277976989746094, "throughput": 1588.9107071522885, "inference_time": 0.053976668248424176, "env_time": 0.37855516540025747, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 232, "reward_mean": 107.47368421052632, "student_loss": null, "teacher_policy_loss": -40.10457992553711, "teacher_value_loss": 379.7252502441406, "teacher_entropy": 0.5624832510948181, "total_time": 1.2621736526489258, "rollout_time": 0.47536516189575195, "train_time": 0.7810909748077393, "student_train_time": 0.005276918411254883, "throughput": 1584.5680155045202, "inference_time": 0.05760187799808136, "env_time": 0.4177632838976706, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 233, "reward_mean": 130.875, "student_loss": null, "teacher_policy_loss": -42.42013168334961, "teacher_value_loss": 389.76861572265625, "teacher_entropy": 0.5572664737701416, "total_time": 1.2133967876434326, "rollout_time": 0.42585110664367676, "train_time": 0.7822170257568359, "student_train_time": 0.004878520965576172, "throughput": 1648.2654481756529, "inference_time": 0.055793191997167924, "env_time": 0.37005791464650883, "samples": 2000, "teacher_eval_reward": 493.0}
{"epoch": 234, "reward_mean": 111.0, "student_loss": null, "teacher_policy_loss": -41.68510818481445, "teacher_value_loss": 570.4777221679688, "teacher_entropy": 0.565212607383728, "total_time": 1.2694377899169922, "rollout_time": 0.41117262840270996, "train_time": 0.8463256359100342, "student_train_time": 0.01157689094543457, "throughput": 1575.500600254526, "inference_time": 0.052120710750386934, "env_time": 0.359051917652323, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 235, "reward_mean": 117.625, "student_loss": null, "teacher_policy_loss": -41.429378509521484, "teacher_value_loss": 402.64471435546875, "teacher_entropy": 0.5592933893203735, "total_time": 1.1577236652374268, "rollout_time": 0.3982887268066406, "train_time": 0.745955228805542, "student_train_time": 0.013080835342407227, "throughput": 1727.5279585736366, "inference_time": 0.05189529475467225, "env_time": 0.3463934320519684, "samples": 2000, "teacher_eval_reward": 177.0}
{"epoch": 236, "reward_mean": 107.36842105263158, "student_loss": null, "teacher_policy_loss": -38.628273010253906, "teacher_value_loss": 355.9364318847656, "teacher_entropy": 0.548173725605011, "total_time": 1.2149262428283691, "rollout_time": 0.40068888664245605, "train_time": 0.8037593364715576, "student_train_time": 0.010040521621704102, "throughput": 1646.1904677801392, "inference_time": 0.05251237500192474, "env_time": 0.3481765116405313, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 237, "reward_mean": 101.26315789473684, "student_loss": null, "teacher_policy_loss": -40.36418533325195, "teacher_value_loss": 445.1007385253906, "teacher_entropy": 0.5495801568031311, "total_time": 1.1791138648986816, "rollout_time": 0.4101064205169678, "train_time": 0.7589952945709229, "student_train_time": 0.009644269943237305, "throughput": 1696.189027657524, "inference_time": 0.052162813749646375, "env_time": 0.3579436067673214, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 238, "reward_mean": 113.875, "student_loss": null, "teacher_policy_loss": -41.39347839355469, "teacher_value_loss": 341.811279296875, "teacher_entropy": 0.5589597225189209, "total_time": 1.213313341140747, "rollout_time": 0.4238431453704834, "train_time": 0.777536153793335, "student_train_time": 0.011583566665649414, "throughput": 1648.3788088241217, "inference_time": 0.05565536449807951, "env_time": 0.3681877808724039, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 239, "reward_mean": 123.6470588235294, "student_loss": null, "teacher_policy_loss": -42.419368743896484, "teacher_value_loss": 475.89276123046875, "teacher_entropy": 0.5601610541343689, "total_time": 1.1659982204437256, "rollout_time": 0.4138679504394531, "train_time": 0.740839958190918, "student_train_time": 0.010950088500976562, "throughput": 1715.2684840624297, "inference_time": 0.053824492499188636, "env_time": 0.3600434579402645, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 240, "reward_mean": 114.0, "student_loss": null, "teacher_policy_loss": -42.65585708618164, "teacher_value_loss": 580.5552368164062, "teacher_entropy": 0.5399255752563477, "total_time": 1.2180891036987305, "rollout_time": 0.42223191261291504, "train_time": 0.7724924087524414, "student_train_time": 0.023016691207885742, "throughput": 1641.9160092040847, "inference_time": 0.05355830200073797, "env_time": 0.36867361061217707, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 241, "reward_mean": 121.125, "student_loss": null, "teacher_policy_loss": -46.666385650634766, "teacher_value_loss": 498.43768310546875, "teacher_entropy": 0.5436248779296875, "total_time": 1.2150068283081055, "rollout_time": 0.4017457962036133, "train_time": 0.80470871925354, "student_train_time": 0.008193016052246094, "throughput": 1646.0812839916266, "inference_time": 0.0527613462517138, "env_time": 0.3489844499518995, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 242, "reward_mean": 110.84210526315789, "student_loss": null, "teacher_policy_loss": -39.29471969604492, "teacher_value_loss": 418.4690246582031, "teacher_entropy": 0.5469467639923096, "total_time": 1.183438777923584, "rollout_time": 0.4101898670196533, "train_time": 0.7680299282073975, "student_train_time": 0.004869937896728516, "throughput": 1689.9902532424387, "inference_time": 0.05160818225033381, "env_time": 0.3585816847693195, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 243, "reward_mean": 105.1, "student_loss": null, "teacher_policy_loss": -39.123226165771484, "teacher_value_loss": 424.1780700683594, "teacher_entropy": 0.5338420271873474, "total_time": 1.2659263610839844, "rollout_time": 0.41582250595092773, "train_time": 0.8401603698730469, "student_train_time": 0.009567499160766602, "throughput": 1579.8707266727938, "inference_time": 0.05410783524826002, "env_time": 0.3617146707026677, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 244, "reward_mean": 91.75, "student_loss": null, "teacher_policy_loss": -35.95018768310547, "teacher_value_loss": 313.13079833984375, "teacher_entropy": 0.5261247754096985, "total_time": 1.2160897254943848, "rollout_time": 0.42169809341430664, "train_time": 0.7839648723602295, "student_train_time": 0.010040283203125, "throughput": 1644.6154901826237, "inference_time": 0.052380769747060185, "env_time": 0.36931732366724646, "samples": 2000, "teacher_eval_reward": 149.0}
{"epoch": 245, "reward_mean": 113.75, "student_loss": null, "teacher_policy_loss": -40.630531311035156, "teacher_value_loss": 351.21685791015625, "teacher_entropy": 0.5270476937294006, "total_time": 1.158362627029419, "rollout_time": 0.41132402420043945, "train_time": 0.7351813316345215, "student_train_time": 0.011472463607788086, "throughput": 1726.575040778837, "inference_time": 0.05234135124999284, "env_time": 0.3589826729504466, "samples": 2000, "teacher_eval_reward": 405.0}
{"epoch": 246, "reward_mean": 114.8, "student_loss": null, "teacher_policy_loss": -39.01233673095703, "teacher_value_loss": 473.53662109375, "teacher_entropy": 0.5299578905105591, "total_time": 1.1639845371246338, "rollout_time": 0.411914587020874, "train_time": 0.7286648750305176, "student_train_time": 0.02300882339477539, "throughput": 1718.2358839066346, "inference_time": 0.05478028299694415, "env_time": 0.35713430402392987, "samples": 2000, "teacher_eval_reward": 205.0}
{"epoch": 247, "reward_mean": 90.3157894736842, "student_loss": null, "teacher_policy_loss": -37.04963684082031, "teacher_value_loss": 322.5763244628906, "teacher_entropy": 0.5244698524475098, "total_time": 1.2419304847717285, "rollout_time": 0.4035365581512451, "train_time": 0.8109016418457031, "student_train_time": 0.027126789093017578, "throughput": 1610.39609263445, "inference_time": 0.0529041527456684, "env_time": 0.3506324054055767, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 248, "reward_mean": 131.5625, "student_loss": null, "teacher_policy_loss": -41.4842529296875, "teacher_value_loss": 473.2222595214844, "teacher_entropy": 0.537998378276825, "total_time": -0.2940535545349121, "rollout_time": -1.2011473178863525, "train_time": 0.8961029052734375, "student_train_time": 0.010638952255249023, "throughput": 200000000000.0, "inference_time": 0.05557840874791964, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 249, "reward_mean": 124.875, "student_loss": null, "teacher_policy_loss": -41.94439697265625, "teacher_value_loss": 412.3338623046875, "teacher_entropy": 0.5466205477714539, "total_time": 1.2266819477081299, "rollout_time": 0.4062364101409912, "train_time": 0.8082218170166016, "student_train_time": 0.011871576309204102, "throughput": 1630.4144719311296, "inference_time": 0.053222897247906076, "env_time": 0.35301351289308514, "samples": 2000, "teacher_eval_reward": 170.0}
{"epoch": 250, "reward_mean": 138.8, "student_loss": null, "teacher_policy_loss": -44.51045227050781, "teacher_value_loss": 484.1031188964844, "teacher_entropy": 0.5507010221481323, "total_time": 1.1917212009429932, "rollout_time": 0.40344738960266113, "train_time": 0.7739136219024658, "student_train_time": 0.013939857482910156, "throughput": 1678.2448767525714, "inference_time": 0.052039422251027645, "env_time": 0.3514079673516335, "samples": 2000, "teacher_eval_reward": 177.0}
{"epoch": 251, "reward_mean": 133.30769230769232, "student_loss": null, "teacher_policy_loss": -46.99347686767578, "teacher_value_loss": 408.78955078125, "teacher_entropy": 0.5440598130226135, "total_time": 1.337188482284546, "rollout_time": 0.5120108127593994, "train_time": 0.7619149684906006, "student_train_time": 0.06290102005004883, "throughput": 1495.6754612356972, "inference_time": 0.060514200753345904, "env_time": 0.4514966120060535, "samples": 2000, "teacher_eval_reward": 240.0}
{"epoch": 252, "reward_mean": 135.35294117647058, "student_loss": null, "teacher_policy_loss": -42.04392623901367, "teacher_value_loss": 416.6027526855469, "teacher_entropy": 0.5406556725502014, "total_time": 1.2264337539672852, "rollout_time": 0.40723252296447754, "train_time": 0.8094394207000732, "student_train_time": 0.009377002716064453, "throughput": 1630.7444193625395, "inference_time": 0.05579357000181062, "env_time": 0.3514389529626669, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 253, "reward_mean": 133.78571428571428, "student_loss": null, "teacher_policy_loss": -44.39641571044922, "teacher_value_loss": 475.1659240722656, "teacher_entropy": 0.5496344566345215, "total_time": 1.2077791690826416, "rollout_time": 0.41241955757141113, "train_time": 0.786949872970581, "student_train_time": 0.008056402206420898, "throughput": 1655.9318550915918, "inference_time": 0.0534190655000657, "env_time": 0.35900049207134543, "samples": 2000, "teacher_eval_reward": 202.0}
{"epoch": 254, "reward_mean": 172.66666666666666, "student_loss": null, "teacher_policy_loss": -47.80385208129883, "teacher_value_loss": 454.28961181640625, "teacher_entropy": 0.5497908592224121, "total_time": 1.185168743133545, "rollout_time": 0.41238903999328613, "train_time": 0.7601208686828613, "student_train_time": 0.012274742126464844, "throughput": 1687.5234109803382, "inference_time": 0.05261026700009097, "env_time": 0.35977877299319516, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 255, "reward_mean": 123.0, "student_loss": null, "teacher_policy_loss": -45.956947326660156, "teacher_value_loss": 594.1768188476562, "teacher_entropy": 0.5492600202560425, "total_time": 1.2486727237701416, "rollout_time": 0.40738677978515625, "train_time": 0.8322315216064453, "student_train_time": 0.007981300354003906, "throughput": 1601.7007194338012, "inference_time": 0.05272447725019447, "env_time": 0.3546623025349618, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 256, "reward_mean": 126.17647058823529, "student_loss": null, "teacher_policy_loss": -39.68902587890625, "teacher_value_loss": 371.7636413574219, "teacher_entropy": 0.5507057905197144, "total_time": 1.2147974967956543, "rollout_time": 0.4116806983947754, "train_time": 0.7955164909362793, "student_train_time": 0.0072536468505859375, "throughput": 1646.364933476997, "inference_time": 0.05381075049899664, "env_time": 0.35786994789577875, "samples": 2000, "teacher_eval_reward": 178.0}
{"epoch": 257, "reward_mean": 112.15789473684211, "student_loss": null, "teacher_policy_loss": -37.093326568603516, "teacher_value_loss": 297.0185546875, "teacher_entropy": 0.5436407923698425, "total_time": 1.130204677581787, "rollout_time": 0.39843297004699707, "train_time": 0.7258772850036621, "student_train_time": 0.005537509918212891, "throughput": 1769.5909773433673, "inference_time": 0.05114762775315285, "env_time": 0.3472853422938442, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 258, "reward_mean": 136.3846153846154, "student_loss": null, "teacher_policy_loss": -45.031185150146484, "teacher_value_loss": 379.3460693359375, "teacher_entropy": 0.5665774345397949, "total_time": 1.1698825359344482, "rollout_time": 0.4035766124725342, "train_time": 0.761211633682251, "student_train_time": 0.0047533512115478516, "throughput": 1709.5733448166163, "inference_time": 0.05034822575009912, "env_time": 0.35322838672243506, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 259, "reward_mean": 123.1875, "student_loss": null, "teacher_policy_loss": -40.27370834350586, "teacher_value_loss": 375.990966796875, "teacher_entropy": 0.5494245886802673, "total_time": 1.15226411819458, "rollout_time": 0.3997070789337158, "train_time": 0.7357387542724609, "student_train_time": 0.01646709442138672, "throughput": 1735.713165427464, "inference_time": 0.05177680074689306, "env_time": 0.34793027818682276, "samples": 2000, "teacher_eval_reward": 180.0}
{"epoch": 260, "reward_mean": 140.64285714285714, "student_loss": null, "teacher_policy_loss": -44.807525634765625, "teacher_value_loss": 476.2276611328125, "teacher_entropy": 0.558127760887146, "total_time": 1.1496245861053467, "rollout_time": 0.40376925468444824, "train_time": 0.7320139408111572, "student_train_time": 0.013489723205566406, "throughput": 1739.6983538561244, "inference_time": 0.05322697799761045, "env_time": 0.3505422766868378, "samples": 2000, "teacher_eval_reward": 205.0}
{"epoch": 261, "reward_mean": 159.92307692307693, "student_loss": null, "teacher_policy_loss": -50.52949523925781, "teacher_value_loss": 834.1018676757812, "teacher_entropy": 0.5533090233802795, "total_time": 1.1475770473480225, "rollout_time": 0.3981668949127197, "train_time": 0.7396063804626465, "student_train_time": 0.009462356567382812, "throughput": 1742.8023718510865, "inference_time": 0.05250868400173658, "env_time": 0.34565821091098314, "samples": 2000, "teacher_eval_reward": 178.0}
{"epoch": 262, "reward_mean": 154.6153846153846, "student_loss": null, "teacher_policy_loss": -45.832645416259766, "teacher_value_loss": 452.83026123046875, "teacher_entropy": 0.5633928179740906, "total_time": 1.1773366928100586, "rollout_time": 0.4175879955291748, "train_time": 0.7488594055175781, "student_train_time": 0.010323286056518555, "throughput": 1698.7493995676077, "inference_time": 0.0533871595017672, "env_time": 0.3642008360274076, "samples": 2000, "teacher_eval_reward": 194.0}
{"epoch": 263, "reward_mean": 129.0625, "student_loss": null, "teacher_policy_loss": -42.253299713134766, "teacher_value_loss": 345.21221923828125, "teacher_entropy": 0.5482056140899658, "total_time": 1.2387804985046387, "rollout_time": 0.4189581871032715, "train_time": 0.8070549964904785, "student_train_time": 0.012418746948242188, "throughput": 1614.491027598713, "inference_time": 0.05426953199878426, "env_time": 0.3646886551044872, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 264, "reward_mean": 138.9375, "student_loss": null, "teacher_policy_loss": -47.32416915893555, "teacher_value_loss": 545.7422485351562, "teacher_entropy": 0.5445247292518616, "total_time": 1.152467966079712, "rollout_time": 0.4146695137023926, "train_time": 0.7301895618438721, "student_train_time": 0.007206439971923828, "throughput": 1735.4061534597722, "inference_time": 0.05609051675094179, "env_time": 0.3585789969514508, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 265, "reward_mean": 141.25, "student_loss": null, "teacher_policy_loss": -46.97085189819336, "teacher_value_loss": 317.46063232421875, "teacher_entropy": 0.5613428950309753, "total_time": 1.2285242080688477, "rollout_time": 0.41655468940734863, "train_time": 0.7999842166900635, "student_train_time": 0.011633872985839844, "throughput": 1627.9695482304392, "inference_time": 0.057476741746995685, "env_time": 0.35907794766035295, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 266, "reward_mean": 157.69230769230768, "student_loss": null, "teacher_policy_loss": -46.73469161987305, "teacher_value_loss": 399.219482421875, "teacher_entropy": 0.5437459349632263, "total_time": 1.1152427196502686, "rollout_time": 0.403531551361084, "train_time": 0.7066457271575928, "student_train_time": 0.0047245025634765625, "throughput": 1793.3315902991812, "inference_time": 0.05279541325126047, "env_time": 0.3507361381098235, "samples": 2000, "teacher_eval_reward": 248.0}
{"epoch": 267, "reward_mean": 172.8181818181818, "student_loss": null, "teacher_policy_loss": -50.23111343383789, "teacher_value_loss": 351.0914611816406, "teacher_entropy": 0.563077449798584, "total_time": 1.2602019309997559, "rollout_time": 0.40459656715393066, "train_time": 0.8128108978271484, "student_train_time": 0.0424344539642334, "throughput": 1587.0472428282508, "inference_time": 0.05595691074950082, "env_time": 0.34863965640442984, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 268, "reward_mean": 187.45454545454547, "student_loss": null, "teacher_policy_loss": -48.35126495361328, "teacher_value_loss": 473.44879150390625, "teacher_entropy": 0.5531845092773438, "total_time": 1.4531714916229248, "rollout_time": 0.4177734851837158, "train_time": 1.0010497570037842, "student_train_time": 0.03388404846191406, "throughput": 1376.3000523540195, "inference_time": 0.055119793746030155, "env_time": 0.36265369143768567, "samples": 2000, "teacher_eval_reward": 270.0}
{"epoch": 269, "reward_mean": 178.0909090909091, "student_loss": null, "teacher_policy_loss": -49.282005310058594, "teacher_value_loss": 454.3039245605469, "teacher_entropy": 0.5588196516036987, "total_time": 1.2619593143463135, "rollout_time": 0.41373205184936523, "train_time": 0.8396248817443848, "student_train_time": 0.008180856704711914, "throughput": 1584.8371474923395, "inference_time": 0.05046301675020004, "env_time": 0.3632690350991652, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 270, "reward_mean": 137.76923076923077, "student_loss": null, "teacher_policy_loss": -46.21429443359375, "teacher_value_loss": 342.79217529296875, "teacher_entropy": 0.5506366491317749, "total_time": 1.27154541015625, "rollout_time": 0.4090240001678467, "train_time": 0.837454080581665, "student_train_time": 0.024707794189453125, "throughput": 1572.8891662266597, "inference_time": 0.05335497199951078, "env_time": 0.3556690281683359, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 271, "reward_mean": 133.73333333333332, "student_loss": null, "teacher_policy_loss": -43.30744552612305, "teacher_value_loss": 375.5103759765625, "teacher_entropy": 0.5454791784286499, "total_time": 1.2700908184051514, "rollout_time": 0.4399394989013672, "train_time": 0.8231425285339355, "student_train_time": 0.006649494171142578, "throughput": 1574.69054261127, "inference_time": 0.06575753424988307, "env_time": 0.3741819646514841, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 272, "reward_mean": 159.64285714285714, "student_loss": null, "teacher_policy_loss": -42.918487548828125, "teacher_value_loss": 303.4390869140625, "teacher_entropy": 0.5511409044265747, "total_time": -0.4317455291748047, "rollout_time": -1.2310128211975098, "train_time": 0.7726504802703857, "student_train_time": 0.02619767189025879, "throughput": 200000000000.0, "inference_time": 0.0541254034984604, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 185.0}
{"epoch": 273, "reward_mean": 154.92857142857142, "student_loss": null, "teacher_policy_loss": -46.384883880615234, "teacher_value_loss": 471.9626770019531, "teacher_entropy": 0.5517241358757019, "total_time": 1.1962623596191406, "rollout_time": 0.4060404300689697, "train_time": 0.7826087474822998, "student_train_time": 0.0072290897369384766, "throughput": 1671.874053311139, "inference_time": 0.05240160475409539, "env_time": 0.35363882531487434, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 274, "reward_mean": 217.66666666666666, "student_loss": null, "teacher_policy_loss": -55.02740478515625, "teacher_value_loss": 829.590576171875, "teacher_entropy": 0.5603654980659485, "total_time": 1.217911958694458, "rollout_time": 0.42107081413269043, "train_time": 0.7853775024414062, "student_train_time": 0.011104106903076172, "throughput": 1642.1548254965014, "inference_time": 0.05389386774709237, "env_time": 0.36717694638559806, "samples": 2000, "teacher_eval_reward": 171.0}
{"epoch": 275, "reward_mean": 155.75, "student_loss": null, "teacher_policy_loss": -45.80424880981445, "teacher_value_loss": 390.56915283203125, "teacher_entropy": 0.5527496933937073, "total_time": 1.1529664993286133, "rollout_time": 0.40554165840148926, "train_time": 0.7392482757568359, "student_train_time": 0.007834434509277344, "throughput": 1734.6557780860285, "inference_time": 0.05413831025134641, "env_time": 0.35140334815014285, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 276, "reward_mean": 169.08333333333334, "student_loss": null, "teacher_policy_loss": -49.584835052490234, "teacher_value_loss": 530.0597534179688, "teacher_entropy": 0.5473261475563049, "total_time": 1.2047362327575684, "rollout_time": 0.4164395332336426, "train_time": 0.7639675140380859, "student_train_time": 0.023934364318847656, "throughput": 1660.1144263936687, "inference_time": 0.055448388745617194, "env_time": 0.3609911444880254, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 277, "reward_mean": 145.07142857142858, "student_loss": null, "teacher_policy_loss": -44.71853256225586, "teacher_value_loss": 438.0404052734375, "teacher_entropy": 0.5507117509841919, "total_time": 1.2128393650054932, "rollout_time": 0.4055502414703369, "train_time": 0.7739462852478027, "student_train_time": 0.03298354148864746, "throughput": 1649.0229932394564, "inference_time": 0.05243165199829036, "env_time": 0.35311858947204655, "samples": 2000, "teacher_eval_reward": 336.0}
{"epoch": 278, "reward_mean": 179.0, "student_loss": null, "teacher_policy_loss": -52.0006103515625, "teacher_value_loss": 500.9280700683594, "teacher_entropy": 0.5493943095207214, "total_time": 1.2625184059143066, "rollout_time": 0.4216306209564209, "train_time": 0.8299543857574463, "student_train_time": 0.010592937469482422, "throughput": 1584.135320824582, "inference_time": 0.05487144900052954, "env_time": 0.36675917195589136, "samples": 2000, "teacher_eval_reward": 170.0}
{"epoch": 279, "reward_mean": 179.92307692307693, "student_loss": null, "teacher_policy_loss": -45.16019821166992, "teacher_value_loss": 377.4370422363281, "teacher_entropy": 0.5413593649864197, "total_time": 1.217588186264038, "rollout_time": 0.41150927543640137, "train_time": 0.7972257137298584, "student_train_time": 0.00846099853515625, "throughput": 1642.5914956818522, "inference_time": 0.05607197474751047, "env_time": 0.3554373006888909, "samples": 2000, "teacher_eval_reward": 170.0}
{"epoch": 280, "reward_mean": 172.45454545454547, "student_loss": null, "teacher_policy_loss": -47.579280853271484, "teacher_value_loss": 382.406005859375, "teacher_entropy": 0.5460048317909241, "total_time": 1.226264476776123, "rollout_time": 0.40728139877319336, "train_time": 0.8034393787384033, "student_train_time": 0.015189409255981445, "throughput": 1630.9695321665397, "inference_time": 0.051909169251302956, "env_time": 0.3553722295218904, "samples": 2000, "teacher_eval_reward": 158.0}
{"epoch": 281, "reward_mean": 149.42857142857142, "student_loss": null, "teacher_policy_loss": -43.390960693359375, "teacher_value_loss": 458.9667053222656, "teacher_entropy": 0.5326137542724609, "total_time": 1.3921449184417725, "rollout_time": 0.4143211841583252, "train_time": 0.9722774028778076, "student_train_time": 0.005196094512939453, "throughput": 1436.6320441973812, "inference_time": 0.05224937324999246, "env_time": 0.36207181090833274, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 282, "reward_mean": 179.8181818181818, "student_loss": null, "teacher_policy_loss": -46.88516616821289, "teacher_value_loss": 339.3627624511719, "teacher_entropy": 0.5293563604354858, "total_time": 1.1053993701934814, "rollout_time": 0.40804076194763184, "train_time": 0.6899313926696777, "student_train_time": 0.007073640823364258, "throughput": 1809.3008318341397, "inference_time": 0.05222817599872087, "env_time": 0.35581258594891096, "samples": 2000, "teacher_eval_reward": 234.0}
{"epoch": 283, "reward_mean": 191.1818181818182, "student_loss": null, "teacher_policy_loss": -48.87665557861328, "teacher_value_loss": 463.68499755859375, "teacher_entropy": 0.5587242841720581, "total_time": 1.18153715133667, "rollout_time": 0.4056987762451172, "train_time": 0.7575783729553223, "student_train_time": 0.017877817153930664, "throughput": 1692.7102103707912, "inference_time": 0.05177641325053628, "env_time": 0.3539223629945809, "samples": 2000, "teacher_eval_reward": 190.0}
{"epoch": 284, "reward_mean": 147.53846153846155, "student_loss": null, "teacher_policy_loss": -45.19925308227539, "teacher_value_loss": 449.1240234375, "teacher_entropy": 0.5219976902008057, "total_time": 1.1419367790222168, "rollout_time": 0.4085056781768799, "train_time": 0.7202451229095459, "student_train_time": 0.012828826904296875, "throughput": 1751.4104429778502, "inference_time": 0.05163424199815836, "env_time": 0.3568714361787215, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 285, "reward_mean": 127.53846153846153, "student_loss": null, "teacher_policy_loss": -46.7364501953125, "teacher_value_loss": 394.9739990234375, "teacher_entropy": 0.5311089158058167, "total_time": 1.1193323135375977, "rollout_time": 0.40738725662231445, "train_time": 0.7034759521484375, "student_train_time": 0.008117198944091797, "throughput": 1786.7794718434359, "inference_time": 0.053152795249729934, "env_time": 0.3542344613725845, "samples": 2000, "teacher_eval_reward": 158.0}
{"epoch": 286, "reward_mean": 237.9, "student_loss": null, "teacher_policy_loss": -52.82266616821289, "teacher_value_loss": 500.8291931152344, "teacher_entropy": 0.5474653244018555, "total_time": 1.2785451412200928, "rollout_time": 0.399493932723999, "train_time": 0.869706392288208, "student_train_time": 0.009003162384033203, "throughput": 1564.2779715164659, "inference_time": 0.052458938000086164, "env_time": 0.34703499472391286, "samples": 2000, "teacher_eval_reward": 147.0}
{"epoch": 287, "reward_mean": 189.3, "student_loss": null, "teacher_policy_loss": -49.21217346191406, "teacher_value_loss": 410.30706787109375, "teacher_entropy": 0.5171266198158264, "total_time": -0.5015394687652588, "rollout_time": -1.2603645324707031, "train_time": 0.747183084487915, "student_train_time": 0.011261463165283203, "throughput": 200000000000.0, "inference_time": 0.0494056849994422, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 180.0}
{"epoch": 288, "reward_mean": 174.11111111111111, "student_loss": null, "teacher_policy_loss": -54.28118896484375, "teacher_value_loss": 573.8374633789062, "teacher_entropy": 0.5272728204727173, "total_time": 1.2372770309448242, "rollout_time": 0.42824482917785645, "train_time": 0.7914750576019287, "student_train_time": 0.017154932022094727, "throughput": 1616.452863812348, "inference_time": 0.055419651998022346, "env_time": 0.3728251771798341, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 289, "reward_mean": 240.1, "student_loss": null, "teacher_policy_loss": -50.468936920166016, "teacher_value_loss": 538.5160522460938, "teacher_entropy": 0.5181708335876465, "total_time": 1.1484079360961914, "rollout_time": 0.4035940170288086, "train_time": 0.7371606826782227, "student_train_time": 0.007256031036376953, "throughput": 1741.5414306510668, "inference_time": 0.05403084275110359, "env_time": 0.349563174277705, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 290, "reward_mean": 178.08333333333334, "student_loss": null, "teacher_policy_loss": -42.548797607421875, "teacher_value_loss": 217.0333251953125, "teacher_entropy": 0.49824631214141846, "total_time": 1.2083125114440918, "rollout_time": 0.41467785835266113, "train_time": 0.7817835807800293, "student_train_time": 0.011441230773925781, "throughput": 1655.2009360639145, "inference_time": 0.05304185025386232, "env_time": 0.3616360080987988, "samples": 2000, "teacher_eval_reward": 133.0}
{"epoch": 291, "reward_mean": 191.5, "student_loss": null, "teacher_policy_loss": -55.014102935791016, "teacher_value_loss": 364.66619873046875, "teacher_entropy": 0.5336754322052002, "total_time": 1.1317036151885986, "rollout_time": 0.41043639183044434, "train_time": 0.7095355987548828, "student_train_time": 0.011375665664672852, "throughput": 1767.247160085019, "inference_time": 0.054463235000184795, "env_time": 0.35597315683025954, "samples": 2000, "teacher_eval_reward": 147.0}
{"epoch": 292, "reward_mean": 224.54545454545453, "student_loss": null, "teacher_policy_loss": -50.49690246582031, "teacher_value_loss": 530.5648803710938, "teacher_entropy": 0.5115305185317993, "total_time": 1.2001597881317139, "rollout_time": 0.42342400550842285, "train_time": 0.7608006000518799, "student_train_time": 0.015578746795654297, "throughput": 1666.4447682532304, "inference_time": 0.05832073775025037, "env_time": 0.3651032677581725, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 293, "reward_mean": 163.1818181818182, "student_loss": null, "teacher_policy_loss": -45.48472213745117, "teacher_value_loss": 522.4263916015625, "teacher_entropy": 0.4972057640552521, "total_time": 1.2310693264007568, "rollout_time": 0.40366101264953613, "train_time": 0.8139064311981201, "student_train_time": 0.012897253036499023, "throughput": 1624.6038765723652, "inference_time": 0.05205474799890908, "env_time": 0.35160626465062705, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 294, "reward_mean": 199.0, "student_loss": null, "teacher_policy_loss": -57.321624755859375, "teacher_value_loss": 605.4166259765625, "teacher_entropy": 0.5246151685714722, "total_time": 1.1072964668273926, "rollout_time": 0.3930346965789795, "train_time": 0.7037801742553711, "student_train_time": 0.01006174087524414, "throughput": 1806.201012932306, "inference_time": 0.05162710924980729, "env_time": 0.3414075873291722, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 295, "reward_mean": 192.0, "student_loss": null, "teacher_policy_loss": -46.68092346191406, "teacher_value_loss": 430.49481201171875, "teacher_entropy": 0.5163205862045288, "total_time": 1.3106560707092285, "rollout_time": 0.4015929698944092, "train_time": 0.8977999687194824, "student_train_time": 0.01086878776550293, "throughput": 1525.953333369715, "inference_time": 0.050798156999690036, "env_time": 0.35079481289471914, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 296, "reward_mean": 204.9, "student_loss": null, "teacher_policy_loss": -50.677425384521484, "teacher_value_loss": 390.8185729980469, "teacher_entropy": 0.4967057406902313, "total_time": 1.141880750656128, "rollout_time": 0.3952205181121826, "train_time": 0.7358918190002441, "student_train_time": 0.010389566421508789, "throughput": 1751.4963789789733, "inference_time": 0.05279126625032404, "env_time": 0.3424292518618586, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 297, "reward_mean": 180.41666666666666, "student_loss": null, "teacher_policy_loss": -51.04087448120117, "teacher_value_loss": 594.9156494140625, "teacher_entropy": 0.5353596210479736, "total_time": 1.188040018081665, "rollout_time": 0.39856767654418945, "train_time": 0.775601863861084, "student_train_time": 0.013457775115966797, "throughput": 1683.4449762301874, "inference_time": 0.05388576149732671, "env_time": 0.34468191504686274, "samples": 2000, "teacher_eval_reward": 161.0}
{"epoch": 298, "reward_mean": 185.3, "student_loss": null, "teacher_policy_loss": -48.89235305786133, "teacher_value_loss": 426.1378173828125, "teacher_entropy": 0.5047165155410767, "total_time": 1.209660530090332, "rollout_time": 0.4273092746734619, "train_time": 0.7713432312011719, "student_train_time": 0.010654211044311523, "throughput": 1653.3564171517185, "inference_time": 0.055266420751877376, "env_time": 0.37204285392158454, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 299, "reward_mean": 164.2, "student_loss": null, "teacher_policy_loss": -47.642547607421875, "teacher_value_loss": 314.99847412109375, "teacher_entropy": 0.5120540261268616, "total_time": 1.1514215469360352, "rollout_time": 0.408494234085083, "train_time": 0.7301280498504639, "student_train_time": 0.012450218200683594, "throughput": 1736.9833014868063, "inference_time": 0.054055284250353, "env_time": 0.35443894983473, "samples": 2000, "teacher_eval_reward": 162.0}
{"epoch": 300, "reward_mean": 161.5, "student_loss": null, "teacher_policy_loss": -42.4996337890625, "teacher_value_loss": 423.9523010253906, "teacher_entropy": 0.5158713459968567, "total_time": 1.1358816623687744, "rollout_time": 0.40886402130126953, "train_time": 0.7197668552398682, "student_train_time": 0.006659746170043945, "throughput": 1760.7467980680206, "inference_time": 0.05466046474612085, "env_time": 0.3542035565551487, "samples": 2000, "teacher_eval_reward": 118.0}
{"epoch": 301, "reward_mean": 156.9, "student_loss": null, "teacher_policy_loss": -47.11840057373047, "teacher_value_loss": 421.53619384765625, "teacher_entropy": 0.5085967779159546, "total_time": 1.2210493087768555, "rollout_time": 0.4077332019805908, "train_time": 0.7886989116668701, "student_train_time": 0.02421879768371582, "throughput": 1637.9354917316418, "inference_time": 0.05274863749718861, "env_time": 0.3549845644834022, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 302, "reward_mean": 261.125, "student_loss": null, "teacher_policy_loss": -51.38908386230469, "teacher_value_loss": 517.36962890625, "teacher_entropy": 0.5002447366714478, "total_time": 1.0775935649871826, "rollout_time": 0.3891870975494385, "train_time": 0.6763284206390381, "student_train_time": 0.011727571487426758, "throughput": 1855.987326746693, "inference_time": 0.0515534067454837, "env_time": 0.3376336908039548, "samples": 2000, "teacher_eval_reward": 181.0}
{"epoch": 303, "reward_mean": 229.9, "student_loss": null, "teacher_policy_loss": -50.10966873168945, "teacher_value_loss": 628.7962036132812, "teacher_entropy": 0.523632824420929, "total_time": 1.310333490371704, "rollout_time": 0.41889119148254395, "train_time": 0.8766891956329346, "student_train_time": 0.014322280883789062, "throughput": 1526.328995401512, "inference_time": 0.055597960251361656, "env_time": 0.3632932312311823, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 304, "reward_mean": 195.27272727272728, "student_loss": null, "teacher_policy_loss": -48.45741653442383, "teacher_value_loss": 479.10919189453125, "teacher_entropy": 0.5235058665275574, "total_time": 1.3093864917755127, "rollout_time": 0.5258142948150635, "train_time": 0.7764401435852051, "student_train_time": 0.006667137145996094, "throughput": 1527.4328951477294, "inference_time": 0.05393358125093073, "env_time": 0.47188071356413275, "samples": 2000, "teacher_eval_reward": 144.0}
{"epoch": 305, "reward_mean": 221.85714285714286, "student_loss": null, "teacher_policy_loss": -53.69062042236328, "teacher_value_loss": 441.73724365234375, "teacher_entropy": 0.5104512572288513, "total_time": 1.1340382099151611, "rollout_time": 0.3963584899902344, "train_time": 0.7325093746185303, "student_train_time": 0.004826784133911133, "throughput": 1763.6090058637642, "inference_time": 0.053154124497041266, "env_time": 0.3432043654931931, "samples": 2000, "teacher_eval_reward": 120.0}
{"epoch": 306, "reward_mean": 191.46153846153845, "student_loss": null, "teacher_policy_loss": -45.23937225341797, "teacher_value_loss": 304.547119140625, "teacher_entropy": 0.5104594230651855, "total_time": 1.1299004554748535, "rollout_time": 0.4091451168060303, "train_time": 0.7123210430145264, "student_train_time": 0.008091211318969727, "throughput": 1770.0674340904459, "inference_time": 0.05151949450043958, "env_time": 0.3576256223055907, "samples": 2000, "teacher_eval_reward": 388.0}
{"epoch": 307, "reward_mean": 181.4, "student_loss": null, "teacher_policy_loss": -52.280277252197266, "teacher_value_loss": 342.031494140625, "teacher_entropy": 0.5145564675331116, "total_time": 1.2104406356811523, "rollout_time": 0.4203770160675049, "train_time": 0.7772102355957031, "student_train_time": 0.012415885925292969, "throughput": 1652.29086090169, "inference_time": 0.05284849349902743, "env_time": 0.36752852256847746, "samples": 2000, "teacher_eval_reward": 178.0}
{"epoch": 308, "reward_mean": 173.33333333333334, "student_loss": null, "teacher_policy_loss": -49.489776611328125, "teacher_value_loss": 542.6325073242188, "teacher_entropy": 0.494675874710083, "total_time": 1.3607189655303955, "rollout_time": 0.4054276943206787, "train_time": 0.9315245151519775, "student_train_time": 0.02331995964050293, "throughput": 1469.8112179397888, "inference_time": 0.050851260251306485, "env_time": 0.3545764340693722, "samples": 2000, "teacher_eval_reward": 172.0}
{"epoch": 309, "reward_mean": 194.72727272727272, "student_loss": null, "teacher_policy_loss": -51.945892333984375, "teacher_value_loss": 499.2650451660156, "teacher_entropy": 0.5278844833374023, "total_time": 1.1731984615325928, "rollout_time": 0.4019432067871094, "train_time": 0.7629988193511963, "student_train_time": 0.007892608642578125, "throughput": 1704.7414104066636, "inference_time": 0.05275403525172351, "env_time": 0.34918917153538587, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 310, "reward_mean": 143.07142857142858, "student_loss": null, "teacher_policy_loss": -43.98942565917969, "teacher_value_loss": 762.5177612304688, "teacher_entropy": 0.5065089464187622, "total_time": 1.250608205795288, "rollout_time": 0.4023170471191406, "train_time": 0.8354275226593018, "student_train_time": 0.012422800064086914, "throughput": 1599.2218751900464, "inference_time": 0.05351654325261279, "env_time": 0.34880050386652783, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 311, "reward_mean": 202.5, "student_loss": null, "teacher_policy_loss": -50.451263427734375, "teacher_value_loss": 466.726318359375, "teacher_entropy": 0.4944114089012146, "total_time": 1.3846848011016846, "rollout_time": 0.4197046756744385, "train_time": 0.9586787223815918, "student_train_time": 0.005951642990112305, "throughput": 1444.3720321106707, "inference_time": 0.05557845050088872, "env_time": 0.36412622517354976, "samples": 2000, "teacher_eval_reward": 160.0}
{"epoch": 312, "reward_mean": 218.875, "student_loss": null, "teacher_policy_loss": -54.98054504394531, "teacher_value_loss": 493.4008483886719, "teacher_entropy": 0.5398289561271667, "total_time": 1.1647813320159912, "rollout_time": 0.41306400299072266, "train_time": 0.7423055171966553, "student_train_time": 0.009008407592773438, "throughput": 1717.060485969861, "inference_time": 0.05263334399910491, "env_time": 0.36043065899161775, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 313, "reward_mean": 208.9090909090909, "student_loss": null, "teacher_policy_loss": -45.94695281982422, "teacher_value_loss": 253.59678649902344, "teacher_entropy": 0.5238072276115417, "total_time": 1.1825542449951172, "rollout_time": 0.42427635192871094, "train_time": 0.7502157688140869, "student_train_time": 0.007656574249267578, "throughput": 1691.2543407328076, "inference_time": 0.05430382099802955, "env_time": 0.3699725309306814, "samples": 2000, "teacher_eval_reward": 193.0}
{"epoch": 314, "reward_mean": 226.44444444444446, "student_loss": null, "teacher_policy_loss": -55.10057067871094, "teacher_value_loss": 593.5026245117188, "teacher_entropy": 0.5393471121788025, "total_time": 1.2425262928009033, "rollout_time": 0.4447627067565918, "train_time": 0.7891457080841064, "student_train_time": 0.008258819580078125, "throughput": 1609.6238861003087, "inference_time": 0.05713756224668032, "env_time": 0.3876251445099115, "samples": 2000, "teacher_eval_reward": 297.0}
{"epoch": 315, "reward_mean": 207.9, "student_loss": null, "teacher_policy_loss": -53.001922607421875, "teacher_value_loss": 589.125732421875, "teacher_entropy": 0.5267926454544067, "total_time": 1.2054100036621094, "rollout_time": 0.4171171188354492, "train_time": 0.7779829502105713, "student_train_time": 0.00991368293762207, "throughput": 1659.186495817919, "inference_time": 0.05650330425385164, "env_time": 0.3606138145815976, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 316, "reward_mean": 232.57142857142858, "student_loss": null, "teacher_policy_loss": -56.5914421081543, "teacher_value_loss": 514.8821411132812, "teacher_entropy": 0.5387580394744873, "total_time": 1.2025136947631836, "rollout_time": 0.40265512466430664, "train_time": 0.7911696434020996, "student_train_time": 0.008191823959350586, "throughput": 1663.182721918081, "inference_time": 0.054250134997573696, "env_time": 0.34840498966673294, "samples": 2000, "teacher_eval_reward": 180.0}
{"epoch": 317, "reward_mean": 239.5, "student_loss": null, "teacher_policy_loss": -52.045936584472656, "teacher_value_loss": 407.411376953125, "teacher_entropy": 0.5292636156082153, "total_time": 1.1657235622406006, "rollout_time": 0.42295050621032715, "train_time": 0.731900691986084, "student_train_time": 0.010473251342773438, "throughput": 1715.6726215226042, "inference_time": 0.054914730500399855, "env_time": 0.3680357757099273, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 318, "reward_mean": 172.6, "student_loss": null, "teacher_policy_loss": -51.91107940673828, "teacher_value_loss": 498.252197265625, "teacher_entropy": 0.5232536196708679, "total_time": 1.2192800045013428, "rollout_time": 0.42470836639404297, "train_time": 0.783613920211792, "student_train_time": 0.010608673095703125, "throughput": 1640.312309409153, "inference_time": 0.053120203250614395, "env_time": 0.3715881631434286, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 319, "reward_mean": 216.36363636363637, "student_loss": null, "teacher_policy_loss": -52.24800109863281, "teacher_value_loss": 443.5586853027344, "teacher_entropy": 0.5405799746513367, "total_time": 1.4241108894348145, "rollout_time": 0.4250500202178955, "train_time": 0.9926660060882568, "student_train_time": 0.006033182144165039, "throughput": 1404.3850200413383, "inference_time": 0.05357512424939159, "env_time": 0.3714748959685039, "samples": 2000, "teacher_eval_reward": 199.0}
{"epoch": 320, "reward_mean": 196.9, "student_loss": null, "teacher_policy_loss": -48.26566696166992, "teacher_value_loss": 523.64404296875, "teacher_entropy": 0.5401527881622314, "total_time": 1.2132058143615723, "rollout_time": 0.4145205020904541, "train_time": 0.7919313907623291, "student_train_time": 0.006352663040161133, "throughput": 1648.5249051105677, "inference_time": 0.054668875499373826, "env_time": 0.3598516265910803, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 321, "reward_mean": 217.33333333333334, "student_loss": null, "teacher_policy_loss": -56.779075622558594, "teacher_value_loss": 624.7879028320312, "teacher_entropy": 0.5347416400909424, "total_time": 1.2236149311065674, "rollout_time": 0.4104900360107422, "train_time": 0.80753493309021, "student_train_time": 0.005202054977416992, "throughput": 1634.5011401514319, "inference_time": 0.052409852499636145, "env_time": 0.35808018351110604, "samples": 2000, "teacher_eval_reward": 267.0}
{"epoch": 322, "reward_mean": 181.45454545454547, "student_loss": null, "teacher_policy_loss": -49.426265716552734, "teacher_value_loss": 677.1359252929688, "teacher_entropy": 0.5337226986885071, "total_time": 1.2282581329345703, "rollout_time": 0.4063529968261719, "train_time": 0.8149940967559814, "student_train_time": 0.006571054458618164, "throughput": 1628.322212059426, "inference_time": 0.05354976550120227, "env_time": 0.3528032313249696, "samples": 2000, "teacher_eval_reward": 331.0}
{"epoch": 323, "reward_mean": 165.5, "student_loss": null, "teacher_policy_loss": -45.178165435791016, "teacher_value_loss": 286.0013427734375, "teacher_entropy": 0.5267543196678162, "total_time": 1.129817008972168, "rollout_time": 0.4159841537475586, "train_time": 0.7067697048187256, "student_train_time": 0.006718158721923828, "throughput": 1770.1981684799262, "inference_time": 0.05337220025444367, "env_time": 0.3626119534931149, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 324, "reward_mean": 207.0, "student_loss": null, "teacher_policy_loss": -54.61881637573242, "teacher_value_loss": 766.2064819335938, "teacher_entropy": 0.5433922410011292, "total_time": 1.203514814376831, "rollout_time": 0.4232451915740967, "train_time": 0.7716131210327148, "student_train_time": 0.008313655853271484, "throughput": 1661.7992367925954, "inference_time": 0.05484310075257781, "env_time": 0.36840209082151887, "samples": 2000, "teacher_eval_reward": 166.0}
{"epoch": 325, "reward_mean": 193.0, "student_loss": null, "teacher_policy_loss": -48.38258743286133, "teacher_value_loss": 387.15838623046875, "teacher_entropy": 0.5326452851295471, "total_time": 1.241917610168457, "rollout_time": 0.4131166934967041, "train_time": 0.8025896549224854, "student_train_time": 0.025850772857666016, "throughput": 1610.4127871483477, "inference_time": 0.05199410925195025, "env_time": 0.36112258424475385, "samples": 2000, "teacher_eval_reward": 383.0}
{"epoch": 326, "reward_mean": 237.11111111111111, "student_loss": null, "teacher_policy_loss": -52.8720588684082, "teacher_value_loss": 397.9140625, "teacher_entropy": 0.5248702168464661, "total_time": 1.2434051036834717, "rollout_time": 0.4315516948699951, "train_time": 0.8026525974273682, "student_train_time": 0.008840084075927734, "throughput": 1608.4862399834024, "inference_time": 0.056087909498501176, "env_time": 0.37546378537149394, "samples": 2000, "teacher_eval_reward": 178.0}
{"epoch": 327, "reward_mean": 209.77777777777777, "student_loss": null, "teacher_policy_loss": -48.083404541015625, "teacher_value_loss": 460.6171875, "teacher_entropy": 0.5181218981742859, "total_time": 1.2131457328796387, "rollout_time": 0.4494748115539551, "train_time": 0.7568197250366211, "student_train_time": 0.006494998931884766, "throughput": 1648.6065489037403, "inference_time": 0.05626540199682495, "env_time": 0.39320940955713013, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 328, "reward_mean": 209.63636363636363, "student_loss": null, "teacher_policy_loss": -53.1159782409668, "teacher_value_loss": 613.814208984375, "teacher_entropy": 0.5297435522079468, "total_time": 1.1650824546813965, "rollout_time": 0.40612220764160156, "train_time": 0.7493391036987305, "student_train_time": 0.009263992309570312, "throughput": 1716.6167012161557, "inference_time": 0.051674536502105184, "env_time": 0.3544476711394964, "samples": 2000, "teacher_eval_reward": 204.0}
{"epoch": 329, "reward_mean": 219.77777777777777, "student_loss": null, "teacher_policy_loss": -52.74327850341797, "teacher_value_loss": 401.5453796386719, "teacher_entropy": 0.5306904911994934, "total_time": 1.297356367111206, "rollout_time": 0.407620906829834, "train_time": 0.8816556930541992, "student_train_time": 0.007727622985839844, "throughput": 1541.5964731828885, "inference_time": 0.05305999524819072, "env_time": 0.35456091158164327, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 330, "reward_mean": 209.3, "student_loss": null, "teacher_policy_loss": -51.51660919189453, "teacher_value_loss": 455.5116271972656, "teacher_entropy": 0.527644157409668, "total_time": -0.4150965213775635, "rollout_time": -1.2690446376800537, "train_time": 0.8469092845916748, "student_train_time": 0.0066852569580078125, "throughput": 200000000000.0, "inference_time": 0.052127262248745865, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 331, "reward_mean": 190.875, "student_loss": null, "teacher_policy_loss": -55.70115661621094, "teacher_value_loss": 558.2589721679688, "teacher_entropy": 0.5355709791183472, "total_time": 1.2981250286102295, "rollout_time": 0.4411334991455078, "train_time": 0.8503553867340088, "student_train_time": 0.006278514862060547, "throughput": 1540.6836444261435, "inference_time": 0.05739904550284791, "env_time": 0.3837344536426599, "samples": 2000, "teacher_eval_reward": 174.0}
{"epoch": 332, "reward_mean": 284.85714285714283, "student_loss": null, "teacher_policy_loss": -52.15222930908203, "teacher_value_loss": 633.110107421875, "teacher_entropy": 0.5066449642181396, "total_time": 1.279587745666504, "rollout_time": 0.40621447563171387, "train_time": 0.8647820949554443, "student_train_time": 0.008194684982299805, "throughput": 1563.0034022858292, "inference_time": 0.05105006450287419, "env_time": 0.3551644111288397, "samples": 2000, "teacher_eval_reward": 131.0}
{"epoch": 333, "reward_mean": 250.44444444444446, "student_loss": null, "teacher_policy_loss": -48.83431625366211, "teacher_value_loss": 514.2868041992188, "teacher_entropy": 0.507411003112793, "total_time": 1.165804147720337, "rollout_time": 0.419858455657959, "train_time": 0.7357432842254639, "student_train_time": 0.009701251983642578, "throughput": 1715.554026729863, "inference_time": 0.05402594100132774, "env_time": 0.36583251465663125, "samples": 2000, "teacher_eval_reward": 210.0}
{"epoch": 334, "reward_mean": 205.44444444444446, "student_loss": null, "teacher_policy_loss": -49.74951171875, "teacher_value_loss": 452.2373046875, "teacher_entropy": 0.531004011631012, "total_time": 1.2846205234527588, "rollout_time": 0.4033772945404053, "train_time": 0.8723347187042236, "student_train_time": 0.008562326431274414, "throughput": 1556.8799995694205, "inference_time": 0.052328388499745415, "env_time": 0.35104890604065986, "samples": 2000, "teacher_eval_reward": 337.0}
{"epoch": 335, "reward_mean": 224.88888888888889, "student_loss": null, "teacher_policy_loss": -53.167877197265625, "teacher_value_loss": 383.57977294921875, "teacher_entropy": 0.5334059596061707, "total_time": 1.1709668636322021, "rollout_time": 0.40405774116516113, "train_time": 0.7516918182373047, "student_train_time": 0.014851808547973633, "throughput": 1707.9902618219564, "inference_time": 0.05197702974805907, "env_time": 0.35208071141710207, "samples": 2000, "teacher_eval_reward": 201.0}
{"epoch": 336, "reward_mean": 235.88888888888889, "student_loss": null, "teacher_policy_loss": -52.36363983154297, "teacher_value_loss": 452.95458984375, "teacher_entropy": 0.5348520278930664, "total_time": 1.2720329761505127, "rollout_time": 0.4290809631347656, "train_time": 0.829676628112793, "student_train_time": 0.012838602066040039, "throughput": 1572.2862830588685, "inference_time": 0.05144476999896597, "env_time": 0.37763619313579966, "samples": 2000, "teacher_eval_reward": 335.0}
{"epoch": 337, "reward_mean": 230.71428571428572, "student_loss": null, "teacher_policy_loss": -56.69162368774414, "teacher_value_loss": 522.439453125, "teacher_entropy": 0.5251504182815552, "total_time": 1.1503846645355225, "rollout_time": 0.41292452812194824, "train_time": 0.7318325042724609, "student_train_time": 0.005277872085571289, "throughput": 1738.548905993559, "inference_time": 0.050751085246929506, "env_time": 0.36217344287501874, "samples": 2000, "teacher_eval_reward": 164.0}
{"epoch": 338, "reward_mean": 290.8888888888889, "student_loss": null, "teacher_policy_loss": -52.024044036865234, "teacher_value_loss": 696.6919555664062, "teacher_entropy": 0.5310524702072144, "total_time": 1.255605936050415, "rollout_time": 0.418961763381958, "train_time": 0.8246607780456543, "student_train_time": 0.011523246765136719, "throughput": 1592.8564389326812, "inference_time": 0.052632270750450516, "env_time": 0.3663294926315075, "samples": 2000, "teacher_eval_reward": 157.0}
{"epoch": 339, "reward_mean": 165.0909090909091, "student_loss": null, "teacher_policy_loss": -52.514312744140625, "teacher_value_loss": 720.1312255859375, "teacher_entropy": 0.5162914991378784, "total_time": 1.1187467575073242, "rollout_time": 0.40462374687194824, "train_time": 0.7061705589294434, "student_train_time": 0.0076029300689697266, "throughput": 1787.714678571398, "inference_time": 0.05308418050151431, "env_time": 0.35153956637043393, "samples": 2000, "teacher_eval_reward": 191.0}
{"epoch": 340, "reward_mean": 232.85714285714286, "student_loss": null, "teacher_policy_loss": -53.80087661743164, "teacher_value_loss": 346.9471130371094, "teacher_entropy": 0.5324053764343262, "total_time": 1.235520839691162, "rollout_time": 0.4141666889190674, "train_time": 0.8072712421417236, "student_train_time": 0.013722896575927734, "throughput": 1618.7505186071419, "inference_time": 0.05638730050111462, "env_time": 0.35777938841795276, "samples": 2000, "teacher_eval_reward": 411.0}
{"epoch": 341, "reward_mean": 218.45454545454547, "student_loss": null, "teacher_policy_loss": -53.56926345825195, "teacher_value_loss": 620.4510498046875, "teacher_entropy": 0.5245060920715332, "total_time": 1.2780094146728516, "rollout_time": 0.4153635501861572, "train_time": 0.8553423881530762, "student_train_time": 0.00694584846496582, "throughput": 1564.9336984829376, "inference_time": 0.053067523003392125, "env_time": 0.3622960271827651, "samples": 2000, "teacher_eval_reward": 337.0}
{"epoch": 342, "reward_mean": 214.0, "student_loss": null, "teacher_policy_loss": -59.12479782104492, "teacher_value_loss": 532.4985961914062, "teacher_entropy": 0.5229161381721497, "total_time": 1.2637388706207275, "rollout_time": 0.4000208377838135, "train_time": 0.8578674793243408, "student_train_time": 0.005510568618774414, "throughput": 1582.6054309919527, "inference_time": 0.05360049999910643, "env_time": 0.34642033778470704, "samples": 2000, "teacher_eval_reward": 312.0}
{"epoch": 343, "reward_mean": 213.4, "student_loss": null, "teacher_policy_loss": -50.35350036621094, "teacher_value_loss": 418.40521240234375, "teacher_entropy": 0.5050705671310425, "total_time": 1.3353614807128906, "rollout_time": 0.5605118274688721, "train_time": 0.7628505229949951, "student_train_time": 0.01160287857055664, "throughput": 1497.7217995926378, "inference_time": 0.07658754475471596, "env_time": 0.4839242827141561, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 344, "reward_mean": 207.66666666666666, "student_loss": null, "teacher_policy_loss": -53.760711669921875, "teacher_value_loss": 606.6710205078125, "teacher_entropy": 0.521542489528656, "total_time": 1.2623367309570312, "rollout_time": 0.4295778274536133, "train_time": 0.8220298290252686, "student_train_time": 0.01038980484008789, "throughput": 1584.3633088959668, "inference_time": 0.05675902075176964, "env_time": 0.37281880670184364, "samples": 2000, "teacher_eval_reward": 186.0}
{"epoch": 345, "reward_mean": 246.66666666666666, "student_loss": null, "teacher_policy_loss": -53.8369140625, "teacher_value_loss": 646.2072143554688, "teacher_entropy": 0.5172674059867859, "total_time": 1.1594138145446777, "rollout_time": 0.4257504940032959, "train_time": 0.7245950698852539, "student_train_time": 0.008658885955810547, "throughput": 1725.0096341015526, "inference_time": 0.05458321250011977, "env_time": 0.3711672815031761, "samples": 2000, "teacher_eval_reward": 201.0}
{"epoch": 346, "reward_mean": 203.6, "student_loss": null, "teacher_policy_loss": -50.378578186035156, "teacher_value_loss": 525.396728515625, "teacher_entropy": 0.5114099979400635, "total_time": 1.208122730255127, "rollout_time": 0.41751670837402344, "train_time": 0.7804696559906006, "student_train_time": 0.009706497192382812, "throughput": 1655.4609477280899, "inference_time": 0.05308089550010209, "env_time": 0.36443581287392135, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 347, "reward_mean": 220.55555555555554, "student_loss": null, "teacher_policy_loss": -49.69231414794922, "teacher_value_loss": 377.6731262207031, "teacher_entropy": 0.5151970982551575, "total_time": 1.1678626537322998, "rollout_time": 0.4082498550415039, "train_time": 0.7543284893035889, "student_train_time": 0.004941463470458984, "throughput": 1712.5301452258311, "inference_time": 0.052996822002342014, "env_time": 0.3552530330391619, "samples": 2000, "teacher_eval_reward": 299.0}
{"epoch": 348, "reward_mean": 170.75, "student_loss": null, "teacher_policy_loss": -48.281307220458984, "teacher_value_loss": 458.0141906738281, "teacher_entropy": 0.5280707478523254, "total_time": 1.152320384979248, "rollout_time": 0.4143824577331543, "train_time": 0.726273775100708, "student_train_time": 0.011277914047241211, "throughput": 1735.6284120895923, "inference_time": 0.05311725899605335, "env_time": 0.36126519873710095, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 349, "reward_mean": 282.14285714285717, "student_loss": null, "teacher_policy_loss": -57.28140640258789, "teacher_value_loss": 622.9988403320312, "teacher_entropy": 0.5340334177017212, "total_time": 1.1732306480407715, "rollout_time": 0.3916151523590088, "train_time": 0.7747530937194824, "student_train_time": 0.006520986557006836, "throughput": 1704.69464238757, "inference_time": 0.05091745924755742, "env_time": 0.34069769311145137, "samples": 2000, "teacher_eval_reward": 394.0}
{"epoch": 350, "reward_mean": 221.3, "student_loss": null, "teacher_policy_loss": -52.157325744628906, "teacher_value_loss": 423.3927307128906, "teacher_entropy": 0.5160495638847351, "total_time": 1.1936671733856201, "rollout_time": 0.40074801445007324, "train_time": 0.7824065685272217, "student_train_time": 0.010165929794311523, "throughput": 1675.5089229163966, "inference_time": 0.05084615250234492, "env_time": 0.3499018619477283, "samples": 2000, "teacher_eval_reward": 488.0}
{"epoch": 351, "reward_mean": 178.1, "student_loss": null, "teacher_policy_loss": -49.54146194458008, "teacher_value_loss": 607.0946655273438, "teacher_entropy": 0.5227499008178711, "total_time": 1.1489522457122803, "rollout_time": 0.4044790267944336, "train_time": 0.7138996124267578, "student_train_time": 0.030170202255249023, "throughput": 1740.716385266406, "inference_time": 0.05124563025140105, "env_time": 0.35323339654303254, "samples": 2000, "teacher_eval_reward": 337.0}
{"epoch": 352, "reward_mean": 263.14285714285717, "student_loss": null, "teacher_policy_loss": -55.0522575378418, "teacher_value_loss": 560.179931640625, "teacher_entropy": 0.5280742049217224, "total_time": 1.1809587478637695, "rollout_time": 0.4282665252685547, "train_time": 0.7310729026794434, "student_train_time": 0.02124953269958496, "throughput": 1693.539256657178, "inference_time": 0.056723875499756105, "env_time": 0.3715426497687986, "samples": 2000, "teacher_eval_reward": 157.0}
{"epoch": 353, "reward_mean": 232.3, "student_loss": null, "teacher_policy_loss": -51.19023132324219, "teacher_value_loss": 566.1488037109375, "teacher_entropy": 0.5193138718605042, "total_time": 1.2357957363128662, "rollout_time": 0.4187636375427246, "train_time": 0.8087952136993408, "student_train_time": 0.00789785385131836, "throughput": 1618.3904355967613, "inference_time": 0.055077963250369066, "env_time": 0.36368567429235554, "samples": 2000, "teacher_eval_reward": 194.0}
{"epoch": 354, "reward_mean": 239.0, "student_loss": null, "teacher_policy_loss": -55.57008743286133, "teacher_value_loss": 513.7216796875, "teacher_entropy": 0.5299258232116699, "total_time": 1.1202163696289062, "rollout_time": 0.4063858985900879, "train_time": 0.6997511386871338, "student_train_time": 0.013734102249145508, "throughput": 1785.3693752596557, "inference_time": 0.05222035999963737, "env_time": 0.3541655385904505, "samples": 2000, "teacher_eval_reward": 259.0}
{"epoch": 355, "reward_mean": 270.0, "student_loss": null, "teacher_policy_loss": -59.32254409790039, "teacher_value_loss": 547.0914916992188, "teacher_entropy": 0.5273002982139587, "total_time": 1.3683292865753174, "rollout_time": 0.41571855545043945, "train_time": 0.9401776790618896, "student_train_time": 0.012083768844604492, "throughput": 1461.63647860351, "inference_time": 0.05256741349910499, "env_time": 0.36315114195133447, "samples": 2000, "teacher_eval_reward": 383.0}
{"epoch": 356, "reward_mean": 286.0, "student_loss": null, "teacher_policy_loss": -53.550540924072266, "teacher_value_loss": 492.6673889160156, "teacher_entropy": 0.5370096564292908, "total_time": -0.4729185104370117, "rollout_time": 0.4095308780670166, "train_time": -0.890798807144165, "student_train_time": 0.00799703598022461, "throughput": 200000000000.0, "inference_time": 0.0545262637505175, "env_time": 0.3550046143164991, "samples": 2000, "teacher_eval_reward": 361.0}
{"epoch": 357, "reward_mean": 211.0, "student_loss": null, "teacher_policy_loss": -49.19308853149414, "teacher_value_loss": 522.1583251953125, "teacher_entropy": 0.5244922041893005, "total_time": 1.2169218063354492, "rollout_time": 0.4153099060058594, "train_time": 0.7944517135620117, "student_train_time": 0.0068089962005615234, "throughput": 1643.4909700752721, "inference_time": 0.05612354025060995, "env_time": 0.3591863657552494, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 358, "reward_mean": 208.66666666666666, "student_loss": null, "teacher_policy_loss": -56.04778289794922, "teacher_value_loss": 653.5938110351562, "teacher_entropy": 0.5230465531349182, "total_time": 1.2797362804412842, "rollout_time": 0.41478514671325684, "train_time": 0.8560690879821777, "student_train_time": 0.00853276252746582, "throughput": 1562.8219896292628, "inference_time": 0.053140478500381505, "env_time": 0.36164466821287533, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 359, "reward_mean": 272.25, "student_loss": null, "teacher_policy_loss": -55.349491119384766, "teacher_value_loss": 602.4933471679688, "teacher_entropy": 0.5264986157417297, "total_time": 1.183861494064331, "rollout_time": 0.4044027328491211, "train_time": 0.7719428539276123, "student_train_time": 0.00715947151184082, "throughput": 1689.386815964233, "inference_time": 0.053033005000315825, "env_time": 0.35136972784880527, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 360, "reward_mean": 281.875, "student_loss": null, "teacher_policy_loss": -56.629398345947266, "teacher_value_loss": 495.3282470703125, "teacher_entropy": 0.531353771686554, "total_time": 1.2797391414642334, "rollout_time": 0.4321272373199463, "train_time": 0.8307156562805176, "student_train_time": 0.01653313636779785, "throughput": 1562.8184957378649, "inference_time": 0.057900769249613404, "env_time": 0.3742264680703329, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 361, "reward_mean": 188.125, "student_loss": null, "teacher_policy_loss": -54.90922546386719, "teacher_value_loss": 418.61676025390625, "teacher_entropy": 0.5270331501960754, "total_time": 1.150822401046753, "rollout_time": 0.4135749340057373, "train_time": 0.7301943302154541, "student_train_time": 0.006708383560180664, "throughput": 1737.8876168736906, "inference_time": 0.05497177474819637, "env_time": 0.35860315925754094, "samples": 2000, "teacher_eval_reward": 283.0}
{"epoch": 362, "reward_mean": 300.2857142857143, "student_loss": null, "teacher_policy_loss": -54.993526458740234, "teacher_value_loss": 455.16583251953125, "teacher_entropy": 0.534693717956543, "total_time": 1.2471168041229248, "rollout_time": 0.41208815574645996, "train_time": 0.8269948959350586, "student_train_time": 0.007687807083129883, "throughput": 1603.69902272832, "inference_time": 0.053416014748449925, "env_time": 0.35867214099801004, "samples": 2000, "teacher_eval_reward": 210.0}
{"epoch": 363, "reward_mean": 250.33333333333334, "student_loss": null, "teacher_policy_loss": -52.88759231567383, "teacher_value_loss": 438.4243469238281, "teacher_entropy": 0.5328666567802429, "total_time": 1.2688281536102295, "rollout_time": 0.3977222442626953, "train_time": 0.8625586032867432, "student_train_time": 0.008161306381225586, "throughput": 1576.2575840623874, "inference_time": 0.052680368751566675, "env_time": 0.34504187551112864, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 364, "reward_mean": 203.2, "student_loss": null, "teacher_policy_loss": -48.85789108276367, "teacher_value_loss": 417.8091735839844, "teacher_entropy": 0.5273206233978271, "total_time": 1.3392274379730225, "rollout_time": 0.4083547592163086, "train_time": 0.9193403720855713, "student_train_time": 0.01114511489868164, "throughput": 1493.3983155445835, "inference_time": 0.05416985075032699, "env_time": 0.3541849084659816, "samples": 2000, "teacher_eval_reward": 280.0}
{"epoch": 365, "reward_mean": 226.625, "student_loss": null, "teacher_policy_loss": -53.296600341796875, "teacher_value_loss": 499.9397888183594, "teacher_entropy": 0.5297086238861084, "total_time": 1.1998891830444336, "rollout_time": 0.41988229751586914, "train_time": 0.7706525325775146, "student_train_time": 0.009005069732666016, "throughput": 1666.8205933196891, "inference_time": 0.05247327200174823, "env_time": 0.3674090255141209, "samples": 2000, "teacher_eval_reward": 264.0}
{"epoch": 366, "reward_mean": 236.11111111111111, "student_loss": null, "teacher_policy_loss": -53.22877883911133, "teacher_value_loss": 409.92242431640625, "teacher_entropy": 0.525648295879364, "total_time": 1.1756675243377686, "rollout_time": 0.4130058288574219, "train_time": 0.755112886428833, "student_train_time": 0.007208108901977539, "throughput": 1701.161219985695, "inference_time": 0.05293634075155751, "env_time": 0.36006948810586437, "samples": 2000, "teacher_eval_reward": 181.0}
{"epoch": 367, "reward_mean": 287.0, "student_loss": null, "teacher_policy_loss": -56.38029861450195, "teacher_value_loss": 413.7117004394531, "teacher_entropy": 0.5341805219650269, "total_time": 1.210446834564209, "rollout_time": 0.4101436138153076, "train_time": 0.7748174667358398, "student_train_time": 0.025146007537841797, "throughput": 1652.2823992679116, "inference_time": 0.05294993849884122, "env_time": 0.3571936753164664, "samples": 2000, "teacher_eval_reward": 243.0}
{"epoch": 368, "reward_mean": 206.11111111111111, "student_loss": null, "teacher_policy_loss": -51.783714294433594, "teacher_value_loss": 393.7387390136719, "teacher_entropy": 0.5173936486244202, "total_time": 1.2087604999542236, "rollout_time": 0.41194725036621094, "train_time": 0.7845425605773926, "student_train_time": 0.011926889419555664, "throughput": 1654.587488651177, "inference_time": 0.05359773899976972, "env_time": 0.3583495113664412, "samples": 2000, "teacher_eval_reward": 135.0}
{"epoch": 369, "reward_mean": 245.44444444444446, "student_loss": null, "teacher_policy_loss": -52.655479431152344, "teacher_value_loss": 466.526123046875, "teacher_entropy": 0.5020395517349243, "total_time": 1.1849920749664307, "rollout_time": 0.4097156524658203, "train_time": 0.7658967971801758, "student_train_time": 0.00902557373046875, "throughput": 1687.7750005683856, "inference_time": 0.05306680524938656, "env_time": 0.35664884721643375, "samples": 2000, "teacher_eval_reward": 154.0}
{"epoch": 370, "reward_mean": 229.75, "student_loss": null, "teacher_policy_loss": -53.85466003417969, "teacher_value_loss": 546.705078125, "teacher_entropy": 0.5155749320983887, "total_time": 1.263679027557373, "rollout_time": 0.40043163299560547, "train_time": 0.8468143939971924, "student_train_time": 0.01608443260192871, "throughput": 1582.6803772045641, "inference_time": 0.05314651850324026, "env_time": 0.3472851144923652, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 371, "reward_mean": 216.45454545454547, "student_loss": null, "teacher_policy_loss": -49.43976974487305, "teacher_value_loss": 614.7994995117188, "teacher_entropy": 0.5178689360618591, "total_time": 1.184091329574585, "rollout_time": 0.4032716751098633, "train_time": 0.769521951675415, "student_train_time": 0.010955333709716797, "throughput": 1689.0589011563416, "inference_time": 0.049966683248953814, "env_time": 0.35330499186090947, "samples": 2000, "teacher_eval_reward": 188.0}
{"epoch": 372, "reward_mean": 188.75, "student_loss": null, "teacher_policy_loss": -52.765323638916016, "teacher_value_loss": 395.429443359375, "teacher_entropy": 0.5088449120521545, "total_time": 1.157017707824707, "rollout_time": 0.4102795124053955, "train_time": 0.7397003173828125, "student_train_time": 0.006597280502319336, "throughput": 1728.5820143238536, "inference_time": 0.052042487499647905, "env_time": 0.3582370249057476, "samples": 2000, "teacher_eval_reward": 344.0}
{"epoch": 373, "reward_mean": 317.6666666666667, "student_loss": null, "teacher_policy_loss": -61.623802185058594, "teacher_value_loss": 543.7509765625, "teacher_entropy": 0.5281891226768494, "total_time": 1.1186416149139404, "rollout_time": 0.4011683464050293, "train_time": 0.7078619003295898, "student_train_time": 0.009262800216674805, "throughput": 1787.8827082200623, "inference_time": 0.05206828575069267, "env_time": 0.34910006065433663, "samples": 2000, "teacher_eval_reward": 370.0}
{"epoch": 374, "reward_mean": 314.6666666666667, "student_loss": null, "teacher_policy_loss": -58.590965270996094, "teacher_value_loss": 439.9227294921875, "teacher_entropy": 0.5378274917602539, "total_time": 1.1249113082885742, "rollout_time": 0.40446949005126953, "train_time": 0.7135396003723145, "student_train_time": 0.006448030471801758, "throughput": 1777.9179436312847, "inference_time": 0.054257939745639305, "env_time": 0.3502115503056302, "samples": 2000, "teacher_eval_reward": 241.0}
{"epoch": 375, "reward_mean": 270.0, "student_loss": null, "teacher_policy_loss": -52.9947395324707, "teacher_value_loss": 570.7554931640625, "teacher_entropy": 0.5217585563659668, "total_time": 1.2625184059143066, "rollout_time": 0.4102044105529785, "train_time": 0.8463199138641357, "student_train_time": 0.0056209564208984375, "throughput": 1584.135320824582, "inference_time": 0.05338456825347748, "env_time": 0.35681984229950103, "samples": 2000, "teacher_eval_reward": 347.0}
{"epoch": 376, "reward_mean": 272.125, "student_loss": null, "teacher_policy_loss": -53.29893493652344, "teacher_value_loss": 458.2552490234375, "teacher_entropy": 0.5355616211891174, "total_time": 1.196514368057251, "rollout_time": 0.4069497585296631, "train_time": 0.7845644950866699, "student_train_time": 0.004658699035644531, "throughput": 1671.5219251795093, "inference_time": 0.054303113752212084, "env_time": 0.352646644777451, "samples": 2000, "teacher_eval_reward": 486.0}
{"epoch": 377, "reward_mean": 241.28571428571428, "student_loss": null, "teacher_policy_loss": -58.35301971435547, "teacher_value_loss": 354.9623718261719, "teacher_entropy": 0.5267742872238159, "total_time": 1.249990463256836, "rollout_time": 0.4121668338775635, "train_time": 0.8293662071228027, "student_train_time": 0.00811767578125, "throughput": 1600.012207124383, "inference_time": 0.052884606503198484, "env_time": 0.359282227374365, "samples": 2000, "teacher_eval_reward": 148.0}
{"epoch": 378, "reward_mean": 293.25, "student_loss": null, "teacher_policy_loss": -55.902503967285156, "teacher_value_loss": 596.9007568359375, "teacher_entropy": 0.5148863792419434, "total_time": 1.2071921825408936, "rollout_time": 0.438366174697876, "train_time": 0.7597854137420654, "student_train_time": 0.008691787719726562, "throughput": 1656.7370373376737, "inference_time": 0.05553330274904056, "env_time": 0.3828328719488354, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 379, "reward_mean": 279.57142857142856, "student_loss": null, "teacher_policy_loss": -58.734046936035156, "teacher_value_loss": 520.5331420898438, "teacher_entropy": 0.5264428853988647, "total_time": 1.1727683544158936, "rollout_time": 0.4182393550872803, "train_time": 0.7456047534942627, "student_train_time": 0.00794219970703125, "throughput": 1705.366616066406, "inference_time": 0.054940728498877434, "env_time": 0.36329862658840284, "samples": 2000, "teacher_eval_reward": 233.0}
{"epoch": 380, "reward_mean": 341.2, "student_loss": null, "teacher_policy_loss": -61.097145080566406, "teacher_value_loss": 509.9434814453125, "teacher_entropy": 0.5151159763336182, "total_time": 1.208101749420166, "rollout_time": 0.42264795303344727, "train_time": 0.7784016132354736, "student_train_time": 0.006671905517578125, "throughput": 1655.4896977509627, "inference_time": 0.05370274349820647, "env_time": 0.3689452095352408, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 381, "reward_mean": 287.375, "student_loss": null, "teacher_policy_loss": -54.114967346191406, "teacher_value_loss": 501.2771911621094, "teacher_entropy": 0.5150929093360901, "total_time": 1.1669361591339111, "rollout_time": 0.40903782844543457, "train_time": 0.7452166080474854, "student_train_time": 0.012335062026977539, "throughput": 1713.889816804015, "inference_time": 0.054189846997928726, "env_time": 0.35484798144750584, "samples": 2000, "teacher_eval_reward": 170.0}
{"epoch": 382, "reward_mean": 276.0, "student_loss": null, "teacher_policy_loss": -57.51988220214844, "teacher_value_loss": 459.3909912109375, "teacher_entropy": 0.5067389011383057, "total_time": 1.2982349395751953, "rollout_time": 0.414902925491333, "train_time": 0.8771309852600098, "student_train_time": 0.005853891372680664, "throughput": 1540.553207306556, "inference_time": 0.05724505824878179, "env_time": 0.3576578672425512, "samples": 2000, "teacher_eval_reward": 243.0}
{"epoch": 383, "reward_mean": 337.4, "student_loss": null, "teacher_policy_loss": -60.51552200317383, "teacher_value_loss": 399.4765625, "teacher_entropy": 0.5309187173843384, "total_time": 1.1831178665161133, "rollout_time": 0.40430617332458496, "train_time": 0.7722084522247314, "student_train_time": 0.0061528682708740234, "throughput": 1690.4486497945734, "inference_time": 0.05361656099967149, "env_time": 0.35068961232491347, "samples": 2000, "teacher_eval_reward": 327.0}
{"epoch": 384, "reward_mean": 357.14285714285717, "student_loss": null, "teacher_policy_loss": -59.30632019042969, "teacher_value_loss": 400.38824462890625, "teacher_entropy": 0.5138751268386841, "total_time": 1.1893391609191895, "rollout_time": 0.40393924713134766, "train_time": 0.7751734256744385, "student_train_time": 0.009883880615234375, "throughput": 1681.6061101143641, "inference_time": 0.05280928950139696, "env_time": 0.3511299576299507, "samples": 2000, "teacher_eval_reward": 269.0}
{"epoch": 385, "reward_mean": 290.1666666666667, "student_loss": null, "teacher_policy_loss": -59.072044372558594, "teacher_value_loss": 650.9533081054688, "teacher_entropy": 0.5124218463897705, "total_time": 1.1883995532989502, "rollout_time": 0.4192488193511963, "train_time": 0.7594740390777588, "student_train_time": 0.009253978729248047, "throughput": 1682.9356712968117, "inference_time": 0.054566867752782855, "env_time": 0.36468195159841343, "samples": 2000, "teacher_eval_reward": 244.0}
{"epoch": 386, "reward_mean": 281.0, "student_loss": null, "teacher_policy_loss": -52.30807876586914, "teacher_value_loss": 593.0004272460938, "teacher_entropy": 0.5130243897438049, "total_time": 1.2186846733093262, "rollout_time": 0.41228556632995605, "train_time": 0.8007173538208008, "student_train_time": 0.005320072174072266, "throughput": 1641.1136069915606, "inference_time": 0.054690037751242926, "env_time": 0.35759552857871313, "samples": 2000, "teacher_eval_reward": 287.0}
{"epoch": 387, "reward_mean": 291.3333333333333, "student_loss": null, "teacher_policy_loss": -59.761173248291016, "teacher_value_loss": 607.083740234375, "teacher_entropy": 0.5049477815628052, "total_time": 1.2349743843078613, "rollout_time": 0.4113450050354004, "train_time": 0.8183810710906982, "student_train_time": 0.004902839660644531, "throughput": 1619.4667884718076, "inference_time": 0.05448612000088815, "env_time": 0.35685888503451224, "samples": 2000, "teacher_eval_reward": 329.0}
{"epoch": 388, "reward_mean": 350.8333333333333, "student_loss": null, "teacher_policy_loss": -60.169071197509766, "teacher_value_loss": 759.7958374023438, "teacher_entropy": 0.5217950344085693, "total_time": 1.2458617687225342, "rollout_time": 0.4131591320037842, "train_time": 0.8249647617340088, "student_train_time": 0.007396697998046875, "throughput": 1605.3145302393655, "inference_time": 0.053149524497257516, "env_time": 0.36000960750652666, "samples": 2000, "teacher_eval_reward": 213.0}
{"epoch": 389, "reward_mean": 333.0, "student_loss": null, "teacher_policy_loss": -59.830291748046875, "teacher_value_loss": 775.9053344726562, "teacher_entropy": 0.5018278956413269, "total_time": 1.1548659801483154, "rollout_time": 0.41771697998046875, "train_time": 0.72635817527771, "student_train_time": 0.010372638702392578, "throughput": 1731.8026804661324, "inference_time": 0.053752124497918885, "env_time": 0.36396485548254986, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 390, "reward_mean": 314.8, "student_loss": null, "teacher_policy_loss": -62.230777740478516, "teacher_value_loss": 553.867431640625, "teacher_entropy": 0.5169622898101807, "total_time": 1.1765823364257812, "rollout_time": 0.40285801887512207, "train_time": 0.7673962116241455, "student_train_time": 0.005980253219604492, "throughput": 1699.8385392012553, "inference_time": 0.05153097374795834, "env_time": 0.35132704512716373, "samples": 2000, "teacher_eval_reward": 281.0}
{"epoch": 391, "reward_mean": 271.75, "student_loss": null, "teacher_policy_loss": -59.431575775146484, "teacher_value_loss": 488.48486328125, "teacher_entropy": 0.5193573832511902, "total_time": 1.2491421699523926, "rollout_time": 0.41397738456726074, "train_time": 0.8219397068023682, "student_train_time": 0.012882232666015625, "throughput": 1601.0987765117434, "inference_time": 0.05594633925193193, "env_time": 0.3580310453153288, "samples": 2000, "teacher_eval_reward": 278.0}
{"epoch": 392, "reward_mean": 271.85714285714283, "student_loss": null, "teacher_policy_loss": -54.813926696777344, "teacher_value_loss": 535.7354125976562, "teacher_entropy": 0.5195240378379822, "total_time": 1.4188249111175537, "rollout_time": 0.4068114757537842, "train_time": 1.0039818286895752, "student_train_time": 0.007635354995727539, "throughput": 1409.6172010573716, "inference_time": 0.05368711375024304, "env_time": 0.35312436200354114, "samples": 2000, "teacher_eval_reward": 269.0}
{"epoch": 393, "reward_mean": 302.42857142857144, "student_loss": null, "teacher_policy_loss": -58.8942985534668, "teacher_value_loss": 527.619140625, "teacher_entropy": 0.5130972266197205, "total_time": -0.47017621994018555, "rollout_time": 0.4008066654205322, "train_time": -0.8790628910064697, "student_train_time": 0.007735729217529297, "throughput": 200000000000.0, "inference_time": 0.053946041748304197, "env_time": 0.34686062367222803, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 394, "reward_mean": 230.5, "student_loss": null, "teacher_policy_loss": -56.19748306274414, "teacher_value_loss": 574.3367919921875, "teacher_entropy": 0.5180226564407349, "total_time": 1.1649425029754639, "rollout_time": 0.3941786289215088, "train_time": 0.7614903450012207, "student_train_time": 0.008850812911987305, "throughput": 1716.8229289356818, "inference_time": 0.05122121500085086, "env_time": 0.3429574139206579, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 395, "reward_mean": 259.14285714285717, "student_loss": null, "teacher_policy_loss": -57.60966491699219, "teacher_value_loss": 510.7254943847656, "teacher_entropy": 0.510689377784729, "total_time": 1.2478792667388916, "rollout_time": 0.398634672164917, "train_time": 0.8411288261413574, "student_train_time": 0.007716655731201172, "throughput": 1602.7191518508364, "inference_time": 0.050775422747960874, "env_time": 0.3478592494169561, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 396, "reward_mean": 328.8333333333333, "student_loss": null, "teacher_policy_loss": -66.11976623535156, "teacher_value_loss": 572.8258056640625, "teacher_entropy": 0.5231550335884094, "total_time": 1.275843620300293, "rollout_time": 0.4049408435821533, "train_time": 0.8553271293640137, "student_train_time": 0.015218496322631836, "throughput": 1567.5902345534037, "inference_time": 0.050854799498893044, "env_time": 0.3540860440832603, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 397, "reward_mean": 307.2, "student_loss": null, "teacher_policy_loss": -66.24951934814453, "teacher_value_loss": 614.1722412109375, "teacher_entropy": 0.5358900427818298, "total_time": 1.2773473262786865, "rollout_time": 0.4028310775756836, "train_time": 0.8686816692352295, "student_train_time": 0.005465507507324219, "throughput": 1565.7448517363148, "inference_time": 0.053520622499490855, "env_time": 0.34931045507619274, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 398, "reward_mean": 300.14285714285717, "student_loss": null, "teacher_policy_loss": -58.67340850830078, "teacher_value_loss": 756.0452270507812, "teacher_entropy": 0.5068337917327881, "total_time": 1.3550517559051514, "rollout_time": 0.4350767135620117, "train_time": 0.9090597629547119, "student_train_time": 0.010531902313232422, "throughput": 1475.958384086986, "inference_time": 0.05456584700164058, "env_time": 0.38051086656037114, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 399, "reward_mean": 261.875, "student_loss": null, "teacher_policy_loss": -51.6417350769043, "teacher_value_loss": 695.552734375, "teacher_entropy": 0.5033034682273865, "total_time": 1.2577927112579346, "rollout_time": 0.41014552116394043, "train_time": 0.8076896667480469, "student_train_time": 0.039563894271850586, "throughput": 1590.0871281085533, "inference_time": 0.05394916474949696, "env_time": 0.35619635641444347, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 400, "reward_mean": 209.44444444444446, "student_loss": null, "teacher_policy_loss": -52.79810333251953, "teacher_value_loss": 754.7942504882812, "teacher_entropy": 0.5013089179992676, "total_time": 1.2259953022003174, "rollout_time": 0.4164550304412842, "train_time": 0.7726795673370361, "student_train_time": 0.03645014762878418, "throughput": 1631.327621248272, "inference_time": 0.053986258252962216, "env_time": 0.36246877218832196, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 401, "reward_mean": 241.88888888888889, "student_loss": null, "teacher_policy_loss": -51.29840850830078, "teacher_value_loss": 836.0849609375, "teacher_entropy": 0.5004979968070984, "total_time": 1.226567268371582, "rollout_time": 0.42432332038879395, "train_time": 0.7702271938323975, "student_train_time": 0.03165793418884277, "throughput": 1630.566909432733, "inference_time": 0.05247939624871378, "env_time": 0.37184392414008016, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 402, "reward_mean": 299.2857142857143, "student_loss": null, "teacher_policy_loss": -55.12408447265625, "teacher_value_loss": 636.0206298828125, "teacher_entropy": 0.5141241550445557, "total_time": 1.3304269313812256, "rollout_time": 0.6033484935760498, "train_time": 0.7195169925689697, "student_train_time": 0.007208585739135742, "throughput": 1503.2768450677975, "inference_time": 0.061480825499074854, "env_time": 0.541867668076975, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 403, "reward_mean": 215.8, "student_loss": null, "teacher_policy_loss": -50.3734016418457, "teacher_value_loss": 477.32293701171875, "teacher_entropy": 0.5126399993896484, "total_time": 1.1484217643737793, "rollout_time": 0.41087889671325684, "train_time": 0.7304198741912842, "student_train_time": 0.006773233413696289, "throughput": 1741.5204605518568, "inference_time": 0.05378153724882395, "env_time": 0.3570973594644329, "samples": 2000, "teacher_eval_reward": 370.0}
{"epoch": 404, "reward_mean": 261.42857142857144, "student_loss": null, "teacher_policy_loss": -56.31101608276367, "teacher_value_loss": 602.72802734375, "teacher_entropy": 0.5091109871864319, "total_time": 1.155740737915039, "rollout_time": 0.423140287399292, "train_time": 0.7207331657409668, "student_train_time": 0.01150822639465332, "throughput": 1730.4919125789474, "inference_time": 0.05407276050175369, "env_time": 0.3690675268975383, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 405, "reward_mean": 342.6, "student_loss": null, "teacher_policy_loss": -61.37905502319336, "teacher_value_loss": 642.7637939453125, "teacher_entropy": 0.525327205657959, "total_time": 1.1545376777648926, "rollout_time": 0.42436957359313965, "train_time": 0.7117259502410889, "student_train_time": 0.018094778060913086, "throughput": 1732.2951329504167, "inference_time": 0.054901017997053714, "env_time": 0.36946855559608593, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 406, "reward_mean": 241.55555555555554, "student_loss": null, "teacher_policy_loss": -52.08024978637695, "teacher_value_loss": 319.6160888671875, "teacher_entropy": 0.5178958773612976, "total_time": 1.1376264095306396, "rollout_time": 0.4078638553619385, "train_time": 0.7199256420135498, "student_train_time": 0.009483098983764648, "throughput": 1758.046387851665, "inference_time": 0.05283804199689257, "env_time": 0.3550258133650459, "samples": 2000, "teacher_eval_reward": 433.0}
{"epoch": 407, "reward_mean": 287.85714285714283, "student_loss": null, "teacher_policy_loss": -54.59444046020508, "teacher_value_loss": 382.1865539550781, "teacher_entropy": 0.5157450437545776, "total_time": 1.1967434883117676, "rollout_time": 0.4006984233856201, "train_time": 0.7898497581481934, "student_train_time": 0.00584721565246582, "throughput": 1671.2019071199436, "inference_time": 0.05294668124781765, "env_time": 0.34775174213780247, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 408, "reward_mean": 314.8333333333333, "student_loss": null, "teacher_policy_loss": -58.187522888183594, "teacher_value_loss": 537.3746337890625, "teacher_entropy": 0.5118684768676758, "total_time": 1.1885738372802734, "rollout_time": 0.4222376346588135, "train_time": 0.7588670253753662, "student_train_time": 0.007052898406982422, "throughput": 1682.6888976257912, "inference_time": 0.054040172000554776, "env_time": 0.3681974626582587, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 409, "reward_mean": 255.22222222222223, "student_loss": null, "teacher_policy_loss": -52.709014892578125, "teacher_value_loss": 277.5533142089844, "teacher_entropy": 0.5073871612548828, "total_time": 1.1605379581451416, "rollout_time": 0.41478753089904785, "train_time": 0.7382581233978271, "student_train_time": 0.007149219512939453, "throughput": 1723.3387206020811, "inference_time": 0.0584763552495815, "env_time": 0.35631117564946635, "samples": 2000, "teacher_eval_reward": 211.0}
{"epoch": 410, "reward_mean": 196.44444444444446, "student_loss": null, "teacher_policy_loss": -51.397003173828125, "teacher_value_loss": 378.4454650878906, "teacher_entropy": 0.5062577724456787, "total_time": 1.279595136642456, "rollout_time": 0.39916348457336426, "train_time": 0.8726329803466797, "student_train_time": 0.007440328598022461, "throughput": 1562.9943743361061, "inference_time": 0.0524871659999917, "env_time": 0.34667631857337255, "samples": 2000, "teacher_eval_reward": 197.0}
{"epoch": 411, "reward_mean": 256.22222222222223, "student_loss": null, "teacher_policy_loss": -50.636539459228516, "teacher_value_loss": 589.0670776367188, "teacher_entropy": 0.510249137878418, "total_time": 1.1226797103881836, "rollout_time": 0.40549540519714355, "train_time": 0.7093832492828369, "student_train_time": 0.007437229156494141, "throughput": 1781.4519862556967, "inference_time": 0.051981991750380985, "env_time": 0.35351341344676257, "samples": 2000, "teacher_eval_reward": 260.0}
{"epoch": 412, "reward_mean": 178.72727272727272, "student_loss": null, "teacher_policy_loss": -48.96614456176758, "teacher_value_loss": 419.8985595703125, "teacher_entropy": 0.5015748143196106, "total_time": 1.150738000869751, "rollout_time": 0.4114058017730713, "train_time": 0.7265810966491699, "student_train_time": 0.012335777282714844, "throughput": 1738.0150811812591, "inference_time": 0.054301331003671294, "env_time": 0.3571044707694, "samples": 2000, "teacher_eval_reward": 353.0}
{"epoch": 413, "reward_mean": 283.7142857142857, "student_loss": null, "teacher_policy_loss": -59.65668869018555, "teacher_value_loss": 599.5597534179688, "teacher_entropy": 0.5109053254127502, "total_time": 1.196465253829956, "rollout_time": 0.4287383556365967, "train_time": 0.7594811916351318, "student_train_time": 0.00789022445678711, "throughput": 1671.5905402165936, "inference_time": 0.05428749949987832, "env_time": 0.37445085613671836, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 414, "reward_mean": 252.71428571428572, "student_loss": null, "teacher_policy_loss": -54.26810073852539, "teacher_value_loss": 320.29095458984375, "teacher_entropy": 0.5110672116279602, "total_time": 1.1669635772705078, "rollout_time": 0.4513723850250244, "train_time": 0.7025952339172363, "student_train_time": 0.012642145156860352, "throughput": 1713.8495484820005, "inference_time": 0.055509983999286305, "env_time": 0.3958624010257381, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 415, "reward_mean": 244.42857142857142, "student_loss": null, "teacher_policy_loss": -57.18656539916992, "teacher_value_loss": 496.52593994140625, "teacher_entropy": 0.5199388265609741, "total_time": 1.1694238185882568, "rollout_time": 0.40363526344299316, "train_time": 0.7595653533935547, "student_train_time": 0.005843639373779297, "throughput": 1710.2439408275652, "inference_time": 0.0518310370018753, "env_time": 0.35180422644111786, "samples": 2000, "teacher_eval_reward": 224.0}
{"epoch": 416, "reward_mean": 317.42857142857144, "student_loss": null, "teacher_policy_loss": -59.243961334228516, "teacher_value_loss": 388.94482421875, "teacher_entropy": 0.5163754820823669, "total_time": 1.2962582111358643, "rollout_time": 0.40505003929138184, "train_time": 0.8845944404602051, "student_train_time": 0.006264925003051758, "throughput": 1542.9024733023464, "inference_time": 0.05211768875005873, "env_time": 0.3529323505413231, "samples": 2000, "teacher_eval_reward": 168.0}
{"epoch": 417, "reward_mean": 309.0, "student_loss": null, "teacher_policy_loss": -58.80264663696289, "teacher_value_loss": 441.0425720214844, "teacher_entropy": 0.5083110928535461, "total_time": 1.1531364917755127, "rollout_time": 0.4030601978302002, "train_time": 0.7426621913909912, "student_train_time": 0.00684046745300293, "throughput": 1734.4000595459004, "inference_time": 0.05320723599709254, "env_time": 0.34985296183310766, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 418, "reward_mean": 280.5, "student_loss": null, "teacher_policy_loss": -57.0382080078125, "teacher_value_loss": 370.1866149902344, "teacher_entropy": 0.5173510909080505, "total_time": 1.1447503566741943, "rollout_time": 0.42281246185302734, "train_time": 0.7077004909515381, "student_train_time": 0.013884782791137695, "throughput": 1747.1058107468377, "inference_time": 0.054544154504583275, "env_time": 0.36826830734844407, "samples": 2000, "teacher_eval_reward": 169.0}
{"epoch": 419, "reward_mean": 253.66666666666666, "student_loss": null, "teacher_policy_loss": -52.515968322753906, "teacher_value_loss": 457.527099609375, "teacher_entropy": 0.5082870125770569, "total_time": 1.1763620376586914, "rollout_time": 0.4201645851135254, "train_time": 0.7432417869567871, "student_train_time": 0.012612581253051758, "throughput": 1700.156870057276, "inference_time": 0.05557619474700459, "env_time": 0.3645883903665208, "samples": 2000, "teacher_eval_reward": 166.0}
{"epoch": 420, "reward_mean": 258.2857142857143, "student_loss": null, "teacher_policy_loss": -59.46179962158203, "teacher_value_loss": 599.9450073242188, "teacher_entropy": 0.5116229057312012, "total_time": 1.2415828704833984, "rollout_time": 0.395784854888916, "train_time": 0.8381123542785645, "student_train_time": 0.007352590560913086, "throughput": 1610.8469660356373, "inference_time": 0.05107228650047091, "env_time": 0.3447125683884451, "samples": 2000, "teacher_eval_reward": 213.0}
{"epoch": 421, "reward_mean": 332.6666666666667, "student_loss": null, "teacher_policy_loss": -61.98038101196289, "teacher_value_loss": 561.5610961914062, "teacher_entropy": 0.5104199647903442, "total_time": 1.1809420585632324, "rollout_time": 0.40465259552001953, "train_time": 0.767704963684082, "student_train_time": 0.008240222930908203, "throughput": 1693.5631900800083, "inference_time": 0.053314336500648096, "env_time": 0.35133825901937143, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 422, "reward_mean": 246.75, "student_loss": null, "teacher_policy_loss": -51.017181396484375, "teacher_value_loss": 392.89031982421875, "teacher_entropy": 0.5095965266227722, "total_time": 1.187145471572876, "rollout_time": 0.4313063621520996, "train_time": 0.730057954788208, "student_train_time": 0.025391817092895508, "throughput": 1684.7134979592304, "inference_time": 0.056055501999594526, "env_time": 0.3752508601525051, "samples": 2000, "teacher_eval_reward": 282.0}
{"epoch": 423, "reward_mean": 321.0, "student_loss": null, "teacher_policy_loss": -62.55921173095703, "teacher_value_loss": 480.0984802246094, "teacher_entropy": 0.5209842324256897, "total_time": 1.162259817123413, "rollout_time": 0.4181816577911377, "train_time": 0.7358019351959229, "student_train_time": 0.007897377014160156, "throughput": 1720.7856371994253, "inference_time": 0.05493274824823402, "env_time": 0.3632489095429037, "samples": 2000, "teacher_eval_reward": 148.0}
{"epoch": 424, "reward_mean": 283.44444444444446, "student_loss": null, "teacher_policy_loss": -49.6117057800293, "teacher_value_loss": 331.6213684082031, "teacher_entropy": 0.5095710158348083, "total_time": 1.3731117248535156, "rollout_time": 0.41996002197265625, "train_time": 0.9391260147094727, "student_train_time": 0.013613700866699219, "throughput": 1456.5457156906596, "inference_time": 0.0529369145012879, "env_time": 0.36702310747136835, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 425, "reward_mean": 323.2857142857143, "student_loss": null, "teacher_policy_loss": -61.18803787231445, "teacher_value_loss": 611.9954833984375, "teacher_entropy": 0.513697624206543, "total_time": 1.3248374462127686, "rollout_time": 0.43686366081237793, "train_time": 0.8747587203979492, "student_train_time": 0.012686967849731445, "throughput": 1509.6191655189677, "inference_time": 0.056129248001070664, "env_time": 0.38073441281130727, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 426, "reward_mean": 267.3333333333333, "student_loss": null, "teacher_policy_loss": -56.81956100463867, "teacher_value_loss": 466.87188720703125, "teacher_entropy": 0.5112611055374146, "total_time": -0.3838624954223633, "rollout_time": 0.4100322723388672, "train_time": -0.8268771171569824, "student_train_time": 0.03263211250305176, "throughput": 200000000000.0, "inference_time": 0.054202922498348016, "env_time": 0.35582934984051917, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 427, "reward_mean": 356.7142857142857, "student_loss": null, "teacher_policy_loss": -60.82945251464844, "teacher_value_loss": 608.6143798828125, "teacher_entropy": 0.5155932903289795, "total_time": 1.186612844467163, "rollout_time": 0.42149996757507324, "train_time": 0.755134105682373, "student_train_time": 0.009636640548706055, "throughput": 1685.469704230347, "inference_time": 0.05538890450054623, "env_time": 0.366111063074527, "samples": 2000, "teacher_eval_reward": 387.0}
{"epoch": 428, "reward_mean": 357.8, "student_loss": null, "teacher_policy_loss": -63.16006088256836, "teacher_value_loss": 473.866943359375, "teacher_entropy": 0.512150228023529, "total_time": 1.2211613655090332, "rollout_time": 0.4280693531036377, "train_time": 0.7844812870025635, "student_train_time": 0.008182525634765625, "throughput": 1637.7851907936122, "inference_time": 0.052893653001206076, "env_time": 0.3751757001024316, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 429, "reward_mean": 233.0, "student_loss": null, "teacher_policy_loss": -61.88529968261719, "teacher_value_loss": 615.36279296875, "teacher_entropy": 0.5133270621299744, "total_time": 1.2218623161315918, "rollout_time": 0.4139211177825928, "train_time": 0.8009791374206543, "student_train_time": 0.006570577621459961, "throughput": 1636.8456360385899, "inference_time": 0.05225039875074344, "env_time": 0.36167071903184933, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 430, "reward_mean": 379.3333333333333, "student_loss": null, "teacher_policy_loss": -59.26466369628906, "teacher_value_loss": 514.6123046875, "teacher_entropy": 0.5204723477363586, "total_time": 1.1790931224822998, "rollout_time": 0.42887377738952637, "train_time": 0.7368130683898926, "student_train_time": 0.013031005859375, "throughput": 1696.2188667418195, "inference_time": 0.05416991799813786, "env_time": 0.3747038593913885, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 431, "reward_mean": 265.85714285714283, "student_loss": null, "teacher_policy_loss": -58.43522262573242, "teacher_value_loss": 636.4682006835938, "teacher_entropy": 0.5018066763877869, "total_time": 1.1785619258880615, "rollout_time": 0.41775965690612793, "train_time": 0.7548797130584717, "student_train_time": 0.005574464797973633, "throughput": 1696.9833795478964, "inference_time": 0.054241982247503984, "env_time": 0.36351767465862395, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 432, "reward_mean": 312.0, "student_loss": null, "teacher_policy_loss": -57.62675094604492, "teacher_value_loss": 571.8993530273438, "teacher_entropy": 0.5016419887542725, "total_time": 1.1900017261505127, "rollout_time": 0.4118654727935791, "train_time": 0.7716522216796875, "student_train_time": 0.006123781204223633, "throughput": 1680.669831017571, "inference_time": 0.05262834925383686, "env_time": 0.35923712353974224, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 433, "reward_mean": 305.0, "student_loss": null, "teacher_policy_loss": -61.74038314819336, "teacher_value_loss": 490.00341796875, "teacher_entropy": 0.5069674253463745, "total_time": 1.182055950164795, "rollout_time": 0.4068913459777832, "train_time": 0.7661576271057129, "student_train_time": 0.008663415908813477, "throughput": 1691.9672877761602, "inference_time": 0.053650169000206915, "env_time": 0.3532411769775763, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 434, "reward_mean": 263.5, "student_loss": null, "teacher_policy_loss": -51.46346664428711, "teacher_value_loss": 270.1083679199219, "teacher_entropy": 0.4874117970466614, "total_time": 1.3045506477355957, "rollout_time": 0.41623806953430176, "train_time": 0.873485803604126, "student_train_time": 0.014436483383178711, "throughput": 1533.0949422864853, "inference_time": 0.05458445725378169, "env_time": 0.36165361228052006, "samples": 2000, "teacher_eval_reward": 225.0}
{"epoch": 435, "reward_mean": 357.0, "student_loss": null, "teacher_policy_loss": -65.75462341308594, "teacher_value_loss": 648.5673217773438, "teacher_entropy": 0.5009658336639404, "total_time": 1.2258265018463135, "rollout_time": 0.4052431583404541, "train_time": 0.8141932487487793, "student_train_time": 0.0060443878173828125, "throughput": 1631.5522604443966, "inference_time": 0.05175615125085642, "env_time": 0.3534870070895977, "samples": 2000, "teacher_eval_reward": 372.0}
{"epoch": 436, "reward_mean": 264.0, "student_loss": null, "teacher_policy_loss": -56.98379898071289, "teacher_value_loss": 420.301513671875, "teacher_entropy": 0.5068531036376953, "total_time": 1.179654598236084, "rollout_time": 0.42032790184020996, "train_time": 0.7480263710021973, "student_train_time": 0.010950326919555664, "throughput": 1695.411523839744, "inference_time": 0.054647263249762545, "env_time": 0.3656806385904474, "samples": 2000, "teacher_eval_reward": 204.0}
{"epoch": 437, "reward_mean": 294.75, "student_loss": null, "teacher_policy_loss": -55.76820755004883, "teacher_value_loss": 523.04443359375, "teacher_entropy": 0.49229949712753296, "total_time": -0.5814080238342285, "rollout_time": 0.41082072257995605, "train_time": -0.9990859031677246, "student_train_time": 0.006514787673950195, "throughput": 200000000000.0, "inference_time": 0.05520083774933937, "env_time": 0.3556198848306167, "samples": 2000, "teacher_eval_reward": 416.0}
{"epoch": 438, "reward_mean": 225.7, "student_loss": null, "teacher_policy_loss": -51.1414794921875, "teacher_value_loss": 331.41729736328125, "teacher_entropy": 0.5029256343841553, "total_time": 1.1949808597564697, "rollout_time": 0.42000246047973633, "train_time": 0.7598950862884521, "student_train_time": 0.014736413955688477, "throughput": 1673.666974387848, "inference_time": 0.05410130225368448, "env_time": 0.36590115822605185, "samples": 2000, "teacher_eval_reward": 152.0}
{"epoch": 439, "reward_mean": 297.6666666666667, "student_loss": null, "teacher_policy_loss": -59.19545364379883, "teacher_value_loss": 700.363525390625, "teacher_entropy": 0.4905185401439667, "total_time": 1.209341287612915, "rollout_time": 0.4219675064086914, "train_time": 0.7790303230285645, "student_train_time": 0.007998228073120117, "throughput": 1653.7928709502212, "inference_time": 0.05253638225053692, "env_time": 0.3694311241581545, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 440, "reward_mean": 324.5, "student_loss": null, "teacher_policy_loss": -56.8234977722168, "teacher_value_loss": 639.650146484375, "teacher_entropy": 0.48856741189956665, "total_time": 1.1514813899993896, "rollout_time": 0.40779709815979004, "train_time": 0.7309701442718506, "student_train_time": 0.012269735336303711, "throughput": 1736.893029596475, "inference_time": 0.05357137025055181, "env_time": 0.35422572790923823, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 441, "reward_mean": 273.85714285714283, "student_loss": null, "teacher_policy_loss": -57.63328552246094, "teacher_value_loss": 522.704833984375, "teacher_entropy": 0.5024001598358154, "total_time": 1.3402092456817627, "rollout_time": 0.4133336544036865, "train_time": 0.9100472927093506, "student_train_time": 0.016414403915405273, "throughput": 1492.3042849048566, "inference_time": 0.0553754062493681, "env_time": 0.3579582481543184, "samples": 2000, "teacher_eval_reward": 188.0}
{"epoch": 442, "reward_mean": 265.1666666666667, "student_loss": null, "teacher_policy_loss": -58.87602996826172, "teacher_value_loss": 548.42333984375, "teacher_entropy": 0.4925391674041748, "total_time": 1.3875799179077148, "rollout_time": 0.4172964096069336, "train_time": 0.961909294128418, "student_train_time": 0.008032798767089844, "throughput": 1441.3584213698716, "inference_time": 0.0528329492518651, "env_time": 0.3644634603550685, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 443, "reward_mean": 302.0, "student_loss": null, "teacher_policy_loss": -54.80205535888672, "teacher_value_loss": 405.13262939453125, "teacher_entropy": 0.49628791213035583, "total_time": 1.260915994644165, "rollout_time": 0.42804384231567383, "train_time": 0.824810266494751, "student_train_time": 0.007666349411010742, "throughput": 1586.148489269031, "inference_time": 0.05460220375357494, "env_time": 0.3734416385620989, "samples": 2000, "teacher_eval_reward": 147.0}
{"epoch": 444, "reward_mean": 243.85714285714286, "student_loss": null, "teacher_policy_loss": -54.10688400268555, "teacher_value_loss": 438.29327392578125, "teacher_entropy": 0.48458945751190186, "total_time": 1.160055160522461, "rollout_time": 0.40831446647644043, "train_time": 0.7398624420166016, "student_train_time": 0.01147770881652832, "throughput": 1724.0559484251146, "inference_time": 0.05542021175267564, "env_time": 0.3528942547237648, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 445, "reward_mean": 329.8333333333333, "student_loss": null, "teacher_policy_loss": -58.95124816894531, "teacher_value_loss": 527.6466674804688, "teacher_entropy": 0.48966357111930847, "total_time": 1.2574803829193115, "rollout_time": 0.4137096405029297, "train_time": 0.8304741382598877, "student_train_time": 0.012845516204833984, "throughput": 1590.4820680835492, "inference_time": 0.05319979524961127, "env_time": 0.3605098452533184, "samples": 2000, "teacher_eval_reward": 328.0}
{"epoch": 446, "reward_mean": 266.57142857142856, "student_loss": null, "teacher_policy_loss": -56.06145477294922, "teacher_value_loss": 490.0966796875, "teacher_entropy": 0.4960118234157562, "total_time": 1.2430825233459473, "rollout_time": 0.4248368740081787, "train_time": 0.7904801368713379, "student_train_time": 0.027418136596679688, "throughput": 1608.9036427096514, "inference_time": 0.054904179750110416, "env_time": 0.3699326942580683, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 447, "reward_mean": 276.57142857142856, "student_loss": null, "teacher_policy_loss": -54.6519775390625, "teacher_value_loss": 509.3676452636719, "teacher_entropy": 0.48235800862312317, "total_time": 1.132291555404663, "rollout_time": 0.39882445335388184, "train_time": 0.7279846668243408, "student_train_time": 0.005133628845214844, "throughput": 1766.3295203903835, "inference_time": 0.05135917374911969, "env_time": 0.34746527960476215, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 448, "reward_mean": 233.0, "student_loss": null, "teacher_policy_loss": -51.950164794921875, "teacher_value_loss": 378.6355285644531, "teacher_entropy": 0.4956035912036896, "total_time": 1.1543378829956055, "rollout_time": 0.404965877532959, "train_time": 0.7413182258605957, "student_train_time": 0.007678985595703125, "throughput": 1732.5949615461195, "inference_time": 0.05227773650199197, "env_time": 0.352688141030967, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 449, "reward_mean": 314.125, "student_loss": null, "teacher_policy_loss": -56.05294418334961, "teacher_value_loss": 535.5064086914062, "teacher_entropy": 0.4947839379310608, "total_time": 1.2540075778961182, "rollout_time": 0.4214510917663574, "train_time": 0.8176455497741699, "student_train_time": 0.014558076858520508, "throughput": 1594.8866938710635, "inference_time": 0.05460615300069094, "env_time": 0.3668449387656665, "samples": 2000, "teacher_eval_reward": 155.0}
{"epoch": 450, "reward_mean": 284.57142857142856, "student_loss": null, "teacher_policy_loss": -57.27802658081055, "teacher_value_loss": 656.5199584960938, "teacher_entropy": 0.5067580938339233, "total_time": 1.1487910747528076, "rollout_time": 0.4089343547821045, "train_time": 0.7275235652923584, "student_train_time": 0.011913537979125977, "throughput": 1740.960601065213, "inference_time": 0.053249968999466546, "env_time": 0.35568438578263795, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 451, "reward_mean": 271.6666666666667, "student_loss": null, "teacher_policy_loss": -56.73821258544922, "teacher_value_loss": 646.5887451171875, "teacher_entropy": 0.4972195625305176, "total_time": 1.2286474704742432, "rollout_time": 0.41200971603393555, "train_time": 0.8063902854919434, "student_train_time": 0.009847402572631836, "throughput": 1627.8062243745344, "inference_time": 0.05616245400085518, "env_time": 0.35584726203308037, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 452, "reward_mean": 248.42857142857142, "student_loss": null, "teacher_policy_loss": -55.677589416503906, "teacher_value_loss": 502.2934265136719, "teacher_entropy": 0.5002673864364624, "total_time": 1.157060146331787, "rollout_time": 0.4197380542755127, "train_time": 0.7294049263000488, "student_train_time": 0.0075609683990478516, "throughput": 1728.5186136093048, "inference_time": 0.054172205002146256, "env_time": 0.36556584927336644, "samples": 2000, "teacher_eval_reward": 348.0}
{"epoch": 453, "reward_mean": 266.8888888888889, "student_loss": null, "teacher_policy_loss": -58.496028900146484, "teacher_value_loss": 665.9050903320312, "teacher_entropy": 0.48970767855644226, "total_time": 1.2873003482818604, "rollout_time": 0.41396546363830566, "train_time": 0.865079402923584, "student_train_time": 0.007912874221801758, "throughput": 1553.6389799547314, "inference_time": 0.05508939575054228, "env_time": 0.3588760678877634, "samples": 2000, "teacher_eval_reward": 427.0}
{"epoch": 454, "reward_mean": 224.5, "student_loss": null, "teacher_policy_loss": -49.223453521728516, "teacher_value_loss": 394.5635681152344, "teacher_entropy": 0.48388344049453735, "total_time": 1.3511459827423096, "rollout_time": 0.41788315773010254, "train_time": 0.9193224906921387, "student_train_time": 0.013545989990234375, "throughput": 1480.224953887488, "inference_time": 0.052378201999545126, "env_time": 0.3655049557305574, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 455, "reward_mean": 214.0, "student_loss": null, "teacher_policy_loss": -60.69807815551758, "teacher_value_loss": 375.27362060546875, "teacher_entropy": 0.5055184960365295, "total_time": 1.217573881149292, "rollout_time": 0.4066505432128906, "train_time": 0.8025040626525879, "student_train_time": 0.008030414581298828, "throughput": 1642.6107942724268, "inference_time": 0.05250426125030572, "env_time": 0.3541462819625849, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 456, "reward_mean": 250.0, "student_loss": null, "teacher_policy_loss": -45.669368743896484, "teacher_value_loss": 388.0095520019531, "teacher_entropy": 0.49336713552474976, "total_time": 1.197174072265625, "rollout_time": 0.40114474296569824, "train_time": 0.7897763252258301, "student_train_time": 0.005910158157348633, "throughput": 1670.6008310178695, "inference_time": 0.050922479498240136, "env_time": 0.3502222634674581, "samples": 2000, "teacher_eval_reward": 130.0}
{"epoch": 457, "reward_mean": 226.11111111111111, "student_loss": null, "teacher_policy_loss": -51.896053314208984, "teacher_value_loss": 459.0643615722656, "teacher_entropy": 0.49396154284477234, "total_time": 1.2708463668823242, "rollout_time": 0.40820789337158203, "train_time": 0.8377692699432373, "student_train_time": 0.024500608444213867, "throughput": 1573.754351524375, "inference_time": 0.05306371824872258, "env_time": 0.35514417512285945, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 458, "reward_mean": 201.22222222222223, "student_loss": null, "teacher_policy_loss": -52.59664535522461, "teacher_value_loss": 351.3553771972656, "teacher_entropy": 0.4884755313396454, "total_time": 1.2376775741577148, "rollout_time": 0.4045979976654053, "train_time": 0.8260855674743652, "student_train_time": 0.005959749221801758, "throughput": 1615.929739505116, "inference_time": 0.05179950800300048, "env_time": 0.3527984896624048, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 459, "reward_mean": 253.75, "student_loss": null, "teacher_policy_loss": -53.798709869384766, "teacher_value_loss": 413.9516906738281, "teacher_entropy": 0.48710766434669495, "total_time": 1.2046661376953125, "rollout_time": 0.42833662033081055, "train_time": 0.7691922187805176, "student_train_time": 0.0068013668060302734, "throughput": 1660.211022305539, "inference_time": 0.05507644400074696, "env_time": 0.3732601763300636, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 460, "reward_mean": 274.7142857142857, "student_loss": null, "teacher_policy_loss": -57.21306610107422, "teacher_value_loss": 355.41680908203125, "teacher_entropy": 0.4957587718963623, "total_time": 1.1664633750915527, "rollout_time": 0.4142463207244873, "train_time": 0.7417104244232178, "student_train_time": 0.010150909423828125, "throughput": 1714.584480496891, "inference_time": 0.05482947224993495, "env_time": 0.35941684847455235, "samples": 2000, "teacher_eval_reward": 130.0}
{"epoch": 461, "reward_mean": 199.0, "student_loss": null, "teacher_policy_loss": -48.70273971557617, "teacher_value_loss": 429.57464599609375, "teacher_entropy": 0.4797813594341278, "total_time": 1.2078850269317627, "rollout_time": 0.417130708694458, "train_time": 0.7831203937530518, "student_train_time": 0.007280588150024414, "throughput": 1655.7867308615841, "inference_time": 0.05523554275328024, "env_time": 0.36189516594117777, "samples": 2000, "teacher_eval_reward": 122.0}
{"epoch": 462, "reward_mean": 240.375, "student_loss": null, "teacher_policy_loss": -54.77131652832031, "teacher_value_loss": 510.21746826171875, "teacher_entropy": 0.48589926958084106, "total_time": 1.1648409366607666, "rollout_time": 0.40782976150512695, "train_time": 0.7490172386169434, "student_train_time": 0.007633686065673828, "throughput": 1716.972624376829, "inference_time": 0.05176357825064315, "env_time": 0.3560661832544838, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 463, "reward_mean": 258.625, "student_loss": null, "teacher_policy_loss": -54.202842712402344, "teacher_value_loss": 546.8933715820312, "teacher_entropy": 0.4866579473018646, "total_time": -0.535085916519165, "rollout_time": 0.3974156379699707, "train_time": -0.9396460056304932, "student_train_time": 0.0068073272705078125, "throughput": 200000000000.0, "inference_time": 0.052918941497637206, "env_time": 0.3444966964723335, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 464, "reward_mean": 254.77777777777777, "student_loss": null, "teacher_policy_loss": -47.311912536621094, "teacher_value_loss": 522.6914672851562, "teacher_entropy": 0.4656886160373688, "total_time": 1.2355239391326904, "rollout_time": 0.41263723373413086, "train_time": 0.8134450912475586, "student_train_time": 0.009088516235351562, "throughput": 1618.746457801501, "inference_time": 0.051755142996171344, "env_time": 0.3608820907379595, "samples": 2000, "teacher_eval_reward": 131.0}
{"epoch": 465, "reward_mean": 324.75, "student_loss": null, "teacher_policy_loss": -59.56211471557617, "teacher_value_loss": 616.83544921875, "teacher_entropy": 0.48479998111724854, "total_time": 1.1839444637298584, "rollout_time": 0.401259183883667, "train_time": 0.7755277156829834, "student_train_time": 0.006819009780883789, "throughput": 1689.2684253949446, "inference_time": 0.053320562750741374, "env_time": 0.3479386211329256, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 466, "reward_mean": 371.6, "student_loss": null, "teacher_policy_loss": -61.55134201049805, "teacher_value_loss": 706.5656127929688, "teacher_entropy": 0.4993712604045868, "total_time": 1.2688558101654053, "rollout_time": 0.424086332321167, "train_time": 0.8366081714630127, "student_train_time": 0.0077800750732421875, "throughput": 1576.2232272391016, "inference_time": 0.05839282300280502, "env_time": 0.365693509318362, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 467, "reward_mean": 279.55555555555554, "student_loss": null, "teacher_policy_loss": -52.25214385986328, "teacher_value_loss": 566.07275390625, "teacher_entropy": 0.4845646321773529, "total_time": 1.1429338455200195, "rollout_time": 0.40622401237487793, "train_time": 0.7307515144348145, "student_train_time": 0.005492448806762695, "throughput": 1749.8825569296419, "inference_time": 0.05358244824856229, "env_time": 0.35264156412631564, "samples": 2000, "teacher_eval_reward": 171.0}
{"epoch": 468, "reward_mean": 283.2857142857143, "student_loss": null, "teacher_policy_loss": -57.840763092041016, "teacher_value_loss": 650.22216796875, "teacher_entropy": 0.4899287223815918, "total_time": 1.3893940448760986, "rollout_time": 0.4652845859527588, "train_time": 0.9165389537811279, "student_train_time": 0.007227420806884766, "throughput": 1439.4764446959705, "inference_time": 0.05996994075144357, "env_time": 0.4053146452013152, "samples": 2000, "teacher_eval_reward": 230.0}
{"epoch": 469, "reward_mean": 310.5, "student_loss": null, "teacher_policy_loss": -58.84428787231445, "teacher_value_loss": 586.779052734375, "teacher_entropy": 0.487712562084198, "total_time": 1.2123489379882812, "rollout_time": 0.4116339683532715, "train_time": 0.7893555164337158, "student_train_time": 0.010982990264892578, "throughput": 1649.6900663918693, "inference_time": 0.05270067200228823, "env_time": 0.35893329635098326, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 470, "reward_mean": 338.0, "student_loss": null, "teacher_policy_loss": -55.887847900390625, "teacher_value_loss": 569.6395874023438, "teacher_entropy": 0.49146145582199097, "total_time": 1.2192366123199463, "rollout_time": 0.42493176460266113, "train_time": 0.7882494926452637, "student_train_time": 0.005640745162963867, "throughput": 1640.3706875193225, "inference_time": 0.05234870349715948, "env_time": 0.37258306110550166, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 471, "reward_mean": 295.2857142857143, "student_loss": null, "teacher_policy_loss": -56.621490478515625, "teacher_value_loss": 541.2361450195312, "teacher_entropy": 0.48626354336738586, "total_time": 1.263028860092163, "rollout_time": 0.41567111015319824, "train_time": 0.8332138061523438, "student_train_time": 0.01374363899230957, "throughput": 1583.4950912001016, "inference_time": 0.05522900800099251, "env_time": 0.36044210215220573, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 472, "reward_mean": 404.8, "student_loss": null, "teacher_policy_loss": -64.17032623291016, "teacher_value_loss": 669.5933837890625, "teacher_entropy": 0.5011983513832092, "total_time": 1.2314908504486084, "rollout_time": 0.413027286529541, "train_time": 0.8128762245178223, "student_train_time": 0.0051991939544677734, "throughput": 1624.0477948101998, "inference_time": 0.05393627125420153, "env_time": 0.3590910152753395, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 473, "reward_mean": 331.6666666666667, "student_loss": null, "teacher_policy_loss": -59.525691986083984, "teacher_value_loss": 585.4156494140625, "teacher_entropy": 0.48345762491226196, "total_time": 1.394209623336792, "rollout_time": 0.4199080467224121, "train_time": 0.9657857418060303, "student_train_time": 0.008159637451171875, "throughput": 1434.5045153349013, "inference_time": 0.05511958550050622, "env_time": 0.3647884612219059, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 474, "reward_mean": 302.4, "student_loss": null, "teacher_policy_loss": -59.90005111694336, "teacher_value_loss": 320.38262939453125, "teacher_entropy": 0.49606993794441223, "total_time": 1.219985008239746, "rollout_time": 0.40461063385009766, "train_time": 0.8016366958618164, "student_train_time": 0.013402462005615234, "throughput": 1639.3644073427572, "inference_time": 0.050890365252485026, "env_time": 0.35372026859761263, "samples": 2000, "teacher_eval_reward": 371.0}
{"epoch": 475, "reward_mean": 248.33333333333334, "student_loss": null, "teacher_policy_loss": -51.48246383666992, "teacher_value_loss": 566.2308959960938, "teacher_entropy": 0.48647642135620117, "total_time": 1.2543675899505615, "rollout_time": 0.42795753479003906, "train_time": 0.8072700500488281, "student_train_time": 0.01855635643005371, "throughput": 1594.4289505110908, "inference_time": 0.05461450574944138, "env_time": 0.3733430290405977, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 476, "reward_mean": 338.3333333333333, "student_loss": null, "teacher_policy_loss": -62.10735321044922, "teacher_value_loss": 526.8995971679688, "teacher_entropy": 0.4978187680244446, "total_time": 1.2115304470062256, "rollout_time": 0.43186402320861816, "train_time": 0.7701592445373535, "student_train_time": 0.009112358093261719, "throughput": 1650.8045711456418, "inference_time": 0.05492333399627114, "env_time": 0.376940689212347, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 477, "reward_mean": 330.5, "student_loss": null, "teacher_policy_loss": -60.447113037109375, "teacher_value_loss": 549.8883666992188, "teacher_entropy": 0.4965270459651947, "total_time": 1.2010738849639893, "rollout_time": 0.428647518157959, "train_time": 0.758075475692749, "student_train_time": 0.013965606689453125, "throughput": 1665.1764933345164, "inference_time": 0.05616533075158259, "env_time": 0.3724821874063764, "samples": 2000, "teacher_eval_reward": 294.0}
{"epoch": 478, "reward_mean": 322.6666666666667, "student_loss": null, "teacher_policy_loss": -56.68355178833008, "teacher_value_loss": 675.806884765625, "teacher_entropy": 0.48094063997268677, "total_time": 1.2667384147644043, "rollout_time": 0.41821718215942383, "train_time": 0.8353235721588135, "student_train_time": 0.012851953506469727, "throughput": 1578.8579367998184, "inference_time": 0.053822889751245384, "env_time": 0.36439429240817844, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 479, "reward_mean": 379.3333333333333, "student_loss": null, "teacher_policy_loss": -58.100189208984375, "teacher_value_loss": 648.094482421875, "teacher_entropy": 0.4906541407108307, "total_time": 1.244828701019287, "rollout_time": 0.4329233169555664, "train_time": 0.7867870330810547, "student_train_time": 0.024750709533691406, "throughput": 1606.6467606043832, "inference_time": 0.056927182000436005, "env_time": 0.3759961349551304, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 480, "reward_mean": 316.5, "student_loss": null, "teacher_policy_loss": -63.068138122558594, "teacher_value_loss": 534.2808837890625, "teacher_entropy": 0.4901447594165802, "total_time": 1.3051865100860596, "rollout_time": 0.4619917869567871, "train_time": 0.8363759517669678, "student_train_time": 0.0064716339111328125, "throughput": 1532.3480472289948, "inference_time": 0.05656343250086593, "env_time": 0.4054283544559212, "samples": 2000, "teacher_eval_reward": 164.0}
{"epoch": 481, "reward_mean": 305.0, "student_loss": null, "teacher_policy_loss": -58.1719856262207, "teacher_value_loss": 723.8064575195312, "teacher_entropy": 0.46700459718704224, "total_time": 1.2353041172027588, "rollout_time": 0.44110560417175293, "train_time": 0.7784264087677002, "student_train_time": 0.015369415283203125, "throughput": 1619.0345131600711, "inference_time": 0.05921048425113895, "env_time": 0.381895119920614, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 482, "reward_mean": 263.375, "student_loss": null, "teacher_policy_loss": -46.77081298828125, "teacher_value_loss": 421.55975341796875, "teacher_entropy": 0.4337921142578125, "total_time": 1.2708823680877686, "rollout_time": 0.42459774017333984, "train_time": 0.837639331817627, "student_train_time": 0.008298158645629883, "throughput": 1573.709770644861, "inference_time": 0.056220570995378694, "env_time": 0.36837716917796115, "samples": 2000, "teacher_eval_reward": 370.0}
{"epoch": 483, "reward_mean": 347.5, "student_loss": null, "teacher_policy_loss": -59.476905822753906, "teacher_value_loss": 1012.21826171875, "teacher_entropy": 0.49517855048179626, "total_time": 1.5589573383331299, "rollout_time": 0.5371251106262207, "train_time": 1.0082852840423584, "student_train_time": 0.012973308563232422, "throughput": 1282.9087434415892, "inference_time": 0.06985208750631955, "env_time": 0.46727302311990115, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 484, "reward_mean": 327.5, "student_loss": null, "teacher_policy_loss": -61.798343658447266, "teacher_value_loss": 1020.7203979492188, "teacher_entropy": 0.47383013367652893, "total_time": 1.2728397846221924, "rollout_time": 0.4238705635070801, "train_time": 0.8377816677093506, "student_train_time": 0.01079249382019043, "throughput": 1571.2896659603118, "inference_time": 0.05308797275347388, "env_time": 0.3707825907536062, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 485, "reward_mean": 315.6666666666667, "student_loss": null, "teacher_policy_loss": -57.8878288269043, "teacher_value_loss": 438.7783203125, "teacher_entropy": 0.46192386746406555, "total_time": 1.1684415340423584, "rollout_time": 0.405778169631958, "train_time": 0.750340461730957, "student_train_time": 0.011937141418457031, "throughput": 1711.6817074113833, "inference_time": 0.051007512248474995, "env_time": 0.354770657383483, "samples": 2000, "teacher_eval_reward": 248.0}
{"epoch": 486, "reward_mean": 317.42857142857144, "student_loss": null, "teacher_policy_loss": -60.108211517333984, "teacher_value_loss": 674.9486083984375, "teacher_entropy": 0.467906653881073, "total_time": 1.0603551864624023, "rollout_time": 0.39360547065734863, "train_time": 0.6599726676940918, "student_train_time": 0.006249427795410156, "throughput": 1886.1604352334775, "inference_time": 0.051289896750404296, "env_time": 0.34231557390694434, "samples": 2000, "teacher_eval_reward": 380.0}
{"epoch": 487, "reward_mean": 286.2857142857143, "student_loss": null, "teacher_policy_loss": -55.423580169677734, "teacher_value_loss": 465.2199401855469, "teacher_entropy": 0.4780109226703644, "total_time": 1.1224408149719238, "rollout_time": 0.4057905673980713, "train_time": 0.7115330696105957, "student_train_time": 0.0047664642333984375, "throughput": 1781.831142740499, "inference_time": 0.05212324475110108, "env_time": 0.3536673226469702, "samples": 2000, "teacher_eval_reward": 118.0}
{"epoch": 488, "reward_mean": 384.4, "student_loss": null, "teacher_policy_loss": -58.68753433227539, "teacher_value_loss": 516.2412109375, "teacher_entropy": 0.4475191533565521, "total_time": 1.1656506061553955, "rollout_time": 0.39982175827026367, "train_time": 0.7567458152770996, "student_train_time": 0.008705377578735352, "throughput": 1715.7800025485299, "inference_time": 0.05210539725237595, "env_time": 0.3477163610178877, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 489, "reward_mean": 324.2, "student_loss": null, "teacher_policy_loss": -58.4257698059082, "teacher_value_loss": 591.1823120117188, "teacher_entropy": 0.4700944423675537, "total_time": 1.1658198833465576, "rollout_time": 0.43639588356018066, "train_time": 0.7195091247558594, "student_train_time": 0.009547233581542969, "throughput": 1715.5308710800823, "inference_time": 0.06132820024936336, "env_time": 0.3750676833108173, "samples": 2000, "teacher_eval_reward": 438.0}
{"epoch": 490, "reward_mean": 284.85714285714283, "student_loss": null, "teacher_policy_loss": -57.475135803222656, "teacher_value_loss": 441.71881103515625, "teacher_entropy": 0.47867345809936523, "total_time": 1.1747660636901855, "rollout_time": 0.4012782573699951, "train_time": 0.7622458934783936, "student_train_time": 0.010873794555664062, "throughput": 1702.4666117078514, "inference_time": 0.05387952024614151, "env_time": 0.3473987371238536, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 491, "reward_mean": 392.0, "student_loss": null, "teacher_policy_loss": -56.0198974609375, "teacher_value_loss": 502.7568359375, "teacher_entropy": 0.4595862329006195, "total_time": 1.2885291576385498, "rollout_time": 0.413588285446167, "train_time": 0.8669877052307129, "student_train_time": 0.0075893402099609375, "throughput": 1552.1573478906307, "inference_time": 0.05131826424587871, "env_time": 0.3622700212002883, "samples": 2000, "teacher_eval_reward": 220.0}
{"epoch": 492, "reward_mean": 269.875, "student_loss": null, "teacher_policy_loss": -49.425846099853516, "teacher_value_loss": 619.6525268554688, "teacher_entropy": 0.4557584226131439, "total_time": 1.1199030876159668, "rollout_time": 0.39578938484191895, "train_time": 0.7128760814666748, "student_train_time": 0.010861635208129883, "throughput": 1785.8688150039577, "inference_time": 0.052270745249757056, "env_time": 0.3435186395921619, "samples": 2000, "teacher_eval_reward": 248.0}
{"epoch": 493, "reward_mean": 397.8, "student_loss": null, "teacher_policy_loss": -65.85124969482422, "teacher_value_loss": 719.3004150390625, "teacher_entropy": 0.4861590564250946, "total_time": 1.1472125053405762, "rollout_time": 0.4110276699066162, "train_time": 0.7275063991546631, "student_train_time": 0.008328676223754883, "throughput": 1743.3561704474746, "inference_time": 0.05396087600240662, "env_time": 0.3570667939042096, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 494, "reward_mean": 365.6, "student_loss": null, "teacher_policy_loss": -63.97071838378906, "teacher_value_loss": 887.3060302734375, "teacher_entropy": 0.4549733102321625, "total_time": 1.3956263065338135, "rollout_time": 0.5176248550415039, "train_time": 0.861262321472168, "student_train_time": 0.016381502151489258, "throughput": 1433.048367343557, "inference_time": 0.056527647497432554, "env_time": 0.46109720754407135, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 495, "reward_mean": 343.1666666666667, "student_loss": null, "teacher_policy_loss": -56.909027099609375, "teacher_value_loss": 640.6298217773438, "teacher_entropy": 0.46975383162498474, "total_time": 1.1069269180297852, "rollout_time": 0.3955044746398926, "train_time": 0.7040791511535645, "student_train_time": 0.006999492645263672, "throughput": 1806.8040151736413, "inference_time": 0.0509459372483434, "env_time": 0.3445585373915492, "samples": 2000, "teacher_eval_reward": 152.0}
{"epoch": 496, "reward_mean": 335.0, "student_loss": null, "teacher_policy_loss": -61.52512741088867, "teacher_value_loss": 537.0659790039062, "teacher_entropy": 0.48189523816108704, "total_time": 1.2584583759307861, "rollout_time": 0.4317934513092041, "train_time": 0.8149621486663818, "student_train_time": 0.011350870132446289, "throughput": 1589.2460475863986, "inference_time": 0.0571397207498876, "env_time": 0.3746537305593165, "samples": 2000, "teacher_eval_reward": 334.0}
{"epoch": 497, "reward_mean": 380.7142857142857, "student_loss": null, "teacher_policy_loss": -57.23720932006836, "teacher_value_loss": 502.7110290527344, "teacher_entropy": 0.48787084221839905, "total_time": 1.1910746097564697, "rollout_time": 0.40032243728637695, "train_time": 0.7848982810974121, "student_train_time": 0.005497932434082031, "throughput": 1679.1559349996767, "inference_time": 0.05305029375074355, "env_time": 0.3472721435356334, "samples": 2000, "teacher_eval_reward": 157.0}
{"epoch": 498, "reward_mean": 319.2, "student_loss": null, "teacher_policy_loss": -61.3150520324707, "teacher_value_loss": 583.3377685546875, "teacher_entropy": 0.4658259451389313, "total_time": 1.164226770401001, "rollout_time": 0.42996740341186523, "train_time": 0.7149550914764404, "student_train_time": 0.018940210342407227, "throughput": 1717.878381469556, "inference_time": 0.05275542374897668, "env_time": 0.37721197966288855, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 499, "reward_mean": 348.2, "student_loss": null, "teacher_policy_loss": -64.4494400024414, "teacher_value_loss": 548.5497436523438, "teacher_entropy": 0.4571956992149353, "total_time": 1.3278617858886719, "rollout_time": 0.40375828742980957, "train_time": 0.913210391998291, "student_train_time": 0.010416984558105469, "throughput": 1506.1808550063058, "inference_time": 0.051189272000669916, "env_time": 0.35256901542913965, "samples": 2000, "teacher_eval_reward": 241.0}
{"epoch": 500, "reward_mean": 295.57142857142856, "student_loss": null, "teacher_policy_loss": -58.113948822021484, "teacher_value_loss": 559.9462890625, "teacher_entropy": 0.47320058941841125, "total_time": 1.1179530620574951, "rollout_time": 0.4030320644378662, "train_time": 0.708214521408081, "student_train_time": 0.006351947784423828, "throughput": 1788.983874080701, "inference_time": 0.05312485700017078, "env_time": 0.34990720743769543, "samples": 2000, "teacher_eval_reward": 131.0}
