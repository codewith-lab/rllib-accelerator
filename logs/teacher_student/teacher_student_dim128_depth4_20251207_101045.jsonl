{"epoch": 1, "reward_mean": 26.666666666666668, "student_loss": null, "teacher_policy_loss": -14.632575988769531, "teacher_value_loss": 422.56488037109375, "teacher_entropy": 0.6072783470153809, "total_time": 1.6004600524902344, "rollout_time": 0.4973480701446533, "train_time": 0.9336762428283691, "student_train_time": 0.1689624786376953, "throughput": 1249.6406873061917, "inference_time": 0.06276980376969732, "env_time": 0.434578266374956, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 2, "reward_mean": 25.772151898734176, "student_loss": null, "teacher_policy_loss": -15.092912673950195, "teacher_value_loss": 236.56707763671875, "teacher_entropy": 0.6644632816314697, "total_time": 1.350126028060913, "rollout_time": 0.45691537857055664, "train_time": 0.8849740028381348, "student_train_time": 0.007885932922363281, "throughput": 1481.3431919925677, "inference_time": 0.05735893574819784, "env_time": 0.3995564428223588, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 3, "reward_mean": 24.59493670886076, "student_loss": null, "teacher_policy_loss": -14.804823875427246, "teacher_value_loss": 178.67530822753906, "teacher_entropy": 0.6705742478370667, "total_time": 1.2246849536895752, "rollout_time": 0.4720799922943115, "train_time": 0.7389850616455078, "student_train_time": 0.013260364532470703, "throughput": 1633.0730560334348, "inference_time": 0.061168191761680646, "env_time": 0.4109118005326309, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 4, "reward_mean": 29.205882352941178, "student_loss": null, "teacher_policy_loss": -14.829933166503906, "teacher_value_loss": 180.56617736816406, "teacher_entropy": 0.5916517972946167, "total_time": 1.2448828220367432, "rollout_time": 0.42084312438964844, "train_time": 0.8128249645233154, "student_train_time": 0.010862350463867188, "throughput": 1606.5769119761935, "inference_time": 0.05646530975536734, "env_time": 0.3643778146342811, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 5, "reward_mean": 32.904761904761905, "student_loss": null, "teacher_policy_loss": -17.769575119018555, "teacher_value_loss": 300.4560852050781, "teacher_entropy": 0.5534098148345947, "total_time": 1.4033079147338867, "rollout_time": 0.48740530014038086, "train_time": 0.9000394344329834, "student_train_time": 0.01544046401977539, "throughput": 1425.2039620109074, "inference_time": 0.0664375852302328, "env_time": 0.42096771491014806, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 6, "reward_mean": 29.279411764705884, "student_loss": null, "teacher_policy_loss": -17.35441017150879, "teacher_value_loss": 194.41452026367188, "teacher_entropy": 0.6314319968223572, "total_time": 1.2069666385650635, "rollout_time": 0.43334531784057617, "train_time": 0.7573938369750977, "student_train_time": 0.015876293182373047, "throughput": 1657.0466292073795, "inference_time": 0.0565047464788222, "env_time": 0.376840571361754, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 7, "reward_mean": 31.852459016393443, "student_loss": null, "teacher_policy_loss": -18.06468963623047, "teacher_value_loss": 221.2329864501953, "teacher_entropy": 0.5950669050216675, "total_time": 1.4172513484954834, "rollout_time": 0.4462738037109375, "train_time": 0.9550862312316895, "student_train_time": 0.015520572662353516, "throughput": 1411.1822875477574, "inference_time": 0.05818971947883256, "env_time": 0.38808408423210494, "samples": 2000, "teacher_eval_reward": 28.0}
{"epoch": 8, "reward_mean": 26.4025974025974, "student_loss": null, "teacher_policy_loss": -14.380265235900879, "teacher_value_loss": 130.1070098876953, "teacher_entropy": 0.6166703701019287, "total_time": 1.2753474712371826, "rollout_time": 0.46706700325012207, "train_time": 0.7913029193878174, "student_train_time": 0.016554832458496094, "throughput": 1568.2000749645508, "inference_time": 0.061606466993907816, "env_time": 0.40546053625621425, "samples": 2000, "teacher_eval_reward": 25.0}
{"epoch": 9, "reward_mean": 27.75, "student_loss": null, "teacher_policy_loss": -16.276683807373047, "teacher_value_loss": 156.29605102539062, "teacher_entropy": 0.6291307806968689, "total_time": 1.34956955909729, "rollout_time": 0.4450263977050781, "train_time": 0.8935966491699219, "student_train_time": 0.010540962219238281, "throughput": 1481.95399527074, "inference_time": 0.057939873959185206, "env_time": 0.3870865237458929, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 10, "reward_mean": 27.88888888888889, "student_loss": null, "teacher_policy_loss": -12.26436710357666, "teacher_value_loss": 105.32166290283203, "teacher_entropy": 0.5013349652290344, "total_time": 1.2445907592773438, "rollout_time": 0.4532153606414795, "train_time": 0.7798757553100586, "student_train_time": 0.011141538619995117, "throughput": 1606.9539204688256, "inference_time": 0.06086514449270908, "env_time": 0.3923502161487704, "samples": 2000, "teacher_eval_reward": 12.0}
{"epoch": 11, "reward_mean": 30.257575757575758, "student_loss": null, "teacher_policy_loss": -15.384651184082031, "teacher_value_loss": 195.1472930908203, "teacher_entropy": 0.5443309545516968, "total_time": 1.4502174854278564, "rollout_time": 0.4902956485748291, "train_time": 0.9456367492675781, "student_train_time": 0.01392221450805664, "throughput": 1379.1034931632628, "inference_time": 0.06656729056157928, "env_time": 0.4237283580132498, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 12, "reward_mean": 28.845070422535212, "student_loss": null, "teacher_policy_loss": -15.472583770751953, "teacher_value_loss": 96.29718017578125, "teacher_entropy": 0.6532624363899231, "total_time": 1.325451135635376, "rollout_time": 0.5100851058959961, "train_time": 0.7915515899658203, "student_train_time": 0.023449182510375977, "throughput": 1508.9202055278095, "inference_time": 0.07233226002972515, "env_time": 0.43775284586627095, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 13, "reward_mean": 28.636363636363637, "student_loss": null, "teacher_policy_loss": -15.381721496582031, "teacher_value_loss": 186.21343994140625, "teacher_entropy": 0.5292770266532898, "total_time": 1.261603832244873, "rollout_time": 0.4585123062133789, "train_time": 0.7927680015563965, "student_train_time": 0.009969949722290039, "throughput": 1585.28370704236, "inference_time": 0.059678515997802606, "env_time": 0.3988337902155763, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 14, "reward_mean": 34.22950819672131, "student_loss": null, "teacher_policy_loss": -15.847677230834961, "teacher_value_loss": 159.0260772705078, "teacher_entropy": 0.5196878910064697, "total_time": 1.5003855228424072, "rollout_time": 0.47183728218078613, "train_time": 1.0121545791625977, "student_train_time": 0.01598048210144043, "throughput": 1332.9907344154437, "inference_time": 0.06294182452074892, "env_time": 0.4088954576600372, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 15, "reward_mean": 32.35087719298246, "student_loss": null, "teacher_policy_loss": -18.7408390045166, "teacher_value_loss": 163.79556274414062, "teacher_entropy": 0.6121793985366821, "total_time": 1.3890342712402344, "rollout_time": 0.4487471580505371, "train_time": 0.9306786060333252, "student_train_time": 0.009247779846191406, "throughput": 1439.849283354434, "inference_time": 0.059664238287950866, "env_time": 0.38908291976258624, "samples": 2000, "teacher_eval_reward": 25.0}
{"epoch": 16, "reward_mean": 35.63934426229508, "student_loss": null, "teacher_policy_loss": -16.939958572387695, "teacher_value_loss": 149.5645751953125, "teacher_entropy": 0.5549570322036743, "total_time": 1.3556385040283203, "rollout_time": 0.47066259384155273, "train_time": 0.8692519664764404, "student_train_time": 0.01533365249633789, "throughput": 1475.3195590542318, "inference_time": 0.059613048790197354, "env_time": 0.4110495450513554, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 17, "reward_mean": 32.21666666666667, "student_loss": null, "teacher_policy_loss": -18.79181671142578, "teacher_value_loss": 206.3146209716797, "teacher_entropy": 0.5867862105369568, "total_time": 1.273533582687378, "rollout_time": 0.44594740867614746, "train_time": 0.8121175765991211, "student_train_time": 0.015115499496459961, "throughput": 1570.4336557655993, "inference_time": 0.05868933523197484, "env_time": 0.3872580734441726, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 18, "reward_mean": 39.326530612244895, "student_loss": null, "teacher_policy_loss": -19.2886905670166, "teacher_value_loss": 250.03097534179688, "teacher_entropy": 0.48947960138320923, "total_time": 1.5159614086151123, "rollout_time": 0.6214594841003418, "train_time": 0.8561842441558838, "student_train_time": 0.03794097900390625, "throughput": 1319.2947977660428, "inference_time": 0.07969824669453374, "env_time": 0.5417612374058081, "samples": 2000, "teacher_eval_reward": 14.0}
{"epoch": 19, "reward_mean": 38.36363636363637, "student_loss": null, "teacher_policy_loss": -16.30893898010254, "teacher_value_loss": 257.8721618652344, "teacher_entropy": 0.39682480692863464, "total_time": 1.2556281089782715, "rollout_time": 0.43930721282958984, "train_time": 0.7899603843688965, "student_train_time": 0.02601027488708496, "throughput": 1592.8283109458564, "inference_time": 0.05949053574477148, "env_time": 0.37981667708481837, "samples": 2000, "teacher_eval_reward": 14.0}
{"epoch": 20, "reward_mean": 42.95454545454545, "student_loss": null, "teacher_policy_loss": -17.85053062438965, "teacher_value_loss": 277.67449951171875, "teacher_entropy": 0.3531942069530487, "total_time": 1.343928337097168, "rollout_time": 0.4406149387359619, "train_time": 0.8890392780303955, "student_train_time": 0.013918638229370117, "throughput": 1488.174588475395, "inference_time": 0.05722645845344232, "env_time": 0.3833884802825196, "samples": 2000, "teacher_eval_reward": 13.0}
{"epoch": 21, "reward_mean": 35.62068965517241, "student_loss": null, "teacher_policy_loss": -14.161579132080078, "teacher_value_loss": 169.7609405517578, "teacher_entropy": 0.3783886432647705, "total_time": -1.3656721115112305, "rollout_time": 0.44052696228027344, "train_time": -1.81748628616333, "student_train_time": 0.01090550422668457, "throughput": 200000000000.0, "inference_time": 0.05882916451082565, "env_time": 0.3816977977694478, "samples": 2000, "teacher_eval_reward": 24.0}
{"epoch": 22, "reward_mean": 43.73913043478261, "student_loss": null, "teacher_policy_loss": -21.255531311035156, "teacher_value_loss": 265.5401611328125, "teacher_entropy": 0.504976212978363, "total_time": 1.2999036312103271, "rollout_time": 0.45433902740478516, "train_time": 0.8262934684753418, "student_train_time": 0.01892542839050293, "throughput": 1538.575592821308, "inference_time": 0.06225877175347705, "env_time": 0.3920802556513081, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 23, "reward_mean": 45.22222222222222, "student_loss": null, "teacher_policy_loss": -23.394067764282227, "teacher_value_loss": 288.60565185546875, "teacher_entropy": 0.546810507774353, "total_time": 1.2396855354309082, "rollout_time": 0.4363515377044678, "train_time": 0.7939033508300781, "student_train_time": 0.009087800979614258, "throughput": 1613.312362562019, "inference_time": 0.0608244110171654, "env_time": 0.37552712668730237, "samples": 2000, "teacher_eval_reward": 21.0}
{"epoch": 24, "reward_mean": 38.229166666666664, "student_loss": null, "teacher_policy_loss": -17.924732208251953, "teacher_value_loss": 174.3861541748047, "teacher_entropy": 0.4545919895172119, "total_time": 1.2607672214508057, "rollout_time": 0.4347245693206787, "train_time": 0.8081274032592773, "student_train_time": 0.017531633377075195, "throughput": 1586.335658138808, "inference_time": 0.06165868397874874, "env_time": 0.37306588534192997, "samples": 2000, "teacher_eval_reward": 25.0}
{"epoch": 25, "reward_mean": 46.77777777777778, "student_loss": null, "teacher_policy_loss": -21.310546875, "teacher_value_loss": 263.88360595703125, "teacher_entropy": 0.49694275856018066, "total_time": 1.3055555820465088, "rollout_time": 0.4314396381378174, "train_time": 0.846804141998291, "student_train_time": 0.026953697204589844, "throughput": 1531.9148625330242, "inference_time": 0.05956504299319931, "env_time": 0.37187459514461807, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 26, "reward_mean": 41.6875, "student_loss": null, "teacher_policy_loss": -21.092470169067383, "teacher_value_loss": 181.9366912841797, "teacher_entropy": 0.5487789511680603, "total_time": 1.2103641033172607, "rollout_time": 0.42485713958740234, "train_time": 0.7754385471343994, "student_train_time": 0.009681940078735352, "throughput": 1652.3953366747855, "inference_time": 0.05731200774425815, "env_time": 0.3675451318431442, "samples": 2000, "teacher_eval_reward": 100.0}
{"epoch": 27, "reward_mean": 44.24444444444445, "student_loss": null, "teacher_policy_loss": -21.703306198120117, "teacher_value_loss": 241.56326293945312, "teacher_entropy": 0.5070759654045105, "total_time": 1.3104004859924316, "rollout_time": 0.43459296226501465, "train_time": 0.863292932510376, "student_train_time": 0.012150049209594727, "throughput": 1526.2509602057269, "inference_time": 0.05466211650673358, "env_time": 0.37993084575828107, "samples": 2000, "teacher_eval_reward": 29.0}
{"epoch": 28, "reward_mean": 46.69767441860465, "student_loss": null, "teacher_policy_loss": -19.495885848999023, "teacher_value_loss": 202.5634002685547, "teacher_entropy": 0.46500858664512634, "total_time": 1.2689940929412842, "rollout_time": 0.45141077041625977, "train_time": 0.8015294075012207, "student_train_time": 0.015575885772705078, "throughput": 1576.051465585931, "inference_time": 0.06059958169316815, "env_time": 0.3908111887230916, "samples": 2000, "teacher_eval_reward": 107.0}
{"epoch": 29, "reward_mean": 49.825, "student_loss": null, "teacher_policy_loss": -22.129594802856445, "teacher_value_loss": 319.4064636230469, "teacher_entropy": 0.46733319759368896, "total_time": 1.3602015972137451, "rollout_time": 0.4393761157989502, "train_time": 0.9010345935821533, "student_train_time": 0.019438982009887695, "throughput": 1470.3702775359375, "inference_time": 0.05594474175813957, "env_time": 0.3834313740408106, "samples": 2000, "teacher_eval_reward": 113.0}
{"epoch": 30, "reward_mean": 43.84782608695652, "student_loss": null, "teacher_policy_loss": -21.463319778442383, "teacher_value_loss": 250.83880615234375, "teacher_entropy": 0.5261510014533997, "total_time": 1.2590787410736084, "rollout_time": 0.4400637149810791, "train_time": 0.8077516555786133, "student_train_time": 0.010848283767700195, "throughput": 1588.46300454141, "inference_time": 0.058936854564308305, "env_time": 0.3811268604167708, "samples": 2000, "teacher_eval_reward": 496.0}
{"epoch": 31, "reward_mean": 45.02439024390244, "student_loss": null, "teacher_policy_loss": -25.945383071899414, "teacher_value_loss": 305.9990234375, "teacher_entropy": 0.574777364730835, "total_time": 1.2505271434783936, "rollout_time": 0.44669175148010254, "train_time": 0.7776315212249756, "student_train_time": 0.025829076766967773, "throughput": 1599.325540777081, "inference_time": 0.0621857913047279, "env_time": 0.38450596017537464, "samples": 2000, "teacher_eval_reward": 36.0}
{"epoch": 32, "reward_mean": 59.432432432432435, "student_loss": null, "teacher_policy_loss": -26.525089263916016, "teacher_value_loss": 345.9773864746094, "teacher_entropy": 0.5354523062705994, "total_time": 1.3021109104156494, "rollout_time": 0.45313429832458496, "train_time": 0.8347585201263428, "student_train_time": 0.013843774795532227, "throughput": 1535.9674694389712, "inference_time": 0.0597279757475917, "env_time": 0.39340632257699326, "samples": 2000, "teacher_eval_reward": 172.0}
{"epoch": 33, "reward_mean": 48.125, "student_loss": null, "teacher_policy_loss": -23.712385177612305, "teacher_value_loss": 299.0420227050781, "teacher_entropy": 0.5507321953773499, "total_time": 1.2231342792510986, "rollout_time": 0.44330453872680664, "train_time": 0.7705175876617432, "student_train_time": 0.008883476257324219, "throughput": 1635.1434457585158, "inference_time": 0.060501657748318394, "env_time": 0.38280288097848825, "samples": 2000, "teacher_eval_reward": 386.0}
{"epoch": 34, "reward_mean": 46.2, "student_loss": null, "teacher_policy_loss": -24.251996994018555, "teacher_value_loss": 382.8284606933594, "teacher_entropy": 0.5778268575668335, "total_time": 1.2159979343414307, "rollout_time": 0.44855785369873047, "train_time": 0.7557439804077148, "student_train_time": 0.011330842971801758, "throughput": 1644.7396360777332, "inference_time": 0.05941241974505829, "env_time": 0.3891454339536722, "samples": 2000, "teacher_eval_reward": 104.0}
{"epoch": 35, "reward_mean": 53.638888888888886, "student_loss": null, "teacher_policy_loss": -26.25664710998535, "teacher_value_loss": 365.83355712890625, "teacher_entropy": 0.5770249366760254, "total_time": 1.2416772842407227, "rollout_time": 0.46047472953796387, "train_time": 0.7546403408050537, "student_train_time": 0.026139259338378906, "throughput": 1610.7244816216369, "inference_time": 0.061176446009994834, "env_time": 0.39929828352796903, "samples": 2000, "teacher_eval_reward": 226.0}
{"epoch": 36, "reward_mean": 51.275, "student_loss": null, "teacher_policy_loss": -23.752023696899414, "teacher_value_loss": 324.4289855957031, "teacher_entropy": 0.5463761687278748, "total_time": 1.4130370616912842, "rollout_time": 0.42728543281555176, "train_time": 0.9750349521636963, "student_train_time": 0.010359525680541992, "throughput": 1415.3910426143893, "inference_time": 0.05686525019700639, "env_time": 0.37042018261854537, "samples": 2000, "teacher_eval_reward": 342.0}
{"epoch": 37, "reward_mean": 47.743589743589745, "student_loss": null, "teacher_policy_loss": -25.63421630859375, "teacher_value_loss": 292.4713134765625, "teacher_entropy": 0.5656945705413818, "total_time": 1.485138177871704, "rollout_time": 0.42337512969970703, "train_time": 1.0507445335388184, "student_train_time": 0.010612010955810547, "throughput": 1346.6760398457502, "inference_time": 0.056650600490684155, "env_time": 0.3667245292090229, "samples": 2000, "teacher_eval_reward": 315.0}
{"epoch": 38, "reward_mean": 59.91428571428571, "student_loss": null, "teacher_policy_loss": -25.80055809020996, "teacher_value_loss": 204.45603942871094, "teacher_entropy": 0.5772704482078552, "total_time": 1.2930514812469482, "rollout_time": 0.44265055656433105, "train_time": 0.8363962173461914, "student_train_time": 0.01364755630493164, "throughput": 1546.7288263506023, "inference_time": 0.05926888645262807, "env_time": 0.383381670111703, "samples": 2000, "teacher_eval_reward": 174.0}
{"epoch": 39, "reward_mean": 59.54545454545455, "student_loss": null, "teacher_policy_loss": -26.40540313720703, "teacher_value_loss": 241.62205505371094, "teacher_entropy": 0.5446084141731262, "total_time": 1.2045202255249023, "rollout_time": 0.43250036239624023, "train_time": 0.7619140148162842, "student_train_time": 0.009500980377197266, "throughput": 1660.412135569119, "inference_time": 0.05838537397903565, "env_time": 0.3741149884172046, "samples": 2000, "teacher_eval_reward": 315.0}
{"epoch": 40, "reward_mean": 50.921052631578945, "student_loss": null, "teacher_policy_loss": -27.107196807861328, "teacher_value_loss": 373.6390686035156, "teacher_entropy": 0.5510458946228027, "total_time": 1.208827018737793, "rollout_time": 0.4430088996887207, "train_time": 0.7557017803192139, "student_train_time": 0.009718894958496094, "throughput": 1654.4964407631433, "inference_time": 0.05761634676127869, "env_time": 0.385392552927442, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 41, "reward_mean": 56.85294117647059, "student_loss": null, "teacher_policy_loss": -29.306734085083008, "teacher_value_loss": 477.9357604980469, "teacher_entropy": 0.5558903813362122, "total_time": 1.3508210182189941, "rollout_time": 0.4480118751525879, "train_time": 0.889108419418335, "student_train_time": 0.013334274291992188, "throughput": 1480.5810488771663, "inference_time": 0.05836082748101035, "env_time": 0.38965104767157754, "samples": 2000, "teacher_eval_reward": 415.0}
{"epoch": 42, "reward_mean": 68.5, "student_loss": null, "teacher_policy_loss": -30.1213321685791, "teacher_value_loss": 487.0531005859375, "teacher_entropy": 0.5599024891853333, "total_time": 1.202681064605713, "rollout_time": 0.43381738662719727, "train_time": 0.7532660961151123, "student_train_time": 0.015146017074584961, "throughput": 1662.9512668478574, "inference_time": 0.05765536502440227, "env_time": 0.376162021602795, "samples": 2000, "teacher_eval_reward": 253.0}
{"epoch": 43, "reward_mean": 60.875, "student_loss": null, "teacher_policy_loss": -28.717424392700195, "teacher_value_loss": 401.9937438964844, "teacher_entropy": 0.5547134876251221, "total_time": 1.2476813793182373, "rollout_time": 0.44507694244384766, "train_time": 0.791353702545166, "student_train_time": 0.010897636413574219, "throughput": 1602.9733497287964, "inference_time": 0.058925074754370144, "env_time": 0.3861518676894775, "samples": 2000, "teacher_eval_reward": 264.0}
{"epoch": 44, "reward_mean": 61.08571428571429, "student_loss": null, "teacher_policy_loss": -30.225582122802734, "teacher_value_loss": 468.5653076171875, "teacher_entropy": 0.5549682378768921, "total_time": 1.4525554180145264, "rollout_time": 0.6033182144165039, "train_time": 0.8322052955627441, "student_train_time": 0.016631364822387695, "throughput": 1376.8837837070384, "inference_time": 0.07204655019450001, "env_time": 0.5312716642220039, "samples": 2000, "teacher_eval_reward": 475.0}
{"epoch": 45, "reward_mean": 58.0, "student_loss": null, "teacher_policy_loss": -29.314983367919922, "teacher_value_loss": 323.273681640625, "teacher_entropy": 0.5825657844543457, "total_time": 1.2398312091827393, "rollout_time": 0.46674680709838867, "train_time": 0.7629439830780029, "student_train_time": 0.009737730026245117, "throughput": 1613.122806707166, "inference_time": 0.0636918717482331, "env_time": 0.4030549353501556, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 46, "reward_mean": 59.911764705882355, "student_loss": null, "teacher_policy_loss": -28.905582427978516, "teacher_value_loss": 379.5042724609375, "teacher_entropy": 0.5902898907661438, "total_time": 1.272345781326294, "rollout_time": 0.4298057556152344, "train_time": 0.8316590785980225, "student_train_time": 0.010533809661865234, "throughput": 1571.8997377546211, "inference_time": 0.056761373783956515, "env_time": 0.37304438183127786, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 47, "reward_mean": 58.65625, "student_loss": null, "teacher_policy_loss": -26.46822738647461, "teacher_value_loss": 300.20404052734375, "teacher_entropy": 0.5604089498519897, "total_time": 1.2055768966674805, "rollout_time": 0.43584322929382324, "train_time": 0.7575387954711914, "student_train_time": 0.011801719665527344, "throughput": 1658.9568077561091, "inference_time": 0.06103688749135472, "env_time": 0.3748063418024685, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 48, "reward_mean": 73.64285714285714, "student_loss": null, "teacher_policy_loss": -32.06438064575195, "teacher_value_loss": 417.0208740234375, "teacher_entropy": 0.5818854570388794, "total_time": 1.1948251724243164, "rollout_time": 0.4194967746734619, "train_time": 0.7642621994018555, "student_train_time": 0.010666608810424805, "throughput": 1673.885055452902, "inference_time": 0.0549188117893209, "env_time": 0.364577962884141, "samples": 2000, "teacher_eval_reward": 197.0}
{"epoch": 49, "reward_mean": 67.44827586206897, "student_loss": null, "teacher_policy_loss": -31.776874542236328, "teacher_value_loss": 368.5649108886719, "teacher_entropy": 0.5976887345314026, "total_time": 1.2134132385253906, "rollout_time": 0.42534494400024414, "train_time": 0.7757143974304199, "student_train_time": 0.01199197769165039, "throughput": 1648.243101773403, "inference_time": 0.05580300868314225, "env_time": 0.3695419353171019, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 50, "reward_mean": 56.78378378378378, "student_loss": null, "teacher_policy_loss": -24.337175369262695, "teacher_value_loss": 341.54486083984375, "teacher_entropy": 0.5855870246887207, "total_time": 1.330622911453247, "rollout_time": 0.4230763912200928, "train_time": 0.8921215534210205, "student_train_time": 0.015072822570800781, "throughput": 1503.0554357550398, "inference_time": 0.05603042399525293, "env_time": 0.36704596722483984, "samples": 2000, "teacher_eval_reward": 116.0}
{"epoch": 51, "reward_mean": 65.29629629629629, "student_loss": null, "teacher_policy_loss": -31.122909545898438, "teacher_value_loss": 321.5833740234375, "teacher_entropy": 0.5697005987167358, "total_time": 1.2053072452545166, "rollout_time": 0.4317035675048828, "train_time": 0.7564105987548828, "student_train_time": 0.01683950424194336, "throughput": 1659.3279496778214, "inference_time": 0.056712129235165776, "env_time": 0.37499143826971704, "samples": 2000, "teacher_eval_reward": 122.0}
{"epoch": 52, "reward_mean": 85.76, "student_loss": null, "teacher_policy_loss": -35.26047897338867, "teacher_value_loss": 388.1215515136719, "teacher_entropy": 0.5890438556671143, "total_time": 1.271036148071289, "rollout_time": 0.45685887336730957, "train_time": 0.8015403747558594, "student_train_time": 0.012247562408447266, "throughput": 1573.5193708179456, "inference_time": 0.06318216577528801, "env_time": 0.39367670759202156, "samples": 2000, "teacher_eval_reward": 30.0}
{"epoch": 53, "reward_mean": 91.52380952380952, "student_loss": null, "teacher_policy_loss": -36.39139175415039, "teacher_value_loss": 572.3052368164062, "teacher_entropy": 0.5329565405845642, "total_time": 1.1931407451629639, "rollout_time": 0.4320507049560547, "train_time": 0.7496521472930908, "student_train_time": 0.011072397232055664, "throughput": 1676.2481778516683, "inference_time": 0.05582818247239629, "env_time": 0.3762225224836584, "samples": 2000, "teacher_eval_reward": 26.0}
{"epoch": 54, "reward_mean": 76.81481481481481, "student_loss": null, "teacher_policy_loss": -29.675514221191406, "teacher_value_loss": 406.0271301269531, "teacher_entropy": 0.49455076456069946, "total_time": 1.3744919300079346, "rollout_time": 0.44359779357910156, "train_time": 0.9141364097595215, "student_train_time": 0.016402482986450195, "throughput": 1455.0831156851204, "inference_time": 0.058204332237437484, "env_time": 0.3853934613416641, "samples": 2000, "teacher_eval_reward": 99.0}
{"epoch": 55, "reward_mean": 70.44827586206897, "student_loss": null, "teacher_policy_loss": -32.92433547973633, "teacher_value_loss": 460.5289001464844, "teacher_entropy": 0.5455652475357056, "total_time": 1.206371784210205, "rollout_time": 0.4284975528717041, "train_time": 0.7676949501037598, "student_train_time": 0.009784936904907227, "throughput": 1657.863708499592, "inference_time": 0.05943800075328909, "env_time": 0.369059552118415, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 56, "reward_mean": 88.0, "student_loss": null, "teacher_policy_loss": -36.04531478881836, "teacher_value_loss": 394.08355712890625, "teacher_entropy": 0.5692105889320374, "total_time": 1.3034965991973877, "rollout_time": 0.4440033435821533, "train_time": 0.8384578227996826, "student_train_time": 0.02064204216003418, "throughput": 1534.3346512998007, "inference_time": 0.05733664297804353, "env_time": 0.3866667006041098, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 57, "reward_mean": 94.5, "student_loss": null, "teacher_policy_loss": -36.53839874267578, "teacher_value_loss": 439.66632080078125, "teacher_entropy": 0.5185325145721436, "total_time": 1.1626408100128174, "rollout_time": 0.4213547706604004, "train_time": 0.7310571670532227, "student_train_time": 0.009882688522338867, "throughput": 1720.221742412389, "inference_time": 0.05514128082177194, "env_time": 0.36621348983862845, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 58, "reward_mean": 73.92592592592592, "student_loss": null, "teacher_policy_loss": -26.915613174438477, "teacher_value_loss": 385.8731384277344, "teacher_entropy": 0.4968515634536743, "total_time": 1.4463903903961182, "rollout_time": 0.42864394187927246, "train_time": 1.0056016445159912, "student_train_time": 0.01174306869506836, "throughput": 1382.7525495743002, "inference_time": 0.05727838075108593, "env_time": 0.3713655611281865, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 59, "reward_mean": 73.34482758620689, "student_loss": null, "teacher_policy_loss": -29.376876831054688, "teacher_value_loss": 428.4139404296875, "teacher_entropy": 0.5455853343009949, "total_time": 1.4439220428466797, "rollout_time": 0.4308793544769287, "train_time": 0.9957485198974609, "student_train_time": 0.01686573028564453, "throughput": 1385.116329450181, "inference_time": 0.05709755317730014, "env_time": 0.37378180129962857, "samples": 2000, "teacher_eval_reward": 180.0}
{"epoch": 60, "reward_mean": 73.53846153846153, "student_loss": null, "teacher_policy_loss": -34.251678466796875, "teacher_value_loss": 440.07049560546875, "teacher_entropy": 0.5707170963287354, "total_time": 1.1937916278839111, "rollout_time": 0.44464802742004395, "train_time": 0.7403137683868408, "student_train_time": 0.008469581604003906, "throughput": 1675.3342486956087, "inference_time": 0.05845603575471614, "env_time": 0.3861919916653278, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 61, "reward_mean": 89.69565217391305, "student_loss": null, "teacher_policy_loss": -32.44013977050781, "teacher_value_loss": 378.3568115234375, "teacher_entropy": 0.5287458300590515, "total_time": 1.276597499847412, "rollout_time": 0.4413926601409912, "train_time": 0.8254501819610596, "student_train_time": 0.009350061416625977, "throughput": 1566.6645126902208, "inference_time": 0.05725546972644224, "env_time": 0.38413719041454897, "samples": 2000, "teacher_eval_reward": 45.0}
{"epoch": 62, "reward_mean": 107.41176470588235, "student_loss": null, "teacher_policy_loss": -40.21144485473633, "teacher_value_loss": 534.1488647460938, "teacher_entropy": 0.5389694571495056, "total_time": 1.308922529220581, "rollout_time": 0.4537794589996338, "train_time": 0.8418936729431152, "student_train_time": 0.01288604736328125, "throughput": 1527.9743112000158, "inference_time": 0.06263927227519162, "env_time": 0.3911401867244422, "samples": 2000, "teacher_eval_reward": 473.0}
{"epoch": 63, "reward_mean": 86.30434782608695, "student_loss": null, "teacher_policy_loss": -35.667442321777344, "teacher_value_loss": 379.3294372558594, "teacher_entropy": 0.5585823655128479, "total_time": 1.2196619510650635, "rollout_time": 0.46140360832214355, "train_time": 0.7425510883331299, "student_train_time": 0.015351295471191406, "throughput": 1639.7986329355526, "inference_time": 0.06286702470242744, "env_time": 0.3985365836197161, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 64, "reward_mean": 89.29166666666667, "student_loss": null, "teacher_policy_loss": -31.690013885498047, "teacher_value_loss": 294.5843811035156, "teacher_entropy": 0.5226855874061584, "total_time": 1.3149843215942383, "rollout_time": 0.4453709125518799, "train_time": 0.8557770252227783, "student_train_time": 0.013330698013305664, "throughput": 1520.9306811926656, "inference_time": 0.05775932922551874, "env_time": 0.38761158332636114, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 65, "reward_mean": 84.45833333333333, "student_loss": null, "teacher_policy_loss": -32.610679626464844, "teacher_value_loss": 389.6583557128906, "teacher_entropy": 0.5014051198959351, "total_time": 1.1699681282043457, "rollout_time": 0.42351484298706055, "train_time": 0.735034704208374, "student_train_time": 0.01106715202331543, "throughput": 1709.4482762274713, "inference_time": 0.056385097765087266, "env_time": 0.3671297452219733, "samples": 2000, "teacher_eval_reward": 266.0}
{"epoch": 66, "reward_mean": 114.88235294117646, "student_loss": null, "teacher_policy_loss": -42.63956069946289, "teacher_value_loss": 501.5899963378906, "teacher_entropy": 0.5385847091674805, "total_time": -1.313108205795288, "rollout_time": -2.108475923538208, "train_time": 0.7773666381835938, "student_train_time": 0.017489910125732422, "throughput": 200000000000.0, "inference_time": 0.06007632731052581, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 67, "reward_mean": 108.11764705882354, "student_loss": null, "teacher_policy_loss": -39.4084358215332, "teacher_value_loss": 495.8501892089844, "teacher_entropy": 0.5303142070770264, "total_time": 1.1685380935668945, "rollout_time": 0.41695570945739746, "train_time": 0.7438945770263672, "student_train_time": 0.00733637809753418, "throughput": 1711.540266432493, "inference_time": 0.057519464016877464, "env_time": 0.35943624544052, "samples": 2000, "teacher_eval_reward": 36.0}
{"epoch": 68, "reward_mean": 110.44444444444444, "student_loss": null, "teacher_policy_loss": -35.5267219543457, "teacher_value_loss": 366.5185546875, "teacher_entropy": 0.4814990162849426, "total_time": 1.2864048480987549, "rollout_time": 0.4404149055480957, "train_time": 0.8081309795379639, "student_train_time": 0.037122488021850586, "throughput": 1554.720508831963, "inference_time": 0.059815413998876465, "env_time": 0.38059949154921924, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 69, "reward_mean": 113.05263157894737, "student_loss": null, "teacher_policy_loss": -38.121856689453125, "teacher_value_loss": 364.2691650390625, "teacher_entropy": 0.5286607146263123, "total_time": 1.2072062492370605, "rollout_time": 0.4187445640563965, "train_time": 0.7737710475921631, "student_train_time": 0.014340877532958984, "throughput": 1656.7177325862713, "inference_time": 0.05628900126248482, "env_time": 0.36245556279391167, "samples": 2000, "teacher_eval_reward": 58.0}
{"epoch": 70, "reward_mean": 112.38888888888889, "student_loss": null, "teacher_policy_loss": -35.25502395629883, "teacher_value_loss": 432.05438232421875, "teacher_entropy": 0.470055490732193, "total_time": 1.2904863357543945, "rollout_time": 0.449857234954834, "train_time": 0.7910170555114746, "student_train_time": 0.04915285110473633, "throughput": 1549.8033141364776, "inference_time": 0.05729035004878824, "env_time": 0.39256688490604574, "samples": 2000, "teacher_eval_reward": 43.0}
{"epoch": 71, "reward_mean": 116.61111111111111, "student_loss": null, "teacher_policy_loss": -32.68472671508789, "teacher_value_loss": 427.1756286621094, "teacher_entropy": 0.36294031143188477, "total_time": 1.2109649181365967, "rollout_time": 0.44901251792907715, "train_time": 0.747765064239502, "student_train_time": 0.013795614242553711, "throughput": 1651.5755081307816, "inference_time": 0.05938014625098731, "env_time": 0.38963237167808984, "samples": 2000, "teacher_eval_reward": 47.0}
{"epoch": 72, "reward_mean": 96.16666666666667, "student_loss": null, "teacher_policy_loss": -34.784759521484375, "teacher_value_loss": 495.37384033203125, "teacher_entropy": 0.38855743408203125, "total_time": 1.2999837398529053, "rollout_time": 0.4414219856262207, "train_time": 0.8480691909790039, "student_train_time": 0.010140657424926758, "throughput": 1538.4807814798532, "inference_time": 0.058944367217918625, "env_time": 0.3824776184083021, "samples": 2000, "teacher_eval_reward": 346.0}
{"epoch": 73, "reward_mean": 93.79166666666667, "student_loss": null, "teacher_policy_loss": -33.37599182128906, "teacher_value_loss": 385.4228210449219, "teacher_entropy": 0.4897674322128296, "total_time": 1.528503656387329, "rollout_time": 0.43849968910217285, "train_time": 1.065258502960205, "student_train_time": 0.02439093589782715, "throughput": 1308.4692284786997, "inference_time": 0.060411717953684274, "env_time": 0.3780879711484886, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 74, "reward_mean": 109.83333333333333, "student_loss": null, "teacher_policy_loss": -37.00931930541992, "teacher_value_loss": 314.6702575683594, "teacher_entropy": 0.4841557741165161, "total_time": 1.573288917541504, "rollout_time": 0.5622763633728027, "train_time": 0.991248607635498, "student_train_time": 0.019405364990234375, "throughput": 1271.2223277624653, "inference_time": 0.07765313873824198, "env_time": 0.48462322463456076, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 75, "reward_mean": 132.6153846153846, "student_loss": null, "teacher_policy_loss": -44.87875747680664, "teacher_value_loss": 499.8603820800781, "teacher_entropy": 0.4733450710773468, "total_time": 1.2577600479125977, "rollout_time": 0.4398305416107178, "train_time": 0.8014614582061768, "student_train_time": 0.016113758087158203, "throughput": 1590.1284218076714, "inference_time": 0.06173142268926313, "env_time": 0.37809911892145465, "samples": 2000, "teacher_eval_reward": 161.0}
{"epoch": 76, "reward_mean": 158.21428571428572, "student_loss": null, "teacher_policy_loss": -45.07548522949219, "teacher_value_loss": 474.17156982421875, "teacher_entropy": 0.48345744609832764, "total_time": 1.410372257232666, "rollout_time": 0.45908069610595703, "train_time": 0.9285905361175537, "student_train_time": 0.022272109985351562, "throughput": 1418.0653297337685, "inference_time": 0.06093668125686236, "env_time": 0.3981440148490947, "samples": 2000, "teacher_eval_reward": 222.0}
{"epoch": 77, "reward_mean": 115.88235294117646, "student_loss": null, "teacher_policy_loss": -43.53167724609375, "teacher_value_loss": 503.36663818359375, "teacher_entropy": 0.4911232888698578, "total_time": 1.280735969543457, "rollout_time": 0.4561753273010254, "train_time": 0.8055586814880371, "student_train_time": 0.018635272979736328, "throughput": 1561.602115940367, "inference_time": 0.0645608321774489, "env_time": 0.3916144951235765, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 78, "reward_mean": 133.875, "student_loss": null, "teacher_policy_loss": -41.23445129394531, "teacher_value_loss": 386.2178649902344, "teacher_entropy": 0.4694196879863739, "total_time": 1.2693722248077393, "rollout_time": 0.4485607147216797, "train_time": 0.8029046058654785, "student_train_time": 0.01749444007873535, "throughput": 1575.5819773848625, "inference_time": 0.05931725524897047, "env_time": 0.3892434594727092, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 79, "reward_mean": 102.66666666666667, "student_loss": null, "teacher_policy_loss": -40.63935852050781, "teacher_value_loss": 593.7125854492188, "teacher_entropy": 0.4797426462173462, "total_time": 1.440593957901001, "rollout_time": 0.5740580558776855, "train_time": 0.8487851619720459, "student_train_time": 0.017390012741088867, "throughput": 1388.3162490241696, "inference_time": 0.06262968421833648, "env_time": 0.5114283716593491, "samples": 2000, "teacher_eval_reward": 284.0}
{"epoch": 80, "reward_mean": 110.11111111111111, "student_loss": null, "teacher_policy_loss": -38.22974395751953, "teacher_value_loss": 490.9593811035156, "teacher_entropy": 0.4871813654899597, "total_time": 1.294750452041626, "rollout_time": 0.4272933006286621, "train_time": 0.8516583442687988, "student_train_time": 0.015442371368408203, "throughput": 1544.6992096788242, "inference_time": 0.058138074058661005, "env_time": 0.3691552265700011, "samples": 2000, "teacher_eval_reward": 197.0}
{"epoch": 81, "reward_mean": 148.84615384615384, "student_loss": null, "teacher_policy_loss": -43.87053298950195, "teacher_value_loss": 341.4159851074219, "teacher_entropy": 0.5074675679206848, "total_time": 1.3299496173858643, "rollout_time": 0.5497617721557617, "train_time": 0.7675046920776367, "student_train_time": 0.012256145477294922, "throughput": 1503.816365563667, "inference_time": 0.12135097855025379, "env_time": 0.42841079360550793, "samples": 2000, "teacher_eval_reward": 184.0}
{"epoch": 82, "reward_mean": 152.08333333333334, "student_loss": null, "teacher_policy_loss": -47.9760856628418, "teacher_value_loss": 357.1529235839844, "teacher_entropy": 0.5077201128005981, "total_time": -1.350388765335083, "rollout_time": -2.171116828918457, "train_time": 0.808844804763794, "student_train_time": 0.011526346206665039, "throughput": 200000000000.0, "inference_time": 0.05852118378970772, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 463.0}
{"epoch": 83, "reward_mean": 178.16666666666666, "student_loss": null, "teacher_policy_loss": -50.84149932861328, "teacher_value_loss": 482.0555114746094, "teacher_entropy": 0.5195891261100769, "total_time": 1.251955270767212, "rollout_time": 0.43944811820983887, "train_time": 0.7943770885467529, "student_train_time": 0.01767873764038086, "throughput": 1597.5011621416618, "inference_time": 0.06161940023230272, "env_time": 0.37782871797753614, "samples": 2000, "teacher_eval_reward": 239.0}
{"epoch": 84, "reward_mean": 182.6, "student_loss": null, "teacher_policy_loss": -50.142852783203125, "teacher_value_loss": 370.6767578125, "teacher_entropy": 0.5159186720848083, "total_time": 1.3333990573883057, "rollout_time": 0.44098663330078125, "train_time": 0.8797633647918701, "student_train_time": 0.012296438217163086, "throughput": 1499.9260640826824, "inference_time": 0.05898987279397261, "env_time": 0.38199676050680864, "samples": 2000, "teacher_eval_reward": 211.0}
{"epoch": 85, "reward_mean": 152.2, "student_loss": null, "teacher_policy_loss": -45.32889938354492, "teacher_value_loss": 330.23284912109375, "teacher_entropy": 0.5265377163887024, "total_time": 1.222660779953003, "rollout_time": 0.43010520935058594, "train_time": 0.7807300090789795, "student_train_time": 0.011469841003417969, "throughput": 1635.7766870356934, "inference_time": 0.05734464150918939, "env_time": 0.37276056784139655, "samples": 2000, "teacher_eval_reward": 133.0}
{"epoch": 86, "reward_mean": 142.8, "student_loss": null, "teacher_policy_loss": -44.03877639770508, "teacher_value_loss": 480.1663818359375, "teacher_entropy": 0.502226710319519, "total_time": 1.1975669860839844, "rollout_time": 0.44321656227111816, "train_time": 0.7393934726715088, "student_train_time": 0.014600753784179688, "throughput": 1670.0527179193145, "inference_time": 0.0574748809904122, "env_time": 0.38574168128070596, "samples": 2000, "teacher_eval_reward": 143.0}
{"epoch": 87, "reward_mean": 160.0, "student_loss": null, "teacher_policy_loss": -46.020103454589844, "teacher_value_loss": 339.5232849121094, "teacher_entropy": 0.5083792805671692, "total_time": 1.4638779163360596, "rollout_time": 0.4346318244934082, "train_time": 1.0155987739562988, "student_train_time": 0.013294696807861328, "throughput": 1366.2341495018932, "inference_time": 0.058241871989594074, "env_time": 0.37638995250381413, "samples": 2000, "teacher_eval_reward": 266.0}
{"epoch": 88, "reward_mean": 172.66666666666666, "student_loss": null, "teacher_policy_loss": -47.71741485595703, "teacher_value_loss": 465.9126892089844, "teacher_entropy": 0.5343902111053467, "total_time": 1.2389953136444092, "rollout_time": 0.4309244155883789, "train_time": 0.7864358425140381, "student_train_time": 0.021157503128051758, "throughput": 1614.2111095780938, "inference_time": 0.05839999452837219, "env_time": 0.3725244210600067, "samples": 2000, "teacher_eval_reward": 193.0}
{"epoch": 89, "reward_mean": 162.76923076923077, "student_loss": null, "teacher_policy_loss": -44.35297393798828, "teacher_value_loss": 479.3042907714844, "teacher_entropy": 0.5020429491996765, "total_time": 1.276395559310913, "rollout_time": 0.444124698638916, "train_time": 0.812577486038208, "student_train_time": 0.019254207611083984, "throughput": 1566.9123771315365, "inference_time": 0.05832881943570101, "env_time": 0.385795879203215, "samples": 2000, "teacher_eval_reward": 254.0}
{"epoch": 90, "reward_mean": 128.375, "student_loss": null, "teacher_policy_loss": -43.5827751159668, "teacher_value_loss": 489.6169128417969, "teacher_entropy": 0.5291294455528259, "total_time": 1.3492281436920166, "rollout_time": 0.4708101749420166, "train_time": 0.8480973243713379, "student_train_time": 0.02988266944885254, "throughput": 1482.3289962861409, "inference_time": 0.05845398275050684, "env_time": 0.41235619219150976, "samples": 2000, "teacher_eval_reward": 158.0}
{"epoch": 91, "reward_mean": 175.2, "student_loss": null, "teacher_policy_loss": -51.93203353881836, "teacher_value_loss": 535.3733520507812, "teacher_entropy": 0.5464054942131042, "total_time": 1.3291738033294678, "rollout_time": 0.4439582824707031, "train_time": 0.8717362880706787, "student_train_time": 0.011818408966064453, "throughput": 1504.694115239233, "inference_time": 0.05858484702730493, "env_time": 0.3853734354433982, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 92, "reward_mean": 156.3846153846154, "student_loss": null, "teacher_policy_loss": -44.20144271850586, "teacher_value_loss": 529.2268676757812, "teacher_entropy": 0.5228336453437805, "total_time": 1.2530670166015625, "rollout_time": 0.43067383766174316, "train_time": 0.8048548698425293, "student_train_time": 0.01717209815979004, "throughput": 1596.0838275228018, "inference_time": 0.0577873377569631, "env_time": 0.37288649990478007, "samples": 2000, "teacher_eval_reward": 155.0}
{"epoch": 93, "reward_mean": 206.6, "student_loss": null, "teacher_policy_loss": -50.725006103515625, "teacher_value_loss": 532.0919189453125, "teacher_entropy": 0.5162636637687683, "total_time": 1.3383128643035889, "rollout_time": 0.4422142505645752, "train_time": 0.8777258396148682, "student_train_time": 0.017976999282836914, "throughput": 1494.418871211202, "inference_time": 0.060139967088616686, "env_time": 0.3820742834759585, "samples": 2000, "teacher_eval_reward": 203.0}
{"epoch": 94, "reward_mean": 135.91666666666666, "student_loss": null, "teacher_policy_loss": -47.51692581176758, "teacher_value_loss": 573.7432861328125, "teacher_entropy": 0.5329274535179138, "total_time": 1.3671255111694336, "rollout_time": 0.4421854019165039, "train_time": 0.9049012660980225, "student_train_time": 0.019687891006469727, "throughput": 1462.9234723951631, "inference_time": 0.05967117002910527, "env_time": 0.38251423188739864, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 95, "reward_mean": 209.0, "student_loss": null, "teacher_policy_loss": -48.43075180053711, "teacher_value_loss": 387.6446228027344, "teacher_entropy": 0.5414488315582275, "total_time": -1.3009939193725586, "rollout_time": -2.1837260723114014, "train_time": 0.8562929630279541, "student_train_time": 0.026082515716552734, "throughput": 200000000000.0, "inference_time": 0.05825872752939176, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 150.0}
{"epoch": 96, "reward_mean": 181.72727272727272, "student_loss": null, "teacher_policy_loss": -48.623409271240234, "teacher_value_loss": 467.2366943359375, "teacher_entropy": 0.5312634706497192, "total_time": 1.2808265686035156, "rollout_time": 0.46461009979248047, "train_time": 0.8055157661437988, "student_train_time": 0.010349035263061523, "throughput": 1561.4916562674046, "inference_time": 0.06462388898762583, "env_time": 0.39998621080485464, "samples": 2000, "teacher_eval_reward": 185.0}
{"epoch": 97, "reward_mean": 149.35714285714286, "student_loss": null, "teacher_policy_loss": -41.828163146972656, "teacher_value_loss": 486.3797302246094, "teacher_entropy": 0.5184861421585083, "total_time": 1.2282044887542725, "rollout_time": 0.4577348232269287, "train_time": 0.7544589042663574, "student_train_time": 0.015605449676513672, "throughput": 1628.3933321466154, "inference_time": 0.06268534849732532, "env_time": 0.3950494747296034, "samples": 2000, "teacher_eval_reward": 115.0}
{"epoch": 98, "reward_mean": 188.0, "student_loss": null, "teacher_policy_loss": -47.743412017822266, "teacher_value_loss": 412.9070129394531, "teacher_entropy": 0.5152876377105713, "total_time": 1.3782248497009277, "rollout_time": 0.4448983669281006, "train_time": 0.9213809967041016, "student_train_time": 0.011591672897338867, "throughput": 1451.142025507664, "inference_time": 0.06158069048251491, "env_time": 0.3833176764455857, "samples": 2000, "teacher_eval_reward": 255.0}
{"epoch": 99, "reward_mean": 224.55555555555554, "student_loss": null, "teacher_policy_loss": -55.32548904418945, "teacher_value_loss": 534.2130737304688, "teacher_entropy": 0.5444719791412354, "total_time": 1.2842762470245361, "rollout_time": 0.42751431465148926, "train_time": 0.8323793411254883, "student_train_time": 0.023993730545043945, "throughput": 1557.2973529905905, "inference_time": 0.06004136047158681, "env_time": 0.36747295417990244, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 100, "reward_mean": 190.66666666666666, "student_loss": null, "teacher_policy_loss": -47.88097381591797, "teacher_value_loss": 615.6582641601562, "teacher_entropy": 0.5249565243721008, "total_time": 1.2572810649871826, "rollout_time": 0.435854434967041, "train_time": 0.801732063293457, "student_train_time": 0.01934504508972168, "throughput": 1590.7342086794165, "inference_time": 0.05880923830954998, "env_time": 0.37704519665749103, "samples": 2000, "teacher_eval_reward": 102.0}
{"epoch": 101, "reward_mean": 178.0, "student_loss": null, "teacher_policy_loss": -47.94031524658203, "teacher_value_loss": 391.14886474609375, "teacher_entropy": 0.48105114698410034, "total_time": 1.3107457160949707, "rollout_time": 0.4435114860534668, "train_time": 0.8566334247589111, "student_train_time": 0.010250091552734375, "throughput": 1525.848969362635, "inference_time": 0.058676121007010806, "env_time": 0.384835365046456, "samples": 2000, "teacher_eval_reward": 154.0}
{"epoch": 102, "reward_mean": 162.6, "student_loss": null, "teacher_policy_loss": -45.5428581237793, "teacher_value_loss": 461.50531005859375, "teacher_entropy": 0.5343816876411438, "total_time": 1.2511944770812988, "rollout_time": 0.45227599143981934, "train_time": 0.7885990142822266, "student_train_time": 0.009965658187866211, "throughput": 1598.472528959258, "inference_time": 0.061512414999015164, "env_time": 0.3907635764408042, "samples": 2000, "teacher_eval_reward": 250.0}
{"epoch": 103, "reward_mean": 159.1, "student_loss": null, "teacher_policy_loss": -52.135963439941406, "teacher_value_loss": 549.6010131835938, "teacher_entropy": 0.5377367734909058, "total_time": 1.2607409954071045, "rollout_time": 0.4479646682739258, "train_time": 0.7992782592773438, "student_train_time": 0.013107776641845703, "throughput": 1586.3686572309662, "inference_time": 0.06031562244061206, "env_time": 0.3876490458333137, "samples": 2000, "teacher_eval_reward": 434.0}
{"epoch": 104, "reward_mean": 232.3, "student_loss": null, "teacher_policy_loss": -52.70326614379883, "teacher_value_loss": 756.589599609375, "teacher_entropy": 0.5543755888938904, "total_time": 1.354841709136963, "rollout_time": 0.4545304775238037, "train_time": 0.8883187770843506, "student_train_time": 0.011429548263549805, "throughput": 1476.1872080790931, "inference_time": 0.06111711423727684, "env_time": 0.3934133632865269, "samples": 2000, "teacher_eval_reward": 171.0}
{"epoch": 105, "reward_mean": 177.72727272727272, "student_loss": null, "teacher_policy_loss": -47.816837310791016, "teacher_value_loss": 480.2521667480469, "teacher_entropy": 0.5400938987731934, "total_time": 1.3410096168518066, "rollout_time": 0.44626402854919434, "train_time": 0.8798046112060547, "student_train_time": 0.014572381973266602, "throughput": 1491.4136146877593, "inference_time": 0.059701419764678576, "env_time": 0.38656260878451576, "samples": 2000, "teacher_eval_reward": 197.0}
{"epoch": 106, "reward_mean": 225.5, "student_loss": null, "teacher_policy_loss": -55.90167236328125, "teacher_value_loss": 658.4838256835938, "teacher_entropy": 0.5389077663421631, "total_time": 1.2904367446899414, "rollout_time": 0.43322277069091797, "train_time": 0.8471989631652832, "student_train_time": 0.009649276733398438, "throughput": 1549.8628725738497, "inference_time": 0.058310614209403866, "env_time": 0.3749121564815141, "samples": 2000, "teacher_eval_reward": 275.0}
{"epoch": 107, "reward_mean": 236.88888888888889, "student_loss": null, "teacher_policy_loss": -55.45124053955078, "teacher_value_loss": 643.0093383789062, "teacher_entropy": 0.552909255027771, "total_time": 1.2421560287475586, "rollout_time": 0.4392673969268799, "train_time": 0.7836143970489502, "student_train_time": 0.018909454345703125, "throughput": 1610.1036856187548, "inference_time": 0.06112741147626366, "env_time": 0.3781399854506162, "samples": 2000, "teacher_eval_reward": 248.0}
{"epoch": 108, "reward_mean": 186.66666666666666, "student_loss": null, "teacher_policy_loss": -49.082279205322266, "teacher_value_loss": 461.1776123046875, "teacher_entropy": 0.5436664819717407, "total_time": 1.2789645195007324, "rollout_time": 0.4470376968383789, "train_time": 0.81662917137146, "student_train_time": 0.014945507049560547, "throughput": 1563.7650376577585, "inference_time": 0.061266516999239684, "env_time": 0.3857711798391392, "samples": 2000, "teacher_eval_reward": 176.0}
{"epoch": 109, "reward_mean": 149.76923076923077, "student_loss": null, "teacher_policy_loss": -47.38581466674805, "teacher_value_loss": 521.9078979492188, "teacher_entropy": 0.5378121137619019, "total_time": 1.3984971046447754, "rollout_time": 0.4487934112548828, "train_time": 0.8857564926147461, "student_train_time": 0.06357765197753906, "throughput": 1430.10664330836, "inference_time": 0.05965679423388792, "env_time": 0.3891366170209949, "samples": 2000, "teacher_eval_reward": 192.0}
{"epoch": 110, "reward_mean": 177.88888888888889, "student_loss": null, "teacher_policy_loss": -54.657466888427734, "teacher_value_loss": 378.6627197265625, "teacher_entropy": 0.5575708150863647, "total_time": 1.3319764137268066, "rollout_time": 0.4579153060913086, "train_time": 0.8610115051269531, "student_train_time": 0.012685537338256836, "throughput": 1501.5280896784764, "inference_time": 0.05973678705049679, "env_time": 0.3981785190408118, "samples": 2000, "teacher_eval_reward": 158.0}
{"epoch": 111, "reward_mean": 222.66666666666666, "student_loss": null, "teacher_policy_loss": -54.52307891845703, "teacher_value_loss": 303.62835693359375, "teacher_entropy": 0.541975736618042, "total_time": 1.2713227272033691, "rollout_time": 0.45690035820007324, "train_time": 0.801654577255249, "student_train_time": 0.012363195419311523, "throughput": 1573.1646710977636, "inference_time": 0.05987822478346061, "env_time": 0.39702213341661263, "samples": 2000, "teacher_eval_reward": 211.0}
{"epoch": 112, "reward_mean": 188.58333333333334, "student_loss": null, "teacher_policy_loss": -48.44883346557617, "teacher_value_loss": 528.7256469726562, "teacher_entropy": 0.5442562699317932, "total_time": 1.350292444229126, "rollout_time": 0.4464130401611328, "train_time": 0.8893139362335205, "student_train_time": 0.014160394668579102, "throughput": 1481.1606245355156, "inference_time": 0.06152910647324461, "env_time": 0.3848839336878882, "samples": 2000, "teacher_eval_reward": 447.0}
{"epoch": 113, "reward_mean": 191.1, "student_loss": null, "teacher_policy_loss": -52.221187591552734, "teacher_value_loss": 404.5025634765625, "teacher_entropy": 0.5502903461456299, "total_time": 1.3722920417785645, "rollout_time": 0.44922828674316406, "train_time": 0.9071333408355713, "student_train_time": 0.015536308288574219, "throughput": 1457.415724285548, "inference_time": 0.06078111842907674, "env_time": 0.3884471683140873, "samples": 2000, "teacher_eval_reward": 375.0}
{"epoch": 114, "reward_mean": 163.41666666666666, "student_loss": null, "teacher_policy_loss": -46.668067932128906, "teacher_value_loss": 405.04425048828125, "teacher_entropy": 0.5542651414871216, "total_time": 1.2965481281280518, "rollout_time": 0.4521181583404541, "train_time": 0.8198528289794922, "student_train_time": 0.02421283721923828, "throughput": 1542.557469800668, "inference_time": 0.05841588628027239, "env_time": 0.3937022720601817, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 115, "reward_mean": 190.6, "student_loss": null, "teacher_policy_loss": -52.0986213684082, "teacher_value_loss": 534.1610717773438, "teacher_entropy": 0.5484883785247803, "total_time": 1.2493534088134766, "rollout_time": 0.467801570892334, "train_time": 0.769007682800293, "student_train_time": 0.012162208557128906, "throughput": 1600.828065054403, "inference_time": 0.06212484902061988, "env_time": 0.4056767218717141, "samples": 2000, "teacher_eval_reward": 349.0}
{"epoch": 116, "reward_mean": 196.9090909090909, "student_loss": null, "teacher_policy_loss": -47.14299774169922, "teacher_value_loss": 382.33349609375, "teacher_entropy": 0.554044783115387, "total_time": 1.7789547443389893, "rollout_time": 0.4591193199157715, "train_time": 1.2972259521484375, "student_train_time": 0.021976709365844727, "throughput": 1124.255693611332, "inference_time": 0.062233786169599625, "env_time": 0.39688553374617186, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 117, "reward_mean": 168.3, "student_loss": null, "teacher_policy_loss": -49.719608306884766, "teacher_value_loss": 522.2294921875, "teacher_entropy": 0.544734537601471, "total_time": 1.2840051651000977, "rollout_time": 0.4353337287902832, "train_time": 0.8336277008056641, "student_train_time": 0.014688253402709961, "throughput": 1557.626132947904, "inference_time": 0.057283994705358054, "env_time": 0.37804973408492515, "samples": 2000, "teacher_eval_reward": 198.0}
{"epoch": 118, "reward_mean": 324.7142857142857, "student_loss": null, "teacher_policy_loss": -59.46755599975586, "teacher_value_loss": 767.2525634765625, "teacher_entropy": 0.5494329333305359, "total_time": 1.2191543579101562, "rollout_time": 0.44789552688598633, "train_time": 0.7561295032501221, "student_train_time": 0.014690637588500977, "throughput": 1640.4813607264216, "inference_time": 0.05967126549148816, "env_time": 0.38822426139449817, "samples": 2000, "teacher_eval_reward": 265.0}
{"epoch": 119, "reward_mean": 242.375, "student_loss": null, "teacher_policy_loss": -52.121482849121094, "teacher_value_loss": 508.23895263671875, "teacher_entropy": 0.5627022981643677, "total_time": 1.3739111423492432, "rollout_time": 0.4445505142211914, "train_time": 0.9150104522705078, "student_train_time": 0.013950824737548828, "throughput": 1455.6982168295185, "inference_time": 0.05931610045809066, "env_time": 0.38523441376310075, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 120, "reward_mean": 197.0, "student_loss": null, "teacher_policy_loss": -50.05060577392578, "teacher_value_loss": 458.48724365234375, "teacher_entropy": 0.548831582069397, "total_time": 1.374100923538208, "rollout_time": 0.4688749313354492, "train_time": 0.8936982154846191, "student_train_time": 0.011124372482299805, "throughput": 1455.4971659942912, "inference_time": 0.061306494992095395, "env_time": 0.4075684363433538, "samples": 2000, "teacher_eval_reward": 317.0}
{"epoch": 121, "reward_mean": 188.5, "student_loss": null, "teacher_policy_loss": -50.145545959472656, "teacher_value_loss": 361.41046142578125, "teacher_entropy": 0.556985080242157, "total_time": 1.280491590499878, "rollout_time": 0.4545609951019287, "train_time": 0.8148026466369629, "student_train_time": 0.010767459869384766, "throughput": 1561.9001443181994, "inference_time": 0.05965834671224002, "env_time": 0.3949026483896887, "samples": 2000, "teacher_eval_reward": 147.0}
{"epoch": 122, "reward_mean": 225.11111111111111, "student_loss": null, "teacher_policy_loss": -53.19697570800781, "teacher_value_loss": 400.34844970703125, "teacher_entropy": 0.5484773516654968, "total_time": 1.2441534996032715, "rollout_time": 0.4321150779724121, "train_time": 0.794478178024292, "student_train_time": 0.017207622528076172, "throughput": 1607.5186869126264, "inference_time": 0.056758062999506365, "env_time": 0.37535701497290574, "samples": 2000, "teacher_eval_reward": 230.0}
{"epoch": 123, "reward_mean": 207.5, "student_loss": null, "teacher_policy_loss": -50.83846664428711, "teacher_value_loss": 500.61346435546875, "teacher_entropy": 0.5549446940422058, "total_time": 1.213663101196289, "rollout_time": 0.4256436824798584, "train_time": 0.7772464752197266, "student_train_time": 0.010380983352661133, "throughput": 1647.9037700236834, "inference_time": 0.058772122791197035, "env_time": 0.36687155968866136, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 124, "reward_mean": 218.55555555555554, "student_loss": null, "teacher_policy_loss": -49.72002410888672, "teacher_value_loss": 414.03759765625, "teacher_entropy": 0.5467826724052429, "total_time": 1.3316972255706787, "rollout_time": 0.44528818130493164, "train_time": 0.8713490962982178, "student_train_time": 0.01449728012084961, "throughput": 1501.8428825988808, "inference_time": 0.06250916273893381, "env_time": 0.38277901856599783, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 125, "reward_mean": 317.5, "student_loss": null, "teacher_policy_loss": -59.103755950927734, "teacher_value_loss": 461.0825500488281, "teacher_entropy": 0.548175573348999, "total_time": 1.4298157691955566, "rollout_time": 0.46210241317749023, "train_time": 0.953866720199585, "student_train_time": 0.013410091400146484, "throughput": 1398.7816074550924, "inference_time": 0.060100909018729, "env_time": 0.40200150415876124, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 126, "reward_mean": 219.55555555555554, "student_loss": null, "teacher_policy_loss": -50.75434494018555, "teacher_value_loss": 350.318603515625, "teacher_entropy": 0.5212107300758362, "total_time": 1.278517723083496, "rollout_time": 0.4653360843658447, "train_time": 0.7997682094573975, "student_train_time": 0.013053178787231445, "throughput": 1564.3115178540127, "inference_time": 0.061714093266346026, "env_time": 0.4036219910994987, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 127, "reward_mean": 209.8, "student_loss": null, "teacher_policy_loss": -51.37641906738281, "teacher_value_loss": 476.81182861328125, "teacher_entropy": 0.5523446798324585, "total_time": 1.3312742710113525, "rollout_time": 0.4395711421966553, "train_time": 0.8737483024597168, "student_train_time": 0.017594099044799805, "throughput": 1502.3200279237913, "inference_time": 0.057889844736564555, "env_time": 0.3816812974600907, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 128, "reward_mean": 285.0, "student_loss": null, "teacher_policy_loss": -57.087764739990234, "teacher_value_loss": 515.3953247070312, "teacher_entropy": 0.5376229286193848, "total_time": 1.2456414699554443, "rollout_time": 0.45534300804138184, "train_time": 0.7743535041809082, "student_train_time": 0.01553201675415039, "throughput": 1605.5984392294988, "inference_time": 0.06101828579630819, "env_time": 0.39432472224507364, "samples": 2000, "teacher_eval_reward": 198.0}
{"epoch": 129, "reward_mean": 175.44444444444446, "student_loss": null, "teacher_policy_loss": -54.64665985107422, "teacher_value_loss": 352.3125, "teacher_entropy": 0.5409817695617676, "total_time": 1.5543625354766846, "rollout_time": 0.46059393882751465, "train_time": 1.0773370265960693, "student_train_time": 0.016057729721069336, "throughput": 1286.701110167101, "inference_time": 0.06103441780760477, "env_time": 0.3995595210199099, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 130, "reward_mean": 244.375, "student_loss": null, "teacher_policy_loss": -48.26142120361328, "teacher_value_loss": 452.0804443359375, "teacher_entropy": 0.47500282526016235, "total_time": 1.4346528053283691, "rollout_time": 0.48523664474487305, "train_time": 0.938223123550415, "student_train_time": 0.010819435119628906, "throughput": 1394.065513671255, "inference_time": 0.06227548304559605, "env_time": 0.422961161699277, "samples": 2000, "teacher_eval_reward": 105.0}
{"epoch": 131, "reward_mean": 251.33333333333334, "student_loss": null, "teacher_policy_loss": -45.04468536376953, "teacher_value_loss": 435.8721923828125, "teacher_entropy": 0.46120014786720276, "total_time": 1.293226957321167, "rollout_time": 0.4488246440887451, "train_time": 0.8222906589508057, "student_train_time": 0.02171158790588379, "throughput": 1546.5189529785755, "inference_time": 0.0606379839409783, "env_time": 0.3881866601477668, "samples": 2000, "teacher_eval_reward": 152.0}
{"epoch": 132, "reward_mean": 228.22222222222223, "student_loss": null, "teacher_policy_loss": -49.18533706665039, "teacher_value_loss": 349.97967529296875, "teacher_entropy": 0.5211081504821777, "total_time": 1.342756986618042, "rollout_time": 0.46345019340515137, "train_time": 0.8681519031524658, "student_train_time": 0.010750293731689453, "throughput": 1489.4727936119957, "inference_time": 0.06221646725498431, "env_time": 0.40123372615016706, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 133, "reward_mean": 263.25, "student_loss": null, "teacher_policy_loss": -50.63994216918945, "teacher_value_loss": 499.68267822265625, "teacher_entropy": 0.5080958008766174, "total_time": 1.2534990310668945, "rollout_time": 0.43883323669433594, "train_time": 0.7994050979614258, "student_train_time": 0.014727354049682617, "throughput": 1595.533742293948, "inference_time": 0.057896076470569824, "env_time": 0.3809371602237661, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 134, "reward_mean": 184.1818181818182, "student_loss": null, "teacher_policy_loss": -43.47982406616211, "teacher_value_loss": 540.5693359375, "teacher_entropy": 0.48989570140838623, "total_time": -1.342172384262085, "rollout_time": 0.4537851810455322, "train_time": -1.8103840351104736, "student_train_time": 0.014063358306884766, "throughput": 200000000000.0, "inference_time": 0.06303583879343932, "env_time": 0.3907493422520929, "samples": 2000, "teacher_eval_reward": 181.0}
{"epoch": 135, "reward_mean": 240.0, "student_loss": null, "teacher_policy_loss": -53.2750358581543, "teacher_value_loss": 527.8255615234375, "teacher_entropy": 0.5224606990814209, "total_time": 1.4175634384155273, "rollout_time": 0.4455127716064453, "train_time": 0.944998025894165, "student_train_time": 0.026689529418945312, "throughput": 1410.8716024980777, "inference_time": 0.06049725274715456, "env_time": 0.38501551885929075, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 136, "reward_mean": 253.75, "student_loss": null, "teacher_policy_loss": -52.962547302246094, "teacher_value_loss": 412.1649475097656, "teacher_entropy": 0.49898844957351685, "total_time": 1.2514591217041016, "rollout_time": 0.45478010177612305, "train_time": 0.7836909294128418, "student_train_time": 0.012624502182006836, "throughput": 1598.1345018098687, "inference_time": 0.06561151272580901, "env_time": 0.38916858905031404, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 137, "reward_mean": 303.14285714285717, "student_loss": null, "teacher_policy_loss": -55.607643127441406, "teacher_value_loss": 543.4940185546875, "teacher_entropy": 0.48695114254951477, "total_time": 1.3004963397979736, "rollout_time": 0.4487922191619873, "train_time": 0.8407371044158936, "student_train_time": 0.010609865188598633, "throughput": 1537.8743782629108, "inference_time": 0.06075544747909589, "env_time": 0.3880367716828914, "samples": 2000, "teacher_eval_reward": 205.0}
{"epoch": 138, "reward_mean": 185.5, "student_loss": null, "teacher_policy_loss": -51.12998580932617, "teacher_value_loss": 509.6325378417969, "teacher_entropy": 0.5117966532707214, "total_time": 1.275031566619873, "rollout_time": 0.43019628524780273, "train_time": 0.830374002456665, "student_train_time": 0.014071226119995117, "throughput": 1568.5886156544568, "inference_time": 0.05674565972367418, "env_time": 0.37345062552412855, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 139, "reward_mean": 231.42857142857142, "student_loss": null, "teacher_policy_loss": -56.875003814697266, "teacher_value_loss": 507.41424560546875, "teacher_entropy": 0.5041918754577637, "total_time": 1.2305104732513428, "rollout_time": 0.42232656478881836, "train_time": 0.7643256187438965, "student_train_time": 0.04351472854614258, "throughput": 1625.3417126271643, "inference_time": 0.05762990173388971, "env_time": 0.36469666305492865, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 140, "reward_mean": 291.85714285714283, "student_loss": null, "teacher_policy_loss": -58.099525451660156, "teacher_value_loss": 553.5601196289062, "teacher_entropy": 0.5122837424278259, "total_time": 1.2892119884490967, "rollout_time": 0.43559980392456055, "train_time": 0.8439550399780273, "student_train_time": 0.009305715560913086, "throughput": 1551.335248135546, "inference_time": 0.05941439251728298, "env_time": 0.37618541140727757, "samples": 2000, "teacher_eval_reward": 371.0}
{"epoch": 141, "reward_mean": 253.9, "student_loss": null, "teacher_policy_loss": -53.192283630371094, "teacher_value_loss": 588.677001953125, "teacher_entropy": 0.5032293796539307, "total_time": 1.4936113357543945, "rollout_time": 0.494138240814209, "train_time": 0.9788777828216553, "student_train_time": 0.02019667625427246, "throughput": 1339.036436135401, "inference_time": 0.0660482911971485, "env_time": 0.4280899496170605, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 142, "reward_mean": 248.14285714285714, "student_loss": null, "teacher_policy_loss": -53.633182525634766, "teacher_value_loss": 469.6485290527344, "teacher_entropy": 0.49465760588645935, "total_time": 1.3006792068481445, "rollout_time": 0.44153308868408203, "train_time": 0.845740556716919, "student_train_time": 0.013044357299804688, "throughput": 1537.65816311193, "inference_time": 0.05997945497256296, "env_time": 0.38155363371151907, "samples": 2000, "teacher_eval_reward": 407.0}
{"epoch": 143, "reward_mean": 224.5, "student_loss": null, "teacher_policy_loss": -56.056331634521484, "teacher_value_loss": 581.2224731445312, "teacher_entropy": 0.5157967805862427, "total_time": 1.3255457878112793, "rollout_time": 0.4501056671142578, "train_time": 0.862128734588623, "student_train_time": 0.012945890426635742, "throughput": 1508.8124592831825, "inference_time": 0.06095018702581001, "env_time": 0.3891554800884478, "samples": 2000, "teacher_eval_reward": 195.0}
{"epoch": 144, "reward_mean": 240.2, "student_loss": null, "teacher_policy_loss": -49.04816436767578, "teacher_value_loss": 594.6791381835938, "teacher_entropy": 0.5068859457969666, "total_time": 1.4126691818237305, "rollout_time": 0.45192527770996094, "train_time": 0.9503300189971924, "student_train_time": 0.010059595108032227, "throughput": 1415.7596312945936, "inference_time": 0.0595808332273009, "env_time": 0.39234444448266004, "samples": 2000, "teacher_eval_reward": 170.0}
{"epoch": 145, "reward_mean": 239.25, "student_loss": null, "teacher_policy_loss": -54.02962112426758, "teacher_value_loss": 548.8717651367188, "teacher_entropy": 0.5098071694374084, "total_time": 1.3607897758483887, "rollout_time": 0.4435555934906006, "train_time": 0.8984007835388184, "student_train_time": 0.017403841018676758, "throughput": 1469.7347345611072, "inference_time": 0.06061463051446481, "env_time": 0.3829409629761358, "samples": 2000, "teacher_eval_reward": 184.0}
{"epoch": 146, "reward_mean": 213.125, "student_loss": null, "teacher_policy_loss": -53.50212478637695, "teacher_value_loss": 503.2114562988281, "teacher_entropy": 0.5100867748260498, "total_time": 1.2972018718719482, "rollout_time": 0.4284343719482422, "train_time": 0.8576383590698242, "student_train_time": 0.01077890396118164, "throughput": 1541.7800755358667, "inference_time": 0.05827544998646772, "env_time": 0.37015892196177447, "samples": 2000, "teacher_eval_reward": 210.0}
{"epoch": 147, "reward_mean": 255.55555555555554, "student_loss": null, "teacher_policy_loss": -51.70390319824219, "teacher_value_loss": 516.3364868164062, "teacher_entropy": 0.5270019769668579, "total_time": 1.185929298400879, "rollout_time": 0.43579816818237305, "train_time": 0.7396399974822998, "student_train_time": 0.010079383850097656, "throughput": 1686.4411754535652, "inference_time": 0.059401894277471, "env_time": 0.37639627390490205, "samples": 2000, "teacher_eval_reward": 314.0}
{"epoch": 148, "reward_mean": 266.25, "student_loss": null, "teacher_policy_loss": -58.87522888183594, "teacher_value_loss": 883.28662109375, "teacher_entropy": 0.5147995352745056, "total_time": -1.2973065376281738, "rollout_time": -2.0852575302124023, "train_time": 0.7785255908966064, "student_train_time": 0.009069204330444336, "throughput": 200000000000.0, "inference_time": 0.05888348100052099, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 142.0}
{"epoch": 149, "reward_mean": 365.6, "student_loss": null, "teacher_policy_loss": -59.484779357910156, "teacher_value_loss": 986.8773803710938, "teacher_entropy": 0.4697897732257843, "total_time": 1.2964894771575928, "rollout_time": 0.4531104564666748, "train_time": 0.8303358554840088, "student_train_time": 0.012650251388549805, "throughput": 1542.6272524670042, "inference_time": 0.06334323473674885, "env_time": 0.38976722172992595, "samples": 2000, "teacher_eval_reward": 248.0}
{"epoch": 150, "reward_mean": 195.2, "student_loss": null, "teacher_policy_loss": -43.9361457824707, "teacher_value_loss": 512.3924560546875, "teacher_entropy": 0.4395197331905365, "total_time": 1.3592805862426758, "rollout_time": 0.4581027030944824, "train_time": 0.885688066482544, "student_train_time": 0.015103340148925781, "throughput": 1471.366559812644, "inference_time": 0.060558206769201206, "env_time": 0.3975444963252812, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 151, "reward_mean": 263.25, "student_loss": null, "teacher_policy_loss": -54.10476303100586, "teacher_value_loss": 440.15570068359375, "teacher_entropy": 0.5191295742988586, "total_time": 1.2740800380706787, "rollout_time": 0.43695712089538574, "train_time": 0.8266913890838623, "student_train_time": 0.010073661804199219, "throughput": 1569.7600937446375, "inference_time": 0.0590444067511271, "env_time": 0.37791271414425864, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 152, "reward_mean": 264.57142857142856, "student_loss": null, "teacher_policy_loss": -47.71689224243164, "teacher_value_loss": 374.41729736328125, "teacher_entropy": 0.4595239460468292, "total_time": 1.2613601684570312, "rollout_time": 0.4494006633758545, "train_time": 0.7913269996643066, "student_train_time": 0.020270347595214844, "throughput": 1585.5899448977493, "inference_time": 0.059309884478352615, "env_time": 0.3900907788975019, "samples": 2000, "teacher_eval_reward": 21.0}
{"epoch": 153, "reward_mean": 219.625, "student_loss": null, "teacher_policy_loss": -44.313167572021484, "teacher_value_loss": 518.4807739257812, "teacher_entropy": 0.3717469573020935, "total_time": 1.3153424263000488, "rollout_time": 0.44678831100463867, "train_time": 0.8497359752655029, "student_train_time": 0.0183563232421875, "throughput": 1520.516604657722, "inference_time": 0.05988965846518113, "env_time": 0.38689865253945754, "samples": 2000, "teacher_eval_reward": 26.0}
{"epoch": 154, "reward_mean": 247.8, "student_loss": null, "teacher_policy_loss": -42.382442474365234, "teacher_value_loss": 328.6641845703125, "teacher_entropy": 0.41591575741767883, "total_time": 1.20430326461792, "rollout_time": 0.4463677406311035, "train_time": 0.7455437183380127, "student_train_time": 0.011993646621704102, "throughput": 1660.7112666380795, "inference_time": 0.06271062071391498, "env_time": 0.38365711991718854, "samples": 2000, "teacher_eval_reward": 198.0}
{"epoch": 155, "reward_mean": 223.44444444444446, "student_loss": null, "teacher_policy_loss": -50.49943923950195, "teacher_value_loss": 280.4486999511719, "teacher_entropy": 0.5097122192382812, "total_time": 1.5709567070007324, "rollout_time": 0.47133517265319824, "train_time": 1.0820376873016357, "student_train_time": 0.017169713973999023, "throughput": 1273.1095587085886, "inference_time": 0.0593929653205123, "env_time": 0.41194220733268594, "samples": 2000, "teacher_eval_reward": 289.0}
{"epoch": 156, "reward_mean": 244.5, "student_loss": null, "teacher_policy_loss": -47.875892639160156, "teacher_value_loss": 307.5469970703125, "teacher_entropy": 0.42133238911628723, "total_time": 1.3461179733276367, "rollout_time": 0.4567747116088867, "train_time": 0.8584821224212646, "student_train_time": 0.030504941940307617, "throughput": 1485.753878655933, "inference_time": 0.060745946275346796, "env_time": 0.3960287653335399, "samples": 2000, "teacher_eval_reward": 107.0}
{"epoch": 157, "reward_mean": 200.4, "student_loss": null, "teacher_policy_loss": -38.52386474609375, "teacher_value_loss": 340.36407470703125, "teacher_entropy": 0.3491138815879822, "total_time": 1.2170400619506836, "rollout_time": 0.43814611434936523, "train_time": 0.7657384872436523, "student_train_time": 0.012769460678100586, "throughput": 1643.3312776856176, "inference_time": 0.06009556998287735, "env_time": 0.3780505443664879, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 158, "reward_mean": 175.36363636363637, "student_loss": null, "teacher_policy_loss": -38.91532516479492, "teacher_value_loss": 395.28363037109375, "teacher_entropy": 0.3774319589138031, "total_time": 1.2969732284545898, "rollout_time": 0.4549245834350586, "train_time": 0.8179349899291992, "student_train_time": 0.02370285987854004, "throughput": 1542.0518759536021, "inference_time": 0.06121590975271829, "env_time": 0.3937086736823403, "samples": 2000, "teacher_eval_reward": 285.0}
{"epoch": 159, "reward_mean": 179.8, "student_loss": null, "teacher_policy_loss": -42.29589080810547, "teacher_value_loss": 360.2134094238281, "teacher_entropy": 0.4488687813282013, "total_time": 1.4131801128387451, "rollout_time": 0.44428229331970215, "train_time": 0.9562385082244873, "student_train_time": 0.01219630241394043, "throughput": 1415.2477676624478, "inference_time": 0.06085851269563136, "env_time": 0.3834237806240708, "samples": 2000, "teacher_eval_reward": 248.0}
{"epoch": 160, "reward_mean": 189.54545454545453, "student_loss": null, "teacher_policy_loss": -49.76407241821289, "teacher_value_loss": 528.48095703125, "teacher_entropy": 0.517498791217804, "total_time": 1.3100495338439941, "rollout_time": 0.43529367446899414, "train_time": 0.8608300685882568, "student_train_time": 0.013569831848144531, "throughput": 1526.6598310458755, "inference_time": 0.05858353722760512, "env_time": 0.376710137241389, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 161, "reward_mean": 287.0, "student_loss": null, "teacher_policy_loss": -50.41338348388672, "teacher_value_loss": 576.9149780273438, "teacher_entropy": 0.4369489550590515, "total_time": 1.2430753707885742, "rollout_time": 0.43985795974731445, "train_time": 0.7761476039886475, "student_train_time": 0.02670907974243164, "throughput": 1608.9129002139691, "inference_time": 0.05752705293343752, "env_time": 0.38233090681387694, "samples": 2000, "teacher_eval_reward": 109.0}
{"epoch": 162, "reward_mean": 239.33333333333334, "student_loss": null, "teacher_policy_loss": -44.60712814331055, "teacher_value_loss": 518.1903076171875, "teacher_entropy": 0.43410807847976685, "total_time": 1.3391752243041992, "rollout_time": 0.4361913204193115, "train_time": 0.8871335983276367, "student_train_time": 0.015495538711547852, "throughput": 1493.4565422826936, "inference_time": 0.0566226664941496, "env_time": 0.3795686539251619, "samples": 2000, "teacher_eval_reward": 116.0}
{"epoch": 163, "reward_mean": 251.0, "student_loss": null, "teacher_policy_loss": -49.658363342285156, "teacher_value_loss": 573.5614013671875, "teacher_entropy": 0.48336300253868103, "total_time": 1.380021095275879, "rollout_time": 0.4764096736907959, "train_time": 0.8914880752563477, "student_train_time": 0.01171255111694336, "throughput": 1449.2532084085146, "inference_time": 0.06654377847371507, "env_time": 0.40986589521708083, "samples": 2000, "teacher_eval_reward": 299.0}
{"epoch": 164, "reward_mean": 444.75, "student_loss": null, "teacher_policy_loss": -65.2742919921875, "teacher_value_loss": 644.0235595703125, "teacher_entropy": 0.49160706996917725, "total_time": 1.2222561836242676, "rollout_time": 0.43705058097839355, "train_time": 0.7769815921783447, "student_train_time": 0.007867574691772461, "throughput": 1636.3181686424732, "inference_time": 0.05834062173926213, "env_time": 0.3787099592391314, "samples": 2000, "teacher_eval_reward": 317.0}
{"epoch": 165, "reward_mean": 289.7142857142857, "student_loss": null, "teacher_policy_loss": -55.553443908691406, "teacher_value_loss": 472.890625, "teacher_entropy": 0.471044659614563, "total_time": 1.3237602710723877, "rollout_time": 0.44483518600463867, "train_time": 0.851386547088623, "student_train_time": 0.027139902114868164, "throughput": 1510.8475784514862, "inference_time": 0.05993225398015056, "env_time": 0.3849029320244881, "samples": 2000, "teacher_eval_reward": 345.0}
{"epoch": 166, "reward_mean": 393.6, "student_loss": null, "teacher_policy_loss": -63.25432586669922, "teacher_value_loss": 540.9558715820312, "teacher_entropy": 0.49293890595436096, "total_time": 1.2840805053710938, "rollout_time": 0.43747663497924805, "train_time": 0.8327121734619141, "student_train_time": 0.013468503952026367, "throughput": 1557.5347430588151, "inference_time": 0.05945786572920042, "env_time": 0.3780187692500476, "samples": 2000, "teacher_eval_reward": 175.0}
{"epoch": 167, "reward_mean": 252.66666666666666, "student_loss": null, "teacher_policy_loss": -51.206634521484375, "teacher_value_loss": 619.0533447265625, "teacher_entropy": 0.4336889386177063, "total_time": 1.2766878604888916, "rollout_time": 0.4354991912841797, "train_time": 0.8271889686584473, "student_train_time": 0.01364755630493164, "throughput": 1566.5536282565772, "inference_time": 0.06019657852266391, "env_time": 0.3753026127615158, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 168, "reward_mean": 244.14285714285714, "student_loss": null, "teacher_policy_loss": -47.89345932006836, "teacher_value_loss": 757.8742065429688, "teacher_entropy": 0.3847526013851166, "total_time": 1.2189247608184814, "rollout_time": 0.4413433074951172, "train_time": 0.7658059597015381, "student_train_time": 0.01141214370727539, "throughput": 1640.790362365798, "inference_time": 0.06223400027010939, "env_time": 0.3791093072250078, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 169, "reward_mean": 381.75, "student_loss": null, "teacher_policy_loss": -51.65639114379883, "teacher_value_loss": 588.7225952148438, "teacher_entropy": 0.3525679111480713, "total_time": 1.4519422054290771, "rollout_time": 0.5646481513977051, "train_time": 0.8632266521453857, "student_train_time": 0.023658037185668945, "throughput": 1377.4652961540994, "inference_time": 0.059175714526645606, "env_time": 0.5054724368710595, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 170, "reward_mean": 332.625, "student_loss": null, "teacher_policy_loss": -49.95045852661133, "teacher_value_loss": 714.6041259765625, "teacher_entropy": 0.4482651352882385, "total_time": 1.3153786659240723, "rollout_time": 0.44143223762512207, "train_time": 0.8591864109039307, "student_train_time": 0.014316082000732422, "throughput": 1520.474713336613, "inference_time": 0.059474921768924105, "env_time": 0.38195731585619797, "samples": 2000, "teacher_eval_reward": 492.0}
{"epoch": 171, "reward_mean": 281.8333333333333, "student_loss": null, "teacher_policy_loss": -56.744834899902344, "teacher_value_loss": 582.3173828125, "teacher_entropy": 0.4783424437046051, "total_time": 1.259833574295044, "rollout_time": 0.44306516647338867, "train_time": 0.7991898059844971, "student_train_time": 0.017038583755493164, "throughput": 1587.5112719702884, "inference_time": 0.059419976047138334, "env_time": 0.38364519042625034, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 172, "reward_mean": 313.0, "student_loss": null, "teacher_policy_loss": -50.86865234375, "teacher_value_loss": 496.125244140625, "teacher_entropy": 0.4554116427898407, "total_time": 1.268674612045288, "rollout_time": 0.4667239189147949, "train_time": 0.7850604057312012, "student_train_time": 0.016528606414794922, "throughput": 1576.4483509098593, "inference_time": 0.06121889680434833, "env_time": 0.4055050221104466, "samples": 2000, "teacher_eval_reward": 321.0}
{"epoch": 173, "reward_mean": 315.8333333333333, "student_loss": null, "teacher_policy_loss": -61.028160095214844, "teacher_value_loss": 643.0855102539062, "teacher_entropy": 0.46028321981430054, "total_time": 1.295105218887329, "rollout_time": 0.44777965545654297, "train_time": 0.835045576095581, "student_train_time": 0.011911869049072266, "throughput": 1544.2760718069464, "inference_time": 0.0627153422919946, "env_time": 0.38506431316454837, "samples": 2000, "teacher_eval_reward": 401.0}
{"epoch": 174, "reward_mean": 315.6666666666667, "student_loss": null, "teacher_policy_loss": -57.60907745361328, "teacher_value_loss": 505.2598876953125, "teacher_entropy": 0.49225202202796936, "total_time": 1.5054810047149658, "rollout_time": 0.47283411026000977, "train_time": 1.0199685096740723, "student_train_time": 0.012307167053222656, "throughput": 1328.4790666479794, "inference_time": 0.06382967002900841, "env_time": 0.40900444023100135, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 175, "reward_mean": 352.5, "student_loss": null, "teacher_policy_loss": -60.4074821472168, "teacher_value_loss": 717.2188720703125, "teacher_entropy": 0.4816792607307434, "total_time": 1.2742009162902832, "rollout_time": 0.43505287170410156, "train_time": 0.828662633895874, "student_train_time": 0.010100364685058594, "throughput": 1569.611177036988, "inference_time": 0.05685397646630008, "env_time": 0.3781988952378015, "samples": 2000, "teacher_eval_reward": 115.0}
{"epoch": 176, "reward_mean": 303.42857142857144, "student_loss": null, "teacher_policy_loss": -53.375343322753906, "teacher_value_loss": 504.6652526855469, "teacher_entropy": 0.4445211887359619, "total_time": 1.2170166969299316, "rollout_time": 0.42765212059020996, "train_time": 0.7774279117584229, "student_train_time": 0.011580467224121094, "throughput": 1643.3628273508787, "inference_time": 0.05674295877361146, "env_time": 0.3709091618165985, "samples": 2000, "teacher_eval_reward": 149.0}
{"epoch": 177, "reward_mean": 320.0, "student_loss": null, "teacher_policy_loss": -58.53422927856445, "teacher_value_loss": 457.4568176269531, "teacher_entropy": 0.4863772690296173, "total_time": 1.2903437614440918, "rollout_time": 0.4428253173828125, "train_time": 0.8349227905273438, "student_train_time": 0.012241363525390625, "throughput": 1549.974556982935, "inference_time": 0.06062921471675509, "env_time": 0.3821961026660574, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 178, "reward_mean": 260.57142857142856, "student_loss": null, "teacher_policy_loss": -55.46485900878906, "teacher_value_loss": 311.0047302246094, "teacher_entropy": 0.49125584959983826, "total_time": 1.2967326641082764, "rollout_time": 0.43648529052734375, "train_time": 0.8454446792602539, "student_train_time": 0.014392614364624023, "throughput": 1542.33795088006, "inference_time": 0.05936353450124443, "env_time": 0.3771217560260993, "samples": 2000, "teacher_eval_reward": 329.0}
{"epoch": 179, "reward_mean": 252.0, "student_loss": null, "teacher_policy_loss": -54.85975646972656, "teacher_value_loss": 436.1533508300781, "teacher_entropy": 0.46510425209999084, "total_time": 1.3047270774841309, "rollout_time": 0.46068859100341797, "train_time": 0.8259658813476562, "student_train_time": 0.017705440521240234, "throughput": 1532.887631838334, "inference_time": 0.06460344653351058, "env_time": 0.3960851444699074, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 180, "reward_mean": 373.2, "student_loss": null, "teacher_policy_loss": -62.4620246887207, "teacher_value_loss": 415.32635498046875, "teacher_entropy": 0.48298388719558716, "total_time": 1.27492356300354, "rollout_time": 0.45173168182373047, "train_time": 0.8066997528076172, "student_train_time": 0.016062498092651367, "throughput": 1568.7214967525442, "inference_time": 0.05708898079501523, "env_time": 0.39464270102871524, "samples": 2000, "teacher_eval_reward": 169.0}
{"epoch": 181, "reward_mean": 321.57142857142856, "student_loss": null, "teacher_policy_loss": -57.4395751953125, "teacher_value_loss": 487.4433288574219, "teacher_entropy": 0.48274466395378113, "total_time": 1.5038940906524658, "rollout_time": 0.4415168762207031, "train_time": 1.0537693500518799, "student_train_time": 0.008186101913452148, "throughput": 1329.8808821918426, "inference_time": 0.05950307151033485, "env_time": 0.3820138047103683, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 182, "reward_mean": 289.0, "student_loss": null, "teacher_policy_loss": -55.98405075073242, "teacher_value_loss": 450.8205871582031, "teacher_entropy": 0.48126572370529175, "total_time": 1.2897918224334717, "rollout_time": 0.43860745429992676, "train_time": 0.8308470249176025, "student_train_time": 0.019980430603027344, "throughput": 1550.637835667594, "inference_time": 0.05826022272412956, "env_time": 0.3803472315757972, "samples": 2000, "teacher_eval_reward": 259.0}
{"epoch": 183, "reward_mean": 313.2857142857143, "student_loss": null, "teacher_policy_loss": -57.71666717529297, "teacher_value_loss": 472.02618408203125, "teacher_entropy": 0.4914020299911499, "total_time": 1.2475147247314453, "rollout_time": 0.46596503257751465, "train_time": 0.764535665512085, "student_train_time": 0.016650676727294922, "throughput": 1603.187489775356, "inference_time": 0.0632559317182313, "env_time": 0.40270910085928335, "samples": 2000, "teacher_eval_reward": 367.0}
{"epoch": 184, "reward_mean": 265.625, "student_loss": null, "teacher_policy_loss": -54.860355377197266, "teacher_value_loss": 582.6423950195312, "teacher_entropy": 0.4833798110485077, "total_time": 1.2499916553497314, "rollout_time": 0.4329674243927002, "train_time": 0.7986652851104736, "student_train_time": 0.01784682273864746, "throughput": 1600.0106812236486, "inference_time": 0.05956970172155707, "env_time": 0.37339772267114313, "samples": 2000, "teacher_eval_reward": 261.0}
{"epoch": 185, "reward_mean": 276.5, "student_loss": null, "teacher_policy_loss": -59.03485107421875, "teacher_value_loss": 540.8935546875, "teacher_entropy": 0.48396894335746765, "total_time": 1.2766361236572266, "rollout_time": 0.4485774040222168, "train_time": 0.8097929954528809, "student_train_time": 0.017904281616210938, "throughput": 1566.6171142569005, "inference_time": 0.059249895266475505, "env_time": 0.3893275087557413, "samples": 2000, "teacher_eval_reward": 404.0}
{"epoch": 186, "reward_mean": 289.0, "student_loss": null, "teacher_policy_loss": -60.01537322998047, "teacher_value_loss": 501.22528076171875, "teacher_entropy": 0.48409783840179443, "total_time": 1.293715000152588, "rollout_time": 0.4423658847808838, "train_time": 0.8376097679138184, "student_train_time": 0.013271093368530273, "throughput": 1545.935542035231, "inference_time": 0.06018027998288744, "env_time": 0.38218560479799635, "samples": 2000, "teacher_eval_reward": 223.0}
{"epoch": 187, "reward_mean": 274.75, "student_loss": null, "teacher_policy_loss": -57.081207275390625, "teacher_value_loss": 623.2454833984375, "teacher_entropy": 0.4825437366962433, "total_time": -1.3212199211120605, "rollout_time": 0.43189501762390137, "train_time": -1.7629883289337158, "student_train_time": 0.009511709213256836, "throughput": 200000000000.0, "inference_time": 0.05828005001058045, "env_time": 0.3736149676133209, "samples": 2000, "teacher_eval_reward": 309.0}
{"epoch": 188, "reward_mean": 321.5, "student_loss": null, "teacher_policy_loss": -67.20259857177734, "teacher_value_loss": 665.84814453125, "teacher_entropy": 0.4862525463104248, "total_time": 1.1710376739501953, "rollout_time": 0.4216618537902832, "train_time": 0.7392387390136719, "student_train_time": 0.009669780731201172, "throughput": 1707.886983049412, "inference_time": 0.056249113511512405, "env_time": 0.3654127402787708, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 189, "reward_mean": 336.2857142857143, "student_loss": null, "teacher_policy_loss": -59.756927490234375, "teacher_value_loss": 658.3655395507812, "teacher_entropy": 0.4974105656147003, "total_time": 1.2579617500305176, "rollout_time": 0.42200303077697754, "train_time": 0.8197660446166992, "student_train_time": 0.015796661376953125, "throughput": 1589.8734599454085, "inference_time": 0.05805944699568499, "env_time": 0.36394358378129255, "samples": 2000, "teacher_eval_reward": 270.0}
{"epoch": 190, "reward_mean": 235.75, "student_loss": null, "teacher_policy_loss": -55.62031173706055, "teacher_value_loss": 589.0980834960938, "teacher_entropy": 0.4765613377094269, "total_time": 1.197145938873291, "rollout_time": 0.4181094169616699, "train_time": 0.7687435150146484, "student_train_time": 0.009941339492797852, "throughput": 1670.6400907831883, "inference_time": 0.057175172254574136, "env_time": 0.3609342447070958, "samples": 2000, "teacher_eval_reward": 310.0}
{"epoch": 191, "reward_mean": 218.71428571428572, "student_loss": null, "teacher_policy_loss": -59.094688415527344, "teacher_value_loss": 556.6608276367188, "teacher_entropy": 0.46890920400619507, "total_time": 1.2408225536346436, "rollout_time": 0.44861936569213867, "train_time": 0.7821571826934814, "student_train_time": 0.00969243049621582, "throughput": 1611.8340161867286, "inference_time": 0.05975521498839953, "env_time": 0.38886415070373914, "samples": 2000, "teacher_eval_reward": 436.0}
{"epoch": 192, "reward_mean": 432.8, "student_loss": null, "teacher_policy_loss": -64.39181518554688, "teacher_value_loss": 425.003173828125, "teacher_entropy": 0.4942173361778259, "total_time": 1.189802885055542, "rollout_time": 0.4349668025970459, "train_time": 0.7434647083282471, "student_train_time": 0.011004447937011719, "throughput": 1680.9507063068154, "inference_time": 0.05833842671927414, "env_time": 0.37662837587777176, "samples": 2000, "teacher_eval_reward": 214.0}
{"epoch": 193, "reward_mean": 335.7142857142857, "student_loss": null, "teacher_policy_loss": -59.505393981933594, "teacher_value_loss": 463.1702575683594, "teacher_entropy": 0.48400992155075073, "total_time": 1.280285358428955, "rollout_time": 0.43922877311706543, "train_time": 0.8167686462402344, "student_train_time": 0.023932456970214844, "throughput": 1562.1517397138796, "inference_time": 0.05947941726662975, "env_time": 0.3797493558504357, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 194, "reward_mean": 261.75, "student_loss": null, "teacher_policy_loss": -55.9272575378418, "teacher_value_loss": 455.6422119140625, "teacher_entropy": 0.48352789878845215, "total_time": 1.4806487560272217, "rollout_time": 0.6215741634368896, "train_time": 0.8325557708740234, "student_train_time": 0.026088476181030273, "throughput": 1350.7592478355684, "inference_time": 0.07998962073361326, "env_time": 0.5415845427032764, "samples": 2000, "teacher_eval_reward": 180.0}
{"epoch": 195, "reward_mean": 249.0, "student_loss": null, "teacher_policy_loss": -52.43671798706055, "teacher_value_loss": 312.46868896484375, "teacher_entropy": 0.49403488636016846, "total_time": 1.366363763809204, "rollout_time": 0.4401824474334717, "train_time": 0.848721981048584, "student_train_time": 0.0770118236541748, "throughput": 1463.7390517619694, "inference_time": 0.061136878222896485, "env_time": 0.3790455692105752, "samples": 2000, "teacher_eval_reward": 196.0}
{"epoch": 196, "reward_mean": 238.77777777777777, "student_loss": null, "teacher_policy_loss": -53.998046875, "teacher_value_loss": 387.9312438964844, "teacher_entropy": 0.4938555359840393, "total_time": 1.2893671989440918, "rollout_time": 0.4352433681488037, "train_time": 0.8388652801513672, "student_train_time": 0.014897346496582031, "throughput": 1551.148502643677, "inference_time": 0.06123258693696698, "env_time": 0.37401078121183673, "samples": 2000, "teacher_eval_reward": 252.0}
{"epoch": 197, "reward_mean": 297.5, "student_loss": null, "teacher_policy_loss": -58.62321472167969, "teacher_value_loss": 486.9861755371094, "teacher_entropy": 0.5018813610076904, "total_time": 1.1792278289794922, "rollout_time": 0.42391300201416016, "train_time": 0.7415039539337158, "student_train_time": 0.013462305068969727, "throughput": 1696.0251029106114, "inference_time": 0.05790871801582398, "env_time": 0.3660042839983362, "samples": 2000, "teacher_eval_reward": 217.0}
{"epoch": 198, "reward_mean": 327.1666666666667, "student_loss": null, "teacher_policy_loss": -57.56486892700195, "teacher_value_loss": 459.64862060546875, "teacher_entropy": 0.4784882068634033, "total_time": 1.299614667892456, "rollout_time": 0.42932724952697754, "train_time": 0.8565196990966797, "student_train_time": 0.013416528701782227, "throughput": 1538.9176879969634, "inference_time": 0.05739817322137242, "env_time": 0.3719290763056051, "samples": 2000, "teacher_eval_reward": 196.0}
{"epoch": 199, "reward_mean": 329.3333333333333, "student_loss": null, "teacher_policy_loss": -59.55354690551758, "teacher_value_loss": 425.7156982421875, "teacher_entropy": 0.48400846123695374, "total_time": -1.2461071014404297, "rollout_time": -2.149155378341675, "train_time": 0.8903775215148926, "student_train_time": 0.012315511703491211, "throughput": 200000000000.0, "inference_time": 0.06055201048729941, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 200, "reward_mean": 337.85714285714283, "student_loss": null, "teacher_policy_loss": -57.28555679321289, "teacher_value_loss": 614.943359375, "teacher_entropy": 0.4703223407268524, "total_time": 1.177570104598999, "rollout_time": 0.4186553955078125, "train_time": 0.7463912963867188, "student_train_time": 0.012164831161499023, "throughput": 1698.412682343923, "inference_time": 0.05747871377207048, "env_time": 0.361176681735742, "samples": 2000, "teacher_eval_reward": 435.0}
{"epoch": 201, "reward_mean": 417.5, "student_loss": null, "teacher_policy_loss": -63.369178771972656, "teacher_value_loss": 538.345458984375, "teacher_entropy": 0.4993722140789032, "total_time": 1.1908349990844727, "rollout_time": 0.4277043342590332, "train_time": 0.7499194145202637, "student_train_time": 0.01286458969116211, "throughput": 1679.4938018597225, "inference_time": 0.05751164552020782, "env_time": 0.3701926887388254, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 202, "reward_mean": 438.25, "student_loss": null, "teacher_policy_loss": -62.8762092590332, "teacher_value_loss": 574.3644409179688, "teacher_entropy": 0.46618586778640747, "total_time": 1.2913901805877686, "rollout_time": 0.42589831352233887, "train_time": 0.8508594036102295, "student_train_time": 0.014287471771240234, "throughput": 1548.7186057816484, "inference_time": 0.05625073899500421, "env_time": 0.36964757452733465, "samples": 2000, "teacher_eval_reward": 247.0}
{"epoch": 203, "reward_mean": 399.1666666666667, "student_loss": null, "teacher_policy_loss": -60.31979751586914, "teacher_value_loss": 562.8031005859375, "teacher_entropy": 0.49663981795310974, "total_time": 1.2621045112609863, "rollout_time": 0.42459774017333984, "train_time": 0.8214080333709717, "student_train_time": 0.01575922966003418, "throughput": 1584.6548222870797, "inference_time": 0.05688709402784298, "env_time": 0.36771064614549687, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 204, "reward_mean": 245.14285714285714, "student_loss": null, "teacher_policy_loss": -56.67829513549805, "teacher_value_loss": 605.1666870117188, "teacher_entropy": 0.4715850353240967, "total_time": 1.2252211570739746, "rollout_time": 0.43493175506591797, "train_time": 0.778705358505249, "student_train_time": 0.011134624481201172, "throughput": 1632.3583611438135, "inference_time": 0.05965468453177891, "env_time": 0.37527707053413906, "samples": 2000, "teacher_eval_reward": 122.0}
{"epoch": 205, "reward_mean": 382.4, "student_loss": null, "teacher_policy_loss": -58.090152740478516, "teacher_value_loss": 564.9525756835938, "teacher_entropy": 0.4654868245124817, "total_time": 1.3614253997802734, "rollout_time": 0.4504096508026123, "train_time": 0.8843052387237549, "student_train_time": 0.02633810043334961, "throughput": 1469.0485430364301, "inference_time": 0.06111734005753533, "env_time": 0.389292310745077, "samples": 2000, "teacher_eval_reward": 273.0}
{"epoch": 206, "reward_mean": 351.1666666666667, "student_loss": null, "teacher_policy_loss": -60.69088363647461, "teacher_value_loss": 595.9547119140625, "teacher_entropy": 0.48981404304504395, "total_time": 1.3443272113800049, "rollout_time": 0.4423861503601074, "train_time": 0.8920440673828125, "student_train_time": 0.00949549674987793, "throughput": 1487.7330333490172, "inference_time": 0.058501757979684044, "env_time": 0.3838843923804234, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 207, "reward_mean": 308.0, "student_loss": null, "teacher_policy_loss": -54.585052490234375, "teacher_value_loss": 462.75, "teacher_entropy": 0.49661359190940857, "total_time": 1.2387242317199707, "rollout_time": 0.4392697811126709, "train_time": 0.787816047668457, "student_train_time": 0.011250495910644531, "throughput": 1614.564362903434, "inference_time": 0.057789950416918145, "env_time": 0.38147983069575275, "samples": 2000, "teacher_eval_reward": 287.0}
{"epoch": 208, "reward_mean": 337.8333333333333, "student_loss": null, "teacher_policy_loss": -62.685916900634766, "teacher_value_loss": 709.0414428710938, "teacher_entropy": 0.4962742030620575, "total_time": 1.2449185848236084, "rollout_time": 0.44540905952453613, "train_time": 0.7870633602142334, "student_train_time": 0.012084484100341797, "throughput": 1606.5307598274617, "inference_time": 0.0594494780380046, "env_time": 0.38595958148653153, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 209, "reward_mean": 276.0, "student_loss": null, "teacher_policy_loss": -59.196136474609375, "teacher_value_loss": 447.9133605957031, "teacher_entropy": 0.4946995675563812, "total_time": 1.326019525527954, "rollout_time": 0.550579309463501, "train_time": 0.7417590618133545, "student_train_time": 0.03328537940979004, "throughput": 1508.2734164142123, "inference_time": 0.06887060206645401, "env_time": 0.48170870739704696, "samples": 2000, "teacher_eval_reward": 208.0}
{"epoch": 210, "reward_mean": 320.0, "student_loss": null, "teacher_policy_loss": -60.31837844848633, "teacher_value_loss": 579.7156372070312, "teacher_entropy": 0.49950578808784485, "total_time": 1.287052869796753, "rollout_time": 0.4475429058074951, "train_time": 0.8273122310638428, "student_train_time": 0.011773824691772461, "throughput": 1553.937718437187, "inference_time": 0.06300887279030576, "env_time": 0.38453403301718936, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 211, "reward_mean": 351.8333333333333, "student_loss": null, "teacher_policy_loss": -59.640499114990234, "teacher_value_loss": 574.7266845703125, "teacher_entropy": 0.4861050844192505, "total_time": 1.2327589988708496, "rollout_time": 0.4287598133087158, "train_time": 0.7941927909851074, "student_train_time": 0.009458303451538086, "throughput": 1622.377124670684, "inference_time": 0.057578529995225836, "env_time": 0.37118128331349, "samples": 2000, "teacher_eval_reward": 168.0}
{"epoch": 212, "reward_mean": 296.1666666666667, "student_loss": null, "teacher_policy_loss": -55.824886322021484, "teacher_value_loss": 449.7380676269531, "teacher_entropy": 0.4729803800582886, "total_time": 1.2896449565887451, "rollout_time": 0.41547513008117676, "train_time": 0.86350417137146, "student_train_time": 0.010274648666381836, "throughput": 1550.8144235993627, "inference_time": 0.057718813744941144, "env_time": 0.3577563163362356, "samples": 2000, "teacher_eval_reward": 272.0}
{"epoch": 213, "reward_mean": 265.8333333333333, "student_loss": null, "teacher_policy_loss": -56.848899841308594, "teacher_value_loss": 530.8877563476562, "teacher_entropy": 0.45341381430625916, "total_time": 1.1982016563415527, "rollout_time": 0.43341064453125, "train_time": 0.753990888595581, "student_train_time": 0.010341644287109375, "throughput": 1669.1681149119452, "inference_time": 0.05826854151382577, "env_time": 0.37514210301742423, "samples": 2000, "teacher_eval_reward": 235.0}
{"epoch": 214, "reward_mean": 356.0, "student_loss": null, "teacher_policy_loss": -60.05435562133789, "teacher_value_loss": 429.4122009277344, "teacher_entropy": 0.48101818561553955, "total_time": 1.1962213516235352, "rollout_time": 0.42860984802246094, "train_time": 0.7575998306274414, "student_train_time": 0.009558677673339844, "throughput": 1671.9313672888054, "inference_time": 0.0575916914804111, "env_time": 0.37101815654204984, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 215, "reward_mean": 311.6, "student_loss": null, "teacher_policy_loss": -59.077274322509766, "teacher_value_loss": 543.5299072265625, "teacher_entropy": 0.45117494463920593, "total_time": 1.3000872135162354, "rollout_time": 0.4374122619628906, "train_time": 0.8476724624633789, "student_train_time": 0.014443635940551758, "throughput": 1538.358334123424, "inference_time": 0.05905528144830896, "env_time": 0.37835698051458166, "samples": 2000, "teacher_eval_reward": 311.0}
{"epoch": 216, "reward_mean": 397.2, "student_loss": null, "teacher_policy_loss": -63.130027770996094, "teacher_value_loss": 464.7132873535156, "teacher_entropy": 0.4896887242794037, "total_time": 1.3776159286499023, "rollout_time": 0.41359925270080566, "train_time": 0.9558238983154297, "student_train_time": 0.007771015167236328, "throughput": 1451.7834458839695, "inference_time": 0.056224260972157936, "env_time": 0.35737499172864773, "samples": 2000, "teacher_eval_reward": 212.0}
{"epoch": 217, "reward_mean": 372.6666666666667, "student_loss": null, "teacher_policy_loss": -53.6462287902832, "teacher_value_loss": 448.38580322265625, "teacher_entropy": 0.45073431730270386, "total_time": 1.2080745697021484, "rollout_time": 0.41871118545532227, "train_time": 0.7724645137786865, "student_train_time": 0.01654648780822754, "throughput": 1655.5269435835417, "inference_time": 0.059118735229276353, "env_time": 0.3595924502260459, "samples": 2000, "teacher_eval_reward": 214.0}
{"epoch": 218, "reward_mean": 271.75, "student_loss": null, "teacher_policy_loss": -52.21311569213867, "teacher_value_loss": 392.7983703613281, "teacher_entropy": 0.4559258818626404, "total_time": 1.218982458114624, "rollout_time": 0.4340860843658447, "train_time": 0.7724177837371826, "student_train_time": 0.012117862701416016, "throughput": 1640.7126999131392, "inference_time": 0.05990315720191575, "env_time": 0.374182927163929, "samples": 2000, "teacher_eval_reward": 281.0}
{"epoch": 219, "reward_mean": 285.0, "student_loss": null, "teacher_policy_loss": -63.3200798034668, "teacher_value_loss": 447.0690612792969, "teacher_entropy": 0.4782128930091858, "total_time": 1.279489517211914, "rollout_time": 0.4489617347717285, "train_time": 0.809119701385498, "student_train_time": 0.020922183990478516, "throughput": 1563.1233965543715, "inference_time": 0.06334047626842221, "env_time": 0.3856212585033063, "samples": 2000, "teacher_eval_reward": 155.0}
{"epoch": 220, "reward_mean": 353.5, "student_loss": null, "teacher_policy_loss": -59.088409423828125, "teacher_value_loss": 549.6258544921875, "teacher_entropy": 0.4577789604663849, "total_time": 1.276353120803833, "rollout_time": 0.46323585510253906, "train_time": 0.8016693592071533, "student_train_time": 0.010875701904296875, "throughput": 1566.9644766805775, "inference_time": 0.060859141283799545, "env_time": 0.4023767138187395, "samples": 2000, "teacher_eval_reward": 220.0}
{"epoch": 221, "reward_mean": 342.14285714285717, "student_loss": null, "teacher_policy_loss": -59.62209701538086, "teacher_value_loss": 549.7168579101562, "teacher_entropy": 0.4756738841533661, "total_time": 1.212193489074707, "rollout_time": 0.4249849319458008, "train_time": 0.7669587135314941, "student_train_time": 0.019895076751708984, "throughput": 1649.9016188633734, "inference_time": 0.05832099897997978, "env_time": 0.366663932965821, "samples": 2000, "teacher_eval_reward": 193.0}
{"epoch": 222, "reward_mean": 364.4, "student_loss": null, "teacher_policy_loss": -64.05670166015625, "teacher_value_loss": 457.3889465332031, "teacher_entropy": 0.44595739245414734, "total_time": 1.3318004608154297, "rollout_time": 0.4676673412322998, "train_time": 0.8520119190216064, "student_train_time": 0.011775493621826172, "throughput": 1501.7264664223405, "inference_time": 0.060525825050717685, "env_time": 0.4071415161815821, "samples": 2000, "teacher_eval_reward": 235.0}
{"epoch": 223, "reward_mean": 340.3333333333333, "student_loss": null, "teacher_policy_loss": -62.61096954345703, "teacher_value_loss": 372.49371337890625, "teacher_entropy": 0.46077775955200195, "total_time": 1.358083963394165, "rollout_time": 0.4502837657928467, "train_time": 0.892603874206543, "student_train_time": 0.014834880828857422, "throughput": 1472.6629972137648, "inference_time": 0.05936050352465827, "env_time": 0.3909232622681884, "samples": 2000, "teacher_eval_reward": 160.0}
{"epoch": 224, "reward_mean": 325.1666666666667, "student_loss": null, "teacher_policy_loss": -59.889137268066406, "teacher_value_loss": 478.27069091796875, "teacher_entropy": 0.4694640338420868, "total_time": 1.1930866241455078, "rollout_time": 0.4190244674682617, "train_time": 0.7658216953277588, "student_train_time": 0.007858514785766602, "throughput": 1676.3242161334313, "inference_time": 0.0558561690049828, "env_time": 0.3631682984632789, "samples": 2000, "teacher_eval_reward": 107.0}
{"epoch": 225, "reward_mean": 339.4, "student_loss": null, "teacher_policy_loss": -59.3626823425293, "teacher_value_loss": 522.1123046875, "teacher_entropy": 0.42423585057258606, "total_time": 1.3051559925079346, "rollout_time": 0.4325904846191406, "train_time": 0.8518269062042236, "student_train_time": 0.020335912704467773, "throughput": 1532.383877084977, "inference_time": 0.060561311707715504, "env_time": 0.3720291729114251, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 226, "reward_mean": 281.375, "student_loss": null, "teacher_policy_loss": -51.64834976196289, "teacher_value_loss": 521.9741821289062, "teacher_entropy": 0.4540848135948181, "total_time": -1.414107322692871, "rollout_time": -2.1653335094451904, "train_time": 0.7421081066131592, "student_train_time": 0.008719444274902344, "throughput": 200000000000.0, "inference_time": 0.05622952871999587, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 352.0}
{"epoch": 227, "reward_mean": 275.375, "student_loss": null, "teacher_policy_loss": -55.01816177368164, "teacher_value_loss": 633.5088500976562, "teacher_entropy": 0.4597109258174896, "total_time": 1.2930710315704346, "rollout_time": 0.42075324058532715, "train_time": 0.864264726638794, "student_train_time": 0.007704973220825195, "throughput": 1546.705440899871, "inference_time": 0.05870072925972636, "env_time": 0.3620525113256008, "samples": 2000, "teacher_eval_reward": 199.0}
{"epoch": 228, "reward_mean": 260.8333333333333, "student_loss": null, "teacher_policy_loss": -57.93737030029297, "teacher_value_loss": 458.58203125, "teacher_entropy": 0.46164342761039734, "total_time": 1.192553997039795, "rollout_time": 0.42195749282836914, "train_time": 0.7461292743682861, "student_train_time": 0.02411961555480957, "throughput": 1677.0729081991085, "inference_time": 0.05768649099081813, "env_time": 0.364271001837551, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 229, "reward_mean": 443.6, "student_loss": null, "teacher_policy_loss": -64.71102905273438, "teacher_value_loss": 691.8790283203125, "teacher_entropy": 0.4591708183288574, "total_time": 1.2028303146362305, "rollout_time": 0.4146120548248291, "train_time": 0.7783551216125488, "student_train_time": 0.009482145309448242, "throughput": 1662.7449239212565, "inference_time": 0.05698345401287952, "env_time": 0.3576286008119496, "samples": 2000, "teacher_eval_reward": 168.0}
{"epoch": 230, "reward_mean": 422.2, "student_loss": null, "teacher_policy_loss": -63.439537048339844, "teacher_value_loss": 645.6304321289062, "teacher_entropy": 0.46024802327156067, "total_time": 1.2569999694824219, "rollout_time": 0.43719482421875, "train_time": 0.8019556999206543, "student_train_time": 0.017493724822998047, "throughput": 1591.0899352078054, "inference_time": 0.058239335236066836, "env_time": 0.37895548898268316, "samples": 2000, "teacher_eval_reward": 344.0}
{"epoch": 231, "reward_mean": 432.5, "student_loss": null, "teacher_policy_loss": -66.36666107177734, "teacher_value_loss": 693.1121215820312, "teacher_entropy": 0.46091756224632263, "total_time": 1.4741885662078857, "rollout_time": 0.444263219833374, "train_time": 1.014373540878296, "student_train_time": 0.01520395278930664, "throughput": 1356.6785456386222, "inference_time": 0.05952589803200681, "env_time": 0.3847373218013672, "samples": 2000, "teacher_eval_reward": 392.0}
{"epoch": 232, "reward_mean": 390.8333333333333, "student_loss": null, "teacher_policy_loss": -60.69764709472656, "teacher_value_loss": 738.8465576171875, "teacher_entropy": 0.46271461248397827, "total_time": 1.3649442195892334, "rollout_time": 0.4353053569793701, "train_time": 0.9109020233154297, "student_train_time": 0.01829218864440918, "throughput": 1465.2613427689232, "inference_time": 0.06218530649312015, "env_time": 0.37312005048624997, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 233, "reward_mean": 325.8, "student_loss": null, "teacher_policy_loss": -59.61604309082031, "teacher_value_loss": 579.8858032226562, "teacher_entropy": 0.465038537979126, "total_time": 1.2570757865905762, "rollout_time": 0.4448235034942627, "train_time": 0.8020422458648682, "student_train_time": 0.009811639785766602, "throughput": 1590.9939729444418, "inference_time": 0.060197826776857255, "env_time": 0.38462567671740544, "samples": 2000, "teacher_eval_reward": 428.0}
{"epoch": 234, "reward_mean": 318.4, "student_loss": null, "teacher_policy_loss": -62.76506805419922, "teacher_value_loss": 379.40228271484375, "teacher_entropy": 0.4648697078227997, "total_time": 1.244260549545288, "rollout_time": 0.4326756000518799, "train_time": 0.7979750633239746, "student_train_time": 0.013220787048339844, "throughput": 1607.3803840609548, "inference_time": 0.060205997979210224, "env_time": 0.37246960207266966, "samples": 2000, "teacher_eval_reward": 208.0}
{"epoch": 235, "reward_mean": 365.6666666666667, "student_loss": null, "teacher_policy_loss": -60.5580940246582, "teacher_value_loss": 621.5794677734375, "teacher_entropy": 0.4663143754005432, "total_time": 1.2899847030639648, "rollout_time": 0.41906309127807617, "train_time": 0.8594474792480469, "student_train_time": 0.01102900505065918, "throughput": 1550.405981752815, "inference_time": 0.05682966802487499, "env_time": 0.3622334232532012, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 236, "reward_mean": 405.2, "student_loss": null, "teacher_policy_loss": -60.96807861328125, "teacher_value_loss": 445.3802795410156, "teacher_entropy": 0.4775240123271942, "total_time": 1.215846300125122, "rollout_time": 0.4289219379425049, "train_time": 0.7725133895874023, "student_train_time": 0.014057159423828125, "throughput": 1644.9447597070296, "inference_time": 0.05835586177272489, "env_time": 0.37056607616978, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 237, "reward_mean": 302.5, "student_loss": null, "teacher_policy_loss": -57.74123001098633, "teacher_value_loss": 462.0511474609375, "teacher_entropy": 0.4816378057003021, "total_time": 1.2021336555480957, "rollout_time": 0.42534828186035156, "train_time": 0.7638554573059082, "student_train_time": 0.012505531311035156, "throughput": 1663.708515912175, "inference_time": 0.05720107143679343, "env_time": 0.36814721042355814, "samples": 2000, "teacher_eval_reward": 281.0}
{"epoch": 238, "reward_mean": 291.8333333333333, "student_loss": null, "teacher_policy_loss": -58.04140853881836, "teacher_value_loss": 417.3416748046875, "teacher_entropy": 0.4767554998397827, "total_time": 1.2284767627716064, "rollout_time": 0.4159817695617676, "train_time": 0.7961978912353516, "student_train_time": 0.015948057174682617, "throughput": 1628.0324224348656, "inference_time": 0.05657439299284306, "env_time": 0.3594073765689245, "samples": 2000, "teacher_eval_reward": 352.0}
{"epoch": 239, "reward_mean": 406.6666666666667, "student_loss": null, "teacher_policy_loss": -60.900882720947266, "teacher_value_loss": 570.5556030273438, "teacher_entropy": 0.4785051643848419, "total_time": 1.185204029083252, "rollout_time": 0.4370098114013672, "train_time": 0.7391684055328369, "student_train_time": 0.008621692657470703, "throughput": 1687.4731699545332, "inference_time": 0.05925560325886181, "env_time": 0.3777542081425054, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 240, "reward_mean": 298.5, "student_loss": null, "teacher_policy_loss": -58.66520309448242, "teacher_value_loss": 484.8931884765625, "teacher_entropy": 0.4800025224685669, "total_time": 1.15362548828125, "rollout_time": 0.4196591377258301, "train_time": 0.7229037284851074, "student_train_time": 0.010709285736083984, "throughput": 1733.664885455796, "inference_time": 0.05693389728185139, "env_time": 0.3627252404439787, "samples": 2000, "teacher_eval_reward": 478.0}
{"epoch": 241, "reward_mean": 245.28571428571428, "student_loss": null, "teacher_policy_loss": -56.17338943481445, "teacher_value_loss": 216.21958923339844, "teacher_entropy": 0.46984222531318665, "total_time": 1.1969504356384277, "rollout_time": 0.43270254135131836, "train_time": 0.7414188385009766, "student_train_time": 0.02238941192626953, "throughput": 1670.912963854884, "inference_time": 0.060730700241037994, "env_time": 0.37197184111028037, "samples": 2000, "teacher_eval_reward": 264.0}
{"epoch": 242, "reward_mean": 302.14285714285717, "student_loss": null, "teacher_policy_loss": -59.6062126159668, "teacher_value_loss": 505.6579895019531, "teacher_entropy": 0.4687148332595825, "total_time": 1.3047337532043457, "rollout_time": 0.43314313888549805, "train_time": 0.8586866855621338, "student_train_time": 0.012499094009399414, "throughput": 1532.8797887600617, "inference_time": 0.05794903073729074, "env_time": 0.3751941081482073, "samples": 2000, "teacher_eval_reward": 445.0}
{"epoch": 243, "reward_mean": 331.1666666666667, "student_loss": null, "teacher_policy_loss": -57.29581069946289, "teacher_value_loss": 327.3150329589844, "teacher_entropy": 0.47667089104652405, "total_time": 1.172828197479248, "rollout_time": 0.4262816905975342, "train_time": 0.7339639663696289, "student_train_time": 0.01222085952758789, "throughput": 1705.2796004551963, "inference_time": 0.0590858425184706, "env_time": 0.3671958480790636, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 244, "reward_mean": 294.3333333333333, "student_loss": null, "teacher_policy_loss": -59.66923141479492, "teacher_value_loss": 440.1224670410156, "teacher_entropy": 0.4675094783306122, "total_time": 1.2001707553863525, "rollout_time": 0.4394857883453369, "train_time": 0.75130295753479, "student_train_time": 0.009023189544677734, "throughput": 1666.4295401500353, "inference_time": 0.059090438753628405, "env_time": 0.3803953495917085, "samples": 2000, "teacher_eval_reward": 460.0}
{"epoch": 245, "reward_mean": 333.57142857142856, "student_loss": null, "teacher_policy_loss": -56.95505142211914, "teacher_value_loss": 478.83306884765625, "teacher_entropy": 0.45429328083992004, "total_time": 1.2682323455810547, "rollout_time": 0.42952632904052734, "train_time": 0.8246407508850098, "student_train_time": 0.01372385025024414, "throughput": 1576.9981005205145, "inference_time": 0.05892711527303618, "env_time": 0.37059921376749116, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 246, "reward_mean": 379.6666666666667, "student_loss": null, "teacher_policy_loss": -61.650726318359375, "teacher_value_loss": 491.6074523925781, "teacher_entropy": 0.4656433165073395, "total_time": 1.4229040145874023, "rollout_time": 0.43691277503967285, "train_time": 0.9678738117218018, "student_train_time": 0.017759084701538086, "throughput": 1405.57618749845, "inference_time": 0.060271711721725296, "env_time": 0.37664106331794756, "samples": 2000, "teacher_eval_reward": 234.0}
{"epoch": 247, "reward_mean": 409.25, "student_loss": null, "teacher_policy_loss": -65.50479125976562, "teacher_value_loss": 498.43878173828125, "teacher_entropy": 0.4629489779472351, "total_time": 1.21705961227417, "rollout_time": 0.4168562889099121, "train_time": 0.7867393493652344, "student_train_time": 0.013062238693237305, "throughput": 1643.304879916971, "inference_time": 0.05748278699502407, "env_time": 0.35937350191488804, "samples": 2000, "teacher_eval_reward": 237.0}
{"epoch": 248, "reward_mean": 287.3333333333333, "student_loss": null, "teacher_policy_loss": -58.78640365600586, "teacher_value_loss": 432.00323486328125, "teacher_entropy": 0.4488680064678192, "total_time": 1.2487907409667969, "rollout_time": 0.4201340675354004, "train_time": 0.8100509643554688, "student_train_time": 0.018262863159179688, "throughput": 1601.5493504152882, "inference_time": 0.05800278224342037, "env_time": 0.36213128529198, "samples": 2000, "teacher_eval_reward": 350.0}
{"epoch": 249, "reward_mean": 386.5, "student_loss": null, "teacher_policy_loss": -61.16128921508789, "teacher_value_loss": 550.9217529296875, "teacher_entropy": 0.4617912173271179, "total_time": 1.371161699295044, "rollout_time": 0.5508453845977783, "train_time": 0.8084006309509277, "student_train_time": 0.011564254760742188, "throughput": 1458.6171718683952, "inference_time": 0.07568751029066334, "env_time": 0.475157874307115, "samples": 2000, "teacher_eval_reward": 356.0}
{"epoch": 250, "reward_mean": 300.8333333333333, "student_loss": null, "teacher_policy_loss": -61.6488037109375, "teacher_value_loss": 646.4581909179688, "teacher_entropy": 0.46347272396087646, "total_time": 1.2098336219787598, "rollout_time": 0.42816781997680664, "train_time": 0.7569026947021484, "student_train_time": 0.024399280548095703, "throughput": 1653.1198700932719, "inference_time": 0.059496114519788534, "env_time": 0.3686717054570181, "samples": 2000, "teacher_eval_reward": 265.0}
{"epoch": 251, "reward_mean": 329.0, "student_loss": null, "teacher_policy_loss": -62.66499328613281, "teacher_value_loss": 459.4612121582031, "teacher_entropy": 0.45525044202804565, "total_time": 1.3724982738494873, "rollout_time": 0.4640350341796875, "train_time": 0.876014232635498, "student_train_time": 0.03208184242248535, "throughput": 1457.1967324888064, "inference_time": 0.06321710699558025, "env_time": 0.40081792718410725, "samples": 2000, "teacher_eval_reward": 236.0}
{"epoch": 252, "reward_mean": 402.6666666666667, "student_loss": null, "teacher_policy_loss": -56.84188461303711, "teacher_value_loss": 516.05322265625, "teacher_entropy": 0.45010456442832947, "total_time": 1.3128352165222168, "rollout_time": 0.42721128463745117, "train_time": 0.8753347396850586, "student_train_time": 0.009933233261108398, "throughput": 1523.4204375611785, "inference_time": 0.05784279248473467, "env_time": 0.3693684921527165, "samples": 2000, "teacher_eval_reward": 484.0}
{"epoch": 253, "reward_mean": 302.3333333333333, "student_loss": null, "teacher_policy_loss": -58.588775634765625, "teacher_value_loss": 413.9491882324219, "teacher_entropy": 0.46299508213996887, "total_time": 1.3981590270996094, "rollout_time": 0.44568681716918945, "train_time": 0.9417006969451904, "student_train_time": 0.010361671447753906, "throughput": 1430.4524458486462, "inference_time": 0.05878607224440202, "env_time": 0.38690074492478743, "samples": 2000, "teacher_eval_reward": 288.0}
{"epoch": 254, "reward_mean": 405.6666666666667, "student_loss": null, "teacher_policy_loss": -58.79154586791992, "teacher_value_loss": 546.548828125, "teacher_entropy": 0.46124890446662903, "total_time": 1.2183709144592285, "rollout_time": 0.41235971450805664, "train_time": 0.7911369800567627, "student_train_time": 0.014534235000610352, "throughput": 1641.5362319180904, "inference_time": 0.056538434779213276, "env_time": 0.35582127972884336, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 255, "reward_mean": 272.2857142857143, "student_loss": null, "teacher_policy_loss": -56.15185546875, "teacher_value_loss": 484.2451171875, "teacher_entropy": 0.4634913206100464, "total_time": 1.3726637363433838, "rollout_time": 0.43187475204467773, "train_time": 0.9063005447387695, "student_train_time": 0.034131765365600586, "throughput": 1457.021080288583, "inference_time": 0.057950584472564515, "env_time": 0.3739241675721132, "samples": 2000, "teacher_eval_reward": 327.0}
{"epoch": 256, "reward_mean": 368.8, "student_loss": null, "teacher_policy_loss": -57.79121780395508, "teacher_value_loss": 381.7652282714844, "teacher_entropy": 0.43675661087036133, "total_time": 1.39412260055542, "rollout_time": 0.44715309143066406, "train_time": 0.9334399700164795, "student_train_time": 0.013172626495361328, "throughput": 1434.5940588031483, "inference_time": 0.062312073443536065, "env_time": 0.384841017987128, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 257, "reward_mean": 293.125, "student_loss": null, "teacher_policy_loss": -52.82374572753906, "teacher_value_loss": 432.95257568359375, "teacher_entropy": 0.46448230743408203, "total_time": -1.300612449645996, "rollout_time": 0.43564796447753906, "train_time": -1.7688062191009521, "student_train_time": 0.03217673301696777, "throughput": 200000000000.0, "inference_time": 0.05988748697927804, "env_time": 0.375760477498261, "samples": 2000, "teacher_eval_reward": 142.0}
{"epoch": 258, "reward_mean": 297.85714285714283, "student_loss": null, "teacher_policy_loss": -53.881771087646484, "teacher_value_loss": 527.5011596679688, "teacher_entropy": 0.4389464259147644, "total_time": 1.2531633377075195, "rollout_time": 0.4315946102142334, "train_time": 0.8050649166107178, "student_train_time": 0.01611948013305664, "throughput": 1595.9611487347768, "inference_time": 0.05925509152075392, "env_time": 0.3723395186934795, "samples": 2000, "teacher_eval_reward": 128.0}
{"epoch": 259, "reward_mean": 252.57142857142858, "student_loss": null, "teacher_policy_loss": -53.20275115966797, "teacher_value_loss": 340.48443603515625, "teacher_entropy": 0.4518268406391144, "total_time": 1.2464020252227783, "rollout_time": 0.4392740726470947, "train_time": 0.7921245098114014, "student_train_time": 0.014554023742675781, "throughput": 1604.6187020937532, "inference_time": 0.060868744762046845, "env_time": 0.3784053278850479, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 260, "reward_mean": 327.8333333333333, "student_loss": null, "teacher_policy_loss": -59.5965461730957, "teacher_value_loss": 388.5136413574219, "teacher_entropy": 0.463117778301239, "total_time": 1.2185916900634766, "rollout_time": 0.4270608425140381, "train_time": 0.779139518737793, "student_train_time": 0.01203298568725586, "throughput": 1641.238830289266, "inference_time": 0.058609763716958696, "env_time": 0.3684510787970794, "samples": 2000, "teacher_eval_reward": 261.0}
{"epoch": 261, "reward_mean": 318.57142857142856, "student_loss": null, "teacher_policy_loss": -55.1518440246582, "teacher_value_loss": 403.4154968261719, "teacher_entropy": 0.4259674549102783, "total_time": 1.2851860523223877, "rollout_time": 0.46199893951416016, "train_time": 0.812891960144043, "student_train_time": 0.009936332702636719, "throughput": 1556.1949154256008, "inference_time": 0.059960648975902586, "env_time": 0.40203829053825757, "samples": 2000, "teacher_eval_reward": 270.0}
{"epoch": 262, "reward_mean": 354.8, "student_loss": null, "teacher_policy_loss": -56.353057861328125, "teacher_value_loss": 543.6558227539062, "teacher_entropy": 0.43475911021232605, "total_time": 1.3827667236328125, "rollout_time": 0.42076897621154785, "train_time": 0.9518141746520996, "student_train_time": 0.009835004806518555, "throughput": 1446.375564162832, "inference_time": 0.05765300674102036, "env_time": 0.3631159694705275, "samples": 2000, "teacher_eval_reward": 258.0}
{"epoch": 263, "reward_mean": 330.5, "student_loss": null, "teacher_policy_loss": -58.688724517822266, "teacher_value_loss": 492.76324462890625, "teacher_entropy": 0.4543503522872925, "total_time": 1.2600204944610596, "rollout_time": 0.42272257804870605, "train_time": 0.8249199390411377, "student_train_time": 0.012038230895996094, "throughput": 1587.2757695544049, "inference_time": 0.057622021027782466, "env_time": 0.3651005570209236, "samples": 2000, "teacher_eval_reward": 128.0}
{"epoch": 264, "reward_mean": 367.6, "student_loss": null, "teacher_policy_loss": -58.03703308105469, "teacher_value_loss": 590.6727905273438, "teacher_entropy": 0.4278198182582855, "total_time": 1.2325315475463867, "rollout_time": 0.43271732330322266, "train_time": 0.7891721725463867, "student_train_time": 0.010285615921020508, "throughput": 1622.6765180829818, "inference_time": 0.05919218376038771, "env_time": 0.37352513954283495, "samples": 2000, "teacher_eval_reward": 368.0}
{"epoch": 265, "reward_mean": 422.8333333333333, "student_loss": null, "teacher_policy_loss": -63.02251434326172, "teacher_value_loss": 727.1021118164062, "teacher_entropy": 0.44511619210243225, "total_time": 1.209533929824829, "rollout_time": 0.44698452949523926, "train_time": 0.751326322555542, "student_train_time": 0.010764360427856445, "throughput": 1653.5294717111824, "inference_time": 0.06235946452397911, "env_time": 0.38462506497126014, "samples": 2000, "teacher_eval_reward": 460.0}
{"epoch": 266, "reward_mean": 318.5, "student_loss": null, "teacher_policy_loss": -59.593990325927734, "teacher_value_loss": 613.6195068359375, "teacher_entropy": 0.43789002299308777, "total_time": 1.6804583072662354, "rollout_time": 0.4682493209838867, "train_time": 1.0607454776763916, "student_train_time": 0.15108394622802734, "throughput": 1190.151514829067, "inference_time": 0.06077770271804184, "env_time": 0.4074716182658449, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 267, "reward_mean": 335.6666666666667, "student_loss": null, "teacher_policy_loss": -61.91474914550781, "teacher_value_loss": 612.6521606445312, "teacher_entropy": 0.44642552733421326, "total_time": 1.498547077178955, "rollout_time": 0.4249293804168701, "train_time": 1.061150074005127, "student_train_time": 0.012111902236938477, "throughput": 1334.6260724521514, "inference_time": 0.05937332601570233, "env_time": 0.3655560544011678, "samples": 2000, "teacher_eval_reward": 404.0}
{"epoch": 268, "reward_mean": 403.0, "student_loss": null, "teacher_policy_loss": -65.58262634277344, "teacher_value_loss": 631.6381225585938, "teacher_entropy": 0.44696325063705444, "total_time": 1.253547191619873, "rollout_time": 0.4470393657684326, "train_time": 0.7944121360778809, "student_train_time": 0.011689424514770508, "throughput": 1595.4724428168813, "inference_time": 0.06671199799166061, "env_time": 0.380327367776772, "samples": 2000, "teacher_eval_reward": 415.0}
{"epoch": 269, "reward_mean": 333.6666666666667, "student_loss": null, "teacher_policy_loss": -58.642364501953125, "teacher_value_loss": 587.8761596679688, "teacher_entropy": 0.4302242696285248, "total_time": 1.4972889423370361, "rollout_time": 0.421358585357666, "train_time": 1.0666003227233887, "student_train_time": 0.00897979736328125, "throughput": 1335.7475257102412, "inference_time": 0.056080327263771323, "env_time": 0.3652782580938947, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 270, "reward_mean": 400.0, "student_loss": null, "teacher_policy_loss": -60.32566833496094, "teacher_value_loss": 613.249267578125, "teacher_entropy": 0.4503162205219269, "total_time": 1.291250467300415, "rollout_time": 0.43055152893066406, "train_time": 0.8515348434448242, "student_train_time": 0.008805513381958008, "throughput": 1548.8861771189518, "inference_time": 0.05739446777988633, "env_time": 0.37315706115077774, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 271, "reward_mean": 398.0, "student_loss": null, "teacher_policy_loss": -59.3570556640625, "teacher_value_loss": 474.06622314453125, "teacher_entropy": 0.44660672545433044, "total_time": 1.28544282913208, "rollout_time": 0.4274749755859375, "train_time": 0.829289436340332, "student_train_time": 0.028309345245361328, "throughput": 1555.8840538636657, "inference_time": 0.05796123470463499, "env_time": 0.3695137408813025, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 272, "reward_mean": 375.6, "student_loss": null, "teacher_policy_loss": -59.72654724121094, "teacher_value_loss": 523.8026123046875, "teacher_entropy": 0.44711989164352417, "total_time": 1.2626543045043945, "rollout_time": 0.4524836540222168, "train_time": 0.8021454811096191, "student_train_time": 0.007671833038330078, "throughput": 1583.964821459997, "inference_time": 0.06511466527990706, "env_time": 0.38736898874230974, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 273, "reward_mean": 293.14285714285717, "student_loss": null, "teacher_policy_loss": -59.217472076416016, "teacher_value_loss": 792.8433837890625, "teacher_entropy": 0.44597166776657104, "total_time": 1.4211432933807373, "rollout_time": 0.4285411834716797, "train_time": 0.9835221767425537, "student_train_time": 0.00872659683227539, "throughput": 1407.3176218861286, "inference_time": 0.057495037239277735, "env_time": 0.37104614623240195, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 274, "reward_mean": 336.42857142857144, "student_loss": null, "teacher_policy_loss": -58.84685134887695, "teacher_value_loss": 667.2566528320312, "teacher_entropy": 0.44370168447494507, "total_time": 1.2392709255218506, "rollout_time": 0.43346476554870605, "train_time": 0.7916719913482666, "student_train_time": 0.013778448104858398, "throughput": 1613.8521116016746, "inference_time": 0.05769523296112311, "env_time": 0.37576953258758294, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 275, "reward_mean": 326.1666666666667, "student_loss": null, "teacher_policy_loss": -57.51348114013672, "teacher_value_loss": 702.5201416015625, "teacher_entropy": 0.4628889858722687, "total_time": 1.2955706119537354, "rollout_time": 0.4485783576965332, "train_time": 0.8304228782653809, "student_train_time": 0.01621866226196289, "throughput": 1543.7213391124835, "inference_time": 0.0609373307779606, "env_time": 0.3876410269185726, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 276, "reward_mean": 334.0, "student_loss": null, "teacher_policy_loss": -66.145751953125, "teacher_value_loss": 988.9633178710938, "teacher_entropy": 0.46724599599838257, "total_time": 1.3278746604919434, "rollout_time": 0.43459177017211914, "train_time": 0.8834652900695801, "student_train_time": 0.009468555450439453, "throughput": 1506.166251609208, "inference_time": 0.05939603226943291, "env_time": 0.37519573790268623, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 277, "reward_mean": 322.125, "student_loss": null, "teacher_policy_loss": -59.44239044189453, "teacher_value_loss": 763.4144897460938, "teacher_entropy": 0.4562663435935974, "total_time": -1.291640281677246, "rollout_time": -2.1470940113067627, "train_time": 0.8389415740966797, "student_train_time": 0.016082763671875, "throughput": 200000000000.0, "inference_time": 0.059511274739634246, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 278, "reward_mean": 422.75, "student_loss": null, "teacher_policy_loss": -66.28025817871094, "teacher_value_loss": 767.3963623046875, "teacher_entropy": 0.4614695906639099, "total_time": 1.19594144821167, "rollout_time": 0.4245951175689697, "train_time": 0.760643482208252, "student_train_time": 0.010342836380004883, "throughput": 1672.322673480934, "inference_time": 0.05668418530149211, "env_time": 0.3679109322674776, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 279, "reward_mean": 368.0, "student_loss": null, "teacher_policy_loss": -59.81388854980469, "teacher_value_loss": 678.91845703125, "teacher_entropy": 0.45729881525039673, "total_time": 1.1998112201690674, "rollout_time": 0.4250311851501465, "train_time": 0.765831708908081, "student_train_time": 0.00856924057006836, "throughput": 1666.9289021302673, "inference_time": 0.05773109147048672, "env_time": 0.36730009367965977, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 280, "reward_mean": 285.375, "student_loss": null, "teacher_policy_loss": -53.69786071777344, "teacher_value_loss": 879.9811401367188, "teacher_entropy": 0.4664183259010315, "total_time": 1.2024905681610107, "rollout_time": 0.4202394485473633, "train_time": 0.7589962482452393, "student_train_time": 0.022831439971923828, "throughput": 1663.2147086680554, "inference_time": 0.056499429538234835, "env_time": 0.36374001900912845, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 281, "reward_mean": 414.0, "student_loss": null, "teacher_policy_loss": -62.56853103637695, "teacher_value_loss": 421.5143737792969, "teacher_entropy": 0.4762158989906311, "total_time": 1.372215986251831, "rollout_time": 0.4499938488006592, "train_time": 0.9105150699615479, "student_train_time": 0.011344671249389648, "throughput": 1457.4965020360557, "inference_time": 0.06249175472476054, "env_time": 0.38750209407589864, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 282, "reward_mean": 267.5, "student_loss": null, "teacher_policy_loss": -53.84083557128906, "teacher_value_loss": 524.9141235351562, "teacher_entropy": 0.46964719891548157, "total_time": 1.2618765830993652, "rollout_time": 0.42647480964660645, "train_time": 0.825157642364502, "student_train_time": 0.009848356246948242, "throughput": 1584.9410527039727, "inference_time": 0.060528510253789136, "env_time": 0.3659462993928173, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 283, "reward_mean": 273.375, "student_loss": null, "teacher_policy_loss": -56.1664924621582, "teacher_value_loss": 406.5221862792969, "teacher_entropy": 0.47912707924842834, "total_time": 1.2925033569335938, "rollout_time": 0.4223635196685791, "train_time": 0.8567385673522949, "student_train_time": 0.013046026229858398, "throughput": 1547.384762500664, "inference_time": 0.05689214449375868, "env_time": 0.3654713751748204, "samples": 2000, "teacher_eval_reward": 181.0}
{"epoch": 284, "reward_mean": 297.85714285714283, "student_loss": null, "teacher_policy_loss": -55.75873947143555, "teacher_value_loss": 458.3648681640625, "teacher_entropy": 0.4798646569252014, "total_time": 1.1936798095703125, "rollout_time": 0.43036580085754395, "train_time": 0.7546906471252441, "student_train_time": 0.008214712142944336, "throughput": 1675.4911861330197, "inference_time": 0.058378892495966284, "env_time": 0.37198690836157766, "samples": 2000, "teacher_eval_reward": 157.0}
{"epoch": 285, "reward_mean": 291.3333333333333, "student_loss": null, "teacher_policy_loss": -55.42177200317383, "teacher_value_loss": 440.47979736328125, "teacher_entropy": 0.46848416328430176, "total_time": 1.2862634658813477, "rollout_time": 0.44069480895996094, "train_time": 0.8331890106201172, "student_train_time": 0.012016534805297852, "throughput": 1554.891399041331, "inference_time": 0.057821557493298315, "env_time": 0.3828732514666626, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 286, "reward_mean": 264.625, "student_loss": null, "teacher_policy_loss": -52.9125862121582, "teacher_value_loss": 294.2784423828125, "teacher_entropy": 0.47775429487228394, "total_time": 1.2012388706207275, "rollout_time": 0.43427538871765137, "train_time": 0.7582945823669434, "student_train_time": 0.008320331573486328, "throughput": 1664.9477875840973, "inference_time": 0.06041982922943134, "env_time": 0.37385555948822, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 287, "reward_mean": 233.125, "student_loss": null, "teacher_policy_loss": -51.68355941772461, "teacher_value_loss": 367.3149719238281, "teacher_entropy": 0.4628252685070038, "total_time": 1.2147188186645508, "rollout_time": 0.44332289695739746, "train_time": 0.7486255168914795, "student_train_time": 0.022359371185302734, "throughput": 1646.4715696088244, "inference_time": 0.056582045943287085, "env_time": 0.3867408510141104, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 288, "reward_mean": 262.625, "student_loss": null, "teacher_policy_loss": -55.26955032348633, "teacher_value_loss": 380.8968505859375, "teacher_entropy": 0.4811308681964874, "total_time": 1.2230920791625977, "rollout_time": 0.42867112159729004, "train_time": 0.7818217277526855, "student_train_time": 0.012239456176757812, "throughput": 1635.1998627685662, "inference_time": 0.05599484122285503, "env_time": 0.372676280374435, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 289, "reward_mean": 289.3333333333333, "student_loss": null, "teacher_policy_loss": -57.00956344604492, "teacher_value_loss": 275.9056701660156, "teacher_entropy": 0.4777320623397827, "total_time": 1.314453363418579, "rollout_time": 0.44290971755981445, "train_time": 0.8622958660125732, "student_train_time": 0.008893013000488281, "throughput": 1521.5450434836866, "inference_time": 0.06110095377698599, "env_time": 0.38180876378282846, "samples": 2000, "teacher_eval_reward": 158.0}
{"epoch": 290, "reward_mean": 227.7, "student_loss": null, "teacher_policy_loss": -53.00743103027344, "teacher_value_loss": 404.52178955078125, "teacher_entropy": 0.48305419087409973, "total_time": 1.4328255653381348, "rollout_time": 0.4171602725982666, "train_time": 1.005284309387207, "student_train_time": 0.010030031204223633, "throughput": 1395.8433241160217, "inference_time": 0.056196237024778384, "env_time": 0.3609640355734882, "samples": 2000, "teacher_eval_reward": 377.0}
{"epoch": 291, "reward_mean": 236.55555555555554, "student_loss": null, "teacher_policy_loss": -52.108360290527344, "teacher_value_loss": 245.59030151367188, "teacher_entropy": 0.48462221026420593, "total_time": 1.235645055770874, "rollout_time": 0.42128467559814453, "train_time": 0.8046801090240479, "student_train_time": 0.00933074951171875, "throughput": 1618.5877899639008, "inference_time": 0.05493443526029296, "env_time": 0.3663502403378516, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 292, "reward_mean": 229.11111111111111, "student_loss": null, "teacher_policy_loss": -53.152931213378906, "teacher_value_loss": 316.02215576171875, "teacher_entropy": 0.4822894334793091, "total_time": 1.3562471866607666, "rollout_time": 0.44046711921691895, "train_time": 0.8965272903442383, "student_train_time": 0.018888473510742188, "throughput": 1474.657436838063, "inference_time": 0.05795159819172113, "env_time": 0.3825155210251978, "samples": 2000, "teacher_eval_reward": 235.0}
{"epoch": 293, "reward_mean": 202.625, "student_loss": null, "teacher_policy_loss": -53.2118034362793, "teacher_value_loss": 407.68731689453125, "teacher_entropy": 0.49071332812309265, "total_time": 1.3670415878295898, "rollout_time": 0.44291257858276367, "train_time": 0.9007089138031006, "student_train_time": 0.023053884506225586, "throughput": 1463.0132819699647, "inference_time": 0.059542824725212995, "env_time": 0.3833697538575507, "samples": 2000, "teacher_eval_reward": 215.0}
{"epoch": 294, "reward_mean": 265.3333333333333, "student_loss": null, "teacher_policy_loss": -51.524696350097656, "teacher_value_loss": 315.0797119140625, "teacher_entropy": 0.48763301968574524, "total_time": 1.2709221839904785, "rollout_time": 0.45009493827819824, "train_time": 0.7974457740783691, "student_train_time": 0.023022174835205078, "throughput": 1573.6604689048245, "inference_time": 0.06513466676551616, "env_time": 0.3849602715126821, "samples": 2000, "teacher_eval_reward": 326.0}
{"epoch": 295, "reward_mean": 239.375, "student_loss": null, "teacher_policy_loss": -52.292503356933594, "teacher_value_loss": 433.2954406738281, "teacher_entropy": 0.4926315248012543, "total_time": 1.2363183498382568, "rollout_time": 0.4299495220184326, "train_time": 0.797823429107666, "student_train_time": 0.008181333541870117, "throughput": 1617.7063134763412, "inference_time": 0.05726312474689621, "env_time": 0.3726863972715364, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 296, "reward_mean": 225.11111111111111, "student_loss": null, "teacher_policy_loss": -51.249107360839844, "teacher_value_loss": 296.0953674316406, "teacher_entropy": 0.4822566509246826, "total_time": 1.2778041362762451, "rollout_time": 0.4440596103668213, "train_time": 0.8094985485076904, "student_train_time": 0.0238802433013916, "throughput": 1565.185104055435, "inference_time": 0.061543210766103584, "env_time": 0.3825163996007177, "samples": 2000, "teacher_eval_reward": 487.0}
{"epoch": 297, "reward_mean": 228.5, "student_loss": null, "teacher_policy_loss": -56.09989929199219, "teacher_value_loss": 279.79852294921875, "teacher_entropy": 0.47701045870780945, "total_time": -1.3470511436462402, "rollout_time": 0.41751837730407715, "train_time": -1.7764132022857666, "student_train_time": 0.011493921279907227, "throughput": 200000000000.0, "inference_time": 0.05592071245882835, "env_time": 0.3615976648452488, "samples": 2000, "teacher_eval_reward": 307.0}
{"epoch": 298, "reward_mean": 218.28571428571428, "student_loss": null, "teacher_policy_loss": -58.19847869873047, "teacher_value_loss": 370.7517395019531, "teacher_entropy": 0.48415374755859375, "total_time": 1.1987459659576416, "rollout_time": 0.43894290924072266, "train_time": 0.7503936290740967, "student_train_time": 0.009016990661621094, "throughput": 1668.4102026589603, "inference_time": 0.05906466772285057, "env_time": 0.3798782415178721, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 299, "reward_mean": 323.375, "student_loss": null, "teacher_policy_loss": -54.567108154296875, "teacher_value_loss": 492.1658630371094, "teacher_entropy": 0.47111818194389343, "total_time": 1.3946328163146973, "rollout_time": 0.44611668586730957, "train_time": 0.937492847442627, "student_train_time": 0.01056051254272461, "throughput": 1434.0692235286556, "inference_time": 0.05915224298769317, "env_time": 0.3869644428796164, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 300, "reward_mean": 340.6666666666667, "student_loss": null, "teacher_policy_loss": -59.85991668701172, "teacher_value_loss": 306.55303955078125, "teacher_entropy": 0.4789260923862457, "total_time": 1.3221299648284912, "rollout_time": 0.4380156993865967, "train_time": 0.8759188652038574, "student_train_time": 0.007787942886352539, "throughput": 1512.7105906410973, "inference_time": 0.059880781485844636, "env_time": 0.37813491790075204, "samples": 2000, "teacher_eval_reward": 236.0}
{"epoch": 301, "reward_mean": 298.1666666666667, "student_loss": null, "teacher_policy_loss": -56.22431182861328, "teacher_value_loss": 620.546875, "teacher_entropy": 0.4705984592437744, "total_time": 1.2300007343292236, "rollout_time": 0.4432692527770996, "train_time": 0.76334547996521, "student_train_time": 0.02297830581665039, "throughput": 1626.015289406061, "inference_time": 0.0590634769796452, "env_time": 0.3842057757974544, "samples": 2000, "teacher_eval_reward": 135.0}
{"epoch": 302, "reward_mean": 376.2, "student_loss": null, "teacher_policy_loss": -55.90839385986328, "teacher_value_loss": 550.2319946289062, "teacher_entropy": 0.45821666717529297, "total_time": 1.3260529041290283, "rollout_time": 0.4501192569732666, "train_time": 0.8627843856811523, "student_train_time": 0.01279902458190918, "throughput": 1508.2354510686964, "inference_time": 0.0583722392875643, "env_time": 0.3917470176857023, "samples": 2000, "teacher_eval_reward": 275.0}
{"epoch": 303, "reward_mean": 343.0, "student_loss": null, "teacher_policy_loss": -63.91880416870117, "teacher_value_loss": 402.6828308105469, "teacher_entropy": 0.4721214473247528, "total_time": 1.367706537246704, "rollout_time": 0.43718409538269043, "train_time": 0.9217629432678223, "student_train_time": 0.008394718170166016, "throughput": 1462.301996469323, "inference_time": 0.0592344450251403, "env_time": 0.3779496503575501, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 304, "reward_mean": 363.5, "student_loss": null, "teacher_policy_loss": -63.86952209472656, "teacher_value_loss": 682.5917358398438, "teacher_entropy": 0.4526103734970093, "total_time": 1.2518432140350342, "rollout_time": 0.44077563285827637, "train_time": 0.7989485263824463, "student_train_time": 0.011758565902709961, "throughput": 1597.6441598892015, "inference_time": 0.05877754823632131, "env_time": 0.38199808462195506, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 305, "reward_mean": 433.75, "student_loss": null, "teacher_policy_loss": -68.24580383300781, "teacher_value_loss": 558.9837036132812, "teacher_entropy": 0.4667847156524658, "total_time": 1.2887396812438965, "rollout_time": 0.43491029739379883, "train_time": 0.8353254795074463, "student_train_time": 0.017871379852294922, "throughput": 1551.9037933786537, "inference_time": 0.06127343900334381, "env_time": 0.373636858390455, "samples": 2000, "teacher_eval_reward": 273.0}
{"epoch": 306, "reward_mean": 499.25, "student_loss": null, "teacher_policy_loss": -66.72803497314453, "teacher_value_loss": 576.066162109375, "teacher_entropy": 0.46004754304885864, "total_time": 1.6330831050872803, "rollout_time": 0.46944761276245117, "train_time": 0.9908907413482666, "student_train_time": 0.17226219177246094, "throughput": 1224.6774176829842, "inference_time": 0.0614344707755663, "env_time": 0.4080131419868849, "samples": 2000, "teacher_eval_reward": 232.0}
{"epoch": 307, "reward_mean": 453.8, "student_loss": null, "teacher_policy_loss": -62.27765655517578, "teacher_value_loss": 467.7929992675781, "teacher_entropy": 0.44800713658332825, "total_time": 1.3202993869781494, "rollout_time": 0.4436526298522949, "train_time": 0.8675706386566162, "student_train_time": 0.008722543716430664, "throughput": 1514.8079441114664, "inference_time": 0.05789689025004918, "env_time": 0.38575573960224574, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 308, "reward_mean": 323.85714285714283, "student_loss": null, "teacher_policy_loss": -57.417198181152344, "teacher_value_loss": 560.830078125, "teacher_entropy": 0.4492241442203522, "total_time": 1.406299352645874, "rollout_time": 0.43321824073791504, "train_time": 0.9576001167297363, "student_train_time": 0.015124797821044922, "throughput": 1422.1723107794305, "inference_time": 0.05782655322582286, "env_time": 0.3753916875120922, "samples": 2000, "teacher_eval_reward": 287.0}
{"epoch": 309, "reward_mean": 309.8333333333333, "student_loss": null, "teacher_policy_loss": -54.813114166259766, "teacher_value_loss": 672.1505737304688, "teacher_entropy": 0.4502745568752289, "total_time": 1.2825219631195068, "rollout_time": 0.426929235458374, "train_time": 0.8372912406921387, "student_train_time": 0.017943382263183594, "throughput": 1559.4274854641517, "inference_time": 0.0568751712962694, "env_time": 0.3700540641621046, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 310, "reward_mean": 361.0, "student_loss": null, "teacher_policy_loss": -60.590126037597656, "teacher_value_loss": 656.2244262695312, "teacher_entropy": 0.46160149574279785, "total_time": 1.2233941555023193, "rollout_time": 0.4295010566711426, "train_time": 0.7768094539642334, "student_train_time": 0.016736268997192383, "throughput": 1634.7961047589035, "inference_time": 0.05905207148862246, "env_time": 0.3704489851825201, "samples": 2000, "teacher_eval_reward": 339.0}
{"epoch": 311, "reward_mean": 398.6, "student_loss": null, "teacher_policy_loss": -59.123870849609375, "teacher_value_loss": 660.8934326171875, "teacher_entropy": 0.43343082070350647, "total_time": 1.3452470302581787, "rollout_time": 0.41367483139038086, "train_time": 0.920020341873169, "student_train_time": 0.011198759078979492, "throughput": 1486.7157890072885, "inference_time": 0.05499553101253696, "env_time": 0.3586793003778439, "samples": 2000, "teacher_eval_reward": 240.0}
{"epoch": 312, "reward_mean": 337.0, "student_loss": null, "teacher_policy_loss": -49.06400680541992, "teacher_value_loss": 599.3687744140625, "teacher_entropy": 0.41379496455192566, "total_time": 1.2679393291473389, "rollout_time": 0.42566585540771484, "train_time": 0.8325769901275635, "student_train_time": 0.00916147232055664, "throughput": 1577.362539377145, "inference_time": 0.05869122773765412, "env_time": 0.3669746276700607, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 313, "reward_mean": 382.6, "student_loss": null, "teacher_policy_loss": -61.06194305419922, "teacher_value_loss": 621.0541381835938, "teacher_entropy": 0.46227994561195374, "total_time": 1.3600969314575195, "rollout_time": 0.42869138717651367, "train_time": 0.9145867824554443, "student_train_time": 0.01645946502685547, "throughput": 1470.4834293367178, "inference_time": 0.0574759802511835, "env_time": 0.37121540692533017, "samples": 2000, "teacher_eval_reward": 287.0}
{"epoch": 314, "reward_mean": 474.25, "student_loss": null, "teacher_policy_loss": -61.92681884765625, "teacher_value_loss": 634.6236572265625, "teacher_entropy": 0.4602144956588745, "total_time": 1.2634813785552979, "rollout_time": 0.44734907150268555, "train_time": 0.8065440654754639, "student_train_time": 0.008935689926147461, "throughput": 1582.9279591653813, "inference_time": 0.06255722753121518, "env_time": 0.38479184397147037, "samples": 2000, "teacher_eval_reward": 283.0}
{"epoch": 315, "reward_mean": 345.0, "student_loss": null, "teacher_policy_loss": -56.350242614746094, "teacher_value_loss": 727.2460327148438, "teacher_entropy": 0.44852200150489807, "total_time": 1.2772972583770752, "rollout_time": 0.4501152038574219, "train_time": 0.7491171360015869, "student_train_time": 0.0777122974395752, "throughput": 1565.8062262978515, "inference_time": 0.05939578875040752, "env_time": 0.39071941510701436, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 316, "reward_mean": 449.0, "student_loss": null, "teacher_policy_loss": -62.212181091308594, "teacher_value_loss": 427.1351318359375, "teacher_entropy": 0.4568982720375061, "total_time": 1.2909717559814453, "rollout_time": 0.43479323387145996, "train_time": 0.8386533260345459, "student_train_time": 0.017167329788208008, "throughput": 1549.220570266872, "inference_time": 0.057950350259488914, "env_time": 0.37684288361197105, "samples": 2000, "teacher_eval_reward": 488.0}
{"epoch": 317, "reward_mean": 257.625, "student_loss": null, "teacher_policy_loss": -49.893165588378906, "teacher_value_loss": 555.349609375, "teacher_entropy": 0.4131620526313782, "total_time": 1.3201103210449219, "rollout_time": 0.42235469818115234, "train_time": 0.8885445594787598, "student_train_time": 0.008844375610351562, "throughput": 1515.0248945988978, "inference_time": 0.05871693072367634, "env_time": 0.363637767457476, "samples": 2000, "teacher_eval_reward": 462.0}
{"epoch": 318, "reward_mean": 265.375, "student_loss": null, "teacher_policy_loss": -49.97332000732422, "teacher_value_loss": 698.2207641601562, "teacher_entropy": 0.4019271731376648, "total_time": 1.3554649353027344, "rollout_time": 0.42764759063720703, "train_time": 0.9001781940460205, "student_train_time": 0.027289867401123047, "throughput": 1475.5084752917735, "inference_time": 0.05615615574788535, "env_time": 0.3714914348893217, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 319, "reward_mean": 407.75, "student_loss": null, "teacher_policy_loss": -60.22584915161133, "teacher_value_loss": 452.0108642578125, "teacher_entropy": 0.42748191952705383, "total_time": 1.2431254386901855, "rollout_time": 0.44394898414611816, "train_time": 0.782151460647583, "student_train_time": 0.016603946685791016, "throughput": 1608.8480999208675, "inference_time": 0.06227273176591552, "env_time": 0.38167625238020264, "samples": 2000, "teacher_eval_reward": 278.0}
{"epoch": 320, "reward_mean": 400.0, "student_loss": null, "teacher_policy_loss": -60.25713348388672, "teacher_value_loss": 513.3514404296875, "teacher_entropy": 0.4517340660095215, "total_time": 1.4316537380218506, "rollout_time": 0.4316387176513672, "train_time": 0.9755136966705322, "student_train_time": 0.02408576011657715, "throughput": 1396.9858401399815, "inference_time": 0.05808265951418434, "env_time": 0.37355605813718284, "samples": 2000, "teacher_eval_reward": 109.0}
{"epoch": 321, "reward_mean": 277.7142857142857, "student_loss": null, "teacher_policy_loss": -49.95587921142578, "teacher_value_loss": 549.0549926757812, "teacher_entropy": 0.4138076901435852, "total_time": 1.1996397972106934, "rollout_time": 0.42987680435180664, "train_time": 0.7538838386535645, "student_train_time": 0.015517473220825195, "throughput": 1667.1670985326098, "inference_time": 0.058856305013250676, "env_time": 0.37102049933855596, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 322, "reward_mean": 368.8, "student_loss": null, "teacher_policy_loss": -52.284175872802734, "teacher_value_loss": 443.2119445800781, "teacher_entropy": 0.38963472843170166, "total_time": 1.4271330833435059, "rollout_time": 0.46869874000549316, "train_time": 0.9413819313049316, "student_train_time": 0.01669168472290039, "throughput": 1401.4109989759147, "inference_time": 0.06197529522796685, "env_time": 0.4067234447775263, "samples": 2000, "teacher_eval_reward": 190.0}
{"epoch": 323, "reward_mean": 342.1666666666667, "student_loss": null, "teacher_policy_loss": -57.11460876464844, "teacher_value_loss": 480.1191711425781, "teacher_entropy": 0.4426433742046356, "total_time": 1.287275791168213, "rollout_time": 0.42798376083374023, "train_time": 0.8465559482574463, "student_train_time": 0.01229095458984375, "throughput": 1553.6686184279006, "inference_time": 0.05984755221106752, "env_time": 0.3681362086226727, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 324, "reward_mean": 320.4, "student_loss": null, "teacher_policy_loss": -62.73388671875, "teacher_value_loss": 665.548095703125, "teacher_entropy": 0.43554601073265076, "total_time": 1.3490209579467773, "rollout_time": 0.4732851982116699, "train_time": 0.863173246383667, "student_train_time": 0.012195110321044922, "throughput": 1482.5566557868892, "inference_time": 0.06368117923739192, "env_time": 0.409604018974278, "samples": 2000, "teacher_eval_reward": 297.0}
{"epoch": 325, "reward_mean": 382.57142857142856, "student_loss": null, "teacher_policy_loss": -54.203460693359375, "teacher_value_loss": 713.8865356445312, "teacher_entropy": 0.3861282467842102, "total_time": 1.2916688919067383, "rollout_time": 0.4380486011505127, "train_time": 0.8433945178985596, "student_train_time": 0.009792804718017578, "throughput": 1548.3844292693589, "inference_time": 0.05845583121663367, "env_time": 0.379592769933879, "samples": 2000, "teacher_eval_reward": 275.0}
{"epoch": 326, "reward_mean": 374.2, "student_loss": null, "teacher_policy_loss": -57.33245086669922, "teacher_value_loss": 603.9739990234375, "teacher_entropy": 0.39237964153289795, "total_time": 1.2011449337005615, "rollout_time": 0.4385716915130615, "train_time": 0.7553389072418213, "student_train_time": 0.006829977035522461, "throughput": 1665.0779967395579, "inference_time": 0.05978755074283981, "env_time": 0.3787841407702217, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 327, "reward_mean": 312.42857142857144, "student_loss": null, "teacher_policy_loss": -56.33656311035156, "teacher_value_loss": 627.0919799804688, "teacher_entropy": 0.4208764433860779, "total_time": 1.2807080745697021, "rollout_time": 0.4292316436767578, "train_time": 0.8416924476623535, "student_train_time": 0.009347915649414062, "throughput": 1561.6361290389839, "inference_time": 0.05740778001199942, "env_time": 0.3718238636647584, "samples": 2000, "teacher_eval_reward": 152.0}
{"epoch": 328, "reward_mean": 417.4, "student_loss": null, "teacher_policy_loss": -61.76582336425781, "teacher_value_loss": 756.7177124023438, "teacher_entropy": 0.40687206387519836, "total_time": 1.2366142272949219, "rollout_time": 0.42195773124694824, "train_time": 0.8030509948730469, "student_train_time": 0.011202096939086914, "throughput": 1617.3192543441578, "inference_time": 0.05671691248244315, "env_time": 0.3652408187645051, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 329, "reward_mean": 339.8, "student_loss": null, "teacher_policy_loss": -58.135433197021484, "teacher_value_loss": 622.4215698242188, "teacher_entropy": 0.3970354497432709, "total_time": 1.3646392822265625, "rollout_time": 0.4426462650299072, "train_time": 0.90334153175354, "student_train_time": 0.01829361915588379, "throughput": 1465.5887647736295, "inference_time": 0.05792777330316312, "env_time": 0.3847184917267441, "samples": 2000, "teacher_eval_reward": 364.0}
{"epoch": 330, "reward_mean": 328.0, "student_loss": null, "teacher_policy_loss": -64.825439453125, "teacher_value_loss": 541.1756591796875, "teacher_entropy": 0.42899057269096375, "total_time": 1.3740196228027344, "rollout_time": 0.4421365261077881, "train_time": 0.9114658832550049, "student_train_time": 0.019942522048950195, "throughput": 1455.583287755663, "inference_time": 0.060501501513499534, "env_time": 0.38163502459428855, "samples": 2000, "teacher_eval_reward": 322.0}
{"epoch": 331, "reward_mean": 376.25, "student_loss": null, "teacher_policy_loss": -64.53194427490234, "teacher_value_loss": 642.414306640625, "teacher_entropy": 0.41340792179107666, "total_time": 1.3056962490081787, "rollout_time": 0.43100619316101074, "train_time": 0.8644413948059082, "student_train_time": 0.00990152359008789, "throughput": 1531.7498242942968, "inference_time": 0.05956994876396493, "env_time": 0.3714362443970458, "samples": 2000, "teacher_eval_reward": 307.0}
{"epoch": 332, "reward_mean": 393.5, "student_loss": null, "teacher_policy_loss": -53.31440353393555, "teacher_value_loss": 712.304931640625, "teacher_entropy": 0.4081542491912842, "total_time": 1.2218453884124756, "rollout_time": 0.4226090908050537, "train_time": 0.7792201042175293, "student_train_time": 0.01959538459777832, "throughput": 1636.868313263897, "inference_time": 0.05527300070752972, "env_time": 0.367336090097524, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 333, "reward_mean": 449.25, "student_loss": null, "teacher_policy_loss": -62.699771881103516, "teacher_value_loss": 800.8778686523438, "teacher_entropy": 0.4114469885826111, "total_time": 1.3054907321929932, "rollout_time": 0.42905545234680176, "train_time": 0.8631587028503418, "student_train_time": 0.012881278991699219, "throughput": 1531.9909599360803, "inference_time": 0.05683482245149207, "env_time": 0.3722206298953097, "samples": 2000, "teacher_eval_reward": 491.0}
{"epoch": 334, "reward_mean": 443.25, "student_loss": null, "teacher_policy_loss": -62.333953857421875, "teacher_value_loss": 488.79876708984375, "teacher_entropy": 0.4231802821159363, "total_time": 1.3362467288970947, "rollout_time": 0.4443247318267822, "train_time": 0.8656411170959473, "student_train_time": 0.02590322494506836, "throughput": 1496.729576019805, "inference_time": 0.059406671764008934, "env_time": 0.3849180600627733, "samples": 2000, "teacher_eval_reward": 220.0}
{"epoch": 335, "reward_mean": 445.75, "student_loss": null, "teacher_policy_loss": -61.73125457763672, "teacher_value_loss": 634.560546875, "teacher_entropy": 0.4146121144294739, "total_time": 1.3169713020324707, "rollout_time": 0.4412577152252197, "train_time": 0.8584823608398438, "student_train_time": 0.015763521194458008, "throughput": 1518.6359770432482, "inference_time": 0.05793018096665037, "env_time": 0.38332753425856936, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 336, "reward_mean": 348.3333333333333, "student_loss": null, "teacher_policy_loss": -57.75049591064453, "teacher_value_loss": 539.5689697265625, "teacher_entropy": 0.4210045635700226, "total_time": 1.3652379512786865, "rollout_time": 0.4499990940093994, "train_time": 0.8992643356323242, "student_train_time": 0.015611886978149414, "throughput": 1464.9460909922648, "inference_time": 0.05992317401432956, "env_time": 0.39007591999506985, "samples": 2000, "teacher_eval_reward": 307.0}
{"epoch": 337, "reward_mean": 452.0, "student_loss": null, "teacher_policy_loss": -62.053810119628906, "teacher_value_loss": 685.9797973632812, "teacher_entropy": 0.43384426832199097, "total_time": 1.3508810997009277, "rollout_time": 0.44351768493652344, "train_time": 0.8959319591522217, "student_train_time": 0.011031150817871094, "throughput": 1480.5151988896587, "inference_time": 0.0613138517637708, "env_time": 0.38220383317275264, "samples": 2000, "teacher_eval_reward": 320.0}
{"epoch": 338, "reward_mean": 369.5, "student_loss": null, "teacher_policy_loss": -63.77412033081055, "teacher_value_loss": 592.4824829101562, "teacher_entropy": 0.43296974897384644, "total_time": 1.2382140159606934, "rollout_time": 0.436931848526001, "train_time": 0.7899997234344482, "student_train_time": 0.010474681854248047, "throughput": 1615.229656763544, "inference_time": 0.05970605650145444, "env_time": 0.37722579202454654, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 339, "reward_mean": 406.3333333333333, "student_loss": null, "teacher_policy_loss": -63.8908805847168, "teacher_value_loss": 637.488525390625, "teacher_entropy": 0.43022653460502625, "total_time": 1.318340539932251, "rollout_time": 0.4304227828979492, "train_time": 0.8759105205535889, "student_train_time": 0.011655807495117188, "throughput": 1517.0587108720629, "inference_time": 0.057054150454860064, "env_time": 0.37336863244308915, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 340, "reward_mean": 384.0, "student_loss": null, "teacher_policy_loss": -65.20382690429688, "teacher_value_loss": 648.6819458007812, "teacher_entropy": 0.449699729681015, "total_time": 1.3342044353485107, "rollout_time": 0.4413726329803467, "train_time": 0.872671365737915, "student_train_time": 0.019807100296020508, "throughput": 1499.0206500681998, "inference_time": 0.057855663309965166, "env_time": 0.3835169696703815, "samples": 2000, "teacher_eval_reward": 444.0}
{"epoch": 341, "reward_mean": 412.5, "student_loss": null, "teacher_policy_loss": -67.76911926269531, "teacher_value_loss": 529.4068603515625, "teacher_entropy": 0.4280480146408081, "total_time": 1.2956023216247559, "rollout_time": 0.45177364349365234, "train_time": 0.8347160816192627, "student_train_time": 0.008453607559204102, "throughput": 1543.6835567660075, "inference_time": 0.06240255620650714, "env_time": 0.3893710872871452, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 342, "reward_mean": 460.0, "student_loss": null, "teacher_policy_loss": -65.65403747558594, "teacher_value_loss": 613.5689086914062, "teacher_entropy": 0.43321192264556885, "total_time": 1.2109646797180176, "rollout_time": 0.4419567584991455, "train_time": 0.7589931488037109, "student_train_time": 0.009660005569458008, "throughput": 1651.5758332982225, "inference_time": 0.06090216674056137, "env_time": 0.38105459175858414, "samples": 2000, "teacher_eval_reward": 328.0}
{"epoch": 343, "reward_mean": 428.5, "student_loss": null, "teacher_policy_loss": -63.88443374633789, "teacher_value_loss": 552.9089965820312, "teacher_entropy": 0.43456903100013733, "total_time": 1.3113453388214111, "rollout_time": 0.4524376392364502, "train_time": 0.8394367694854736, "student_train_time": 0.019103288650512695, "throughput": 1525.1512632038837, "inference_time": 0.06135347004965297, "env_time": 0.3910841691867972, "samples": 2000, "teacher_eval_reward": 357.0}
{"epoch": 344, "reward_mean": 434.0, "student_loss": null, "teacher_policy_loss": -65.32118225097656, "teacher_value_loss": 570.4549560546875, "teacher_entropy": 0.4354725182056427, "total_time": 1.3389511108398438, "rollout_time": 0.44653749465942383, "train_time": 0.8757054805755615, "student_train_time": 0.016303539276123047, "throughput": 1493.7065168462498, "inference_time": 0.06373738672300533, "env_time": 0.3828001079364185, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 345, "reward_mean": 396.2, "student_loss": null, "teacher_policy_loss": -71.48001098632812, "teacher_value_loss": 429.34375, "teacher_entropy": 0.42751985788345337, "total_time": 1.2460715770721436, "rollout_time": 0.44033336639404297, "train_time": 0.795708179473877, "student_train_time": 0.009673833847045898, "throughput": 1605.0442340554298, "inference_time": 0.05875644250045298, "env_time": 0.38157692389359, "samples": 2000, "teacher_eval_reward": 409.0}
{"epoch": 346, "reward_mean": 372.0, "student_loss": null, "teacher_policy_loss": -62.277400970458984, "teacher_value_loss": 777.7850952148438, "teacher_entropy": 0.4285580813884735, "total_time": 1.2387475967407227, "rollout_time": 0.4458024501800537, "train_time": 0.7780396938323975, "student_train_time": 0.014321565628051758, "throughput": 1614.533909298564, "inference_time": 0.060576811756618554, "env_time": 0.38522563842343516, "samples": 2000, "teacher_eval_reward": 431.0}
{"epoch": 347, "reward_mean": 381.3333333333333, "student_loss": null, "teacher_policy_loss": -66.46741485595703, "teacher_value_loss": 439.7171936035156, "teacher_entropy": 0.43264853954315186, "total_time": 1.2554409503936768, "rollout_time": 0.45288968086242676, "train_time": 0.787564754486084, "student_train_time": 0.014638423919677734, "throughput": 1593.0657665522597, "inference_time": 0.06178117623676371, "env_time": 0.39110850462566304, "samples": 2000, "teacher_eval_reward": 329.0}
{"epoch": 348, "reward_mean": 359.8, "student_loss": null, "teacher_policy_loss": -62.09553527832031, "teacher_value_loss": 599.541259765625, "teacher_entropy": 0.4344850480556488, "total_time": 1.4741437435150146, "rollout_time": 0.4620082378387451, "train_time": 0.995732307434082, "student_train_time": 0.015988588333129883, "throughput": 1356.7197966943916, "inference_time": 0.061907271227028104, "env_time": 0.400100966611717, "samples": 2000, "teacher_eval_reward": 487.0}
{"epoch": 349, "reward_mean": 425.8, "student_loss": null, "teacher_policy_loss": -63.88276672363281, "teacher_value_loss": 829.6293334960938, "teacher_entropy": 0.43657800555229187, "total_time": 1.2977006435394287, "rollout_time": 0.45381927490234375, "train_time": 0.8263871669769287, "student_train_time": 0.01713848114013672, "throughput": 1541.1874918587362, "inference_time": 0.06397854300121253, "env_time": 0.3898407319011312, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 350, "reward_mean": 473.25, "student_loss": null, "teacher_policy_loss": -65.58894348144531, "teacher_value_loss": 590.7532958984375, "teacher_entropy": 0.44733402132987976, "total_time": 1.2338027954101562, "rollout_time": 0.43311452865600586, "train_time": 0.7909650802612305, "student_train_time": 0.009308576583862305, "throughput": 1621.004594445853, "inference_time": 0.058603276273061056, "env_time": 0.3745112523829448, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 351, "reward_mean": 431.4, "student_loss": null, "teacher_policy_loss": -62.6567497253418, "teacher_value_loss": 688.413330078125, "teacher_entropy": 0.4493545889854431, "total_time": 1.5343279838562012, "rollout_time": 0.46024417877197266, "train_time": 1.0453622341156006, "student_train_time": 0.02835822105407715, "throughput": 1303.502263559994, "inference_time": 0.06509345149243018, "env_time": 0.3951507272795425, "samples": 2000, "teacher_eval_reward": 335.0}
{"epoch": 352, "reward_mean": 454.0, "student_loss": null, "teacher_policy_loss": -62.09777069091797, "teacher_value_loss": 540.1937866210938, "teacher_entropy": 0.43670257925987244, "total_time": 1.7437779903411865, "rollout_time": 0.4338221549987793, "train_time": 1.297670602798462, "student_train_time": 0.011882305145263672, "throughput": 1146.9349946369498, "inference_time": 0.05881950878028874, "env_time": 0.37500264621849055, "samples": 2000, "teacher_eval_reward": 269.0}
{"epoch": 353, "reward_mean": 301.8333333333333, "student_loss": null, "teacher_policy_loss": -61.62448501586914, "teacher_value_loss": 675.263916015625, "teacher_entropy": 0.4450506865978241, "total_time": 1.2850205898284912, "rollout_time": 0.44092631340026855, "train_time": 0.8323321342468262, "student_train_time": 0.011365652084350586, "throughput": 1556.39529500997, "inference_time": 0.06060422676091548, "env_time": 0.3803220866393531, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 354, "reward_mean": 463.8, "student_loss": null, "teacher_policy_loss": -65.45922088623047, "teacher_value_loss": 572.19384765625, "teacher_entropy": 0.45315882563591003, "total_time": 1.3700480461120605, "rollout_time": 0.44425344467163086, "train_time": 0.9014968872070312, "student_train_time": 0.023943662643432617, "throughput": 1459.8028190877137, "inference_time": 0.06052820723016339, "env_time": 0.38372523744146747, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 355, "reward_mean": 327.7142857142857, "student_loss": null, "teacher_policy_loss": -56.364051818847656, "teacher_value_loss": 568.4169921875, "teacher_entropy": 0.4470043480396271, "total_time": 1.514014720916748, "rollout_time": 0.4559154510498047, "train_time": 1.0253500938415527, "student_train_time": 0.03232407569885254, "throughput": 1320.9911187580685, "inference_time": 0.06371832276090572, "env_time": 0.39219712828889897, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 356, "reward_mean": 339.0, "student_loss": null, "teacher_policy_loss": -61.82010269165039, "teacher_value_loss": 542.1383666992188, "teacher_entropy": 0.471987247467041, "total_time": 1.2644038200378418, "rollout_time": 0.4485044479370117, "train_time": 0.7965219020843506, "student_train_time": 0.018911361694335938, "throughput": 1581.7731394865154, "inference_time": 0.06060714695195202, "env_time": 0.3878973009850597, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 357, "reward_mean": 401.42857142857144, "student_loss": null, "teacher_policy_loss": -60.83811950683594, "teacher_value_loss": 546.1678466796875, "teacher_entropy": 0.4690680503845215, "total_time": 1.3344807624816895, "rollout_time": 0.4475743770599365, "train_time": 0.873847484588623, "student_train_time": 0.012702226638793945, "throughput": 1498.7102521288255, "inference_time": 0.0630829912952322, "env_time": 0.3844913857647043, "samples": 2000, "teacher_eval_reward": 419.0}
{"epoch": 358, "reward_mean": 415.25, "student_loss": null, "teacher_policy_loss": -62.830284118652344, "teacher_value_loss": 562.3438720703125, "teacher_entropy": 0.4615069031715393, "total_time": 1.33974027633667, "rollout_time": 0.42902565002441406, "train_time": 0.8973410129547119, "student_train_time": 0.013013839721679688, "throughput": 1492.8266585137806, "inference_time": 0.058006540280985064, "env_time": 0.371019109743429, "samples": 2000, "teacher_eval_reward": 262.0}
{"epoch": 359, "reward_mean": 274.0, "student_loss": null, "teacher_policy_loss": -55.71963119506836, "teacher_value_loss": 326.0062561035156, "teacher_entropy": 0.461492121219635, "total_time": 1.2139630317687988, "rollout_time": 0.4408235549926758, "train_time": 0.7445874214172363, "student_train_time": 0.028084278106689453, "throughput": 1647.4966268832009, "inference_time": 0.05913299947860651, "env_time": 0.3816905555140693, "samples": 2000, "teacher_eval_reward": 350.0}
{"epoch": 360, "reward_mean": 314.14285714285717, "student_loss": null, "teacher_policy_loss": -56.65234375, "teacher_value_loss": 300.0316467285156, "teacher_entropy": 0.4582291841506958, "total_time": 1.2702744007110596, "rollout_time": 0.4404633045196533, "train_time": 0.8188741207122803, "student_train_time": 0.010497808456420898, "throughput": 1574.4629655454467, "inference_time": 0.05967505149055796, "env_time": 0.38078825302909536, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 361, "reward_mean": 311.42857142857144, "student_loss": null, "teacher_policy_loss": -53.087825775146484, "teacher_value_loss": 393.14129638671875, "teacher_entropy": 0.4500468671321869, "total_time": 1.2369022369384766, "rollout_time": 0.4359250068664551, "train_time": 0.7837710380554199, "student_train_time": 0.016851186752319336, "throughput": 1616.9426655337836, "inference_time": 0.06205255169152224, "env_time": 0.37387245517493284, "samples": 2000, "teacher_eval_reward": 407.0}
{"epoch": 362, "reward_mean": 307.6666666666667, "student_loss": null, "teacher_policy_loss": -59.02257537841797, "teacher_value_loss": 466.3673400878906, "teacher_entropy": 0.46218597888946533, "total_time": 1.216033935546875, "rollout_time": 0.4282355308532715, "train_time": 0.7608673572540283, "student_train_time": 0.026577472686767578, "throughput": 1644.6909428564259, "inference_time": 0.05811500826894189, "env_time": 0.3701205225843296, "samples": 2000, "teacher_eval_reward": 272.0}
{"epoch": 363, "reward_mean": 370.0, "student_loss": null, "teacher_policy_loss": -60.726871490478516, "teacher_value_loss": 497.7939453125, "teacher_entropy": 0.45241284370422363, "total_time": 1.2684378623962402, "rollout_time": 0.44657254219055176, "train_time": 0.7868680953979492, "student_train_time": 0.03464245796203613, "throughput": 1576.7425896777836, "inference_time": 0.05963220653029566, "env_time": 0.3869403356602561, "samples": 2000, "teacher_eval_reward": 339.0}
{"epoch": 364, "reward_mean": 373.2, "student_loss": null, "teacher_policy_loss": -62.41627502441406, "teacher_value_loss": 510.81256103515625, "teacher_entropy": 0.4532315135002136, "total_time": 1.3101654052734375, "rollout_time": 0.4374713897705078, "train_time": 0.8453757762908936, "student_train_time": 0.026934146881103516, "throughput": 1526.5248127831546, "inference_time": 0.05978326073818607, "env_time": 0.37768812903232174, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 365, "reward_mean": 370.2, "student_loss": null, "teacher_policy_loss": -62.83197021484375, "teacher_value_loss": 671.157958984375, "teacher_entropy": 0.44631505012512207, "total_time": 1.2538769245147705, "rollout_time": 0.454587459564209, "train_time": 0.785010814666748, "student_train_time": 0.01387476921081543, "throughput": 1595.0528803087805, "inference_time": 0.06063181951685692, "env_time": 0.39395564004735206, "samples": 2000, "teacher_eval_reward": 293.0}
{"epoch": 366, "reward_mean": 466.25, "student_loss": null, "teacher_policy_loss": -63.26780700683594, "teacher_value_loss": 684.780517578125, "teacher_entropy": 0.44084808230400085, "total_time": 1.287529468536377, "rollout_time": 0.4443213939666748, "train_time": 0.8284225463867188, "student_train_time": 0.014438390731811523, "throughput": 1553.362504606234, "inference_time": 0.059496819994819816, "env_time": 0.384824573971855, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 367, "reward_mean": 430.6, "student_loss": null, "teacher_policy_loss": -60.00038528442383, "teacher_value_loss": 559.8800048828125, "teacher_entropy": 0.44707080721855164, "total_time": 1.2498557567596436, "rollout_time": 0.4431767463684082, "train_time": 0.7925961017608643, "student_train_time": 0.013685226440429688, "throughput": 1600.1846526555742, "inference_time": 0.06054563850193517, "env_time": 0.38263110786647303, "samples": 2000, "teacher_eval_reward": 263.0}
{"epoch": 368, "reward_mean": 468.0, "student_loss": null, "teacher_policy_loss": -59.13928985595703, "teacher_value_loss": 631.561279296875, "teacher_entropy": 0.4303707182407379, "total_time": -1.242215871810913, "rollout_time": -2.145582437515259, "train_time": 0.8895449638366699, "student_train_time": 0.013347625732421875, "throughput": 200000000000.0, "inference_time": 0.060262056222200044, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 282.0}
{"epoch": 369, "reward_mean": 421.5, "student_loss": null, "teacher_policy_loss": -63.22665786743164, "teacher_value_loss": 731.8377075195312, "teacher_entropy": 0.4445532560348511, "total_time": 1.2146029472351074, "rollout_time": 0.43060731887817383, "train_time": 0.7760238647460938, "student_train_time": 0.007611989974975586, "throughput": 1646.6286407033272, "inference_time": 0.058006939239930944, "env_time": 0.3726003796382429, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 370, "reward_mean": 484.0, "student_loss": null, "teacher_policy_loss": -62.30950164794922, "teacher_value_loss": 718.9468994140625, "teacher_entropy": 0.4437665343284607, "total_time": 1.3021628856658936, "rollout_time": 0.4305574893951416, "train_time": 0.8586108684539795, "student_train_time": 0.012565374374389648, "throughput": 1535.9061619831455, "inference_time": 0.059738383502917713, "env_time": 0.3708191058922239, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 371, "reward_mean": 435.0, "student_loss": null, "teacher_policy_loss": -61.876556396484375, "teacher_value_loss": 699.1240844726562, "teacher_entropy": 0.4501633942127228, "total_time": 1.5405941009521484, "rollout_time": 0.5640864372253418, "train_time": 0.8490703105926514, "student_train_time": 0.12706708908081055, "throughput": 1298.200479129396, "inference_time": 0.07300599272821273, "env_time": 0.49108044449712906, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 372, "reward_mean": 449.75, "student_loss": null, "teacher_policy_loss": -65.47611999511719, "teacher_value_loss": 755.4686279296875, "teacher_entropy": 0.45607665181159973, "total_time": 1.3173542022705078, "rollout_time": 0.42429041862487793, "train_time": 0.866126298904419, "student_train_time": 0.02654886245727539, "throughput": 1518.1945725401167, "inference_time": 0.058759392941283295, "env_time": 0.36553102568359463, "samples": 2000, "teacher_eval_reward": 373.0}
{"epoch": 373, "reward_mean": 423.0, "student_loss": null, "teacher_policy_loss": -63.13067626953125, "teacher_value_loss": 861.8716430664062, "teacher_entropy": 0.44664353132247925, "total_time": 1.7025036811828613, "rollout_time": 0.43851685523986816, "train_time": 1.2544713020324707, "student_train_time": 0.009143352508544922, "throughput": 1174.740484913633, "inference_time": 0.059479861020008684, "env_time": 0.3790369942198595, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 374, "reward_mean": 351.4, "student_loss": null, "teacher_policy_loss": -64.04044342041016, "teacher_value_loss": 696.864990234375, "teacher_entropy": 0.4477843642234802, "total_time": 1.2578904628753662, "rollout_time": 0.44433116912841797, "train_time": 0.7953674793243408, "student_train_time": 0.01778125762939453, "throughput": 1589.9635612374964, "inference_time": 0.059279150284055504, "env_time": 0.38505201884436246, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 375, "reward_mean": 402.6, "student_loss": null, "teacher_policy_loss": -64.2394027709961, "teacher_value_loss": 670.4171752929688, "teacher_entropy": 0.4479292035102844, "total_time": 1.2719731330871582, "rollout_time": 0.44070982933044434, "train_time": 0.813997745513916, "student_train_time": 0.016909122467041016, "throughput": 1572.3602550832777, "inference_time": 0.06060210501527763, "env_time": 0.3801077243151667, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 376, "reward_mean": 394.4, "student_loss": null, "teacher_policy_loss": -60.665218353271484, "teacher_value_loss": 900.0965576171875, "teacher_entropy": 0.4505307078361511, "total_time": 1.3178577423095703, "rollout_time": 0.44913387298583984, "train_time": 0.8547072410583496, "student_train_time": 0.013663530349731445, "throughput": 1517.6144858359012, "inference_time": 0.060944600527363946, "env_time": 0.3881892724584759, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 377, "reward_mean": 402.0, "student_loss": null, "teacher_policy_loss": -61.70102310180664, "teacher_value_loss": 739.3986206054688, "teacher_entropy": 0.4538719058036804, "total_time": 1.3232686519622803, "rollout_time": 0.43363022804260254, "train_time": 0.8768210411071777, "student_train_time": 0.012443065643310547, "throughput": 1511.408886649126, "inference_time": 0.057068067078944296, "env_time": 0.37656216096365824, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 378, "reward_mean": 439.25, "student_loss": null, "teacher_policy_loss": -66.89802551269531, "teacher_value_loss": 618.629150390625, "teacher_entropy": 0.46173155307769775, "total_time": 1.2834861278533936, "rollout_time": 0.46773576736450195, "train_time": 0.800344705581665, "student_train_time": 0.015051603317260742, "throughput": 1558.2560314422428, "inference_time": 0.0630640564722853, "env_time": 0.40467171089221665, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 379, "reward_mean": 413.25, "student_loss": null, "teacher_policy_loss": -65.46458435058594, "teacher_value_loss": 609.6228637695312, "teacher_entropy": 0.46680518984794617, "total_time": 1.1808414459228516, "rollout_time": 0.4343862533569336, "train_time": 0.7365050315856934, "student_train_time": 0.009500503540039062, "throughput": 1693.7074887619306, "inference_time": 0.05987121605539869, "env_time": 0.3745150373015349, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 380, "reward_mean": 424.6666666666667, "student_loss": null, "teacher_policy_loss": -64.6739501953125, "teacher_value_loss": 666.4711303710938, "teacher_entropy": 0.45580995082855225, "total_time": 1.2611725330352783, "rollout_time": 0.4393503665924072, "train_time": 0.805504560470581, "student_train_time": 0.01596665382385254, "throughput": 1585.825846671888, "inference_time": 0.061065703213898814, "env_time": 0.3782846633785084, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 381, "reward_mean": 440.6, "student_loss": null, "teacher_policy_loss": -65.1921615600586, "teacher_value_loss": 620.32666015625, "teacher_entropy": 0.46088817715644836, "total_time": 1.2648811340332031, "rollout_time": 0.42968010902404785, "train_time": 0.818263053894043, "student_train_time": 0.016483306884765625, "throughput": 1581.1762435121434, "inference_time": 0.05660582092605182, "env_time": 0.37307428809799603, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 382, "reward_mean": 451.6, "student_loss": null, "teacher_policy_loss": -65.11579895019531, "teacher_value_loss": 748.4488525390625, "teacher_entropy": 0.475175142288208, "total_time": 1.344454050064087, "rollout_time": 0.4386591911315918, "train_time": 0.8844497203826904, "student_train_time": 0.020976781845092773, "throughput": 1487.5926774177703, "inference_time": 0.05828843319613952, "env_time": 0.3803707579354523, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 383, "reward_mean": 432.75, "student_loss": null, "teacher_policy_loss": -65.43599700927734, "teacher_value_loss": 555.13037109375, "teacher_entropy": 0.47196632623672485, "total_time": 1.3994436264038086, "rollout_time": 0.4420907497406006, "train_time": 0.9468603134155273, "student_train_time": 0.01012730598449707, "throughput": 1429.1393824411912, "inference_time": 0.05739333874225849, "env_time": 0.3846974109983421, "samples": 2000, "teacher_eval_reward": 339.0}
{"epoch": 384, "reward_mean": 389.8, "student_loss": null, "teacher_policy_loss": -62.88682174682617, "teacher_value_loss": 454.8930358886719, "teacher_entropy": 0.4790867269039154, "total_time": 1.3229236602783203, "rollout_time": 0.43995165824890137, "train_time": 0.8723320960998535, "student_train_time": 0.010240554809570312, "throughput": 1511.8030314608134, "inference_time": 0.058923894954205025, "env_time": 0.38102776329469634, "samples": 2000, "teacher_eval_reward": 272.0}
{"epoch": 385, "reward_mean": 416.6, "student_loss": null, "teacher_policy_loss": -61.50067138671875, "teacher_value_loss": 553.3749389648438, "teacher_entropy": 0.473288893699646, "total_time": 1.248378038406372, "rollout_time": 0.4437429904937744, "train_time": 0.7933821678161621, "student_train_time": 0.01089334487915039, "throughput": 1602.0788082375411, "inference_time": 0.06045482525041734, "env_time": 0.38328816524335707, "samples": 2000, "teacher_eval_reward": 329.0}
{"epoch": 386, "reward_mean": 354.4, "student_loss": null, "teacher_policy_loss": -61.12520217895508, "teacher_value_loss": 577.8936767578125, "teacher_entropy": 0.4821980595588684, "total_time": -1.4335439205169678, "rollout_time": -2.232893943786621, "train_time": 0.7905290126800537, "student_train_time": 0.00827932357788086, "throughput": 200000000000.0, "inference_time": 0.06014873326239467, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 351.0}
{"epoch": 387, "reward_mean": 338.0, "student_loss": null, "teacher_policy_loss": -60.386837005615234, "teacher_value_loss": 499.4270935058594, "teacher_entropy": 0.46732616424560547, "total_time": 1.457289457321167, "rollout_time": 0.4423027038574219, "train_time": 0.9951725006103516, "student_train_time": 0.019402027130126953, "throughput": 1372.4109441349144, "inference_time": 0.06106072097827564, "env_time": 0.38124198287914624, "samples": 2000, "teacher_eval_reward": 425.0}
{"epoch": 388, "reward_mean": 363.8333333333333, "student_loss": null, "teacher_policy_loss": -57.39285659790039, "teacher_value_loss": 543.4296875, "teacher_entropy": 0.48102328181266785, "total_time": 1.2900962829589844, "rollout_time": 0.4536895751953125, "train_time": 0.817887544631958, "student_train_time": 0.018156051635742188, "throughput": 1550.271887779391, "inference_time": 0.06161926807908458, "env_time": 0.3920703071162279, "samples": 2000, "teacher_eval_reward": 423.0}
{"epoch": 389, "reward_mean": 330.1666666666667, "student_loss": null, "teacher_policy_loss": -58.329524993896484, "teacher_value_loss": 510.9129333496094, "teacher_entropy": 0.47671687602996826, "total_time": 1.1970570087432861, "rollout_time": 0.42821812629699707, "train_time": 0.7564589977264404, "student_train_time": 0.012034177780151367, "throughput": 1670.7642037029402, "inference_time": 0.05844051726307953, "env_time": 0.36977760903391754, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 390, "reward_mean": 379.4, "student_loss": null, "teacher_policy_loss": -60.09416580200195, "teacher_value_loss": 340.0394592285156, "teacher_entropy": 0.49294400215148926, "total_time": 1.2419662475585938, "rollout_time": 0.42467379570007324, "train_time": 0.805412769317627, "student_train_time": 0.011536359786987305, "throughput": 1610.3497208008012, "inference_time": 0.05755622498872981, "env_time": 0.36711757071134343, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 391, "reward_mean": 333.2857142857143, "student_loss": null, "teacher_policy_loss": -58.6860237121582, "teacher_value_loss": 544.1647338867188, "teacher_entropy": 0.48541152477264404, "total_time": 1.3677387237548828, "rollout_time": 0.4490206241607666, "train_time": 0.9082684516906738, "student_train_time": 0.010067462921142578, "throughput": 1462.2675846373322, "inference_time": 0.06111925750519731, "env_time": 0.3879013666555693, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 392, "reward_mean": 342.8333333333333, "student_loss": null, "teacher_policy_loss": -62.019866943359375, "teacher_value_loss": 540.0173950195312, "teacher_entropy": 0.483426034450531, "total_time": 1.3045849800109863, "rollout_time": 0.4447815418243408, "train_time": 0.834094762802124, "student_train_time": 0.02534937858581543, "throughput": 1533.0545963998125, "inference_time": 0.06066220474531292, "env_time": 0.3841193370790279, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 393, "reward_mean": 265.5, "student_loss": null, "teacher_policy_loss": -56.43545913696289, "teacher_value_loss": 593.8800659179688, "teacher_entropy": 0.47689542174339294, "total_time": 1.2041406631469727, "rollout_time": 0.4350409507751465, "train_time": 0.7524378299713135, "student_train_time": 0.016231536865234375, "throughput": 1660.9355212480586, "inference_time": 0.06136232425524213, "env_time": 0.37367862651990436, "samples": 2000, "teacher_eval_reward": 490.0}
{"epoch": 394, "reward_mean": 307.0, "student_loss": null, "teacher_policy_loss": -58.36154556274414, "teacher_value_loss": 471.505615234375, "teacher_entropy": 0.46957191824913025, "total_time": 1.2339773178100586, "rollout_time": 0.4285569190979004, "train_time": 0.7772014141082764, "student_train_time": 0.02775716781616211, "throughput": 1620.7753344683863, "inference_time": 0.059986436028339085, "env_time": 0.3685704830695613, "samples": 2000, "teacher_eval_reward": 354.0}
{"epoch": 395, "reward_mean": 344.6666666666667, "student_loss": null, "teacher_policy_loss": -58.08999252319336, "teacher_value_loss": 603.75927734375, "teacher_entropy": 0.464841365814209, "total_time": -1.3151695728302002, "rollout_time": 0.4434189796447754, "train_time": -1.7731058597564697, "student_train_time": 0.014168262481689453, "throughput": 200000000000.0, "inference_time": 0.06064744552713819, "env_time": 0.3827715341176372, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 396, "reward_mean": 352.0, "student_loss": null, "teacher_policy_loss": -60.54045104980469, "teacher_value_loss": 610.048095703125, "teacher_entropy": 0.46847254037857056, "total_time": 1.2322704792022705, "rollout_time": 0.4281277656555176, "train_time": 0.7909679412841797, "student_train_time": 0.012702465057373047, "throughput": 1623.0202976985468, "inference_time": 0.058057071513758274, "env_time": 0.3700706941417593, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 397, "reward_mean": 375.0, "student_loss": null, "teacher_policy_loss": -58.31295394897461, "teacher_value_loss": 573.7842407226562, "teacher_entropy": 0.4743080735206604, "total_time": 1.223606824874878, "rollout_time": 0.4208388328552246, "train_time": 0.7855401039123535, "student_train_time": 0.016843318939208984, "throughput": 1634.5119685030472, "inference_time": 0.05804386772615544, "env_time": 0.36279496512906917, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 398, "reward_mean": 386.2, "student_loss": null, "teacher_policy_loss": -64.40062713623047, "teacher_value_loss": 573.4689331054688, "teacher_entropy": 0.46519604325294495, "total_time": 1.2430987358093262, "rollout_time": 0.434650182723999, "train_time": 0.7981204986572266, "student_train_time": 0.009969949722290039, "throughput": 1608.8826594276031, "inference_time": 0.05937975882261526, "env_time": 0.37527042390138377, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 399, "reward_mean": 330.4, "student_loss": null, "teacher_policy_loss": -59.24311065673828, "teacher_value_loss": 503.48681640625, "teacher_entropy": 0.46069204807281494, "total_time": 1.4154558181762695, "rollout_time": 0.45186924934387207, "train_time": 0.9362852573394775, "student_train_time": 0.026926755905151367, "throughput": 1412.972396819055, "inference_time": 0.0596729182798299, "env_time": 0.39219633106404217, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 400, "reward_mean": 465.75, "student_loss": null, "teacher_policy_loss": -62.34162139892578, "teacher_value_loss": 587.592041015625, "teacher_entropy": 0.46644842624664307, "total_time": 1.3188245296478271, "rollout_time": 0.4373025894165039, "train_time": 0.8627057075500488, "student_train_time": 0.01844644546508789, "throughput": 1516.501972050877, "inference_time": 0.05945086523570353, "env_time": 0.3778517241808004, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 401, "reward_mean": 437.2, "student_loss": null, "teacher_policy_loss": -60.85854721069336, "teacher_value_loss": 634.8053588867188, "teacher_entropy": 0.47088369727134705, "total_time": 1.213010311126709, "rollout_time": 0.4337575435638428, "train_time": 0.7692797183990479, "student_train_time": 0.008510589599609375, "throughput": 1648.7906010809527, "inference_time": 0.058675020236478304, "env_time": 0.37508252332736447, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 402, "reward_mean": 417.57142857142856, "student_loss": null, "teacher_policy_loss": -58.32658767700195, "teacher_value_loss": 739.8026123046875, "teacher_entropy": 0.4744408428668976, "total_time": 1.3336410522460938, "rollout_time": 0.5486576557159424, "train_time": 0.7678396701812744, "student_train_time": 0.01673722267150879, "throughput": 1499.6538961001813, "inference_time": 0.06992060104676057, "env_time": 0.4787370546691818, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 403, "reward_mean": 441.25, "student_loss": null, "teacher_policy_loss": -65.0968246459961, "teacher_value_loss": 689.849853515625, "teacher_entropy": 0.4710320234298706, "total_time": 1.3832919597625732, "rollout_time": 0.4603698253631592, "train_time": 0.8914620876312256, "student_train_time": 0.031102418899536133, "throughput": 1445.8263751806076, "inference_time": 0.06126413827769284, "env_time": 0.39910568708546634, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 404, "reward_mean": 348.2, "student_loss": null, "teacher_policy_loss": -61.21098327636719, "teacher_value_loss": 562.5918579101562, "teacher_entropy": 0.4670588970184326, "total_time": 1.259843111038208, "rollout_time": 0.43000245094299316, "train_time": 0.8171391487121582, "student_train_time": 0.012343883514404297, "throughput": 1587.4992548491578, "inference_time": 0.05737001108354889, "env_time": 0.3726324398594443, "samples": 2000, "teacher_eval_reward": 285.0}
{"epoch": 405, "reward_mean": 394.25, "student_loss": null, "teacher_policy_loss": -56.85443115234375, "teacher_value_loss": 479.4832458496094, "teacher_entropy": 0.4443720281124115, "total_time": 1.2773113250732422, "rollout_time": 0.4286620616912842, "train_time": 0.8217573165893555, "student_train_time": 0.026489973068237305, "throughput": 1565.788982482652, "inference_time": 0.05752686625783099, "env_time": 0.3711351954334532, "samples": 2000, "teacher_eval_reward": 289.0}
{"epoch": 406, "reward_mean": 357.0, "student_loss": null, "teacher_policy_loss": -53.014041900634766, "teacher_value_loss": 706.5746459960938, "teacher_entropy": 0.4363882541656494, "total_time": 1.2963690757751465, "rollout_time": 0.43441152572631836, "train_time": 0.8511607646942139, "student_train_time": 0.010439157485961914, "throughput": 1542.7705252874277, "inference_time": 0.059026042252298794, "env_time": 0.37538548347401957, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 407, "reward_mean": 430.75, "student_loss": null, "teacher_policy_loss": -64.46311950683594, "teacher_value_loss": 503.6875, "teacher_entropy": 0.47139719128608704, "total_time": 1.278397560119629, "rollout_time": 0.42911744117736816, "train_time": 0.8282256126403809, "student_train_time": 0.02063441276550293, "throughput": 1564.458555297028, "inference_time": 0.056875186770412256, "env_time": 0.3722422544069559, "samples": 2000, "teacher_eval_reward": 194.0}
{"epoch": 408, "reward_mean": 405.25, "student_loss": null, "teacher_policy_loss": -62.180965423583984, "teacher_value_loss": 705.0213623046875, "teacher_entropy": 0.43176132440567017, "total_time": 1.2559154033660889, "rollout_time": 0.4417281150817871, "train_time": 0.8036580085754395, "student_train_time": 0.010109424591064453, "throughput": 1592.4639467273232, "inference_time": 0.061902195537186344, "env_time": 0.37982591954460077, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 409, "reward_mean": 455.6, "student_loss": null, "teacher_policy_loss": -55.789100646972656, "teacher_value_loss": 560.81103515625, "teacher_entropy": 0.38964125514030457, "total_time": 1.3114049434661865, "rollout_time": 0.43747448921203613, "train_time": 0.8642544746398926, "student_train_time": 0.00931692123413086, "throughput": 1525.0819435786032, "inference_time": 0.059902793964283774, "env_time": 0.37757169524775236, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 410, "reward_mean": 454.4, "student_loss": null, "teacher_policy_loss": -55.642906188964844, "teacher_value_loss": 556.3677368164062, "teacher_entropy": 0.4118707776069641, "total_time": 1.3064310550689697, "rollout_time": 0.4473912715911865, "train_time": 0.847409725189209, "student_train_time": 0.01126241683959961, "throughput": 1530.8882870167342, "inference_time": 0.06058073051462998, "env_time": 0.38681054107655655, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 411, "reward_mean": 480.0, "student_loss": null, "teacher_policy_loss": -64.76764678955078, "teacher_value_loss": 834.2220458984375, "teacher_entropy": 0.4704601466655731, "total_time": 1.4483346939086914, "rollout_time": 0.4449167251586914, "train_time": 0.9926972389221191, "student_train_time": 0.010368108749389648, "throughput": 1380.8962862047463, "inference_time": 0.058403163215189124, "env_time": 0.3865135619435023, "samples": 2000, "teacher_eval_reward": 224.0}
{"epoch": 412, "reward_mean": 482.8, "student_loss": null, "teacher_policy_loss": -56.32126235961914, "teacher_value_loss": 830.0306396484375, "teacher_entropy": 0.4128956198692322, "total_time": 1.2366511821746826, "rollout_time": 0.4493408203125, "train_time": 0.7722344398498535, "student_train_time": 0.014665365219116211, "throughput": 1617.2709239503972, "inference_time": 0.057300912510982016, "env_time": 0.392039907801518, "samples": 2000, "teacher_eval_reward": 221.0}
{"epoch": 413, "reward_mean": 450.25, "student_loss": null, "teacher_policy_loss": -53.65166473388672, "teacher_value_loss": 882.5011596679688, "teacher_entropy": 0.3931783437728882, "total_time": 1.2758839130401611, "rollout_time": 0.44611167907714844, "train_time": 0.8115451335906982, "student_train_time": 0.0178680419921875, "throughput": 1567.5407296533926, "inference_time": 0.06225612951129733, "env_time": 0.3838555495658511, "samples": 2000, "teacher_eval_reward": 495.0}
{"epoch": 414, "reward_mean": 451.25, "student_loss": null, "teacher_policy_loss": -61.91867446899414, "teacher_value_loss": 633.2109985351562, "teacher_entropy": 0.44049981236457825, "total_time": 1.2203376293182373, "rollout_time": 0.4323248863220215, "train_time": 0.776892900466919, "student_train_time": 0.010781049728393555, "throughput": 1638.8907069245538, "inference_time": 0.05781249003484845, "env_time": 0.37451239628717303, "samples": 2000, "teacher_eval_reward": 167.0}
{"epoch": 415, "reward_mean": 441.75, "student_loss": null, "teacher_policy_loss": -60.21782302856445, "teacher_value_loss": 590.0787353515625, "teacher_entropy": 0.43000027537345886, "total_time": -1.2544989585876465, "rollout_time": 0.43707871437072754, "train_time": -1.7191658020019531, "student_train_time": 0.02723383903503418, "throughput": 200000000000.0, "inference_time": 0.06018904025950178, "env_time": 0.37688967411122576, "samples": 2000, "teacher_eval_reward": 116.0}
{"epoch": 416, "reward_mean": 459.8, "student_loss": null, "teacher_policy_loss": -54.63105392456055, "teacher_value_loss": 717.0391845703125, "teacher_entropy": 0.4057154059410095, "total_time": 1.268683671951294, "rollout_time": 0.42794084548950195, "train_time": 0.8249659538269043, "student_train_time": 0.015091657638549805, "throughput": 1576.437093199054, "inference_time": 0.057104242498098756, "env_time": 0.3708366029914032, "samples": 2000, "teacher_eval_reward": 266.0}
{"epoch": 417, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -62.36949920654297, "teacher_value_loss": 648.3887329101562, "teacher_entropy": 0.44165536761283875, "total_time": 1.2233052253723145, "rollout_time": 0.42778849601745605, "train_time": 0.7823894023895264, "student_train_time": 0.012770891189575195, "throughput": 1634.914948876555, "inference_time": 0.06051964796461107, "env_time": 0.367268848052845, "samples": 2000, "teacher_eval_reward": 378.0}
{"epoch": 418, "reward_mean": 493.25, "student_loss": null, "teacher_policy_loss": -60.685298919677734, "teacher_value_loss": 632.7161865234375, "teacher_entropy": 0.4398343563079834, "total_time": 1.2312648296356201, "rollout_time": 0.43560242652893066, "train_time": 0.7789366245269775, "student_train_time": 0.016071081161499023, "throughput": 1624.3459180035857, "inference_time": 0.0564359452600911, "env_time": 0.37916648126883956, "samples": 2000, "teacher_eval_reward": 278.0}
{"epoch": 419, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -58.021141052246094, "teacher_value_loss": 760.3912353515625, "teacher_entropy": 0.42796048521995544, "total_time": 1.272709846496582, "rollout_time": 0.43557143211364746, "train_time": 0.8241086006164551, "student_train_time": 0.012619972229003906, "throughput": 1571.450087783517, "inference_time": 0.0590548150066752, "env_time": 0.37651661710697226, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 420, "reward_mean": 438.5, "student_loss": null, "teacher_policy_loss": -60.46726608276367, "teacher_value_loss": 431.811767578125, "teacher_entropy": 0.44774553179740906, "total_time": 1.2511401176452637, "rollout_time": 0.46155762672424316, "train_time": 0.7727124691009521, "student_train_time": 0.016510963439941406, "throughput": 1598.541979266195, "inference_time": 0.06075469396637345, "env_time": 0.4008029327578697, "samples": 2000, "teacher_eval_reward": 131.0}
{"epoch": 421, "reward_mean": 437.0, "student_loss": null, "teacher_policy_loss": -55.5844612121582, "teacher_value_loss": 470.7001647949219, "teacher_entropy": 0.4078170955181122, "total_time": 1.5117814540863037, "rollout_time": 0.4369025230407715, "train_time": 1.059295892715454, "student_train_time": 0.015221834182739258, "throughput": 1322.9425421207907, "inference_time": 0.059086172752358834, "env_time": 0.37781635028841265, "samples": 2000, "teacher_eval_reward": 96.0}
{"epoch": 422, "reward_mean": 469.8, "student_loss": null, "teacher_policy_loss": -51.41475296020508, "teacher_value_loss": 526.2828979492188, "teacher_entropy": 0.37402430176734924, "total_time": 1.2157320976257324, "rollout_time": 0.4338808059692383, "train_time": 0.7695972919464111, "student_train_time": 0.011821746826171875, "throughput": 1645.099281252758, "inference_time": 0.05976230849955755, "env_time": 0.37411849746968073, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 423, "reward_mean": 437.0, "student_loss": null, "teacher_policy_loss": -60.13520050048828, "teacher_value_loss": 433.01580810546875, "teacher_entropy": 0.4217216670513153, "total_time": 1.2999577522277832, "rollout_time": 0.4486098289489746, "train_time": 0.8384454250335693, "student_train_time": 0.012546300888061523, "throughput": 1538.51153744999, "inference_time": 0.06413946501925238, "env_time": 0.3844703639297222, "samples": 2000, "teacher_eval_reward": 410.0}
{"epoch": 424, "reward_mean": 347.8, "student_loss": null, "teacher_policy_loss": -58.345821380615234, "teacher_value_loss": 366.20159912109375, "teacher_entropy": 0.4237285256385803, "total_time": 1.3102710247039795, "rollout_time": 0.43627190589904785, "train_time": 0.8596811294555664, "student_train_time": 0.01392364501953125, "throughput": 1526.4017613850892, "inference_time": 0.05909049225192575, "env_time": 0.3771814136471221, "samples": 2000, "teacher_eval_reward": 222.0}
{"epoch": 425, "reward_mean": 454.25, "student_loss": null, "teacher_policy_loss": -56.82059097290039, "teacher_value_loss": 372.7187805175781, "teacher_entropy": 0.38885927200317383, "total_time": 1.327641487121582, "rollout_time": 0.44103336334228516, "train_time": 0.8701045513153076, "student_train_time": 0.016064882278442383, "throughput": 1506.4307792430752, "inference_time": 0.05945934604278591, "env_time": 0.38157401729949925, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 426, "reward_mean": 435.1666666666667, "student_loss": null, "teacher_policy_loss": -59.523284912109375, "teacher_value_loss": 567.446044921875, "teacher_entropy": 0.4132273495197296, "total_time": 1.2956433296203613, "rollout_time": 0.43444061279296875, "train_time": 0.8442947864532471, "student_train_time": 0.016541004180908203, "throughput": 1543.6346981279357, "inference_time": 0.05746144843396905, "env_time": 0.3769791643589997, "samples": 2000, "teacher_eval_reward": 308.0}
{"epoch": 427, "reward_mean": 419.6, "student_loss": null, "teacher_policy_loss": -62.19748306274414, "teacher_value_loss": 512.6487426757812, "teacher_entropy": 0.4373040795326233, "total_time": 1.2233729362487793, "rollout_time": 0.4340817928314209, "train_time": 0.77008056640625, "student_train_time": 0.01885199546813965, "throughput": 1634.8244600968428, "inference_time": 0.05771917972742813, "env_time": 0.37636261310399277, "samples": 2000, "teacher_eval_reward": 130.0}
{"epoch": 428, "reward_mean": 431.75, "student_loss": null, "teacher_policy_loss": -57.79054260253906, "teacher_value_loss": 373.71331787109375, "teacher_entropy": 0.40556827187538147, "total_time": 1.1981792449951172, "rollout_time": 0.41785311698913574, "train_time": 0.770815372467041, "student_train_time": 0.009155035018920898, "throughput": 1669.1993358707782, "inference_time": 0.057218859814383904, "env_time": 0.36063425717475184, "samples": 2000, "teacher_eval_reward": 184.0}
{"epoch": 429, "reward_mean": 435.0, "student_loss": null, "teacher_policy_loss": -64.45756530761719, "teacher_value_loss": 511.6894226074219, "teacher_entropy": 0.4399704337120056, "total_time": 1.347656011581421, "rollout_time": 0.4751734733581543, "train_time": 0.8497891426086426, "student_train_time": 0.022311687469482422, "throughput": 1484.0582335644237, "inference_time": 0.06139361665918841, "env_time": 0.4137798566989659, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 430, "reward_mean": 384.8, "student_loss": null, "teacher_policy_loss": -59.553428649902344, "teacher_value_loss": 463.3289794921875, "teacher_entropy": 0.4193027913570404, "total_time": 1.2739887237548828, "rollout_time": 0.4366028308868408, "train_time": 0.8199145793914795, "student_train_time": 0.017038583755493164, "throughput": 1569.87260774594, "inference_time": 0.06019938874123909, "env_time": 0.37640344214560173, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 431, "reward_mean": 432.4, "student_loss": null, "teacher_policy_loss": -58.63542556762695, "teacher_value_loss": 440.0067138671875, "teacher_entropy": 0.41189324855804443, "total_time": 1.2154967784881592, "rollout_time": 0.44359803199768066, "train_time": 0.7618215084075928, "student_train_time": 0.009715795516967773, "throughput": 1645.4177710677357, "inference_time": 0.0603508409949427, "env_time": 0.38324719100273796, "samples": 2000, "teacher_eval_reward": 343.0}
{"epoch": 432, "reward_mean": 432.0, "student_loss": null, "teacher_policy_loss": -61.549259185791016, "teacher_value_loss": 401.1874084472656, "teacher_entropy": 0.4306807219982147, "total_time": 1.429487705230713, "rollout_time": 0.5955286026000977, "train_time": 0.8223557472229004, "student_train_time": 0.011164665222167969, "throughput": 1399.1026244448944, "inference_time": 0.07746347708052781, "env_time": 0.5180651255195698, "samples": 2000, "teacher_eval_reward": 214.0}
{"epoch": 433, "reward_mean": 402.5, "student_loss": null, "teacher_policy_loss": -62.051815032958984, "teacher_value_loss": 383.4706726074219, "teacher_entropy": 0.4307650625705719, "total_time": 1.344639778137207, "rollout_time": 0.4303550720214844, "train_time": 0.8981137275695801, "student_train_time": 0.0157926082611084, "throughput": 1487.3872040069307, "inference_time": 0.0600111232506606, "env_time": 0.37034394877082377, "samples": 2000, "teacher_eval_reward": 363.0}
{"epoch": 434, "reward_mean": 365.6666666666667, "student_loss": null, "teacher_policy_loss": -60.90522766113281, "teacher_value_loss": 400.65533447265625, "teacher_entropy": 0.4288845658302307, "total_time": 1.3422234058380127, "rollout_time": 0.42578911781311035, "train_time": 0.9046099185943604, "student_train_time": 0.011429786682128906, "throughput": 1490.064911177217, "inference_time": 0.05549797332059825, "env_time": 0.3702911444925121, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 435, "reward_mean": 345.0, "student_loss": null, "teacher_policy_loss": -57.48817825317383, "teacher_value_loss": 359.8297424316406, "teacher_entropy": 0.4202946722507477, "total_time": 1.365675687789917, "rollout_time": 0.4485502243041992, "train_time": 0.8979184627532959, "student_train_time": 0.018792390823364258, "throughput": 1464.4765355943437, "inference_time": 0.06098801726875536, "env_time": 0.38756220703544386, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 436, "reward_mean": 346.3333333333333, "student_loss": null, "teacher_policy_loss": -58.66969680786133, "teacher_value_loss": 432.040283203125, "teacher_entropy": 0.4341728985309601, "total_time": 1.2455544471740723, "rollout_time": 0.45676636695861816, "train_time": 0.7682528495788574, "student_train_time": 0.020180940628051758, "throughput": 1605.7106170971667, "inference_time": 0.060625496254942846, "env_time": 0.3961408707036753, "samples": 2000, "teacher_eval_reward": 430.0}
{"epoch": 437, "reward_mean": 391.4, "student_loss": null, "teacher_policy_loss": -60.09988784790039, "teacher_value_loss": 325.6750793457031, "teacher_entropy": 0.43171489238739014, "total_time": 1.2084882259368896, "rollout_time": 0.4378337860107422, "train_time": 0.7604212760925293, "student_train_time": 0.009876489639282227, "throughput": 1654.9602694304158, "inference_time": 0.056980609504535096, "env_time": 0.3808531765062071, "samples": 2000, "teacher_eval_reward": 289.0}
{"epoch": 438, "reward_mean": 325.1666666666667, "student_loss": null, "teacher_policy_loss": -58.44919967651367, "teacher_value_loss": 301.1808776855469, "teacher_entropy": 0.4421965479850769, "total_time": -1.3040826320648193, "rollout_time": -2.1956560611724854, "train_time": 0.8457968235015869, "student_train_time": 0.0454256534576416, "throughput": 200000000000.0, "inference_time": 0.06059257071319735, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 406.0}
{"epoch": 439, "reward_mean": 315.4, "student_loss": null, "teacher_policy_loss": -65.05455017089844, "teacher_value_loss": 356.21563720703125, "teacher_entropy": 0.4346611797809601, "total_time": 1.3187427520751953, "rollout_time": 0.446148157119751, "train_time": 0.8602867126464844, "student_train_time": 0.011860132217407227, "throughput": 1516.5960130228334, "inference_time": 0.061027258743706625, "env_time": 0.38512089837604435, "samples": 2000, "teacher_eval_reward": 460.0}
{"epoch": 440, "reward_mean": 396.3333333333333, "student_loss": null, "teacher_policy_loss": -53.220123291015625, "teacher_value_loss": 401.23919677734375, "teacher_entropy": 0.3985593616962433, "total_time": 1.2583367824554443, "rollout_time": 0.4452171325683594, "train_time": 0.8010380268096924, "student_train_time": 0.011690139770507812, "throughput": 1589.3996169271295, "inference_time": 0.056934005733637605, "env_time": 0.38828312683472177, "samples": 2000, "teacher_eval_reward": 367.0}
{"epoch": 441, "reward_mean": 374.5, "student_loss": null, "teacher_policy_loss": -51.92184066772461, "teacher_value_loss": 478.2986755371094, "teacher_entropy": 0.39581286907196045, "total_time": 1.305619478225708, "rollout_time": 0.44167351722717285, "train_time": 0.846174955368042, "student_train_time": 0.017418384552001953, "throughput": 1531.839891602974, "inference_time": 0.05967657523069647, "env_time": 0.3819969419964764, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 442, "reward_mean": 469.5, "student_loss": null, "teacher_policy_loss": -62.315670013427734, "teacher_value_loss": 650.5126342773438, "teacher_entropy": 0.43359124660491943, "total_time": 1.2666852474212646, "rollout_time": 0.4409184455871582, "train_time": 0.811525821685791, "student_train_time": 0.012663125991821289, "throughput": 1578.924207155351, "inference_time": 0.05739446121879155, "env_time": 0.38352398436836665, "samples": 2000, "teacher_eval_reward": 229.0}
{"epoch": 443, "reward_mean": 486.5, "student_loss": null, "teacher_policy_loss": -61.229671478271484, "teacher_value_loss": 508.6505126953125, "teacher_entropy": 0.4269465208053589, "total_time": 1.6934659481048584, "rollout_time": 0.4864485263824463, "train_time": 1.1895496845245361, "student_train_time": 0.01709914207458496, "throughput": 1181.0098704601535, "inference_time": 0.0714914487380156, "env_time": 0.4149570776444307, "samples": 2000, "teacher_eval_reward": 243.0}
{"epoch": 444, "reward_mean": 373.25, "student_loss": null, "teacher_policy_loss": -61.144493103027344, "teacher_value_loss": 467.5809326171875, "teacher_entropy": 0.40490996837615967, "total_time": 1.3889782428741455, "rollout_time": 0.4425983428955078, "train_time": 0.9330182075500488, "student_train_time": 0.013001441955566406, "throughput": 1439.907363747827, "inference_time": 0.0619232312146778, "env_time": 0.38067511168083, "samples": 2000, "teacher_eval_reward": 254.0}
{"epoch": 445, "reward_mean": 447.6, "student_loss": null, "teacher_policy_loss": -63.69499969482422, "teacher_value_loss": 595.2752685546875, "teacher_entropy": 0.42792609333992004, "total_time": 1.2754828929901123, "rollout_time": 0.4414949417114258, "train_time": 0.8196675777435303, "student_train_time": 0.013960123062133789, "throughput": 1568.0335745714342, "inference_time": 0.05934679799611331, "env_time": 0.38214814371531247, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 446, "reward_mean": 465.2, "student_loss": null, "teacher_policy_loss": -59.6609992980957, "teacher_value_loss": 769.5784912109375, "teacher_entropy": 0.40269535779953003, "total_time": 1.2670857906341553, "rollout_time": 0.441417932510376, "train_time": 0.8141112327575684, "student_train_time": 0.011106729507446289, "throughput": 1578.4250875381006, "inference_time": 0.06122310599130287, "env_time": 0.3801948265190731, "samples": 2000, "teacher_eval_reward": 360.0}
{"epoch": 447, "reward_mean": 458.8, "student_loss": null, "teacher_policy_loss": -55.180233001708984, "teacher_value_loss": 776.6004028320312, "teacher_entropy": 0.3722156286239624, "total_time": 1.2980499267578125, "rollout_time": 0.4477527141571045, "train_time": 0.8331913948059082, "student_train_time": 0.016759395599365234, "throughput": 1540.7727844455678, "inference_time": 0.0609952514514589, "env_time": 0.3867574627056456, "samples": 2000, "teacher_eval_reward": 418.0}
{"epoch": 448, "reward_mean": 429.25, "student_loss": null, "teacher_policy_loss": -61.31576156616211, "teacher_value_loss": 713.6213989257812, "teacher_entropy": 0.40173956751823425, "total_time": -1.0666332244873047, "rollout_time": 0.45768022537231445, "train_time": -1.549602746963501, "student_train_time": 0.02479839324951172, "throughput": 200000000000.0, "inference_time": 0.0583302942559385, "env_time": 0.39934993111637596, "samples": 2000, "teacher_eval_reward": 450.0}
{"epoch": 449, "reward_mean": 409.4, "student_loss": null, "teacher_policy_loss": -59.44544982910156, "teacher_value_loss": 667.1726684570312, "teacher_entropy": 0.417884886264801, "total_time": 1.4335989952087402, "rollout_time": 0.4592628479003906, "train_time": 0.9412844181060791, "student_train_time": 0.03265047073364258, "throughput": 1395.090263514581, "inference_time": 0.06450283304366167, "env_time": 0.39476001485672896, "samples": 2000, "teacher_eval_reward": 374.0}
{"epoch": 450, "reward_mean": 367.25, "student_loss": null, "teacher_policy_loss": -65.42682647705078, "teacher_value_loss": 566.074462890625, "teacher_entropy": 0.4106194078922272, "total_time": 1.3506314754486084, "rollout_time": 0.45787930488586426, "train_time": 0.8803730010986328, "student_train_time": 0.011879205703735352, "throughput": 1480.7888283039647, "inference_time": 0.062393545242230175, "env_time": 0.3954857596436341, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 451, "reward_mean": 480.5, "student_loss": null, "teacher_policy_loss": -66.98340606689453, "teacher_value_loss": 594.5260009765625, "teacher_entropy": 0.42157408595085144, "total_time": 1.3229484558105469, "rollout_time": 0.4413268566131592, "train_time": 0.866248607635498, "student_train_time": 0.015017986297607422, "throughput": 1511.7746962973215, "inference_time": 0.058868722186161904, "env_time": 0.3824581344269973, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 452, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -65.98358917236328, "teacher_value_loss": 599.3621826171875, "teacher_entropy": 0.4112800359725952, "total_time": 1.3129889965057373, "rollout_time": 0.4530367851257324, "train_time": 0.8327028751373291, "student_train_time": 0.02688312530517578, "throughput": 1523.242011412592, "inference_time": 0.06378629648133938, "env_time": 0.38925048864439304, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 453, "reward_mean": 469.5, "student_loss": null, "teacher_policy_loss": -68.5080337524414, "teacher_value_loss": 587.879638671875, "teacher_entropy": 0.42364659905433655, "total_time": 1.2790029048919678, "rollout_time": 0.4622945785522461, "train_time": 0.8049960136413574, "student_train_time": 0.011350870132446289, "throughput": 1563.718105995179, "inference_time": 0.0641274300232908, "env_time": 0.3981671485289553, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 454, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -68.95364379882812, "teacher_value_loss": 591.2776489257812, "teacher_entropy": 0.42552649974823, "total_time": 1.3850898742675781, "rollout_time": 0.43192100524902344, "train_time": 0.9365763664245605, "student_train_time": 0.016196489334106445, "throughput": 1443.9496217222586, "inference_time": 0.05884940731266397, "env_time": 0.37307159793635947, "samples": 2000, "teacher_eval_reward": 376.0}
{"epoch": 455, "reward_mean": 381.1666666666667, "student_loss": null, "teacher_policy_loss": -61.088321685791016, "teacher_value_loss": 722.8243408203125, "teacher_entropy": 0.4177069365978241, "total_time": 1.2815570831298828, "rollout_time": 0.44044041633605957, "train_time": 0.8256838321685791, "student_train_time": 0.015030860900878906, "throughput": 1560.6015731390598, "inference_time": 0.05852378378403955, "env_time": 0.38191663255202, "samples": 2000, "teacher_eval_reward": 404.0}
{"epoch": 456, "reward_mean": 412.0, "student_loss": null, "teacher_policy_loss": -59.6660270690918, "teacher_value_loss": 879.056640625, "teacher_entropy": 0.4077521562576294, "total_time": 1.194263219833374, "rollout_time": 0.42743372917175293, "train_time": 0.7574009895324707, "student_train_time": 0.009073019027709961, "throughput": 1674.6726908989494, "inference_time": 0.056736703734713956, "env_time": 0.370697025437039, "samples": 2000, "teacher_eval_reward": 496.0}
{"epoch": 457, "reward_mean": 436.4, "student_loss": null, "teacher_policy_loss": -59.24933624267578, "teacher_value_loss": 699.0861206054688, "teacher_entropy": 0.4334285259246826, "total_time": -1.378462553024292, "rollout_time": -2.1722095012664795, "train_time": 0.7774696350097656, "student_train_time": 0.01592087745666504, "throughput": 200000000000.0, "inference_time": 0.05606213798819226, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 458, "reward_mean": 409.3333333333333, "student_loss": null, "teacher_policy_loss": -60.04126739501953, "teacher_value_loss": 802.7333984375, "teacher_entropy": 0.4279676377773285, "total_time": 1.2672147750854492, "rollout_time": 0.42858219146728516, "train_time": 0.8232920169830322, "student_train_time": 0.014989614486694336, "throughput": 1578.2644263006944, "inference_time": 0.060081253499447485, "env_time": 0.36850093796783767, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 459, "reward_mean": 439.5, "student_loss": null, "teacher_policy_loss": -62.8426628112793, "teacher_value_loss": 776.4046630859375, "teacher_entropy": 0.4144729971885681, "total_time": 1.3323910236358643, "rollout_time": 0.43179965019226074, "train_time": 0.8863925933837891, "student_train_time": 0.01384425163269043, "throughput": 1501.060848145274, "inference_time": 0.0601684427838336, "env_time": 0.37163120740842714, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 460, "reward_mean": 464.75, "student_loss": null, "teacher_policy_loss": -60.84593963623047, "teacher_value_loss": 627.81689453125, "teacher_entropy": 0.4173203706741333, "total_time": 1.2346789836883545, "rollout_time": 0.4356248378753662, "train_time": 0.7800717353820801, "student_train_time": 0.018518924713134766, "throughput": 1619.8542507181935, "inference_time": 0.05725762350084551, "env_time": 0.3783672143745207, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 461, "reward_mean": 304.4, "student_loss": null, "teacher_policy_loss": -63.07197952270508, "teacher_value_loss": 652.4844970703125, "teacher_entropy": 0.42069166898727417, "total_time": 1.219208002090454, "rollout_time": 0.43421101570129395, "train_time": 0.773129940032959, "student_train_time": 0.011512279510498047, "throughput": 1640.4091808541282, "inference_time": 0.05747431299096206, "env_time": 0.3767367027103319, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 462, "reward_mean": 413.0, "student_loss": null, "teacher_policy_loss": -59.79334259033203, "teacher_value_loss": 686.649169921875, "teacher_entropy": 0.41347649693489075, "total_time": 1.1961851119995117, "rollout_time": 0.431990385055542, "train_time": 0.7516036033630371, "student_train_time": 0.012148380279541016, "throughput": 1671.9820201213274, "inference_time": 0.059135502779099625, "env_time": 0.37285488227644237, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 463, "reward_mean": 407.8333333333333, "student_loss": null, "teacher_policy_loss": -60.76644515991211, "teacher_value_loss": 862.6079711914062, "teacher_entropy": 0.4295441806316376, "total_time": 1.258336067199707, "rollout_time": 0.4287893772125244, "train_time": 0.8197669982910156, "student_train_time": 0.00943136215209961, "throughput": 1589.4005203639972, "inference_time": 0.05641828450279718, "env_time": 0.37237109270972724, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 464, "reward_mean": 403.6, "student_loss": null, "teacher_policy_loss": -61.02959060668945, "teacher_value_loss": 761.9744873046875, "teacher_entropy": 0.420101523399353, "total_time": 1.2358253002166748, "rollout_time": 0.42475223541259766, "train_time": 0.7957456111907959, "student_train_time": 0.014937639236450195, "throughput": 1618.3517198177963, "inference_time": 0.057289275213406654, "env_time": 0.367462960199191, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 465, "reward_mean": 371.2, "student_loss": null, "teacher_policy_loss": -64.45500183105469, "teacher_value_loss": 883.57568359375, "teacher_entropy": 0.4196016788482666, "total_time": 1.2613654136657715, "rollout_time": 0.43316006660461426, "train_time": 0.8163113594055176, "student_train_time": 0.011542081832885742, "throughput": 1585.583351447392, "inference_time": 0.05790830374826328, "env_time": 0.375251762856351, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 466, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -65.65910339355469, "teacher_value_loss": 935.3609008789062, "teacher_entropy": 0.43865084648132324, "total_time": 1.3126428127288818, "rollout_time": 0.43267154693603516, "train_time": 0.8642740249633789, "student_train_time": 0.015267133712768555, "throughput": 1523.6437365943873, "inference_time": 0.058923249704093905, "env_time": 0.37374829723194125, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 467, "reward_mean": 297.0, "student_loss": null, "teacher_policy_loss": -56.43785095214844, "teacher_value_loss": 538.188720703125, "teacher_entropy": 0.43533143401145935, "total_time": 1.2654376029968262, "rollout_time": 0.4296872615814209, "train_time": 0.8230879306793213, "student_train_time": 0.012311697006225586, "throughput": 1580.4809302833844, "inference_time": 0.05710994424043747, "env_time": 0.3725773173409834, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 468, "reward_mean": 417.5, "student_loss": null, "teacher_policy_loss": -65.83207702636719, "teacher_value_loss": 713.9620361328125, "teacher_entropy": 0.438595175743103, "total_time": 1.1737439632415771, "rollout_time": 0.4308037757873535, "train_time": 0.7317099571228027, "student_train_time": 0.010880470275878906, "throughput": 1703.9491257331092, "inference_time": 0.057906265783458366, "env_time": 0.37289751000389515, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 469, "reward_mean": 413.0, "student_loss": null, "teacher_policy_loss": -61.13544845581055, "teacher_value_loss": 749.6231079101562, "teacher_entropy": 0.4194645583629608, "total_time": 1.2661333084106445, "rollout_time": 0.44183874130249023, "train_time": 0.8139324188232422, "student_train_time": 0.009958982467651367, "throughput": 1579.6124995009932, "inference_time": 0.05904713903510128, "env_time": 0.38279160226738895, "samples": 2000, "teacher_eval_reward": 443.0}
{"epoch": 470, "reward_mean": 446.75, "student_loss": null, "teacher_policy_loss": -61.62192153930664, "teacher_value_loss": 706.263427734375, "teacher_entropy": 0.4432775676250458, "total_time": 1.2733399868011475, "rollout_time": 0.44796133041381836, "train_time": 0.8094768524169922, "student_train_time": 0.015539884567260742, "throughput": 1570.6724211373817, "inference_time": 0.05979942348312761, "env_time": 0.38816190693069075, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 471, "reward_mean": 419.8, "student_loss": null, "teacher_policy_loss": -59.35127258300781, "teacher_value_loss": 822.5426025390625, "teacher_entropy": 0.4405071437358856, "total_time": 1.2341761589050293, "rollout_time": 0.439892053604126, "train_time": 0.7822690010070801, "student_train_time": 0.011622190475463867, "throughput": 1620.5142074486478, "inference_time": 0.06204250871451222, "env_time": 0.37784954488961375, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 472, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -63.792972564697266, "teacher_value_loss": 696.2623291015625, "teacher_entropy": 0.4422261118888855, "total_time": 1.33481764793396, "rollout_time": 0.444429874420166, "train_time": 0.8703398704528809, "student_train_time": 0.019614696502685547, "throughput": 1498.332002948578, "inference_time": 0.06192126204223314, "env_time": 0.3825086123779329, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 473, "reward_mean": 364.0, "student_loss": null, "teacher_policy_loss": -57.05099105834961, "teacher_value_loss": 615.9100952148438, "teacher_entropy": 0.45157355070114136, "total_time": 1.3571569919586182, "rollout_time": 0.44522738456726074, "train_time": 0.8950228691101074, "student_train_time": 0.016548871994018555, "throughput": 1473.6688620773675, "inference_time": 0.058100142759940354, "env_time": 0.3871272418073204, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 474, "reward_mean": 360.6, "student_loss": null, "teacher_policy_loss": -59.57815170288086, "teacher_value_loss": 472.69757080078125, "teacher_entropy": 0.46185997128486633, "total_time": 1.2794365882873535, "rollout_time": 0.4349839687347412, "train_time": 0.8301732540130615, "student_train_time": 0.013847827911376953, "throughput": 1563.1880612990665, "inference_time": 0.059136731768376194, "env_time": 0.375847236966365, "samples": 2000, "teacher_eval_reward": 286.0}
{"epoch": 475, "reward_mean": 323.0, "student_loss": null, "teacher_policy_loss": -54.658470153808594, "teacher_value_loss": 533.1148681640625, "teacher_entropy": 0.4595886766910553, "total_time": 1.2825648784637451, "rollout_time": 0.43567657470703125, "train_time": 0.8364067077636719, "student_train_time": 0.010093212127685547, "throughput": 1559.3753061409243, "inference_time": 0.059540829419347574, "env_time": 0.3761357452876837, "samples": 2000, "teacher_eval_reward": 244.0}
{"epoch": 476, "reward_mean": 413.2, "student_loss": null, "teacher_policy_loss": -56.69960021972656, "teacher_value_loss": 311.8497619628906, "teacher_entropy": 0.45648953318595886, "total_time": 1.2030041217803955, "rollout_time": 0.4289679527282715, "train_time": 0.7666845321655273, "student_train_time": 0.0069293975830078125, "throughput": 1662.5046945309582, "inference_time": 0.05784257228697243, "env_time": 0.37112538044129906, "samples": 2000, "teacher_eval_reward": 326.0}
{"epoch": 477, "reward_mean": 274.0, "student_loss": null, "teacher_policy_loss": -56.109588623046875, "teacher_value_loss": 410.42181396484375, "teacher_entropy": 0.4703735113143921, "total_time": 1.2059245109558105, "rollout_time": 0.42966127395629883, "train_time": 0.7625465393066406, "student_train_time": 0.0133056640625, "throughput": 1658.4786044483071, "inference_time": 0.0585996252248151, "env_time": 0.37106164873148373, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 478, "reward_mean": 305.75, "student_loss": null, "teacher_policy_loss": -53.08168411254883, "teacher_value_loss": 397.0444030761719, "teacher_entropy": 0.4551391899585724, "total_time": 1.2933979034423828, "rollout_time": 0.43242311477661133, "train_time": 0.852118730545044, "student_train_time": 0.008504390716552734, "throughput": 1546.3145522943817, "inference_time": 0.05805515800057037, "env_time": 0.37436795677604096, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 479, "reward_mean": 254.0, "student_loss": null, "teacher_policy_loss": -50.06496047973633, "teacher_value_loss": 364.9342041015625, "teacher_entropy": 0.4616624414920807, "total_time": 1.3115284442901611, "rollout_time": 0.4455130100250244, "train_time": 0.8543627262115479, "student_train_time": 0.011288642883300781, "throughput": 1524.9383333675698, "inference_time": 0.058314217796578305, "env_time": 0.3871987922284461, "samples": 2000, "teacher_eval_reward": 201.0}
{"epoch": 480, "reward_mean": 239.75, "student_loss": null, "teacher_policy_loss": -51.41663360595703, "teacher_value_loss": 412.83477783203125, "teacher_entropy": 0.4621535539627075, "total_time": 1.293468713760376, "rollout_time": 0.4342470169067383, "train_time": 0.845782995223999, "student_train_time": 0.013009786605834961, "throughput": 1546.2299000534726, "inference_time": 0.05971931000385666, "env_time": 0.3745277069028816, "samples": 2000, "teacher_eval_reward": 152.0}
{"epoch": 481, "reward_mean": 248.0, "student_loss": null, "teacher_policy_loss": -50.54224395751953, "teacher_value_loss": 272.5131530761719, "teacher_entropy": 0.449349582195282, "total_time": 1.3015449047088623, "rollout_time": 0.44999265670776367, "train_time": 0.8217477798461914, "student_train_time": 0.029425859451293945, "throughput": 1536.6354190041354, "inference_time": 0.061387612302496564, "env_time": 0.3886050444052671, "samples": 2000, "teacher_eval_reward": 201.0}
{"epoch": 482, "reward_mean": 227.55555555555554, "student_loss": null, "teacher_policy_loss": -51.55814743041992, "teacher_value_loss": 262.9268798828125, "teacher_entropy": 0.47751685976982117, "total_time": 1.3364052772521973, "rollout_time": 0.4436376094818115, "train_time": 0.8780069351196289, "student_train_time": 0.014415502548217773, "throughput": 1496.5520071218439, "inference_time": 0.06157670423635864, "env_time": 0.3820609052454529, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 483, "reward_mean": 271.375, "student_loss": null, "teacher_policy_loss": -55.51239013671875, "teacher_value_loss": 465.2178649902344, "teacher_entropy": 0.47353261709213257, "total_time": 1.3663418292999268, "rollout_time": 0.4452188014984131, "train_time": 0.897345781326294, "student_train_time": 0.023418664932250977, "throughput": 1463.762549833332, "inference_time": 0.05901072622873471, "env_time": 0.3862080752696784, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 484, "reward_mean": 248.71428571428572, "student_loss": null, "teacher_policy_loss": -51.305233001708984, "teacher_value_loss": 324.2682189941406, "teacher_entropy": 0.4642464220523834, "total_time": 1.230710744857788, "rollout_time": 0.4290013313293457, "train_time": 0.7853879928588867, "student_train_time": 0.015969514846801758, "throughput": 1625.07722334959, "inference_time": 0.059035751453848206, "env_time": 0.3699655798754975, "samples": 2000, "teacher_eval_reward": 193.0}
{"epoch": 485, "reward_mean": 242.75, "student_loss": null, "teacher_policy_loss": -51.51167678833008, "teacher_value_loss": 378.68109130859375, "teacher_entropy": 0.46880272030830383, "total_time": 1.3183650970458984, "rollout_time": 0.4476611614227295, "train_time": 0.8568234443664551, "student_train_time": 0.01351308822631836, "throughput": 1517.030452703475, "inference_time": 0.061796167470674845, "env_time": 0.38586499395205465, "samples": 2000, "teacher_eval_reward": 218.0}
{"epoch": 486, "reward_mean": 246.625, "student_loss": null, "teacher_policy_loss": -50.591793060302734, "teacher_value_loss": 235.22987365722656, "teacher_entropy": 0.47249844670295715, "total_time": 1.2249722480773926, "rollout_time": 0.43314671516418457, "train_time": 0.7778611183166504, "student_train_time": 0.013611555099487305, "throughput": 1632.6900492146021, "inference_time": 0.056998812207893934, "env_time": 0.37614790295629064, "samples": 2000, "teacher_eval_reward": 234.0}
{"epoch": 487, "reward_mean": 254.44444444444446, "student_loss": null, "teacher_policy_loss": -53.17625427246094, "teacher_value_loss": 370.6357421875, "teacher_entropy": 0.48335716128349304, "total_time": 1.2056305408477783, "rollout_time": 0.4395911693572998, "train_time": 0.7558038234710693, "student_train_time": 0.009775400161743164, "throughput": 1658.8829929554, "inference_time": 0.05952720503046294, "env_time": 0.38006396432683687, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 488, "reward_mean": 231.5, "student_loss": null, "teacher_policy_loss": -49.57309341430664, "teacher_value_loss": 398.1163024902344, "teacher_entropy": 0.47216796875, "total_time": 1.2119414806365967, "rollout_time": 0.43815088272094727, "train_time": 0.764014482498169, "student_train_time": 0.009342193603515625, "throughput": 1650.244695766548, "inference_time": 0.05577257370714506, "env_time": 0.3823783090138022, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 489, "reward_mean": 271.6666666666667, "student_loss": null, "teacher_policy_loss": -55.553646087646484, "teacher_value_loss": 264.0788879394531, "teacher_entropy": 0.4817853569984436, "total_time": 1.3542823791503906, "rollout_time": 0.5006799697875977, "train_time": 0.8431887626647949, "student_train_time": 0.010041952133178711, "throughput": 1476.7968857829344, "inference_time": 0.06524177803112252, "env_time": 0.43543819175647513, "samples": 2000, "teacher_eval_reward": 225.0}
{"epoch": 490, "reward_mean": 262.0, "student_loss": null, "teacher_policy_loss": -50.610374450683594, "teacher_value_loss": 303.9288330078125, "teacher_entropy": 0.47328901290893555, "total_time": 1.1982574462890625, "rollout_time": 0.4220156669616699, "train_time": 0.7669894695281982, "student_train_time": 0.008910655975341797, "throughput": 1669.0903997249425, "inference_time": 0.05821381521127478, "env_time": 0.36380185175039514, "samples": 2000, "teacher_eval_reward": 222.0}
{"epoch": 491, "reward_mean": 284.85714285714283, "student_loss": null, "teacher_policy_loss": -54.51128387451172, "teacher_value_loss": 451.15142822265625, "teacher_entropy": 0.4777388870716095, "total_time": 1.2407288551330566, "rollout_time": 0.4287865161895752, "train_time": 0.795081615447998, "student_train_time": 0.01645970344543457, "throughput": 1611.9557401488164, "inference_time": 0.05706330970679119, "env_time": 0.371723206482784, "samples": 2000, "teacher_eval_reward": 308.0}
{"epoch": 492, "reward_mean": 292.75, "student_loss": null, "teacher_policy_loss": -51.18851852416992, "teacher_value_loss": 399.4949035644531, "teacher_entropy": 0.4783225655555725, "total_time": 1.3358070850372314, "rollout_time": 0.4377307891845703, "train_time": 0.8828811645507812, "student_train_time": 0.014834165573120117, "throughput": 1497.222183055165, "inference_time": 0.05757934275607113, "env_time": 0.3801514464284992, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 493, "reward_mean": 274.42857142857144, "student_loss": null, "teacher_policy_loss": -55.72978591918945, "teacher_value_loss": 565.1064453125, "teacher_entropy": 0.4744291603565216, "total_time": 1.2768120765686035, "rollout_time": 0.4359860420227051, "train_time": 0.8275036811828613, "student_train_time": 0.012968301773071289, "throughput": 1566.4012243484913, "inference_time": 0.059463658813911024, "env_time": 0.37652238320879405, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 494, "reward_mean": 269.5, "student_loss": null, "teacher_policy_loss": -55.279666900634766, "teacher_value_loss": 415.0687561035156, "teacher_entropy": 0.47513872385025024, "total_time": 1.2986650466918945, "rollout_time": 0.4624166488647461, "train_time": 0.8182978630065918, "student_train_time": 0.017535924911499023, "throughput": 1540.0429888327437, "inference_time": 0.060964540258282796, "env_time": 0.4014521086064633, "samples": 2000, "teacher_eval_reward": 445.0}
{"epoch": 495, "reward_mean": 276.5, "student_loss": null, "teacher_policy_loss": -50.9384651184082, "teacher_value_loss": 505.0554504394531, "teacher_entropy": 0.48359379172325134, "total_time": 1.2655680179595947, "rollout_time": 0.43066835403442383, "train_time": 0.8176398277282715, "student_train_time": 0.016855955123901367, "throughput": 1580.3180639982427, "inference_time": 0.058030974490975495, "env_time": 0.37263737954344833, "samples": 2000, "teacher_eval_reward": 412.0}
{"epoch": 496, "reward_mean": 347.6, "student_loss": null, "teacher_policy_loss": -56.89418029785156, "teacher_value_loss": 469.2974853515625, "teacher_entropy": 0.483734667301178, "total_time": 1.1778903007507324, "rollout_time": 0.4206502437591553, "train_time": 0.7420752048492432, "student_train_time": 0.014811038970947266, "throughput": 1697.9509880718886, "inference_time": 0.05775616448954679, "env_time": 0.3628940792696085, "samples": 2000, "teacher_eval_reward": 386.0}
{"epoch": 497, "reward_mean": 368.4, "student_loss": null, "teacher_policy_loss": -59.364437103271484, "teacher_value_loss": 446.8318176269531, "teacher_entropy": 0.4719903767108917, "total_time": 1.2599952220916748, "rollout_time": 0.4372727870941162, "train_time": 0.8086841106414795, "student_train_time": 0.013685226440429688, "throughput": 1587.307606357323, "inference_time": 0.05736984545364976, "env_time": 0.37990294164046645, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 498, "reward_mean": 392.6, "student_loss": null, "teacher_policy_loss": -60.871482849121094, "teacher_value_loss": 547.8521118164062, "teacher_entropy": 0.4876883924007416, "total_time": 1.2077820301055908, "rollout_time": 0.45047879219055176, "train_time": 0.7464699745178223, "student_train_time": 0.01048135757446289, "throughput": 1655.9279324806225, "inference_time": 0.056474689963579294, "env_time": 0.39400410222697246, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 499, "reward_mean": 371.6666666666667, "student_loss": null, "teacher_policy_loss": -58.17414093017578, "teacher_value_loss": 549.009033203125, "teacher_entropy": 0.47807610034942627, "total_time": 1.3105800151824951, "rollout_time": 0.44212865829467773, "train_time": 0.8534376621246338, "student_train_time": 0.014583110809326172, "throughput": 1526.0418874321877, "inference_time": 0.0580305597595725, "env_time": 0.38409809853510524, "samples": 2000, "teacher_eval_reward": 373.0}
{"epoch": 500, "reward_mean": 449.0, "student_loss": null, "teacher_policy_loss": -62.77023696899414, "teacher_value_loss": 561.940673828125, "teacher_entropy": 0.4823317229747772, "total_time": 1.2979416847229004, "rollout_time": 0.4476654529571533, "train_time": 0.8397855758666992, "student_train_time": 0.010036468505859375, "throughput": 1540.9012774152354, "inference_time": 0.05996911489273771, "env_time": 0.3876963380644156, "samples": 2000, "teacher_eval_reward": 500.0}
