{"epoch": 1, "reward_mean": 28.402985074626866, "student_loss": null, "teacher_policy_loss": -17.090682983398438, "teacher_value_loss": 447.7655334472656, "teacher_entropy": 0.6847700476646423, "total_time": 1.6901650428771973, "rollout_time": 0.49825000762939453, "train_time": 1.1913702487945557, "throughput": 1183.3163917503377, "inference_time": 0.06154885675141486, "env_time": 0.43670115087797967, "samples": 2000}
{"epoch": 2, "reward_mean": 29.071428571428573, "student_loss": null, "teacher_policy_loss": -14.955526351928711, "teacher_value_loss": 220.39471435546875, "teacher_entropy": 0.5741231441497803, "total_time": 1.2813656330108643, "rollout_time": 0.41309237480163574, "train_time": 0.8679289817810059, "throughput": 1560.8347441787855, "inference_time": 0.05465051075049132, "env_time": 0.3584418640511444, "samples": 2000}
{"epoch": 3, "reward_mean": 30.134328358208954, "student_loss": null, "teacher_policy_loss": -17.51479148864746, "teacher_value_loss": 186.434814453125, "teacher_entropy": 0.652685284614563, "total_time": 1.2404367923736572, "rollout_time": 0.4338104724884033, "train_time": 0.8062295913696289, "throughput": 1612.3352776185143, "inference_time": 0.05663450850141771, "env_time": 0.3771759639869856, "samples": 2000}
{"epoch": 4, "reward_mean": 28.797101449275363, "student_loss": null, "teacher_policy_loss": -16.726299285888672, "teacher_value_loss": 207.4541778564453, "teacher_entropy": 0.636457622051239, "total_time": 1.1631994247436523, "rollout_time": 0.4259634017944336, "train_time": 0.7368900775909424, "throughput": 1719.395623360769, "inference_time": 0.05303505850042711, "env_time": 0.3729283432940065, "samples": 2000}
{"epoch": 5, "reward_mean": 29.16176470588235, "student_loss": null, "teacher_policy_loss": -18.614639282226562, "teacher_value_loss": 273.6504821777344, "teacher_entropy": 0.6336032748222351, "total_time": 1.2544457912445068, "rollout_time": 0.41959667205810547, "train_time": 0.8344070911407471, "throughput": 1594.3295548991766, "inference_time": 0.05572926500116182, "env_time": 0.36386740705694365, "samples": 2000}
{"epoch": 6, "reward_mean": 29.791044776119403, "student_loss": null, "teacher_policy_loss": -16.223400115966797, "teacher_value_loss": 137.09915161132812, "teacher_entropy": 0.6132832169532776, "total_time": 1.1576240062713623, "rollout_time": 0.40770554542541504, "train_time": 0.7495019435882568, "throughput": 1727.6766801354443, "inference_time": 0.05227353525020817, "env_time": 0.35543201017520687, "samples": 2000}
{"epoch": 7, "reward_mean": 26.84931506849315, "student_loss": null, "teacher_policy_loss": -15.712738990783691, "teacher_value_loss": 126.52450561523438, "teacher_entropy": 0.6340168118476868, "total_time": 1.1673774719238281, "rollout_time": 0.4147367477416992, "train_time": 0.7522802352905273, "throughput": 1713.2419016995566, "inference_time": 0.05271149475174752, "env_time": 0.3620252529899517, "samples": 2000}
{"epoch": 8, "reward_mean": 31.49206349206349, "student_loss": null, "teacher_policy_loss": -15.109033584594727, "teacher_value_loss": 148.7126007080078, "teacher_entropy": 0.5417276620864868, "total_time": 1.2317430973052979, "rollout_time": 0.41851186752319336, "train_time": 0.8128783702850342, "throughput": 1623.7152084516883, "inference_time": 0.05422194125009128, "env_time": 0.3642899262731021, "samples": 2000}
{"epoch": 9, "reward_mean": 28.73611111111111, "student_loss": null, "teacher_policy_loss": -14.366000175476074, "teacher_value_loss": 148.91741943359375, "teacher_entropy": 0.5714989900588989, "total_time": 1.2450401782989502, "rollout_time": 0.41853809356689453, "train_time": 0.8261675834655762, "throughput": 1606.373862354002, "inference_time": 0.053305897000882396, "env_time": 0.36523219656601214, "samples": 2000}
{"epoch": 10, "reward_mean": 27.04054054054054, "student_loss": null, "teacher_policy_loss": -15.55803108215332, "teacher_value_loss": 106.79110717773438, "teacher_entropy": 0.6661198735237122, "total_time": 1.2104063034057617, "rollout_time": 0.4217662811279297, "train_time": 0.7882997989654541, "throughput": 1652.3377269042069, "inference_time": 0.05304303225005924, "env_time": 0.36872324887787045, "samples": 2000}
{"epoch": 11, "reward_mean": 28.0, "student_loss": null, "teacher_policy_loss": -15.132573127746582, "teacher_value_loss": 119.05963897705078, "teacher_entropy": 0.617755651473999, "total_time": 1.2038772106170654, "rollout_time": 0.4230470657348633, "train_time": 0.7804856300354004, "throughput": 1661.2989949156606, "inference_time": 0.053723792997345754, "env_time": 0.3693232727375175, "samples": 2000}
{"epoch": 12, "reward_mean": 33.36206896551724, "student_loss": null, "teacher_policy_loss": -18.97216796875, "teacher_value_loss": 165.440185546875, "teacher_entropy": 0.6588795185089111, "total_time": 1.2908849716186523, "rollout_time": 0.4367685317993164, "train_time": 0.853783130645752, "throughput": 1549.3247221649672, "inference_time": 0.05382403524936308, "env_time": 0.38294449654995333, "samples": 2000}
{"epoch": 13, "reward_mean": 30.309859154929576, "student_loss": null, "teacher_policy_loss": -15.25670337677002, "teacher_value_loss": 146.4879913330078, "teacher_entropy": 0.5909891128540039, "total_time": 1.2922394275665283, "rollout_time": 0.42570948600769043, "train_time": 0.8661274909973145, "throughput": 1547.7008032221136, "inference_time": 0.05767160149997608, "env_time": 0.36803788450771435, "samples": 2000}
{"epoch": 14, "reward_mean": 29.78787878787879, "student_loss": null, "teacher_policy_loss": -18.195077896118164, "teacher_value_loss": 193.37747192382812, "teacher_entropy": 0.6353414058685303, "total_time": 1.1550674438476562, "rollout_time": 0.403714656829834, "train_time": 0.7506673336029053, "throughput": 1731.5006241867409, "inference_time": 0.052482076997250715, "env_time": 0.35123257983258327, "samples": 2000}
{"epoch": 15, "reward_mean": 26.716216216216218, "student_loss": null, "teacher_policy_loss": -15.619675636291504, "teacher_value_loss": 172.30059814453125, "teacher_entropy": 0.6100825071334839, "total_time": 1.2566592693328857, "rollout_time": 0.42284083366394043, "train_time": 0.833446741104126, "throughput": 1591.5213047859238, "inference_time": 0.050893813249615505, "env_time": 0.3719470204143249, "samples": 2000}
{"epoch": 16, "reward_mean": 28.957142857142856, "student_loss": null, "teacher_policy_loss": -14.836057662963867, "teacher_value_loss": 131.2242431640625, "teacher_entropy": 0.5691863298416138, "total_time": 1.1489837169647217, "rollout_time": 0.44248390197753906, "train_time": 0.7061479091644287, "throughput": 1740.6687061531334, "inference_time": 0.054666955248649174, "env_time": 0.3878169467288899, "samples": 2000}
{"epoch": 17, "reward_mean": 28.32857142857143, "student_loss": null, "teacher_policy_loss": -15.455924034118652, "teacher_value_loss": 96.54096984863281, "teacher_entropy": 0.6108945608139038, "total_time": 1.292201042175293, "rollout_time": 0.4118366241455078, "train_time": 0.8800218105316162, "throughput": 1547.7467783443335, "inference_time": 0.052815694248522504, "env_time": 0.3590209298969853, "samples": 2000}
{"epoch": 18, "reward_mean": 32.016129032258064, "student_loss": null, "teacher_policy_loss": -18.52729034423828, "teacher_value_loss": 190.11312866210938, "teacher_entropy": 0.5960423350334167, "total_time": 1.230808973312378, "rollout_time": 0.4271106719970703, "train_time": 0.8033511638641357, "throughput": 1624.9475291178287, "inference_time": 0.055259534250239994, "env_time": 0.3718511377468303, "samples": 2000}
{"epoch": 19, "reward_mean": 29.402985074626866, "student_loss": null, "teacher_policy_loss": -14.678107261657715, "teacher_value_loss": 119.99510192871094, "teacher_entropy": 0.5395499467849731, "total_time": 1.1710402965545654, "rollout_time": 0.423999547958374, "train_time": 0.746687650680542, "throughput": 1707.8831581495526, "inference_time": 0.05107194824972794, "env_time": 0.3729275997086461, "samples": 2000}
{"epoch": 20, "reward_mean": 29.96969696969697, "student_loss": null, "teacher_policy_loss": -15.363412857055664, "teacher_value_loss": 112.51240539550781, "teacher_entropy": 0.5606481432914734, "total_time": 1.2003331184387207, "rollout_time": 0.4224066734313965, "train_time": 0.7775778770446777, "throughput": 1666.2041305678626, "inference_time": 0.05458122200144544, "env_time": 0.36782545142995104, "samples": 2000}
{"epoch": 21, "reward_mean": 28.65753424657534, "student_loss": null, "teacher_policy_loss": -14.944622039794922, "teacher_value_loss": 106.19513702392578, "teacher_entropy": 0.5717037320137024, "total_time": 1.2463405132293701, "rollout_time": 0.4354262351989746, "train_time": 0.8104808330535889, "throughput": 1604.69789657871, "inference_time": 0.056181245749712616, "env_time": 0.379244989449262, "samples": 2000}
{"epoch": 22, "reward_mean": 34.275862068965516, "student_loss": null, "teacher_policy_loss": -19.933910369873047, "teacher_value_loss": 189.16773986816406, "teacher_entropy": 0.6181822419166565, "total_time": 1.1724884510040283, "rollout_time": 0.42313241958618164, "train_time": 0.7489523887634277, "throughput": 1705.7737313210675, "inference_time": 0.056264692500406, "env_time": 0.36686772708577564, "samples": 2000}
{"epoch": 23, "reward_mean": 35.30909090909091, "student_loss": null, "teacher_policy_loss": -20.545883178710938, "teacher_value_loss": 198.2427520751953, "teacher_entropy": 0.61224365234375, "total_time": 1.2738244533538818, "rollout_time": 0.42298364639282227, "train_time": 0.8504514694213867, "throughput": 1570.0750560519966, "inference_time": 0.058248850000211405, "env_time": 0.36473479639261086, "samples": 2000}
{"epoch": 24, "reward_mean": 30.338461538461537, "student_loss": null, "teacher_policy_loss": -16.24090576171875, "teacher_value_loss": 127.07261657714844, "teacher_entropy": 0.6204423904418945, "total_time": 1.292921543121338, "rollout_time": 0.4097709655761719, "train_time": 0.8827629089355469, "throughput": 1546.8842720120908, "inference_time": 0.05132299149954633, "env_time": 0.35844797407662554, "samples": 2000}
{"epoch": 25, "reward_mean": 30.014285714285716, "student_loss": null, "teacher_policy_loss": -17.10852813720703, "teacher_value_loss": 174.1068115234375, "teacher_entropy": 0.6216279864311218, "total_time": 1.1686649322509766, "rollout_time": 0.40904879570007324, "train_time": 0.7592778205871582, "throughput": 1711.354507872313, "inference_time": 0.05340719899783153, "env_time": 0.3556415967022417, "samples": 2000}
{"epoch": 26, "reward_mean": 30.363636363636363, "student_loss": null, "teacher_policy_loss": -17.440214157104492, "teacher_value_loss": 169.2156219482422, "teacher_entropy": 0.616251528263092, "total_time": -0.21722984313964844, "rollout_time": -1.010505199432373, "train_time": 0.7929320335388184, "throughput": 200000000000.0, "inference_time": 0.05481785049971677, "env_time": 0.0, "samples": 2000}
{"epoch": 27, "reward_mean": 28.636363636363637, "student_loss": null, "teacher_policy_loss": -16.360258102416992, "teacher_value_loss": 180.38694763183594, "teacher_entropy": 0.6209484934806824, "total_time": 1.2233877182006836, "rollout_time": 0.4462406635284424, "train_time": 0.7768092155456543, "throughput": 1634.8047068361377, "inference_time": 0.054758832250286105, "env_time": 0.3914818312781563, "samples": 2000}
{"epoch": 28, "reward_mean": 31.01492537313433, "student_loss": null, "teacher_policy_loss": -16.21026039123535, "teacher_value_loss": 155.60934448242188, "teacher_entropy": 0.6096920371055603, "total_time": 1.42091965675354, "rollout_time": 0.48528552055358887, "train_time": 0.9352538585662842, "throughput": 1407.5391177074146, "inference_time": 0.059882797750447025, "env_time": 0.42540272280314184, "samples": 2000}
{"epoch": 29, "reward_mean": 30.272727272727273, "student_loss": null, "teacher_policy_loss": -17.716203689575195, "teacher_value_loss": 133.65850830078125, "teacher_entropy": 0.6217386722564697, "total_time": 1.2682595252990723, "rollout_time": 0.44921016693115234, "train_time": 0.8186748027801514, "throughput": 1576.9643043117485, "inference_time": 0.05561433925038273, "env_time": 0.3935958276807696, "samples": 2000}
{"epoch": 30, "reward_mean": 28.685714285714287, "student_loss": null, "teacher_policy_loss": -15.785507202148438, "teacher_value_loss": 91.14139556884766, "teacher_entropy": 0.630149245262146, "total_time": 1.192276954650879, "rollout_time": 0.43625807762145996, "train_time": 0.7556376457214355, "throughput": 1677.4625997745948, "inference_time": 0.05639958124993427, "env_time": 0.3798584963715257, "samples": 2000}
{"epoch": 31, "reward_mean": 30.53125, "student_loss": null, "teacher_policy_loss": -17.708309173583984, "teacher_value_loss": 149.85140991210938, "teacher_entropy": 0.6388888955116272, "total_time": 1.217186450958252, "rollout_time": 0.4207456111907959, "train_time": 0.7960934638977051, "throughput": 1643.1336369423632, "inference_time": 0.05229667824880835, "env_time": 0.36844893294198755, "samples": 2000}
{"epoch": 32, "reward_mean": 32.19047619047619, "student_loss": null, "teacher_policy_loss": -17.918643951416016, "teacher_value_loss": 176.3633270263672, "teacher_entropy": 0.6311580538749695, "total_time": 1.2229335308074951, "rollout_time": 0.4210031032562256, "train_time": 0.8015933036804199, "throughput": 1635.4118597757417, "inference_time": 0.05240491174942008, "env_time": 0.3685981915068055, "samples": 2000}
{"epoch": 33, "reward_mean": 32.233333333333334, "student_loss": null, "teacher_policy_loss": -17.775659561157227, "teacher_value_loss": 168.12355041503906, "teacher_entropy": 0.6372109055519104, "total_time": 1.2583889961242676, "rollout_time": 0.42208409309387207, "train_time": 0.8359677791595459, "throughput": 1589.3336688097497, "inference_time": 0.052911339500610666, "env_time": 0.3691727535932614, "samples": 2000}
{"epoch": 34, "reward_mean": 28.676056338028168, "student_loss": null, "teacher_policy_loss": -15.978013038635254, "teacher_value_loss": 126.9356460571289, "teacher_entropy": 0.6482391357421875, "total_time": 1.2154903411865234, "rollout_time": 0.4197368621826172, "train_time": 0.7954206466674805, "throughput": 1645.4264852879562, "inference_time": 0.05244118124954866, "env_time": 0.3672956809330685, "samples": 2000}
{"epoch": 35, "reward_mean": 31.59375, "student_loss": null, "teacher_policy_loss": -17.98467445373535, "teacher_value_loss": 155.34449768066406, "teacher_entropy": 0.6516594290733337, "total_time": 1.1391077041625977, "rollout_time": 0.41645264625549316, "train_time": 0.722243070602417, "throughput": 1755.7602259132095, "inference_time": 0.0535449929996048, "env_time": 0.36290765325588836, "samples": 2000}
{"epoch": 36, "reward_mean": 32.28333333333333, "student_loss": null, "teacher_policy_loss": -18.093313217163086, "teacher_value_loss": 135.29344177246094, "teacher_entropy": 0.6464061737060547, "total_time": 1.274618148803711, "rollout_time": 0.42584776878356934, "train_time": 0.8484282493591309, "throughput": 1569.0973817351448, "inference_time": 0.05433505999968702, "env_time": 0.3715127087838823, "samples": 2000}
{"epoch": 37, "reward_mean": 31.555555555555557, "student_loss": null, "teacher_policy_loss": -16.726234436035156, "teacher_value_loss": 104.28026580810547, "teacher_entropy": 0.6370419263839722, "total_time": 1.2549939155578613, "rollout_time": 0.42531681060791016, "train_time": 0.8293190002441406, "throughput": 1593.6332241985203, "inference_time": 0.05283297074913662, "env_time": 0.37248383985877354, "samples": 2000}
{"epoch": 38, "reward_mean": 29.728571428571428, "student_loss": null, "teacher_policy_loss": -16.334110260009766, "teacher_value_loss": 119.19759368896484, "teacher_entropy": 0.6302675008773804, "total_time": 1.4576077461242676, "rollout_time": 0.4268474578857422, "train_time": 1.0304174423217773, "throughput": 1372.111259231392, "inference_time": 0.053346151001278486, "env_time": 0.3735013068844637, "samples": 2000}
{"epoch": 39, "reward_mean": 30.53030303030303, "student_loss": null, "teacher_policy_loss": -16.277833938598633, "teacher_value_loss": 121.67070007324219, "teacher_entropy": 0.6111069321632385, "total_time": 1.1893575191497803, "rollout_time": 0.43611931800842285, "train_time": 0.752882719039917, "throughput": 1681.5801538209575, "inference_time": 0.05649146349929879, "env_time": 0.37962785450912406, "samples": 2000}
{"epoch": 40, "reward_mean": 30.40909090909091, "student_loss": null, "teacher_policy_loss": -17.499242782592773, "teacher_value_loss": 140.8139190673828, "teacher_entropy": 0.62807697057724, "total_time": 1.2098097801208496, "rollout_time": 0.4254465103149414, "train_time": 0.7840054035186768, "throughput": 1653.1524483131698, "inference_time": 0.05453656275034291, "env_time": 0.3709099475645985, "samples": 2000}
{"epoch": 41, "reward_mean": 32.98360655737705, "student_loss": null, "teacher_policy_loss": -19.07213592529297, "teacher_value_loss": 153.57469177246094, "teacher_entropy": 0.6348401308059692, "total_time": 1.2955081462860107, "rollout_time": 0.4239659309387207, "train_time": 0.8711996078491211, "throughput": 1543.7957729047407, "inference_time": 0.05448439225023094, "env_time": 0.36948153868848976, "samples": 2000}
{"epoch": 42, "reward_mean": 27.438356164383563, "student_loss": null, "teacher_policy_loss": -15.104535102844238, "teacher_value_loss": 92.5447998046875, "teacher_entropy": 0.6047504544258118, "total_time": 1.2076692581176758, "rollout_time": 0.4330873489379883, "train_time": 0.7742486000061035, "throughput": 1656.0825628014115, "inference_time": 0.054559863000747555, "env_time": 0.3785274859372407, "samples": 2000}
{"epoch": 43, "reward_mean": 37.44230769230769, "student_loss": null, "teacher_policy_loss": -21.10531997680664, "teacher_value_loss": 176.6609344482422, "teacher_entropy": 0.6136621236801147, "total_time": 1.2428898811340332, "rollout_time": 0.41756582260131836, "train_time": 0.824979305267334, "throughput": 1609.153015370249, "inference_time": 0.0521974107498977, "env_time": 0.36536841185142066, "samples": 2000}
{"epoch": 44, "reward_mean": 34.6140350877193, "student_loss": null, "teacher_policy_loss": -18.52757453918457, "teacher_value_loss": 116.1624526977539, "teacher_entropy": 0.5998473167419434, "total_time": 1.1741135120391846, "rollout_time": 0.42020392417907715, "train_time": 0.7535653114318848, "throughput": 1703.412812724067, "inference_time": 0.05438466900045569, "env_time": 0.36581925517862146, "samples": 2000}
{"epoch": 45, "reward_mean": 32.77777777777778, "student_loss": null, "teacher_policy_loss": -20.512292861938477, "teacher_value_loss": 270.4163513183594, "teacher_entropy": 0.6001142263412476, "total_time": 1.211714267730713, "rollout_time": 0.4268379211425781, "train_time": 0.7845368385314941, "throughput": 1650.554139092198, "inference_time": 0.05509087274793956, "env_time": 0.37174704839463857, "samples": 2000}
{"epoch": 46, "reward_mean": 32.17741935483871, "student_loss": null, "teacher_policy_loss": -18.115041732788086, "teacher_value_loss": 143.4082794189453, "teacher_entropy": 0.6024541258811951, "total_time": 1.2161545753479004, "rollout_time": 0.42734384536743164, "train_time": 0.7884225845336914, "throughput": 1644.5277932107176, "inference_time": 0.054979612751481, "env_time": 0.37236423261595064, "samples": 2000}
{"epoch": 47, "reward_mean": 33.59322033898305, "student_loss": null, "teacher_policy_loss": -19.44789695739746, "teacher_value_loss": 146.44281005859375, "teacher_entropy": 0.6024250984191895, "total_time": 1.1684551239013672, "rollout_time": 0.41655802726745605, "train_time": 0.7515535354614258, "throughput": 1711.6617994897217, "inference_time": 0.053585403751640115, "env_time": 0.36297262351581594, "samples": 2000}
{"epoch": 48, "reward_mean": 36.0, "student_loss": null, "teacher_policy_loss": -19.798194885253906, "teacher_value_loss": 148.93429565429688, "teacher_entropy": 0.6187419891357422, "total_time": 1.2237255573272705, "rollout_time": 0.3986802101135254, "train_time": 0.8247110843658447, "throughput": 1634.3533793379167, "inference_time": 0.05409250424958145, "env_time": 0.34458770586394394, "samples": 2000}
{"epoch": 49, "reward_mean": 34.41379310344828, "student_loss": null, "teacher_policy_loss": -18.86189079284668, "teacher_value_loss": 137.3964080810547, "teacher_entropy": 0.6187800168991089, "total_time": 1.2363612651824951, "rollout_time": 0.47524189949035645, "train_time": 0.7607235908508301, "throughput": 1617.6501612615523, "inference_time": 0.06444413549735373, "env_time": 0.4107977639930027, "samples": 2000}
{"epoch": 50, "reward_mean": 33.03225806451613, "student_loss": null, "teacher_policy_loss": -17.82776641845703, "teacher_value_loss": 146.08692932128906, "teacher_entropy": 0.6334235072135925, "total_time": 1.1004376411437988, "rollout_time": 0.4172694683074951, "train_time": 0.6828382015228271, "throughput": 1817.4587320742617, "inference_time": 0.054122055750724485, "env_time": 0.36314741255677063, "samples": 2000}
{"epoch": 51, "reward_mean": 35.054545454545455, "student_loss": null, "teacher_policy_loss": -20.429378509521484, "teacher_value_loss": 155.83103942871094, "teacher_entropy": 0.6397992372512817, "total_time": -0.24154376983642578, "rollout_time": 0.4116203784942627, "train_time": -0.6535093784332275, "throughput": 200000000000.0, "inference_time": 0.052873028248086484, "env_time": 0.3587473502461762, "samples": 2000}
{"epoch": 52, "reward_mean": 37.27777777777778, "student_loss": null, "teacher_policy_loss": -18.868986129760742, "teacher_value_loss": 119.64189147949219, "teacher_entropy": 0.6534948945045471, "total_time": 1.1497697830200195, "rollout_time": 0.4155592918395996, "train_time": 0.7338624000549316, "throughput": 1739.4786587161304, "inference_time": 0.051651082750026944, "env_time": 0.36390820908957267, "samples": 2000}
{"epoch": 53, "reward_mean": 35.758620689655174, "student_loss": null, "teacher_policy_loss": -19.138315200805664, "teacher_value_loss": 146.18344116210938, "teacher_entropy": 0.6489784121513367, "total_time": 1.1584670543670654, "rollout_time": 0.4058361053466797, "train_time": 0.7522857189178467, "throughput": 1726.4194026585508, "inference_time": 0.052185148250828206, "env_time": 0.3536509570958515, "samples": 2000}
{"epoch": 54, "reward_mean": 35.142857142857146, "student_loss": null, "teacher_policy_loss": -20.463939666748047, "teacher_value_loss": 212.28445434570312, "teacher_entropy": 0.644000232219696, "total_time": 1.215639352798462, "rollout_time": 0.4699091911315918, "train_time": 0.7453768253326416, "throughput": 1645.224790885472, "inference_time": 0.05763687550074792, "env_time": 0.4122723156308439, "samples": 2000}
{"epoch": 55, "reward_mean": 39.68, "student_loss": null, "teacher_policy_loss": -19.11174964904785, "teacher_value_loss": 129.48536682128906, "teacher_entropy": 0.6205570101737976, "total_time": 1.1339590549468994, "rollout_time": 0.4128236770629883, "train_time": 0.7207584381103516, "throughput": 1763.7321129673903, "inference_time": 0.05461585599942964, "env_time": 0.35820782106355864, "samples": 2000}
{"epoch": 56, "reward_mean": 39.67307692307692, "student_loss": null, "teacher_policy_loss": -21.976024627685547, "teacher_value_loss": 180.96702575683594, "teacher_entropy": 0.6334690451622009, "total_time": 1.295675277709961, "rollout_time": 0.4149136543273926, "train_time": 0.8804097175598145, "throughput": 1543.596635983436, "inference_time": 0.05442753399756839, "env_time": 0.3604861203298242, "samples": 2000}
{"epoch": 57, "reward_mean": 34.19642857142857, "student_loss": null, "teacher_policy_loss": -19.187957763671875, "teacher_value_loss": 172.7629852294922, "teacher_entropy": 0.5776758790016174, "total_time": 1.1235542297363281, "rollout_time": 0.4126729965209961, "train_time": 0.7105517387390137, "throughput": 1780.0653916539063, "inference_time": 0.053511955000089984, "env_time": 0.3591610415209061, "samples": 2000}
{"epoch": 58, "reward_mean": 35.07017543859649, "student_loss": null, "teacher_policy_loss": -18.71401023864746, "teacher_value_loss": 166.85902404785156, "teacher_entropy": 0.5625888109207153, "total_time": 1.1392476558685303, "rollout_time": 0.4178047180175781, "train_time": 0.7210981845855713, "throughput": 1755.544538272722, "inference_time": 0.05413211725169731, "env_time": 0.3636726007658808, "samples": 2000}
{"epoch": 59, "reward_mean": 33.3, "student_loss": null, "teacher_policy_loss": -17.764028549194336, "teacher_value_loss": 141.23696899414062, "teacher_entropy": 0.5709584951400757, "total_time": 1.2187769412994385, "rollout_time": 0.4330313205718994, "train_time": 0.7853186130523682, "throughput": 1640.9893658372264, "inference_time": 0.05659768499879192, "env_time": 0.3764336355731075, "samples": 2000}
{"epoch": 60, "reward_mean": 40.509803921568626, "student_loss": null, "teacher_policy_loss": -22.368934631347656, "teacher_value_loss": 198.5005340576172, "teacher_entropy": 0.5858262777328491, "total_time": 1.3065171241760254, "rollout_time": 0.5598623752593994, "train_time": 0.7463006973266602, "throughput": 1530.787437065802, "inference_time": 0.06016420324942828, "env_time": 0.49969817200997113, "samples": 2000}
{"epoch": 61, "reward_mean": 33.30508474576271, "student_loss": null, "teacher_policy_loss": -18.791290283203125, "teacher_value_loss": 139.64169311523438, "teacher_entropy": 0.5660643577575684, "total_time": 1.2597315311431885, "rollout_time": 0.411304235458374, "train_time": 0.8480334281921387, "throughput": 1587.6398665555575, "inference_time": 0.05361200974982694, "env_time": 0.3576922257085471, "samples": 2000}
{"epoch": 62, "reward_mean": 40.375, "student_loss": null, "teacher_policy_loss": -20.71198844909668, "teacher_value_loss": 115.54882049560547, "teacher_entropy": 0.5642666816711426, "total_time": 1.3197007179260254, "rollout_time": 0.48099350929260254, "train_time": 0.8383371829986572, "throughput": 1515.4951216084041, "inference_time": 0.059612634500524564, "env_time": 0.421380874792078, "samples": 2000}
{"epoch": 63, "reward_mean": 36.31578947368421, "student_loss": null, "teacher_policy_loss": -19.133716583251953, "teacher_value_loss": 170.1169891357422, "teacher_entropy": 0.5602486729621887, "total_time": 1.1287152767181396, "rollout_time": 0.4162285327911377, "train_time": 0.7121498584747314, "throughput": 1771.9260483611188, "inference_time": 0.05265876225058719, "env_time": 0.3635697705405505, "samples": 2000}
{"epoch": 64, "reward_mean": 35.035714285714285, "student_loss": null, "teacher_policy_loss": -18.211742401123047, "teacher_value_loss": 90.67642974853516, "teacher_entropy": 0.5735093355178833, "total_time": 1.3394272327423096, "rollout_time": 0.46550631523132324, "train_time": 0.8735442161560059, "throughput": 1493.175553781485, "inference_time": 0.06044224049986724, "env_time": 0.405064074731456, "samples": 2000}
{"epoch": 65, "reward_mean": 34.48275862068966, "student_loss": null, "teacher_policy_loss": -18.08936882019043, "teacher_value_loss": 108.79498291015625, "teacher_entropy": 0.5759639739990234, "total_time": 1.216357707977295, "rollout_time": 0.4249699115753174, "train_time": 0.7910122871398926, "throughput": 1644.253155863039, "inference_time": 0.052994005000641664, "env_time": 0.3719759065746757, "samples": 2000}
{"epoch": 66, "reward_mean": 32.17741935483871, "student_loss": null, "teacher_policy_loss": -17.695091247558594, "teacher_value_loss": 115.75190734863281, "teacher_entropy": 0.5881407856941223, "total_time": 1.2317728996276855, "rollout_time": 0.418445348739624, "train_time": 0.8129861354827881, "throughput": 1623.6759232197087, "inference_time": 0.05362973049955144, "env_time": 0.3648156182400726, "samples": 2000}
{"epoch": 67, "reward_mean": 38.15686274509804, "student_loss": null, "teacher_policy_loss": -21.01771354675293, "teacher_value_loss": 159.81483459472656, "teacher_entropy": 0.6136875152587891, "total_time": 1.2691431045532227, "rollout_time": 0.5573279857635498, "train_time": 0.7113983631134033, "throughput": 1575.8664194957444, "inference_time": 0.08780621775156305, "env_time": 0.46952176801198675, "samples": 2000}
{"epoch": 68, "reward_mean": 35.89655172413793, "student_loss": null, "teacher_policy_loss": -18.17981719970703, "teacher_value_loss": 115.68053436279297, "teacher_entropy": 0.6045048832893372, "total_time": 1.313521146774292, "rollout_time": 0.5305187702178955, "train_time": 0.7826516628265381, "throughput": 1522.6248963798896, "inference_time": 0.05348094900028855, "env_time": 0.47703782121760696, "samples": 2000}
{"epoch": 69, "reward_mean": 38.80392156862745, "student_loss": null, "teacher_policy_loss": -19.88416290283203, "teacher_value_loss": 97.74325561523438, "teacher_entropy": 0.6393551826477051, "total_time": 1.3834328651428223, "rollout_time": 0.5710523128509521, "train_time": 0.812035322189331, "throughput": 1445.6791148976533, "inference_time": 0.09112122500022224, "env_time": 0.4799310878507299, "samples": 2000}
{"epoch": 70, "reward_mean": 34.20338983050848, "student_loss": null, "teacher_policy_loss": -17.503591537475586, "teacher_value_loss": 114.90939331054688, "teacher_entropy": 0.6144641041755676, "total_time": 1.166565179824829, "rollout_time": 0.419248104095459, "train_time": 0.7469758987426758, "throughput": 1714.4348507816076, "inference_time": 0.05264538799792717, "env_time": 0.3666027160975318, "samples": 2000}
{"epoch": 71, "reward_mean": 35.63157894736842, "student_loss": null, "teacher_policy_loss": -17.90664291381836, "teacher_value_loss": 136.28382873535156, "teacher_entropy": 0.6139963269233704, "total_time": 1.2115328311920166, "rollout_time": 0.41724491119384766, "train_time": 0.793942928314209, "throughput": 1650.8013225132474, "inference_time": 0.05272655200116105, "env_time": 0.3645183591926866, "samples": 2000}
{"epoch": 72, "reward_mean": 38.46, "student_loss": null, "teacher_policy_loss": -19.988235473632812, "teacher_value_loss": 114.68028259277344, "teacher_entropy": 0.6503824591636658, "total_time": 1.200852870941162, "rollout_time": 0.4218170642852783, "train_time": 0.7786569595336914, "throughput": 1665.48296498014, "inference_time": 0.05176568075120258, "env_time": 0.37005138353407574, "samples": 2000}
{"epoch": 73, "reward_mean": 45.32608695652174, "student_loss": null, "teacher_policy_loss": -22.678068161010742, "teacher_value_loss": 253.7864532470703, "teacher_entropy": 0.6261338591575623, "total_time": 1.1695582866668701, "rollout_time": 0.42886972427368164, "train_time": 0.7403128147125244, "throughput": 1710.0473082874817, "inference_time": 0.054360331500163284, "env_time": 0.37450939277351836, "samples": 2000}
{"epoch": 74, "reward_mean": 45.02439024390244, "student_loss": null, "teacher_policy_loss": -21.546749114990234, "teacher_value_loss": 173.00897216796875, "teacher_entropy": 0.5774939656257629, "total_time": 1.2712891101837158, "rollout_time": 0.42835116386413574, "train_time": 0.842587947845459, "throughput": 1573.2062706892668, "inference_time": 0.052982191502621845, "env_time": 0.3753689723615139, "samples": 2000}
{"epoch": 75, "reward_mean": 39.72222222222222, "student_loss": null, "teacher_policy_loss": -19.4657039642334, "teacher_value_loss": 143.30545043945312, "teacher_entropy": 0.6066291928291321, "total_time": 1.126410961151123, "rollout_time": 0.4035158157348633, "train_time": 0.7225117683410645, "throughput": 1775.5509036915998, "inference_time": 0.05145009350019336, "env_time": 0.3520657222346699, "samples": 2000}
{"epoch": 76, "reward_mean": 38.44230769230769, "student_loss": null, "teacher_policy_loss": -20.826641082763672, "teacher_value_loss": 147.8979034423828, "teacher_entropy": 0.6251741647720337, "total_time": 1.1993937492370605, "rollout_time": 0.403062105178833, "train_time": 0.7959978580474854, "throughput": 1667.509107223719, "inference_time": 0.05285958950025815, "env_time": 0.35020251567857485, "samples": 2000}
{"epoch": 77, "reward_mean": 41.48936170212766, "student_loss": null, "teacher_policy_loss": -19.785261154174805, "teacher_value_loss": 161.15870666503906, "teacher_entropy": 0.5663818120956421, "total_time": 1.1578710079193115, "rollout_time": 0.41795992851257324, "train_time": 0.7395687103271484, "throughput": 1727.3081252755348, "inference_time": 0.05224835474808742, "env_time": 0.3657115737644858, "samples": 2000}
{"epoch": 78, "reward_mean": 41.12, "student_loss": null, "teacher_policy_loss": -19.475664138793945, "teacher_value_loss": 144.5748748779297, "teacher_entropy": 0.5803169012069702, "total_time": -0.4354262351989746, "rollout_time": -1.1373851299285889, "train_time": 0.70162034034729, "throughput": 200000000000.0, "inference_time": 0.051399918749268636, "env_time": 0.0, "samples": 2000}
{"epoch": 79, "reward_mean": 39.1, "student_loss": null, "teacher_policy_loss": -20.452285766601562, "teacher_value_loss": 112.71741485595703, "teacher_entropy": 0.6239806413650513, "total_time": 1.2617628574371338, "rollout_time": 0.4099700450897217, "train_time": 0.8513894081115723, "throughput": 1585.0839071791652, "inference_time": 0.05226349750120107, "env_time": 0.3577065475885206, "samples": 2000}
{"epoch": 80, "reward_mean": 41.791666666666664, "student_loss": null, "teacher_policy_loss": -20.333824157714844, "teacher_value_loss": 122.79302978515625, "teacher_entropy": 0.6052214503288269, "total_time": 1.1551809310913086, "rollout_time": 0.41676950454711914, "train_time": 0.7380211353302002, "throughput": 1731.330518164444, "inference_time": 0.052451021000536, "env_time": 0.36431848354658314, "samples": 2000}
{"epoch": 81, "reward_mean": 40.2, "student_loss": null, "teacher_policy_loss": -20.845170974731445, "teacher_value_loss": 180.38880920410156, "teacher_entropy": 0.5940921306610107, "total_time": 1.1212363243103027, "rollout_time": 0.4270200729370117, "train_time": 0.6938772201538086, "throughput": 1783.7452788824373, "inference_time": 0.05582545174979714, "env_time": 0.3711946211872146, "samples": 2000}
{"epoch": 82, "reward_mean": 37.39622641509434, "student_loss": null, "teacher_policy_loss": -19.37152862548828, "teacher_value_loss": 103.41044616699219, "teacher_entropy": 0.6034546494483948, "total_time": 1.4376351833343506, "rollout_time": 0.4284815788269043, "train_time": 1.008819818496704, "throughput": 1391.1735210607046, "inference_time": 0.05483712649942163, "env_time": 0.37364445232748267, "samples": 2000}
{"epoch": 83, "reward_mean": 35.6140350877193, "student_loss": null, "teacher_policy_loss": -18.172382354736328, "teacher_value_loss": 90.90833282470703, "teacher_entropy": 0.5986985564231873, "total_time": 1.3441755771636963, "rollout_time": 0.43380260467529297, "train_time": 0.9100267887115479, "throughput": 1487.900862043736, "inference_time": 0.0574150960010229, "env_time": 0.37638750867427007, "samples": 2000}
{"epoch": 84, "reward_mean": 36.236363636363635, "student_loss": null, "teacher_policy_loss": -18.707393646240234, "teacher_value_loss": 98.55146026611328, "teacher_entropy": 0.5912492871284485, "total_time": 1.3180806636810303, "rollout_time": 0.4383385181427002, "train_time": 0.8793940544128418, "throughput": 1517.3578181585335, "inference_time": 0.057452023500047744, "env_time": 0.38088649464265245, "samples": 2000}
{"epoch": 85, "reward_mean": 37.22222222222222, "student_loss": null, "teacher_policy_loss": -20.31927490234375, "teacher_value_loss": 148.11395263671875, "teacher_entropy": 0.5860095024108887, "total_time": 1.1478321552276611, "rollout_time": 0.43543362617492676, "train_time": 0.7120683193206787, "throughput": 1742.4150307091893, "inference_time": 0.05702499049925791, "env_time": 0.37840863567566885, "samples": 2000}
{"epoch": 86, "reward_mean": 41.0, "student_loss": null, "teacher_policy_loss": -21.618146896362305, "teacher_value_loss": 151.23004150390625, "teacher_entropy": 0.5880085229873657, "total_time": 1.1912693977355957, "rollout_time": 0.4216902256011963, "train_time": 0.7692058086395264, "throughput": 1678.8813712512604, "inference_time": 0.05534987124849522, "env_time": 0.36634035435270107, "samples": 2000}
{"epoch": 87, "reward_mean": 49.146341463414636, "student_loss": null, "teacher_policy_loss": -25.7033634185791, "teacher_value_loss": 286.6884460449219, "teacher_entropy": 0.5773391127586365, "total_time": 1.2691731452941895, "rollout_time": 0.43625450134277344, "train_time": 0.8325674533843994, "throughput": 1575.8291194669168, "inference_time": 0.056485177749948434, "env_time": 0.379769323592825, "samples": 2000}
{"epoch": 88, "reward_mean": 36.5, "student_loss": null, "teacher_policy_loss": -19.587636947631836, "teacher_value_loss": 126.8246841430664, "teacher_entropy": 0.5601934194564819, "total_time": 1.269252061843872, "rollout_time": 0.4369058609008789, "train_time": 0.831965446472168, "throughput": 1575.7311412947822, "inference_time": 0.054224836500679885, "env_time": 0.382681024400199, "samples": 2000}
{"epoch": 89, "reward_mean": 36.16981132075472, "student_loss": null, "teacher_policy_loss": -20.469558715820312, "teacher_value_loss": 191.35006713867188, "teacher_entropy": 0.5628637671470642, "total_time": 1.3980920314788818, "rollout_time": 0.4553537368774414, "train_time": 0.9422440528869629, "throughput": 1430.520992158455, "inference_time": 0.06105213249941244, "env_time": 0.39430160437802897, "samples": 2000}
{"epoch": 90, "reward_mean": 45.297872340425535, "student_loss": null, "teacher_policy_loss": -21.97132682800293, "teacher_value_loss": 169.71310424804688, "teacher_entropy": 0.5582746267318726, "total_time": 1.2603206634521484, "rollout_time": 0.44144511222839355, "train_time": 0.8185222148895264, "throughput": 1586.8977300759263, "inference_time": 0.0575569817490873, "env_time": 0.38388813047930626, "samples": 2000}
{"epoch": 91, "reward_mean": 49.473684210526315, "student_loss": null, "teacher_policy_loss": -24.7690372467041, "teacher_value_loss": 168.98194885253906, "teacher_entropy": 0.5611985325813293, "total_time": 1.2258214950561523, "rollout_time": 0.43154406547546387, "train_time": 0.7939045429229736, "throughput": 1631.5589244161395, "inference_time": 0.05443339400011382, "env_time": 0.37711067147535005, "samples": 2000}
{"epoch": 92, "reward_mean": 50.24390243902439, "student_loss": null, "teacher_policy_loss": -24.641157150268555, "teacher_value_loss": 238.19712829589844, "teacher_entropy": 0.5607042908668518, "total_time": 1.3277828693389893, "rollout_time": 0.4942793846130371, "train_time": 0.8330855369567871, "throughput": 1506.270374610015, "inference_time": 0.06864490224796782, "env_time": 0.4256344823650693, "samples": 2000}
