{"epoch": 1, "reward_mean": 20.0, "student_loss": null, "teacher_policy_loss": -9.307677268981934, "teacher_value_loss": 223.33978271484375, "teacher_entropy": 0.40323910117149353, "total_time": 1.508805513381958, "rollout_time": 0.45920228958129883, "train_time": 0.9621548652648926, "student_train_time": 0.08707141876220703, "throughput": 1325.551890062384, "inference_time": 0.06464761002098385, "env_time": 0.394554679560315, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 2, "reward_mean": 17.301724137931036, "student_loss": null, "teacher_policy_loss": -9.394078254699707, "teacher_value_loss": 76.79851531982422, "teacher_entropy": 0.6331392526626587, "total_time": 1.2605342864990234, "rollout_time": 0.43346500396728516, "train_time": 0.8163862228393555, "student_train_time": 0.0102691650390625, "throughput": 1586.6287981382484, "inference_time": 0.05441724823140248, "env_time": 0.3790477557358827, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 3, "reward_mean": 17.025210084033613, "student_loss": null, "teacher_policy_loss": -7.008486270904541, "teacher_value_loss": 61.43183898925781, "teacher_entropy": 0.12668846547603607, "total_time": 1.3610217571258545, "rollout_time": 0.45076680183410645, "train_time": 0.8929803371429443, "student_train_time": 0.016904115676879883, "throughput": 1469.484223546515, "inference_time": 0.05641786822980066, "env_time": 0.3943489336043058, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 4, "reward_mean": 19.959183673469386, "student_loss": null, "teacher_policy_loss": -7.64593505859375, "teacher_value_loss": 95.77996063232422, "teacher_entropy": 0.046733058989048004, "total_time": 1.3466951847076416, "rollout_time": 0.517524003982544, "train_time": 0.7441377639770508, "student_train_time": 0.08465695381164551, "throughput": 1485.117064879226, "inference_time": 0.0608724477551732, "env_time": 0.45665155622737075, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 5, "reward_mean": 19.764705882352942, "student_loss": null, "teacher_policy_loss": -7.906339645385742, "teacher_value_loss": 77.5546875, "teacher_entropy": 0.01812763512134552, "total_time": 1.3118760585784912, "rollout_time": 0.4464125633239746, "train_time": 0.8578915596008301, "student_train_time": 0.0070955753326416016, "throughput": 1524.5342629143936, "inference_time": 0.05598176651801623, "env_time": 0.3904307968059584, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 6, "reward_mean": 19.08653846153846, "student_loss": null, "teacher_policy_loss": -7.3347086906433105, "teacher_value_loss": 63.41733169555664, "teacher_entropy": 0.006583060137927532, "total_time": 1.2177929878234863, "rollout_time": 0.43238043785095215, "train_time": 0.7771248817443848, "student_train_time": 0.007926702499389648, "throughput": 1642.3152539041316, "inference_time": 0.05492046399922401, "env_time": 0.37745997385172814, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 7, "reward_mean": 21.326315789473686, "student_loss": null, "teacher_policy_loss": -7.578060626983643, "teacher_value_loss": 62.843502044677734, "teacher_entropy": 0.00342112616635859, "total_time": 1.352025032043457, "rollout_time": 0.44452857971191406, "train_time": 0.8991904258728027, "student_train_time": 0.007880926132202148, "throughput": 1479.2625525410506, "inference_time": 0.05580218327486364, "env_time": 0.3887263964370504, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 8, "reward_mean": 18.62037037037037, "student_loss": null, "teacher_policy_loss": -6.912698268890381, "teacher_value_loss": 39.85958480834961, "teacher_entropy": 0.0021574893034994602, "total_time": 1.2641055583953857, "rollout_time": 0.4529850482940674, "train_time": 0.7929682731628418, "student_train_time": 0.017769575119018555, "throughput": 1582.1463537734417, "inference_time": 0.05657021075148805, "env_time": 0.39641483754257933, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 9, "reward_mean": 17.74774774774775, "student_loss": null, "teacher_policy_loss": -7.065279960632324, "teacher_value_loss": 28.35057830810547, "teacher_entropy": 0.0019300701096653938, "total_time": 1.2517404556274414, "rollout_time": 0.45742273330688477, "train_time": 0.7799665927886963, "student_train_time": 0.013981103897094727, "throughput": 1597.7753143701739, "inference_time": 0.05710983101562306, "env_time": 0.4003129022912617, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 10, "reward_mean": 22.130434782608695, "student_loss": null, "teacher_policy_loss": -8.763443946838379, "teacher_value_loss": 98.73410034179688, "teacher_entropy": 0.00143233104608953, "total_time": 1.3113420009613037, "rollout_time": 0.45966529846191406, "train_time": 0.8358056545257568, "student_train_time": 0.015427112579345703, "throughput": 1525.155145289225, "inference_time": 0.057017745297343936, "env_time": 0.4026475531645701, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 11, "reward_mean": 20.04040404040404, "student_loss": null, "teacher_policy_loss": -7.563253879547119, "teacher_value_loss": 43.92336654663086, "teacher_entropy": 0.0008693942800164223, "total_time": 1.2376506328582764, "rollout_time": 0.46746039390563965, "train_time": 0.7630355358123779, "student_train_time": 0.0066928863525390625, "throughput": 1615.9649152209663, "inference_time": 0.05749238222688291, "env_time": 0.40996801167875674, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 12, "reward_mean": 19.62135922330097, "student_loss": null, "teacher_policy_loss": -7.04327917098999, "teacher_value_loss": 38.823646545410156, "teacher_entropy": 0.0005105176824145019, "total_time": 1.4063301086425781, "rollout_time": 0.47997140884399414, "train_time": 0.9110255241394043, "student_train_time": 0.014960527420043945, "throughput": 1422.1412083187536, "inference_time": 0.05709566676614486, "env_time": 0.4228757420778493, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 13, "reward_mean": 19.147058823529413, "student_loss": null, "teacher_policy_loss": -7.8320631980896, "teacher_value_loss": 50.62147521972656, "teacher_entropy": 0.0004087855340912938, "total_time": 1.257589340209961, "rollout_time": 0.45058774948120117, "train_time": 0.7937369346618652, "student_train_time": 0.012841463088989258, "throughput": 1590.3442690330771, "inference_time": 0.05559398575860541, "env_time": 0.39499376372259576, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 14, "reward_mean": 19.160377358490567, "student_loss": null, "teacher_policy_loss": -7.674473762512207, "teacher_value_loss": 76.57298278808594, "teacher_entropy": 0.0005433580372482538, "total_time": 1.3074724674224854, "rollout_time": 0.45714807510375977, "train_time": 0.8406116962432861, "student_train_time": 0.009334802627563477, "throughput": 1529.6689221630372, "inference_time": 0.0564777967720147, "env_time": 0.40067027833174507, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 15, "reward_mean": 20.24742268041237, "student_loss": null, "teacher_policy_loss": -8.003409385681152, "teacher_value_loss": 52.626094818115234, "teacher_entropy": 0.000705196987837553, "total_time": 1.2784059047698975, "rollout_time": 0.4532911777496338, "train_time": 0.8082990646362305, "student_train_time": 0.016384124755859375, "throughput": 1564.4483434703657, "inference_time": 0.055129109487097594, "env_time": 0.3981620682625362, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 16, "reward_mean": 20.168316831683168, "student_loss": null, "teacher_policy_loss": -7.674155235290527, "teacher_value_loss": 53.62550354003906, "teacher_entropy": 0.0007575265481136739, "total_time": 1.3365874290466309, "rollout_time": 0.45374226570129395, "train_time": 0.8762879371643066, "student_train_time": 0.006139278411865234, "throughput": 1496.3480551560867, "inference_time": 0.05701681048867613, "env_time": 0.3967254552126178, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 17, "reward_mean": 20.350515463917525, "student_loss": null, "teacher_policy_loss": -7.69878625869751, "teacher_value_loss": 49.16153335571289, "teacher_entropy": 0.000577483035158366, "total_time": 1.3557560443878174, "rollout_time": 0.4585700035095215, "train_time": 0.8823456764221191, "student_train_time": 0.014471292495727539, "throughput": 1475.191652863393, "inference_time": 0.05537804474988661, "env_time": 0.40319195875963487, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 18, "reward_mean": 19.940594059405942, "student_loss": null, "teacher_policy_loss": -7.169477462768555, "teacher_value_loss": 37.33260726928711, "teacher_entropy": 0.0005329547566361725, "total_time": 1.2789902687072754, "rollout_time": 0.4615628719329834, "train_time": 0.8023626804351807, "student_train_time": 0.014515876770019531, "throughput": 1563.7335552376617, "inference_time": 0.05877478127604263, "env_time": 0.40278809065694077, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 19, "reward_mean": 21.35164835164835, "student_loss": null, "teacher_policy_loss": -8.451187133789062, "teacher_value_loss": 71.70172119140625, "teacher_entropy": 0.0005880185635760427, "total_time": 1.2620594501495361, "rollout_time": 0.4310641288757324, "train_time": 0.8183891773223877, "student_train_time": 0.011948347091674805, "throughput": 1584.7114014819415, "inference_time": 0.05323085724921839, "env_time": 0.37783327162651403, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 20, "reward_mean": 20.92929292929293, "student_loss": null, "teacher_policy_loss": -7.6700119972229, "teacher_value_loss": 61.33808517456055, "teacher_entropy": 0.0005659329472109675, "total_time": 1.2364110946655273, "rollout_time": 0.4439668655395508, "train_time": 0.7628040313720703, "student_train_time": 0.02924942970275879, "throughput": 1617.5849671917074, "inference_time": 0.05503539073015418, "env_time": 0.3889314748093966, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 21, "reward_mean": 21.010752688172044, "student_loss": null, "teacher_policy_loss": -8.200552940368652, "teacher_value_loss": 53.15016555786133, "teacher_entropy": 0.0006559486500918865, "total_time": 1.2130866050720215, "rollout_time": 0.4502854347229004, "train_time": 0.753143310546875, "student_train_time": 0.009301185607910156, "throughput": 1648.6869046594238, "inference_time": 0.056999813743459526, "env_time": 0.39328562097944086, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 22, "reward_mean": 20.11111111111111, "student_loss": null, "teacher_policy_loss": -7.620150566101074, "teacher_value_loss": 42.64967727661133, "teacher_entropy": 0.0008057529921643436, "total_time": -1.290351390838623, "rollout_time": -2.1567516326904297, "train_time": 0.8569447994232178, "student_train_time": 0.009081602096557617, "throughput": 200000000000.0, "inference_time": 0.05645668852957897, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 23, "reward_mean": 20.0, "student_loss": null, "teacher_policy_loss": -7.710951328277588, "teacher_value_loss": 44.1644287109375, "teacher_entropy": 0.0008394347387365997, "total_time": 1.4550409317016602, "rollout_time": 0.5563228130340576, "train_time": 0.8432102203369141, "student_train_time": 0.05512690544128418, "throughput": 1374.5317787459176, "inference_time": 0.06470544350213459, "env_time": 0.49161736953192303, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 24, "reward_mean": 20.71276595744681, "student_loss": null, "teacher_policy_loss": -8.428239822387695, "teacher_value_loss": 81.1161117553711, "teacher_entropy": 0.0009033397072926164, "total_time": 1.37166428565979, "rollout_time": 0.45871472358703613, "train_time": 0.903146505355835, "student_train_time": 0.009432077407836914, "throughput": 1458.0827254228402, "inference_time": 0.05648950196700753, "env_time": 0.4022252216200286, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 25, "reward_mean": 20.969072164948454, "student_loss": null, "teacher_policy_loss": -8.210809707641602, "teacher_value_loss": 55.573551177978516, "teacher_entropy": 0.00071672850754112, "total_time": 1.3336191177368164, "rollout_time": 0.44422054290771484, "train_time": 0.8761789798736572, "student_train_time": 0.012845277786254883, "throughput": 1499.6785614426763, "inference_time": 0.05403178076903714, "env_time": 0.3901887621386777, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 26, "reward_mean": 19.89108910891089, "student_loss": null, "teacher_policy_loss": -7.242799282073975, "teacher_value_loss": 41.692771911621094, "teacher_entropy": 0.0007923721568658948, "total_time": 1.2722053527832031, "rollout_time": 0.4491300582885742, "train_time": 0.8099963665008545, "student_train_time": 0.012707948684692383, "throughput": 1572.0732471566803, "inference_time": 0.058225869734997104, "env_time": 0.3909041885535771, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 27, "reward_mean": 22.043956043956044, "student_loss": null, "teacher_policy_loss": -8.224952697753906, "teacher_value_loss": 63.58675765991211, "teacher_entropy": 0.0010413608979433775, "total_time": 1.2598798274993896, "rollout_time": 0.4547441005706787, "train_time": 0.7861218452453613, "student_train_time": 0.018621206283569336, "throughput": 1587.4529906313378, "inference_time": 0.05618919323933369, "env_time": 0.398554907331345, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 28, "reward_mean": 22.78409090909091, "student_loss": null, "teacher_policy_loss": -8.407421112060547, "teacher_value_loss": 59.20176696777344, "teacher_entropy": 0.0010159624507650733, "total_time": 1.2689952850341797, "rollout_time": 0.44228124618530273, "train_time": 0.8140909671783447, "student_train_time": 0.012266874313354492, "throughput": 1576.049985044768, "inference_time": 0.058656389744101034, "env_time": 0.3836248564412017, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 29, "reward_mean": 25.29113924050633, "student_loss": null, "teacher_policy_loss": -9.819162368774414, "teacher_value_loss": 123.20600128173828, "teacher_entropy": 0.000806821568403393, "total_time": 1.3079192638397217, "rollout_time": 0.44676828384399414, "train_time": 0.8498196601867676, "student_train_time": 0.010924577713012695, "throughput": 1529.1463741641846, "inference_time": 0.054359413999918615, "env_time": 0.3924088698440755, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 30, "reward_mean": 21.06451612903226, "student_loss": null, "teacher_policy_loss": -8.144200325012207, "teacher_value_loss": 62.55636978149414, "teacher_entropy": 0.0005372338346205652, "total_time": 1.2567391395568848, "rollout_time": 0.4479074478149414, "train_time": 0.7928366661071777, "student_train_time": 0.01552724838256836, "throughput": 1591.4201579694434, "inference_time": 0.05599172472375358, "env_time": 0.39191572309118783, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 31, "reward_mean": 22.087912087912088, "student_loss": null, "teacher_policy_loss": -7.880899906158447, "teacher_value_loss": 58.231258392333984, "teacher_entropy": 0.0004482680233195424, "total_time": 1.4645946025848389, "rollout_time": 0.4398233890533447, "train_time": 1.0143883228302002, "student_train_time": 0.009967803955078125, "throughput": 1365.5655950597065, "inference_time": 0.05552827098472335, "env_time": 0.3842951180686214, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 32, "reward_mean": 22.51685393258427, "student_loss": null, "teacher_policy_loss": -8.473514556884766, "teacher_value_loss": 66.11013793945312, "teacher_entropy": 0.0005349472630769014, "total_time": 1.2884511947631836, "rollout_time": 0.4614684581756592, "train_time": 0.8136653900146484, "student_train_time": 0.012752056121826172, "throughput": 1552.2512673579372, "inference_time": 0.055494743271992775, "env_time": 0.4059737149036664, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 33, "reward_mean": 21.741573033707866, "student_loss": null, "teacher_policy_loss": -8.34296703338623, "teacher_value_loss": 67.37246704101562, "teacher_entropy": 0.0007847003871574998, "total_time": 1.2913360595703125, "rollout_time": 0.48136115074157715, "train_time": 0.8014266490936279, "student_train_time": 0.008188724517822266, "throughput": 1548.7835139254864, "inference_time": 0.058344686779491894, "env_time": 0.42301646396208525, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 34, "reward_mean": 23.53932584269663, "student_loss": null, "teacher_policy_loss": -8.651363372802734, "teacher_value_loss": 84.98100280761719, "teacher_entropy": 0.0013556435005739331, "total_time": 1.2910380363464355, "rollout_time": 0.45920896530151367, "train_time": 0.8191728591918945, "student_train_time": 0.012284040451049805, "throughput": 1549.1410351161198, "inference_time": 0.057520984716575185, "env_time": 0.4016879805849385, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 35, "reward_mean": 24.098765432098766, "student_loss": null, "teacher_policy_loss": -8.921357154846191, "teacher_value_loss": 77.58207702636719, "teacher_entropy": 0.0016835517017170787, "total_time": 1.294661521911621, "rollout_time": 0.4524383544921875, "train_time": 0.8289735317230225, "student_train_time": 0.012835264205932617, "throughput": 1544.8053148647823, "inference_time": 0.056256581239722436, "env_time": 0.39618177325246506, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 36, "reward_mean": 21.870967741935484, "student_loss": null, "teacher_policy_loss": -7.921395301818848, "teacher_value_loss": 54.236698150634766, "teacher_entropy": 0.001814311370253563, "total_time": 1.3449082374572754, "rollout_time": 0.4473757743835449, "train_time": 0.8826074600219727, "student_train_time": 0.014564275741577148, "throughput": 1487.0903042286818, "inference_time": 0.05516892876494239, "env_time": 0.39220684561860253, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 37, "reward_mean": 21.813186813186814, "student_loss": null, "teacher_policy_loss": -7.704216003417969, "teacher_value_loss": 43.761959075927734, "teacher_entropy": 0.001525629311800003, "total_time": 1.2508807182312012, "rollout_time": 0.46196413040161133, "train_time": 0.7799968719482422, "student_train_time": 0.008485078811645508, "throughput": 1598.87347438538, "inference_time": 0.059357462983825826, "env_time": 0.4026066674177855, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 38, "reward_mean": 21.86813186813187, "student_loss": null, "teacher_policy_loss": -7.9620280265808105, "teacher_value_loss": 52.0833854675293, "teacher_entropy": 0.0016113927122205496, "total_time": 1.30185866355896, "rollout_time": 0.45934200286865234, "train_time": 0.8324708938598633, "student_train_time": 0.009681940078735352, "throughput": 1536.2650769880765, "inference_time": 0.06234070299160521, "env_time": 0.39700129987704713, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 39, "reward_mean": 25.20253164556962, "student_loss": null, "teacher_policy_loss": -9.112404823303223, "teacher_value_loss": 73.9754867553711, "teacher_entropy": 0.0019234450301155448, "total_time": 1.2867064476013184, "rollout_time": 0.44460320472717285, "train_time": 0.8063607215881348, "student_train_time": 0.035186767578125, "throughput": 1554.3560877684304, "inference_time": 0.05762859520564234, "env_time": 0.3869746095215305, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 40, "reward_mean": 22.517241379310345, "student_loss": null, "teacher_policy_loss": -8.818756103515625, "teacher_value_loss": 67.96939086914062, "teacher_entropy": 0.0017843234818428755, "total_time": 1.2544732093811035, "rollout_time": 0.45012950897216797, "train_time": 0.7954962253570557, "student_train_time": 0.008437395095825195, "throughput": 1594.2947087620175, "inference_time": 0.05666561776160961, "env_time": 0.39346389121055836, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 41, "reward_mean": 23.28409090909091, "student_loss": null, "teacher_policy_loss": -8.469892501831055, "teacher_value_loss": 67.687744140625, "teacher_entropy": 0.0015865213936194777, "total_time": 1.577660322189331, "rollout_time": 0.45565342903137207, "train_time": 1.11140775680542, "student_train_time": 0.010161876678466797, "throughput": 1267.7000060599769, "inference_time": 0.06022564949216758, "env_time": 0.3954277795392045, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 42, "reward_mean": 25.734177215189874, "student_loss": null, "teacher_policy_loss": -9.012181282043457, "teacher_value_loss": 53.259857177734375, "teacher_entropy": 0.0015968203078955412, "total_time": 1.3422677516937256, "rollout_time": 0.44812750816345215, "train_time": 0.8868341445922852, "student_train_time": 0.006614208221435547, "throughput": 1490.0156823974369, "inference_time": 0.056000298505750834, "env_time": 0.3921272096577013, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 43, "reward_mean": 26.293333333333333, "student_loss": null, "teacher_policy_loss": -9.258951187133789, "teacher_value_loss": 78.77554321289062, "teacher_entropy": 0.001737538375891745, "total_time": 1.3106906414031982, "rollout_time": 0.4486124515533447, "train_time": 0.8540887832641602, "student_train_time": 0.007598876953125, "throughput": 1525.913084920513, "inference_time": 0.056831398750546214, "env_time": 0.3917810528027985, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 44, "reward_mean": 23.471264367816094, "student_loss": null, "teacher_policy_loss": -8.649534225463867, "teacher_value_loss": 61.636802673339844, "teacher_entropy": 0.0019498311448842287, "total_time": 1.2377197742462158, "rollout_time": 0.4482285976409912, "train_time": 0.7821571826934814, "student_train_time": 0.00698399543762207, "throughput": 1615.8746443378275, "inference_time": 0.05676766049055004, "env_time": 0.39146093715044117, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 45, "reward_mean": 21.439560439560438, "student_loss": null, "teacher_policy_loss": -8.114872932434082, "teacher_value_loss": 67.9780502319336, "teacher_entropy": 0.00241394923068583, "total_time": -1.3263154029846191, "rollout_time": 0.43639707565307617, "train_time": -1.7808642387390137, "student_train_time": 0.017739057540893555, "throughput": 200000000000.0, "inference_time": 0.054295876983815106, "env_time": 0.38210119866926107, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 46, "reward_mean": 23.302325581395348, "student_loss": null, "teacher_policy_loss": -8.310901641845703, "teacher_value_loss": 49.92359161376953, "teacher_entropy": 0.003051891690120101, "total_time": 1.312972068786621, "rollout_time": 0.46107959747314453, "train_time": 0.8429994583129883, "student_train_time": 0.008483171463012695, "throughput": 1523.2616500732522, "inference_time": 0.05510205247992417, "env_time": 0.40597754499322036, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 47, "reward_mean": 24.345238095238095, "student_loss": null, "teacher_policy_loss": -8.606144905090332, "teacher_value_loss": 50.002376556396484, "teacher_entropy": 0.004748875740915537, "total_time": 1.226130485534668, "rollout_time": 0.43646907806396484, "train_time": 0.776465892791748, "student_train_time": 0.012823820114135742, "throughput": 1631.1477641206168, "inference_time": 0.05357454425029573, "env_time": 0.3828945338136691, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 48, "reward_mean": 23.962962962962962, "student_loss": null, "teacher_policy_loss": -9.26402759552002, "teacher_value_loss": 98.52323150634766, "teacher_entropy": 0.005539228208363056, "total_time": 1.3452723026275635, "rollout_time": 0.4382779598236084, "train_time": 0.9001312255859375, "student_train_time": 0.006514549255371094, "throughput": 1486.6878594717466, "inference_time": 0.055462244505179115, "env_time": 0.3828157153184293, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 49, "reward_mean": 25.51948051948052, "student_loss": null, "teacher_policy_loss": -9.6736478805542, "teacher_value_loss": 114.18916320800781, "teacher_entropy": 0.005487757734954357, "total_time": 1.2759757041931152, "rollout_time": 0.43912816047668457, "train_time": 0.8270668983459473, "student_train_time": 0.009417057037353516, "throughput": 1567.4279638927246, "inference_time": 0.05575302574379748, "env_time": 0.3833751347328871, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 50, "reward_mean": 24.879518072289155, "student_loss": null, "teacher_policy_loss": -8.96970272064209, "teacher_value_loss": 80.62812805175781, "teacher_entropy": 0.0046505918726325035, "total_time": 1.4209222793579102, "rollout_time": 0.48951244354248047, "train_time": 0.889291524887085, "student_train_time": 0.041687726974487305, "throughput": 1407.5365198044224, "inference_time": 0.06393346849199588, "env_time": 0.4255789750504846, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 51, "reward_mean": 24.378048780487806, "student_loss": null, "teacher_policy_loss": -8.45215129852295, "teacher_value_loss": 61.82240295410156, "teacher_entropy": 0.0033587615471333265, "total_time": 1.2650678157806396, "rollout_time": 0.4503459930419922, "train_time": 0.8007011413574219, "student_train_time": 0.01360940933227539, "throughput": 1580.942914721021, "inference_time": 0.057043888249609154, "env_time": 0.39330210479238303, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 52, "reward_mean": 26.025641025641026, "student_loss": null, "teacher_policy_loss": -9.660486221313477, "teacher_value_loss": 97.33866882324219, "teacher_entropy": 0.0028904268983751535, "total_time": 1.2985634803771973, "rollout_time": 0.4770636558532715, "train_time": 0.8015625476837158, "student_train_time": 0.01956939697265625, "throughput": 1540.1634423132357, "inference_time": 0.06050581875115313, "env_time": 0.41655783710211836, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 53, "reward_mean": 26.445945945945947, "student_loss": null, "teacher_policy_loss": -9.532230377197266, "teacher_value_loss": 87.64750671386719, "teacher_entropy": 0.003193845972418785, "total_time": 1.3549668788909912, "rollout_time": 0.47097015380859375, "train_time": 0.8779520988464355, "student_train_time": 0.005526542663574219, "throughput": 1476.0508401776974, "inference_time": 0.06060945951321628, "env_time": 0.41036069429537747, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 54, "reward_mean": 27.549295774647888, "student_loss": null, "teacher_policy_loss": -9.484596252441406, "teacher_value_loss": 78.97492980957031, "teacher_entropy": 0.004228217992931604, "total_time": 1.3148603439331055, "rollout_time": 0.4444580078125, "train_time": 0.8532564640045166, "student_train_time": 0.016782760620117188, "throughput": 1521.0740891442929, "inference_time": 0.05626114074311772, "env_time": 0.3881968670693823, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 55, "reward_mean": 26.532467532467532, "student_loss": null, "teacher_policy_loss": -9.428302764892578, "teacher_value_loss": 86.35150909423828, "teacher_entropy": 0.006614134181290865, "total_time": 1.592930555343628, "rollout_time": 0.5914502143859863, "train_time": 0.9728646278381348, "student_train_time": 0.02823638916015625, "throughput": 1255.547514793298, "inference_time": 0.12253535348827427, "env_time": 0.46891486089771206, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 56, "reward_mean": 23.275862068965516, "student_loss": null, "teacher_policy_loss": -8.452762603759766, "teacher_value_loss": 47.13783264160156, "teacher_entropy": 0.008850980550050735, "total_time": 1.4581007957458496, "rollout_time": 0.5753421783447266, "train_time": 0.8703253269195557, "student_train_time": 0.012067556381225586, "throughput": 1371.6472865491835, "inference_time": 0.08729264327575947, "env_time": 0.4880495350689671, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 57, "reward_mean": 25.714285714285715, "student_loss": null, "teacher_policy_loss": -9.73403263092041, "teacher_value_loss": 101.34648132324219, "teacher_entropy": 0.008800597861409187, "total_time": 1.4809422492980957, "rollout_time": 0.5807139873504639, "train_time": 0.8944981098175049, "student_train_time": 0.005321502685546875, "throughput": 1350.4915542438714, "inference_time": 0.08849771124732797, "env_time": 0.4922162761031359, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 58, "reward_mean": 25.70886075949367, "student_loss": null, "teacher_policy_loss": -9.737974166870117, "teacher_value_loss": 111.69393920898438, "teacher_entropy": 0.00777637492865324, "total_time": 1.3373289108276367, "rollout_time": 0.4965949058532715, "train_time": 0.8343193531036377, "student_train_time": 0.006050586700439453, "throughput": 1495.5184052382851, "inference_time": 0.06395984950813727, "env_time": 0.4326350563451342, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 59, "reward_mean": 26.364864864864863, "student_loss": null, "teacher_policy_loss": -9.5330171585083, "teacher_value_loss": 80.16842651367188, "teacher_entropy": 0.005929381586611271, "total_time": 1.501530647277832, "rollout_time": 0.46569347381591797, "train_time": 1.0247485637664795, "student_train_time": 0.010684967041015625, "throughput": 1331.9741449339429, "inference_time": 0.056769864751004206, "env_time": 0.40892360906491376, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 60, "reward_mean": 25.78481012658228, "student_loss": null, "teacher_policy_loss": -9.275333404541016, "teacher_value_loss": 87.33355712890625, "teacher_entropy": 0.005617672577500343, "total_time": 1.286259412765503, "rollout_time": 0.4760746955871582, "train_time": 0.8003106117248535, "student_train_time": 0.009511470794677734, "throughput": 1554.8962986400463, "inference_time": 0.06047451922586333, "env_time": 0.41560017636129487, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 61, "reward_mean": 28.695652173913043, "student_loss": null, "teacher_policy_loss": -10.427206039428711, "teacher_value_loss": 107.10684967041016, "teacher_entropy": 0.006462050136178732, "total_time": 1.2564418315887451, "rollout_time": 0.4382507801055908, "train_time": 0.8047378063201904, "student_train_time": 0.01297616958618164, "throughput": 1591.7967308291866, "inference_time": 0.0559010865390519, "env_time": 0.3823496935665389, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 62, "reward_mean": 29.323529411764707, "student_loss": null, "teacher_policy_loss": -10.850320816040039, "teacher_value_loss": 129.33279418945312, "teacher_entropy": 0.009011841379106045, "total_time": 1.3350613117218018, "rollout_time": 0.4819529056549072, "train_time": 0.845752477645874, "student_train_time": 0.006979227066040039, "throughput": 1498.058540413129, "inference_time": 0.0628648860129033, "env_time": 0.41908801964200393, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 63, "reward_mean": 26.763157894736842, "student_loss": null, "teacher_policy_loss": -9.18940544128418, "teacher_value_loss": 65.7367172241211, "teacher_entropy": 0.010827634483575821, "total_time": 1.3136725425720215, "rollout_time": 0.46032238006591797, "train_time": 0.8379430770874023, "student_train_time": 0.015041828155517578, "throughput": 1522.4494196127655, "inference_time": 0.05642186150089401, "env_time": 0.40390051856502396, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 64, "reward_mean": 27.779411764705884, "student_loss": null, "teacher_policy_loss": -9.799628257751465, "teacher_value_loss": 75.48140716552734, "teacher_entropy": 0.014662813395261765, "total_time": 1.3826639652252197, "rollout_time": 0.46582484245300293, "train_time": 0.9045524597167969, "student_train_time": 0.01153111457824707, "throughput": 1446.483057562163, "inference_time": 0.058802677294806927, "env_time": 0.407022165158196, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 65, "reward_mean": 32.109375, "student_loss": null, "teacher_policy_loss": -11.549180030822754, "teacher_value_loss": 153.69985961914062, "teacher_entropy": 0.01587388664484024, "total_time": 1.2708144187927246, "rollout_time": 0.4480764865875244, "train_time": 0.8025593757629395, "student_train_time": 0.019817352294921875, "throughput": 1573.7939154798091, "inference_time": 0.0575097619994267, "env_time": 0.3905667245880977, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 66, "reward_mean": 25.962025316455698, "student_loss": null, "teacher_policy_loss": -9.681082725524902, "teacher_value_loss": 155.2992401123047, "teacher_entropy": 0.016205625608563423, "total_time": 1.307244062423706, "rollout_time": 0.46923232078552246, "train_time": 0.8312814235687256, "student_train_time": 0.0063588619232177734, "throughput": 1529.9361897975534, "inference_time": 0.056650327727766125, "env_time": 0.41258199305775634, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 67, "reward_mean": 27.416666666666668, "student_loss": null, "teacher_policy_loss": -10.471433639526367, "teacher_value_loss": 147.27088928222656, "teacher_entropy": 0.013147273100912571, "total_time": 1.3402888774871826, "rollout_time": 0.477280855178833, "train_time": 0.8481385707855225, "student_train_time": 0.014251470565795898, "throughput": 1492.2156212693978, "inference_time": 0.05644387527172512, "env_time": 0.4208369799071079, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 68, "reward_mean": 26.346666666666668, "student_loss": null, "teacher_policy_loss": -9.360634803771973, "teacher_value_loss": 92.76420593261719, "teacher_entropy": 0.014739804901182652, "total_time": -1.3734850883483887, "rollout_time": 0.45599937438964844, "train_time": -1.8430485725402832, "student_train_time": 0.01314854621887207, "throughput": 200000000000.0, "inference_time": 0.05518896999910794, "env_time": 0.4008104043905405, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 69, "reward_mean": 28.633802816901408, "student_loss": null, "teacher_policy_loss": -9.637025833129883, "teacher_value_loss": 73.54467010498047, "teacher_entropy": 0.019948462024331093, "total_time": 1.3192503452301025, "rollout_time": 0.45781731605529785, "train_time": 0.8533787727355957, "student_train_time": 0.007663249969482422, "throughput": 1516.0124893893142, "inference_time": 0.060038599761355727, "env_time": 0.3977787162939421, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 70, "reward_mean": 29.71641791044776, "student_loss": null, "teacher_policy_loss": -10.7518949508667, "teacher_value_loss": 142.98117065429688, "teacher_entropy": 0.02829386293888092, "total_time": 1.2528667449951172, "rollout_time": 0.4398810863494873, "train_time": 0.8075330257415771, "student_train_time": 0.005084991455078125, "throughput": 1596.338962614731, "inference_time": 0.05700991626508767, "env_time": 0.38287117008439964, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 71, "reward_mean": 26.864864864864863, "student_loss": null, "teacher_policy_loss": -9.1931791305542, "teacher_value_loss": 66.59825134277344, "teacher_entropy": 0.0373707190155983, "total_time": 1.3125338554382324, "rollout_time": 0.4603285789489746, "train_time": 0.8388078212738037, "student_train_time": 0.013041257858276367, "throughput": 1523.770218736365, "inference_time": 0.05896738774390542, "env_time": 0.4013611912050692, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 72, "reward_mean": 29.38235294117647, "student_loss": null, "teacher_policy_loss": -9.882165908813477, "teacher_value_loss": 79.17861938476562, "teacher_entropy": 0.04550870507955551, "total_time": 1.2799103260040283, "rollout_time": 0.4515693187713623, "train_time": 0.8125572204589844, "student_train_time": 0.015414237976074219, "throughput": 1562.609472996552, "inference_time": 0.05698116699386446, "env_time": 0.39458815177749784, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 73, "reward_mean": 30.015151515151516, "student_loss": null, "teacher_policy_loss": -9.557607650756836, "teacher_value_loss": 62.43952941894531, "teacher_entropy": 0.05597320571541786, "total_time": 1.4009993076324463, "rollout_time": 0.43967127799987793, "train_time": 0.9460616111755371, "student_train_time": 0.014791250228881836, "throughput": 1427.5524542405428, "inference_time": 0.05432910725357942, "env_time": 0.3853421707462985, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 74, "reward_mean": 36.127272727272725, "student_loss": null, "teacher_policy_loss": -11.64637565612793, "teacher_value_loss": 113.57733154296875, "teacher_entropy": 0.07771197706460953, "total_time": 1.4067952632904053, "rollout_time": 0.481616735458374, "train_time": 0.910815954208374, "student_train_time": 0.013943910598754883, "throughput": 1421.6709795582665, "inference_time": 0.06006063199856726, "env_time": 0.42155610345980676, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 75, "reward_mean": 28.957142857142856, "student_loss": null, "teacher_policy_loss": -9.721672058105469, "teacher_value_loss": 71.11317443847656, "teacher_entropy": 0.11735617369413376, "total_time": 1.2474865913391113, "rollout_time": 0.4628794193267822, "train_time": 0.7764389514923096, "student_train_time": 0.007714748382568359, "throughput": 1603.2236449556585, "inference_time": 0.05519943899616919, "env_time": 0.40767998033061303, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 76, "reward_mean": 30.073529411764707, "student_loss": null, "teacher_policy_loss": -10.601617813110352, "teacher_value_loss": 78.52491760253906, "teacher_entropy": 0.20426645874977112, "total_time": 1.2908577919006348, "rollout_time": 0.44579172134399414, "train_time": 0.8339018821716309, "student_train_time": 0.010652780532836914, "throughput": 1549.3573440458051, "inference_time": 0.056730919239271316, "env_time": 0.3890608021047228, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 77, "reward_mean": 29.153846153846153, "student_loss": null, "teacher_policy_loss": -13.522632598876953, "teacher_value_loss": 107.49678802490234, "teacher_entropy": 0.46942487359046936, "total_time": 1.4331371784210205, "rollout_time": 0.43914341926574707, "train_time": 0.985431432723999, "student_train_time": 0.008196353912353516, "throughput": 1395.539819993735, "inference_time": 0.05666809151898633, "env_time": 0.38247532774676074, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 78, "reward_mean": 31.515151515151516, "student_loss": null, "teacher_policy_loss": -16.571739196777344, "teacher_value_loss": 113.46726989746094, "teacher_entropy": 0.6429417133331299, "total_time": 1.4620566368103027, "rollout_time": 0.45028185844421387, "train_time": 1.0034239292144775, "student_train_time": 0.007972478866577148, "throughput": 1367.936063245335, "inference_time": 0.05744675048117642, "env_time": 0.39283510796303744, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 79, "reward_mean": 31.761904761904763, "student_loss": null, "teacher_policy_loss": -14.679645538330078, "teacher_value_loss": 143.0326690673828, "teacher_entropy": 0.47953033447265625, "total_time": 1.2785332202911377, "rollout_time": 0.47373247146606445, "train_time": 0.7918276786804199, "student_train_time": 0.012609720230102539, "throughput": 1564.2925567038262, "inference_time": 0.061779026528711256, "env_time": 0.4119534449373532, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 80, "reward_mean": 30.53030303030303, "student_loss": null, "teacher_policy_loss": -13.173580169677734, "teacher_value_loss": 84.16012573242188, "teacher_entropy": 0.476241797208786, "total_time": 1.224790096282959, "rollout_time": 0.45140600204467773, "train_time": 0.7617428302764893, "student_train_time": 0.011155366897583008, "throughput": 1632.9328642268406, "inference_time": 0.05891012247866456, "env_time": 0.3924958795660132, "samples": 2000, "teacher_eval_reward": 13.0}
{"epoch": 81, "reward_mean": 30.384615384615383, "student_loss": null, "teacher_policy_loss": -16.48331069946289, "teacher_value_loss": 102.241943359375, "teacher_entropy": 0.6221505403518677, "total_time": 1.3567373752593994, "rollout_time": 0.45461273193359375, "train_time": 0.8895394802093506, "student_train_time": 0.012220144271850586, "throughput": 1474.1246437746383, "inference_time": 0.06021863001660677, "env_time": 0.394394101916987, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 82, "reward_mean": 29.388059701492537, "student_loss": null, "teacher_policy_loss": -15.376002311706543, "teacher_value_loss": 114.63858795166016, "teacher_entropy": 0.5720335245132446, "total_time": 1.3195586204528809, "rollout_time": 0.45171236991882324, "train_time": 0.8549726009368896, "student_train_time": 0.012467145919799805, "throughput": 1515.6583186229252, "inference_time": 0.05958713227209955, "env_time": 0.3921252376467237, "samples": 2000, "teacher_eval_reward": 17.0}
{"epoch": 83, "reward_mean": 32.84126984126984, "student_loss": null, "teacher_policy_loss": -14.20896053314209, "teacher_value_loss": 73.29058074951172, "teacher_entropy": 0.5276761054992676, "total_time": 1.315791130065918, "rollout_time": 0.4440882205963135, "train_time": 0.856743574142456, "student_train_time": 0.014578819274902344, "throughput": 1519.9980865502603, "inference_time": 0.0556737839769994, "env_time": 0.3884144366193141, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 84, "reward_mean": 35.05555555555556, "student_loss": null, "teacher_policy_loss": -19.888233184814453, "teacher_value_loss": 179.4080047607422, "teacher_entropy": 0.6055998802185059, "total_time": 1.2744884490966797, "rollout_time": 0.4637587070465088, "train_time": 0.8041386604309082, "student_train_time": 0.0054473876953125, "throughput": 1569.2570626415184, "inference_time": 0.055685972005449, "env_time": 0.4080727350410598, "samples": 2000, "teacher_eval_reward": 34.0}
{"epoch": 85, "reward_mean": 32.15873015873016, "student_loss": null, "teacher_policy_loss": -17.10890769958496, "teacher_value_loss": 118.19678497314453, "teacher_entropy": 0.5892574787139893, "total_time": 1.3111090660095215, "rollout_time": 0.44603466987609863, "train_time": 0.858795166015625, "student_train_time": 0.00591278076171875, "throughput": 1525.4261082086634, "inference_time": 0.055442623509406985, "env_time": 0.39059204636669165, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 86, "reward_mean": 34.83050847457627, "student_loss": null, "teacher_policy_loss": -17.594093322753906, "teacher_value_loss": 151.80987548828125, "teacher_entropy": 0.5365649461746216, "total_time": 1.2898893356323242, "rollout_time": 0.4497652053833008, "train_time": 0.8301799297332764, "student_train_time": 0.00957036018371582, "throughput": 1550.520610374353, "inference_time": 0.05526441046367836, "env_time": 0.3945007949196224, "samples": 2000, "teacher_eval_reward": 28.0}
{"epoch": 87, "reward_mean": 32.01587301587302, "student_loss": null, "teacher_policy_loss": -15.632795333862305, "teacher_value_loss": 69.13348388671875, "teacher_entropy": 0.555999219417572, "total_time": 1.2869818210601807, "rollout_time": 0.4446256160736084, "train_time": 0.8324332237243652, "student_train_time": 0.009563684463500977, "throughput": 1554.0235046618252, "inference_time": 0.05519538277076208, "env_time": 0.3894302333028463, "samples": 2000, "teacher_eval_reward": 120.0}
{"epoch": 88, "reward_mean": 30.65625, "student_loss": null, "teacher_policy_loss": -16.66974449157715, "teacher_value_loss": 86.31869506835938, "teacher_entropy": 0.5813214182853699, "total_time": 1.2462365627288818, "rollout_time": 0.44283199310302734, "train_time": 0.795482873916626, "student_train_time": 0.007569551467895508, "throughput": 1604.8317468880898, "inference_time": 0.05514084524838836, "env_time": 0.387691147854639, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 89, "reward_mean": 34.357142857142854, "student_loss": null, "teacher_policy_loss": -18.84593963623047, "teacher_value_loss": 151.40306091308594, "teacher_entropy": 0.5615181922912598, "total_time": 1.3674607276916504, "rollout_time": 0.43731236457824707, "train_time": 0.9132943153381348, "student_train_time": 0.016492128372192383, "throughput": 1462.564854331218, "inference_time": 0.054912330254410335, "env_time": 0.38240003432383673, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 90, "reward_mean": 36.3859649122807, "student_loss": null, "teacher_policy_loss": -18.277137756347656, "teacher_value_loss": 106.69784545898438, "teacher_entropy": 0.5744239687919617, "total_time": -1.3168270587921143, "rollout_time": 0.43576979637145996, "train_time": -1.7665014266967773, "student_train_time": 0.013272523880004883, "throughput": 200000000000.0, "inference_time": 0.05563973750304285, "env_time": 0.3801300588684171, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 91, "reward_mean": 38.9, "student_loss": null, "teacher_policy_loss": -18.73426055908203, "teacher_value_loss": 101.17005920410156, "teacher_entropy": 0.5628527998924255, "total_time": 1.3058834075927734, "rollout_time": 0.4259669780731201, "train_time": 0.8490378856658936, "student_train_time": 0.030499696731567383, "throughput": 1531.5302946430268, "inference_time": 0.05445936025625997, "env_time": 0.37150761781686015, "samples": 2000, "teacher_eval_reward": 24.0}
{"epoch": 92, "reward_mean": 36.482142857142854, "student_loss": null, "teacher_policy_loss": -17.701501846313477, "teacher_value_loss": 142.2562255859375, "teacher_entropy": 0.5255653262138367, "total_time": 1.196075439453125, "rollout_time": 0.43383049964904785, "train_time": 0.7379209995269775, "student_train_time": 0.02387404441833496, "throughput": 1672.135330288572, "inference_time": 0.053714193492851336, "env_time": 0.3801163061561965, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 93, "reward_mean": 33.278688524590166, "student_loss": null, "teacher_policy_loss": -17.59423828125, "teacher_value_loss": 92.89903259277344, "teacher_entropy": 0.5765373706817627, "total_time": 1.254915475845337, "rollout_time": 0.4490516185760498, "train_time": 0.7894630432128906, "student_train_time": 0.015958070755004883, "throughput": 1593.7328357933898, "inference_time": 0.055717638010719384, "env_time": 0.3933339805653304, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 94, "reward_mean": 35.90909090909091, "student_loss": null, "teacher_policy_loss": -18.151369094848633, "teacher_value_loss": 113.96136474609375, "teacher_entropy": 0.5507082343101501, "total_time": 1.3211026191711426, "rollout_time": 0.4478161334991455, "train_time": 0.8608438968658447, "student_train_time": 0.01207590103149414, "throughput": 1513.8869388169076, "inference_time": 0.05460947174105968, "env_time": 0.39320666175808583, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 95, "reward_mean": 35.08474576271186, "student_loss": null, "teacher_policy_loss": -17.010765075683594, "teacher_value_loss": 94.98429107666016, "teacher_entropy": 0.5504426956176758, "total_time": 1.2864325046539307, "rollout_time": 0.45600390434265137, "train_time": 0.8133993148803711, "student_train_time": 0.016664981842041016, "throughput": 1554.687084448344, "inference_time": 0.055087235998144024, "env_time": 0.40091666834450734, "samples": 2000, "teacher_eval_reward": 168.0}
{"epoch": 96, "reward_mean": 40.31111111111111, "student_loss": null, "teacher_policy_loss": -26.008033752441406, "teacher_value_loss": 335.7430114746094, "teacher_entropy": 0.596748411655426, "total_time": 1.2395012378692627, "rollout_time": 0.45188331604003906, "train_time": 0.7805688381195068, "student_train_time": 0.006688594818115234, "throughput": 1613.5522409304374, "inference_time": 0.05664670102396485, "env_time": 0.3952366150160742, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 97, "reward_mean": 37.1578947368421, "student_loss": null, "teacher_policy_loss": -17.807144165039062, "teacher_value_loss": 123.71088409423828, "teacher_entropy": 0.5778726935386658, "total_time": 1.2427699565887451, "rollout_time": 0.44274139404296875, "train_time": 0.7909634113311768, "student_train_time": 0.008611679077148438, "throughput": 1609.3082950683495, "inference_time": 0.054267918512778124, "env_time": 0.3884734755301906, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 98, "reward_mean": 31.047619047619047, "student_loss": null, "teacher_policy_loss": -16.700105667114258, "teacher_value_loss": 92.04286193847656, "teacher_entropy": 0.5923935770988464, "total_time": 1.2806568145751953, "rollout_time": 0.4536590576171875, "train_time": 0.8108534812927246, "student_train_time": 0.0157015323638916, "throughput": 1561.698635604744, "inference_time": 0.058349894017737824, "env_time": 0.3953091635994497, "samples": 2000, "teacher_eval_reward": 104.0}
{"epoch": 99, "reward_mean": 39.745098039215684, "student_loss": null, "teacher_policy_loss": -21.09375, "teacher_value_loss": 143.9091339111328, "teacher_entropy": 0.6048752665519714, "total_time": 1.2009732723236084, "rollout_time": 0.4397885799407959, "train_time": 0.7432570457458496, "student_train_time": 0.017481088638305664, "throughput": 1665.3159950266486, "inference_time": 0.05626260824374185, "env_time": 0.38352597169705405, "samples": 2000, "teacher_eval_reward": 45.0}
{"epoch": 100, "reward_mean": 30.924242424242426, "student_loss": null, "teacher_policy_loss": -16.671422958374023, "teacher_value_loss": 90.504638671875, "teacher_entropy": 0.600695013999939, "total_time": 1.3139963150024414, "rollout_time": 0.45638132095336914, "train_time": 0.8442988395690918, "student_train_time": 0.012943029403686523, "throughput": 1522.0742837443072, "inference_time": 0.05917782877168065, "env_time": 0.3972034921816885, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 101, "reward_mean": 35.280701754385966, "student_loss": null, "teacher_policy_loss": -18.88331413269043, "teacher_value_loss": 100.48980712890625, "teacher_entropy": 0.6047999262809753, "total_time": 1.2364039421081543, "rollout_time": 0.4411287307739258, "train_time": 0.7893459796905518, "student_train_time": 0.005560636520385742, "throughput": 1617.5943248691538, "inference_time": 0.05593951474020287, "env_time": 0.3851892160337229, "samples": 2000, "teacher_eval_reward": 144.0}
{"epoch": 102, "reward_mean": 34.0, "student_loss": null, "teacher_policy_loss": -19.587186813354492, "teacher_value_loss": 118.37109375, "teacher_entropy": 0.6173408627510071, "total_time": 1.2755398750305176, "rollout_time": 0.47278761863708496, "train_time": 0.794029712677002, "student_train_time": 0.008357763290405273, "throughput": 1567.9635259949437, "inference_time": 0.05608990675955283, "env_time": 0.41669771187753213, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 103, "reward_mean": 40.254901960784316, "student_loss": null, "teacher_policy_loss": -20.51211929321289, "teacher_value_loss": 177.71746826171875, "teacher_entropy": 0.5929936766624451, "total_time": 1.2025372982025146, "rollout_time": 0.4343299865722656, "train_time": 0.7559604644775391, "student_train_time": 0.011870622634887695, "throughput": 1663.1500769161073, "inference_time": 0.05598937699414819, "env_time": 0.37834060957811744, "samples": 2000, "teacher_eval_reward": 34.0}
{"epoch": 104, "reward_mean": 38.5, "student_loss": null, "teacher_policy_loss": -19.459699630737305, "teacher_value_loss": 165.6734619140625, "teacher_entropy": 0.5920495390892029, "total_time": 1.3354063034057617, "rollout_time": 0.439058780670166, "train_time": 0.8807659149169922, "student_train_time": 0.015199899673461914, "throughput": 1497.6715288068415, "inference_time": 0.057437873490925995, "env_time": 0.38162090717924, "samples": 2000, "teacher_eval_reward": 101.0}
{"epoch": 105, "reward_mean": 36.9622641509434, "student_loss": null, "teacher_policy_loss": -19.956613540649414, "teacher_value_loss": 133.14268493652344, "teacher_entropy": 0.6216863393783569, "total_time": 1.2771666049957275, "rollout_time": 0.45330190658569336, "train_time": 0.808945894241333, "student_train_time": 0.014490604400634766, "throughput": 1565.9664073401689, "inference_time": 0.05448474047079799, "env_time": 0.39881716611489537, "samples": 2000, "teacher_eval_reward": 21.0}
{"epoch": 106, "reward_mean": 39.5, "student_loss": null, "teacher_policy_loss": -19.86454963684082, "teacher_value_loss": 149.3602294921875, "teacher_entropy": 0.5886946320533752, "total_time": 1.3618738651275635, "rollout_time": 0.44544243812561035, "train_time": 0.901738166809082, "student_train_time": 0.014319419860839844, "throughput": 1468.5647850453938, "inference_time": 0.0549151150180478, "env_time": 0.39052732310756255, "samples": 2000, "teacher_eval_reward": 19.0}
{"epoch": 107, "reward_mean": 41.142857142857146, "student_loss": null, "teacher_policy_loss": -19.220888137817383, "teacher_value_loss": 199.29380798339844, "teacher_entropy": 0.5536503195762634, "total_time": 1.1920864582061768, "rollout_time": 0.438030481338501, "train_time": 0.7417311668395996, "student_train_time": 0.011909961700439453, "throughput": 1677.7306597455627, "inference_time": 0.05476122250183835, "env_time": 0.38326925883666263, "samples": 2000, "teacher_eval_reward": 26.0}
{"epoch": 108, "reward_mean": 33.733333333333334, "student_loss": null, "teacher_policy_loss": -17.881837844848633, "teacher_value_loss": 132.69993591308594, "teacher_entropy": 0.5934174656867981, "total_time": 1.494004726409912, "rollout_time": 0.42481398582458496, "train_time": 1.0587058067321777, "student_train_time": 0.010070562362670898, "throughput": 1338.683850623413, "inference_time": 0.05578627425074956, "env_time": 0.3690277115738354, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 109, "reward_mean": 37.76923076923077, "student_loss": null, "teacher_policy_loss": -19.822885513305664, "teacher_value_loss": 127.81907653808594, "teacher_entropy": 0.6315481066703796, "total_time": -1.2856159210205078, "rollout_time": -2.1231017112731934, "train_time": 0.8264579772949219, "student_train_time": 0.010617256164550781, "throughput": 200000000000.0, "inference_time": 0.05826105023152195, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 34.0}
{"epoch": 110, "reward_mean": 36.132075471698116, "student_loss": null, "teacher_policy_loss": -17.6130428314209, "teacher_value_loss": 116.48931121826172, "teacher_entropy": 0.5735882520675659, "total_time": 1.2605998516082764, "rollout_time": 0.42940711975097656, "train_time": 0.8238322734832764, "student_train_time": 0.006896257400512695, "throughput": 1586.5462759244301, "inference_time": 0.05368313128383306, "env_time": 0.3757239884671435, "samples": 2000, "teacher_eval_reward": 30.0}
{"epoch": 111, "reward_mean": 38.81481481481482, "student_loss": null, "teacher_policy_loss": -18.503372192382812, "teacher_value_loss": 146.87799072265625, "teacher_entropy": 0.5786905288696289, "total_time": 1.1924755573272705, "rollout_time": 0.44148802757263184, "train_time": 0.7422115802764893, "student_train_time": 0.008425474166870117, "throughput": 1677.1832241850366, "inference_time": 0.059364682992963935, "env_time": 0.3821233445796679, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 112, "reward_mean": 34.517857142857146, "student_loss": null, "teacher_policy_loss": -19.833253860473633, "teacher_value_loss": 167.1609344482422, "teacher_entropy": 0.617772102355957, "total_time": 1.2935361862182617, "rollout_time": 0.42862510681152344, "train_time": 0.8511826992034912, "student_train_time": 0.013189077377319336, "throughput": 1546.1492467768774, "inference_time": 0.05498746801549714, "env_time": 0.3736376387960263, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 113, "reward_mean": 34.5, "student_loss": null, "teacher_policy_loss": -19.86939239501953, "teacher_value_loss": 173.99594116210938, "teacher_entropy": 0.6188767552375793, "total_time": 1.1987197399139404, "rollout_time": 0.45086097717285156, "train_time": 0.7356405258178711, "student_train_time": 0.011855363845825195, "throughput": 1668.4467047681935, "inference_time": 0.05867647449940705, "env_time": 0.3921845026734445, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 114, "reward_mean": 44.68888888888889, "student_loss": null, "teacher_policy_loss": -21.481489181518555, "teacher_value_loss": 161.1679229736328, "teacher_entropy": 0.5778093934059143, "total_time": 1.3224761486053467, "rollout_time": 0.43191957473754883, "train_time": 0.8635954856872559, "student_train_time": 0.026546955108642578, "throughput": 1512.3146093100845, "inference_time": 0.05475292024311784, "env_time": 0.377166654494431, "samples": 2000, "teacher_eval_reward": 36.0}
{"epoch": 115, "reward_mean": 38.1764705882353, "student_loss": null, "teacher_policy_loss": -21.6409969329834, "teacher_value_loss": 188.41172790527344, "teacher_entropy": 0.5849841237068176, "total_time": 1.181631326675415, "rollout_time": 0.44372081756591797, "train_time": 0.7299976348876953, "student_train_time": 0.00751805305480957, "throughput": 1692.5753023382601, "inference_time": 0.05427765323929634, "env_time": 0.3894431643266216, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 116, "reward_mean": 40.36, "student_loss": null, "teacher_policy_loss": -22.645751953125, "teacher_value_loss": 168.05958557128906, "teacher_entropy": 0.608159065246582, "total_time": 1.232100009918213, "rollout_time": 0.4442014694213867, "train_time": 0.7732605934143066, "student_train_time": 0.014258623123168945, "throughput": 1623.2448534212417, "inference_time": 0.05765193522711343, "env_time": 0.3865495341942733, "samples": 2000, "teacher_eval_reward": 42.0}
{"epoch": 117, "reward_mean": 41.91836734693877, "student_loss": null, "teacher_policy_loss": -20.615812301635742, "teacher_value_loss": 143.5643768310547, "teacher_entropy": 0.5686500072479248, "total_time": 1.2987279891967773, "rollout_time": 0.44068074226379395, "train_time": 0.840015172958374, "student_train_time": 0.017625808715820312, "throughput": 1539.9683510609004, "inference_time": 0.056036911996670824, "env_time": 0.3846438302671231, "samples": 2000, "teacher_eval_reward": 27.0}
{"epoch": 118, "reward_mean": 39.34615384615385, "student_loss": null, "teacher_policy_loss": -19.19319725036621, "teacher_value_loss": 159.7652130126953, "teacher_entropy": 0.5428111553192139, "total_time": 1.2983715534210205, "rollout_time": 0.455294132232666, "train_time": 0.8288240432739258, "student_train_time": 0.013817548751831055, "throughput": 1540.3911112580142, "inference_time": 0.05790527252793254, "env_time": 0.3973888597047335, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 119, "reward_mean": 40.0, "student_loss": null, "teacher_policy_loss": -20.39990997314453, "teacher_value_loss": 125.48544311523438, "teacher_entropy": 0.5709952712059021, "total_time": 1.2887279987335205, "rollout_time": 0.4627656936645508, "train_time": 0.8135654926300049, "student_train_time": 0.012022733688354492, "throughput": 1551.9178616166269, "inference_time": 0.057017579736566404, "env_time": 0.4057481139279844, "samples": 2000, "teacher_eval_reward": 101.0}
{"epoch": 120, "reward_mean": 45.23913043478261, "student_loss": null, "teacher_policy_loss": -21.17713165283203, "teacher_value_loss": 100.39493560791016, "teacher_entropy": 0.5897272825241089, "total_time": 1.304119348526001, "rollout_time": 0.4584934711456299, "train_time": 0.8264980316162109, "student_train_time": 0.018726348876953125, "throughput": 1533.601968455209, "inference_time": 0.05963221972979227, "env_time": 0.3988612514158376, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 121, "reward_mean": 38.69387755102041, "student_loss": null, "teacher_policy_loss": -20.182519912719727, "teacher_value_loss": 109.93502807617188, "teacher_entropy": 0.5668960809707642, "total_time": 1.3195908069610596, "rollout_time": 0.460554838180542, "train_time": 0.8529298305511475, "student_train_time": 0.005683422088623047, "throughput": 1515.6213497772715, "inference_time": 0.05629075024444319, "env_time": 0.4042640879360988, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 122, "reward_mean": 43.340425531914896, "student_loss": null, "teacher_policy_loss": -21.237852096557617, "teacher_value_loss": 95.52259063720703, "teacher_entropy": 0.5807218551635742, "total_time": 1.3121800422668457, "rollout_time": 0.4798886775970459, "train_time": 0.8240065574645996, "student_train_time": 0.007918357849121094, "throughput": 1524.1810845902799, "inference_time": 0.06058116825261095, "env_time": 0.41930750934443495, "samples": 2000, "teacher_eval_reward": 90.0}
{"epoch": 123, "reward_mean": 41.979166666666664, "student_loss": null, "teacher_policy_loss": -20.636703491210938, "teacher_value_loss": 119.17054748535156, "teacher_entropy": 0.5631256699562073, "total_time": 1.3474969863891602, "rollout_time": 0.4408071041107178, "train_time": 0.8989028930664062, "student_train_time": 0.007439374923706055, "throughput": 1484.233375066262, "inference_time": 0.05789992272002564, "env_time": 0.38290718139069213, "samples": 2000, "teacher_eval_reward": 286.0}
{"epoch": 124, "reward_mean": 42.645833333333336, "student_loss": null, "teacher_policy_loss": -22.61664581298828, "teacher_value_loss": 191.27883911132812, "teacher_entropy": 0.5756016969680786, "total_time": 1.2258169651031494, "rollout_time": 0.44162917137145996, "train_time": 0.7662990093231201, "student_train_time": 0.01752305030822754, "throughput": 1631.5649537708143, "inference_time": 0.055178327028443164, "env_time": 0.3864508443430168, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 125, "reward_mean": 44.75, "student_loss": null, "teacher_policy_loss": -22.692737579345703, "teacher_value_loss": 117.05485534667969, "teacher_entropy": 0.5794075727462769, "total_time": 1.2734813690185547, "rollout_time": 0.44398975372314453, "train_time": 0.8188564777374268, "student_train_time": 0.010204553604125977, "throughput": 1570.498044695666, "inference_time": 0.057258348747382115, "env_time": 0.3867314049757624, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 126, "reward_mean": 38.21568627450981, "student_loss": null, "teacher_policy_loss": -19.400243759155273, "teacher_value_loss": 123.31196594238281, "teacher_entropy": 0.5594070553779602, "total_time": 1.2999205589294434, "rollout_time": 0.4488701820373535, "train_time": 0.8428432941436768, "student_train_time": 0.007753610610961914, "throughput": 1538.555557308141, "inference_time": 0.055030151754181134, "env_time": 0.3938400302831724, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 127, "reward_mean": 45.75555555555555, "student_loss": null, "teacher_policy_loss": -22.767709732055664, "teacher_value_loss": 139.31517028808594, "teacher_entropy": 0.5710592865943909, "total_time": -1.2275991439819336, "rollout_time": 0.4439361095428467, "train_time": -1.6832451820373535, "student_train_time": 0.011292695999145508, "throughput": 200000000000.0, "inference_time": 0.05866255273213028, "env_time": 0.3852735568107164, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 128, "reward_mean": 47.8780487804878, "student_loss": null, "teacher_policy_loss": -24.92136001586914, "teacher_value_loss": 170.71392822265625, "teacher_entropy": 0.5890426635742188, "total_time": 1.310347318649292, "rollout_time": 0.4431900978088379, "train_time": 0.8556056022644043, "student_train_time": 0.011189699172973633, "throughput": 1526.3128878392356, "inference_time": 0.056823088482815365, "env_time": 0.3863670093260225, "samples": 2000, "teacher_eval_reward": 105.0}
{"epoch": 129, "reward_mean": 42.55555555555556, "student_loss": null, "teacher_policy_loss": -22.372472763061523, "teacher_value_loss": 132.51950073242188, "teacher_entropy": 0.5841591954231262, "total_time": 1.3497083187103271, "rollout_time": 0.46986913681030273, "train_time": 0.865236759185791, "student_train_time": 0.014231443405151367, "throughput": 1481.801639861744, "inference_time": 0.05385689398099203, "env_time": 0.4160122428293107, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 130, "reward_mean": 59.0, "student_loss": null, "teacher_policy_loss": -28.30143165588379, "teacher_value_loss": 304.67333984375, "teacher_entropy": 0.5937937498092651, "total_time": 1.2721226215362549, "rollout_time": 0.45108962059020996, "train_time": 0.8102707862854004, "student_train_time": 0.010335683822631836, "throughput": 1572.1754853983634, "inference_time": 0.057153791270138754, "env_time": 0.3939358293200712, "samples": 2000, "teacher_eval_reward": 78.0}
{"epoch": 131, "reward_mean": 43.851063829787236, "student_loss": null, "teacher_policy_loss": -21.315946578979492, "teacher_value_loss": 145.62464904785156, "teacher_entropy": 0.5825695991516113, "total_time": 1.2962181568145752, "rollout_time": 0.4402804374694824, "train_time": 0.8250637054443359, "student_train_time": 0.030510902404785156, "throughput": 1542.9501503936278, "inference_time": 0.059056363732452155, "env_time": 0.38122407373703027, "samples": 2000, "teacher_eval_reward": 328.0}
{"epoch": 132, "reward_mean": 42.276595744680854, "student_loss": null, "teacher_policy_loss": -21.036869049072266, "teacher_value_loss": 96.98324584960938, "teacher_entropy": 0.5980072021484375, "total_time": 1.2548613548278809, "rollout_time": 0.44586777687072754, "train_time": 0.7774124145507812, "student_train_time": 0.031164884567260742, "throughput": 1593.801572026516, "inference_time": 0.055629292491175875, "env_time": 0.39023848437955166, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 133, "reward_mean": 42.0, "student_loss": null, "teacher_policy_loss": -23.759536743164062, "teacher_value_loss": 179.59580993652344, "teacher_entropy": 0.5830919146537781, "total_time": 1.3068475723266602, "rollout_time": 0.4451103210449219, "train_time": 0.837303638458252, "student_train_time": 0.024051904678344727, "throughput": 1530.4003637082774, "inference_time": 0.0564078504603458, "env_time": 0.3887024705845761, "samples": 2000, "teacher_eval_reward": 96.0}
{"epoch": 134, "reward_mean": 43.28, "student_loss": null, "teacher_policy_loss": -21.637516021728516, "teacher_value_loss": 140.17340087890625, "teacher_entropy": 0.5854706764221191, "total_time": 1.3301167488098145, "rollout_time": 0.461977481842041, "train_time": 0.8573112487792969, "student_train_time": 0.01042938232421875, "throughput": 1503.6274084884622, "inference_time": 0.05945266723392706, "env_time": 0.40252481460811396, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 135, "reward_mean": 47.357142857142854, "student_loss": null, "teacher_policy_loss": -24.5183162689209, "teacher_value_loss": 175.9998321533203, "teacher_entropy": 0.5893344879150391, "total_time": 1.3065428733825684, "rollout_time": 0.4602088928222656, "train_time": 0.8269956111907959, "student_train_time": 0.018969058990478516, "throughput": 1530.757268471496, "inference_time": 0.05970470747888612, "env_time": 0.4005041853433795, "samples": 2000, "teacher_eval_reward": 40.0}
{"epoch": 136, "reward_mean": 46.30952380952381, "student_loss": null, "teacher_policy_loss": -22.682043075561523, "teacher_value_loss": 153.68069458007812, "teacher_entropy": 0.5720486044883728, "total_time": 1.29463529586792, "rollout_time": 0.4645397663116455, "train_time": 0.8225550651550293, "student_train_time": 0.006993532180786133, "throughput": 1544.8366087216907, "inference_time": 0.05829640348292742, "env_time": 0.4062433628287181, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 137, "reward_mean": 43.208333333333336, "student_loss": null, "teacher_policy_loss": -20.744165420532227, "teacher_value_loss": 126.03601837158203, "teacher_entropy": 0.5871787667274475, "total_time": 1.458573579788208, "rollout_time": 0.4893763065338135, "train_time": 0.9220728874206543, "student_train_time": 0.04675602912902832, "throughput": 1371.2026789148408, "inference_time": 0.06329232651296479, "env_time": 0.4260839800208487, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 138, "reward_mean": 49.225, "student_loss": null, "teacher_policy_loss": -24.035314559936523, "teacher_value_loss": 138.80099487304688, "teacher_entropy": 0.6070297956466675, "total_time": 1.3346850872039795, "rollout_time": 0.44774699211120605, "train_time": 0.8764266967773438, "student_train_time": 0.010146617889404297, "throughput": 1498.4808170665808, "inference_time": 0.05613928273214697, "env_time": 0.3916077093790591, "samples": 2000, "teacher_eval_reward": 47.0}
{"epoch": 139, "reward_mean": 46.04651162790697, "student_loss": null, "teacher_policy_loss": -22.758930206298828, "teacher_value_loss": 147.35687255859375, "teacher_entropy": 0.5773444175720215, "total_time": 1.3783390522003174, "rollout_time": 0.46186208724975586, "train_time": 0.9062442779541016, "student_train_time": 0.009866476058959961, "throughput": 1451.0217909064474, "inference_time": 0.06177547946754203, "env_time": 0.40008660778221383, "samples": 2000, "teacher_eval_reward": 71.0}
{"epoch": 140, "reward_mean": 53.54054054054054, "student_loss": null, "teacher_policy_loss": -25.230031967163086, "teacher_value_loss": 180.36761474609375, "teacher_entropy": 0.5981384515762329, "total_time": 1.2647159099578857, "rollout_time": 0.47438931465148926, "train_time": 0.7828190326690674, "student_train_time": 0.00713658332824707, "throughput": 1581.3828103629999, "inference_time": 0.05828519676288124, "env_time": 0.416104117888608, "samples": 2000, "teacher_eval_reward": 406.0}
{"epoch": 141, "reward_mean": 47.13953488372093, "student_loss": null, "teacher_policy_loss": -22.556650161743164, "teacher_value_loss": 143.24659729003906, "teacher_entropy": 0.6034164428710938, "total_time": 1.4637088775634766, "rollout_time": 0.45526671409606934, "train_time": 0.9960360527038574, "student_train_time": 0.012027502059936523, "throughput": 1366.391931248819, "inference_time": 0.056928858501123614, "env_time": 0.3983378555949457, "samples": 2000, "teacher_eval_reward": 232.0}
{"epoch": 142, "reward_mean": 46.77272727272727, "student_loss": null, "teacher_policy_loss": -23.783729553222656, "teacher_value_loss": 152.7355194091797, "teacher_entropy": 0.5948287844657898, "total_time": 1.3097574710845947, "rollout_time": 0.4486532211303711, "train_time": 0.8468756675720215, "student_train_time": 0.013864517211914062, "throughput": 1527.000260852739, "inference_time": 0.0558761180145666, "env_time": 0.3927771031158045, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 143, "reward_mean": 43.2, "student_loss": null, "teacher_policy_loss": -22.387109756469727, "teacher_value_loss": 156.7032470703125, "teacher_entropy": 0.5863479971885681, "total_time": 1.5995526313781738, "rollout_time": 0.47711920738220215, "train_time": 1.0909473896026611, "student_train_time": 0.031127452850341797, "throughput": 1250.3496044871001, "inference_time": 0.06221375275072205, "env_time": 0.4149054546314801, "samples": 2000, "teacher_eval_reward": 293.0}
{"epoch": 144, "reward_mean": 46.883720930232556, "student_loss": null, "teacher_policy_loss": -22.957578659057617, "teacher_value_loss": 141.99087524414062, "teacher_entropy": 0.5875202417373657, "total_time": 1.3757014274597168, "rollout_time": 0.48613619804382324, "train_time": 0.8745512962341309, "student_train_time": 0.01464700698852539, "throughput": 1453.8038269634374, "inference_time": 0.059174177234126546, "env_time": 0.4269620208096967, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 145, "reward_mean": 48.90243902439025, "student_loss": null, "teacher_policy_loss": -24.431154251098633, "teacher_value_loss": 164.88400268554688, "teacher_entropy": 0.5746203660964966, "total_time": 1.3408710956573486, "rollout_time": 0.4416773319244385, "train_time": 0.888465404510498, "student_train_time": 0.01036691665649414, "throughput": 1491.567687958491, "inference_time": 0.05662089203178766, "env_time": 0.3850564398926508, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 146, "reward_mean": 53.22222222222222, "student_loss": null, "teacher_policy_loss": -25.74114227294922, "teacher_value_loss": 149.24195861816406, "teacher_entropy": 0.570902943611145, "total_time": 1.2284960746765137, "rollout_time": 0.44417309761047363, "train_time": 0.7758119106292725, "student_train_time": 0.008082866668701172, "throughput": 1628.006829835934, "inference_time": 0.057941030262554705, "env_time": 0.38623206734791893, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 147, "reward_mean": 47.23809523809524, "student_loss": null, "teacher_policy_loss": -24.07657241821289, "teacher_value_loss": 164.9482879638672, "teacher_entropy": 0.5666089057922363, "total_time": 1.3358185291290283, "rollout_time": 0.44451427459716797, "train_time": 0.8792018890380859, "student_train_time": 0.011735677719116211, "throughput": 1497.2093562020186, "inference_time": 0.056755789243652544, "env_time": 0.3877584853535154, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 148, "reward_mean": 52.8974358974359, "student_loss": null, "teacher_policy_loss": -24.443492889404297, "teacher_value_loss": 179.39439392089844, "teacher_entropy": 0.5467967391014099, "total_time": 1.3041539192199707, "rollout_time": 0.45003652572631836, "train_time": 0.839282751083374, "student_train_time": 0.014406204223632812, "throughput": 1533.5613155203512, "inference_time": 0.05815523721412319, "env_time": 0.39188128851219517, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 149, "reward_mean": 42.93617021276596, "student_loss": null, "teacher_policy_loss": -20.30772590637207, "teacher_value_loss": 130.04873657226562, "teacher_entropy": 0.5430930256843567, "total_time": 1.3981001377105713, "rollout_time": 0.46175265312194824, "train_time": 0.9311189651489258, "student_train_time": 0.00487065315246582, "throughput": 1430.5126979495594, "inference_time": 0.059765173005871475, "env_time": 0.40198748011607677, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 150, "reward_mean": 53.78378378378378, "student_loss": null, "teacher_policy_loss": -26.20807456970215, "teacher_value_loss": 234.0421905517578, "teacher_entropy": 0.5586311221122742, "total_time": 1.284341812133789, "rollout_time": 0.44943690299987793, "train_time": 0.8205370903015137, "student_train_time": 0.014002084732055664, "throughput": 1557.2178536157953, "inference_time": 0.05712278947157756, "env_time": 0.39231411352830037, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 151, "reward_mean": 44.77272727272727, "student_loss": null, "teacher_policy_loss": -23.053041458129883, "teacher_value_loss": 169.57154846191406, "teacher_entropy": 0.5401943922042847, "total_time": 1.2758803367614746, "rollout_time": 0.4481470584869385, "train_time": 0.819042444229126, "student_train_time": 0.008312463760375977, "throughput": 1567.5451234529835, "inference_time": 0.057367094999790424, "env_time": 0.39077996348714805, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 152, "reward_mean": 55.02777777777778, "student_loss": null, "teacher_policy_loss": -26.137542724609375, "teacher_value_loss": 181.36875915527344, "teacher_entropy": 0.5506470799446106, "total_time": 1.274867296218872, "rollout_time": 0.4493532180786133, "train_time": 0.8165433406829834, "student_train_time": 0.008599042892456055, "throughput": 1568.7907329114164, "inference_time": 0.056001413768171915, "env_time": 0.39335180431044137, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 153, "reward_mean": 55.75675675675676, "student_loss": null, "teacher_policy_loss": -26.697376251220703, "teacher_value_loss": 187.9466094970703, "teacher_entropy": 0.5568644404411316, "total_time": 1.2478251457214355, "rollout_time": 0.44733691215515137, "train_time": 0.792060375213623, "student_train_time": 0.008056163787841797, "throughput": 1602.7886654293147, "inference_time": 0.0547362382603751, "env_time": 0.39260067389477626, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 154, "reward_mean": 49.1, "student_loss": null, "teacher_policy_loss": -23.32387924194336, "teacher_value_loss": 142.4649200439453, "teacher_entropy": 0.559374213218689, "total_time": 1.3217413425445557, "rollout_time": 0.44870829582214355, "train_time": 0.8624024391174316, "student_train_time": 0.010270357131958008, "throughput": 1513.155362266033, "inference_time": 0.05823732425324124, "env_time": 0.3904709715689023, "samples": 2000, "teacher_eval_reward": 141.0}
{"epoch": 155, "reward_mean": 45.91111111111111, "student_loss": null, "teacher_policy_loss": -21.209213256835938, "teacher_value_loss": 138.32691955566406, "teacher_entropy": 0.5545758008956909, "total_time": 1.2129673957824707, "rollout_time": 0.4470803737640381, "train_time": 0.7575118541717529, "student_train_time": 0.007968664169311523, "throughput": 1648.848936050605, "inference_time": 0.057010490709217265, "env_time": 0.3900698830548208, "samples": 2000, "teacher_eval_reward": 78.0}
{"epoch": 156, "reward_mean": 45.73809523809524, "student_loss": null, "teacher_policy_loss": -22.86811637878418, "teacher_value_loss": 133.68753051757812, "teacher_entropy": 0.5688418745994568, "total_time": 1.360499382019043, "rollout_time": 0.4686105251312256, "train_time": 0.8758721351623535, "student_train_time": 0.0156557559967041, "throughput": 1470.0484442939687, "inference_time": 0.05286161802450806, "env_time": 0.4157489071067175, "samples": 2000, "teacher_eval_reward": 116.0}
{"epoch": 157, "reward_mean": 50.743589743589745, "student_loss": null, "teacher_policy_loss": -25.197786331176758, "teacher_value_loss": 152.3573760986328, "teacher_entropy": 0.574962854385376, "total_time": 1.2376165390014648, "rollout_time": 0.44202089309692383, "train_time": 0.7828245162963867, "student_train_time": 0.012412786483764648, "throughput": 1616.009431817744, "inference_time": 0.05582180324836372, "env_time": 0.3861990898485601, "samples": 2000, "teacher_eval_reward": 295.0}
{"epoch": 158, "reward_mean": 58.75, "student_loss": null, "teacher_policy_loss": -27.809778213500977, "teacher_value_loss": 215.03697204589844, "teacher_entropy": 0.5834765434265137, "total_time": 1.2105426788330078, "rollout_time": 0.4321167469024658, "train_time": 0.7676224708557129, "student_train_time": 0.010366678237915039, "throughput": 1652.1515804201533, "inference_time": 0.05423281624007359, "env_time": 0.37788393066239223, "samples": 2000, "teacher_eval_reward": 278.0}
{"epoch": 159, "reward_mean": 56.68421052631579, "student_loss": null, "teacher_policy_loss": -27.374670028686523, "teacher_value_loss": 232.00753784179688, "teacher_entropy": 0.5681549906730652, "total_time": -1.2889835834503174, "rollout_time": -2.1180591583251953, "train_time": 0.820197582244873, "student_train_time": 0.008521080017089844, "throughput": 200000000000.0, "inference_time": 0.05891197553228267, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 160, "reward_mean": 53.39473684210526, "student_loss": null, "teacher_policy_loss": -25.306053161621094, "teacher_value_loss": 187.11917114257812, "teacher_entropy": 0.5693394541740417, "total_time": 1.2696211338043213, "rollout_time": 0.4493999481201172, "train_time": 0.8086884021759033, "student_train_time": 0.011159420013427734, "throughput": 1575.273084819528, "inference_time": 0.05587432072206866, "env_time": 0.3935256273980485, "samples": 2000, "teacher_eval_reward": 318.0}
{"epoch": 161, "reward_mean": 56.0, "student_loss": null, "teacher_policy_loss": -25.294124603271484, "teacher_value_loss": 190.02603149414062, "teacher_entropy": 0.5722840428352356, "total_time": 1.198357105255127, "rollout_time": 0.4292302131652832, "train_time": 0.7616193294525146, "student_train_time": 0.007149457931518555, "throughput": 1668.9515931682197, "inference_time": 0.056619638482516166, "env_time": 0.37261057468276704, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 162, "reward_mean": 52.21052631578947, "student_loss": null, "teacher_policy_loss": -25.097103118896484, "teacher_value_loss": 186.5172882080078, "teacher_entropy": 0.5720693469047546, "total_time": 1.2893452644348145, "rollout_time": 0.42424774169921875, "train_time": 0.8572540283203125, "student_train_time": 0.0074045658111572266, "throughput": 1551.174890983682, "inference_time": 0.054031679504078056, "env_time": 0.3702160621951407, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 163, "reward_mean": 59.57575757575758, "student_loss": null, "teacher_policy_loss": -28.139554977416992, "teacher_value_loss": 208.311279296875, "teacher_entropy": 0.5720118284225464, "total_time": 1.2225475311279297, "rollout_time": 0.4285449981689453, "train_time": 0.7861728668212891, "student_train_time": 0.007462501525878906, "throughput": 1635.9282147130818, "inference_time": 0.055229417505870515, "env_time": 0.3733155806630748, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 164, "reward_mean": 51.71052631578947, "student_loss": null, "teacher_policy_loss": -24.9755916595459, "teacher_value_loss": 207.4255828857422, "teacher_entropy": 0.5753663182258606, "total_time": 1.3144159317016602, "rollout_time": 0.42780065536499023, "train_time": 0.8785419464111328, "student_train_time": 0.0077097415924072266, "throughput": 1521.5883737887852, "inference_time": 0.054407772017839306, "env_time": 0.37339288334715093, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 165, "reward_mean": 57.05555555555556, "student_loss": null, "teacher_policy_loss": -26.77613639831543, "teacher_value_loss": 142.4291229248047, "teacher_entropy": 0.5722957253456116, "total_time": 1.1728627681732178, "rollout_time": 0.4287407398223877, "train_time": 0.7298440933227539, "student_train_time": 0.01381683349609375, "throughput": 1705.2293365191247, "inference_time": 0.05288404525617807, "env_time": 0.3758566945662096, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 166, "reward_mean": 60.096774193548384, "student_loss": null, "teacher_policy_loss": -28.63629722595215, "teacher_value_loss": 169.78326416015625, "teacher_entropy": 0.5810698866844177, "total_time": 1.371389389038086, "rollout_time": 0.45052313804626465, "train_time": 0.9060442447662354, "student_train_time": 0.014400243759155273, "throughput": 1458.374999826148, "inference_time": 0.05934113698094734, "env_time": 0.3911820010653173, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 167, "reward_mean": 60.72222222222222, "student_loss": null, "teacher_policy_loss": -26.676706314086914, "teacher_value_loss": 222.6555938720703, "teacher_entropy": 0.5822325348854065, "total_time": 1.2884063720703125, "rollout_time": 0.46596717834472656, "train_time": 0.8163635730743408, "student_train_time": 0.005620002746582031, "throughput": 1552.305269017137, "inference_time": 0.05960603499352146, "env_time": 0.4063611433512051, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 168, "reward_mean": 55.52777777777778, "student_loss": null, "teacher_policy_loss": -27.34006690979004, "teacher_value_loss": 217.9816436767578, "teacher_entropy": 0.5642033815383911, "total_time": 1.3175945281982422, "rollout_time": 0.44924163818359375, "train_time": 0.8489277362823486, "student_train_time": 0.019046783447265625, "throughput": 1517.9176576688733, "inference_time": 0.056368141514212766, "env_time": 0.392873496669381, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 169, "reward_mean": 52.921052631578945, "student_loss": null, "teacher_policy_loss": -24.48857307434082, "teacher_value_loss": 177.56439208984375, "teacher_entropy": 0.5632982850074768, "total_time": 1.2540228366851807, "rollout_time": 0.44225239753723145, "train_time": 0.797677755355835, "student_train_time": 0.013720273971557617, "throughput": 1594.8672874942986, "inference_time": 0.05549915524170501, "env_time": 0.38675324229552643, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 170, "reward_mean": 54.108108108108105, "student_loss": null, "teacher_policy_loss": -24.999650955200195, "teacher_value_loss": 150.65878295898438, "teacher_entropy": 0.5666720867156982, "total_time": 1.2802956104278564, "rollout_time": 0.4445767402648926, "train_time": 0.826167106628418, "student_train_time": 0.009188413619995117, "throughput": 1562.139230745022, "inference_time": 0.05716213900632283, "env_time": 0.38741460125856975, "samples": 2000, "teacher_eval_reward": 154.0}
{"epoch": 171, "reward_mean": 62.774193548387096, "student_loss": null, "teacher_policy_loss": -28.357892990112305, "teacher_value_loss": 178.81765747070312, "teacher_entropy": 0.5668530464172363, "total_time": 1.2574834823608398, "rollout_time": 0.43381452560424805, "train_time": 0.8169984817504883, "student_train_time": 0.006305694580078125, "throughput": 1590.4781478681023, "inference_time": 0.05600360376502067, "env_time": 0.3778109218392274, "samples": 2000, "teacher_eval_reward": 356.0}
{"epoch": 172, "reward_mean": 57.696969696969695, "student_loss": null, "teacher_policy_loss": -28.377315521240234, "teacher_value_loss": 241.52029418945312, "teacher_entropy": 0.5581603646278381, "total_time": 1.2835774421691895, "rollout_time": 0.42935752868652344, "train_time": 0.8460261821746826, "student_train_time": 0.007775306701660156, "throughput": 1558.1451763596654, "inference_time": 0.05787069451525895, "env_time": 0.3714868341712645, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 173, "reward_mean": 55.97142857142857, "student_loss": null, "teacher_policy_loss": -27.11491584777832, "teacher_value_loss": 224.8875274658203, "teacher_entropy": 0.552829921245575, "total_time": 1.2406716346740723, "rollout_time": 0.4347388744354248, "train_time": 0.795396089553833, "student_train_time": 0.010170459747314453, "throughput": 1612.0300844351982, "inference_time": 0.05454332272893225, "env_time": 0.38019555170649255, "samples": 2000, "teacher_eval_reward": 342.0}
{"epoch": 174, "reward_mean": 75.85714285714286, "student_loss": null, "teacher_policy_loss": -34.38407516479492, "teacher_value_loss": 371.1629943847656, "teacher_entropy": 0.5558590292930603, "total_time": 1.2890264987945557, "rollout_time": 0.4670076370239258, "train_time": 0.8108034133911133, "student_train_time": 0.010851144790649414, "throughput": 1551.5584837629929, "inference_time": 0.05896261998441332, "env_time": 0.40804501703951246, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 175, "reward_mean": 58.4, "student_loss": null, "teacher_policy_loss": -26.72045135498047, "teacher_value_loss": 182.6204071044922, "teacher_entropy": 0.5522866249084473, "total_time": 1.2448487281799316, "rollout_time": 0.44466257095336914, "train_time": 0.7894556522369385, "student_train_time": 0.01029825210571289, "throughput": 1606.6209128270227, "inference_time": 0.05506325347505481, "env_time": 0.38959931747831433, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 176, "reward_mean": 60.064516129032256, "student_loss": null, "teacher_policy_loss": -32.09485626220703, "teacher_value_loss": 371.2051696777344, "teacher_entropy": 0.5523923635482788, "total_time": 1.247145175933838, "rollout_time": 0.45032167434692383, "train_time": 0.7823495864868164, "student_train_time": 0.014067888259887695, "throughput": 1603.6625395294811, "inference_time": 0.05577676174289081, "env_time": 0.394544912604033, "samples": 2000, "teacher_eval_reward": 414.0}
{"epoch": 177, "reward_mean": 66.3103448275862, "student_loss": null, "teacher_policy_loss": -28.85797119140625, "teacher_value_loss": 156.92161560058594, "teacher_entropy": 0.5546883344650269, "total_time": 1.2448034286499023, "rollout_time": 0.44719696044921875, "train_time": 0.7876839637756348, "student_train_time": 0.009469270706176758, "throughput": 1606.6793792246974, "inference_time": 0.05560289648565231, "env_time": 0.39159406396356644, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 178, "reward_mean": 64.97058823529412, "student_loss": null, "teacher_policy_loss": -30.31763458251953, "teacher_value_loss": 358.826904296875, "teacher_entropy": 0.5524952411651611, "total_time": 1.2851357460021973, "rollout_time": 0.43879199028015137, "train_time": 0.8389542102813721, "student_train_time": 0.007016181945800781, "throughput": 1556.2558322897826, "inference_time": 0.055148043510598654, "env_time": 0.3836439467695527, "samples": 2000, "teacher_eval_reward": 115.0}
{"epoch": 179, "reward_mean": 62.36666666666667, "student_loss": null, "teacher_policy_loss": -29.587900161743164, "teacher_value_loss": 217.71371459960938, "teacher_entropy": 0.5481194257736206, "total_time": 1.295240879058838, "rollout_time": 0.4455606937408447, "train_time": 0.8376591205596924, "student_train_time": 0.01165318489074707, "throughput": 1544.1143283350214, "inference_time": 0.05489735997070966, "env_time": 0.39066333377013507, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 180, "reward_mean": 66.7741935483871, "student_loss": null, "teacher_policy_loss": -29.80137062072754, "teacher_value_loss": 197.43377685546875, "teacher_entropy": 0.5433005094528198, "total_time": 1.2351856231689453, "rollout_time": 0.4297921657562256, "train_time": 0.7965948581695557, "student_train_time": 0.008441448211669922, "throughput": 1619.1898306498063, "inference_time": 0.055611181495805795, "env_time": 0.3741809842604198, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 181, "reward_mean": 59.08571428571429, "student_loss": null, "teacher_policy_loss": -27.755109786987305, "teacher_value_loss": 195.9607696533203, "teacher_entropy": 0.5335742235183716, "total_time": 1.3326103687286377, "rollout_time": 0.46693944931030273, "train_time": 0.8521151542663574, "student_train_time": 0.013176679611206055, "throughput": 1500.8137764289484, "inference_time": 0.05449888150633342, "env_time": 0.4124405678039693, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 182, "reward_mean": 62.193548387096776, "student_loss": null, "teacher_policy_loss": -32.625892639160156, "teacher_value_loss": 360.9974060058594, "teacher_entropy": 0.5464839935302734, "total_time": 1.4148969650268555, "rollout_time": 0.43975090980529785, "train_time": 0.9673454761505127, "student_train_time": 0.0073430538177490234, "throughput": 1413.5304898064, "inference_time": 0.057070277010097925, "env_time": 0.3826806327951999, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 183, "reward_mean": 59.8, "student_loss": null, "teacher_policy_loss": -27.60703468322754, "teacher_value_loss": 180.0346221923828, "teacher_entropy": 0.5391097664833069, "total_time": 1.2692174911499023, "rollout_time": 0.43581271171569824, "train_time": 0.8189539909362793, "student_train_time": 0.01408696174621582, "throughput": 1575.774060746684, "inference_time": 0.05744062398935057, "env_time": 0.3783720877263477, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 184, "reward_mean": 60.78787878787879, "student_loss": null, "teacher_policy_loss": -27.86833381652832, "teacher_value_loss": 179.9893035888672, "teacher_entropy": 0.5526968240737915, "total_time": 1.2024831771850586, "rollout_time": 0.4336822032928467, "train_time": 0.7557337284088135, "student_train_time": 0.01269984245300293, "throughput": 1663.2249314970716, "inference_time": 0.05560434275139414, "env_time": 0.37807786054145254, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 185, "reward_mean": 62.93333333333333, "student_loss": null, "teacher_policy_loss": -29.084278106689453, "teacher_value_loss": 229.99949645996094, "teacher_entropy": 0.5406655669212341, "total_time": 1.2812302112579346, "rollout_time": 0.43635129928588867, "train_time": 0.8372166156768799, "student_train_time": 0.0072286128997802734, "throughput": 1560.9997191967277, "inference_time": 0.05468889148778544, "env_time": 0.38166240779810323, "samples": 2000, "teacher_eval_reward": 320.0}
{"epoch": 186, "reward_mean": 79.03846153846153, "student_loss": null, "teacher_policy_loss": -35.6933708190918, "teacher_value_loss": 373.68414306640625, "teacher_entropy": 0.5635952353477478, "total_time": 1.2134590148925781, "rollout_time": 0.41953539848327637, "train_time": 0.7841281890869141, "student_train_time": 0.009432077407836914, "throughput": 1648.1809236688975, "inference_time": 0.053009883756203635, "env_time": 0.36652551472707273, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 187, "reward_mean": 76.08, "student_loss": null, "teacher_policy_loss": -32.258419036865234, "teacher_value_loss": 244.47618103027344, "teacher_entropy": 0.5533797740936279, "total_time": 1.1981377601623535, "rollout_time": 0.43576860427856445, "train_time": 0.7513792514801025, "student_train_time": 0.010546684265136719, "throughput": 1669.2571309404273, "inference_time": 0.054808891502034385, "env_time": 0.38095971277653007, "samples": 2000, "teacher_eval_reward": 414.0}
{"epoch": 188, "reward_mean": 57.4054054054054, "student_loss": null, "teacher_policy_loss": -25.244352340698242, "teacher_value_loss": 246.6067657470703, "teacher_entropy": 0.5508109927177429, "total_time": 1.2689533233642578, "rollout_time": 0.45084047317504883, "train_time": 0.811424970626831, "student_train_time": 0.006323337554931641, "throughput": 1576.1021017680825, "inference_time": 0.06145625152203138, "env_time": 0.38938422165301745, "samples": 2000, "teacher_eval_reward": 105.0}
{"epoch": 189, "reward_mean": 65.10714285714286, "student_loss": null, "teacher_policy_loss": -29.645793914794922, "teacher_value_loss": 277.5931701660156, "teacher_entropy": 0.5629926323890686, "total_time": 1.192291259765625, "rollout_time": 0.4213714599609375, "train_time": 0.7644453048706055, "student_train_time": 0.006112813949584961, "throughput": 1677.4424735723976, "inference_time": 0.05539076550849131, "env_time": 0.3659806944524462, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 190, "reward_mean": 74.26923076923077, "student_loss": null, "teacher_policy_loss": -32.20851135253906, "teacher_value_loss": 248.6615753173828, "teacher_entropy": 0.5564106702804565, "total_time": 1.257725715637207, "rollout_time": 0.44725918769836426, "train_time": 0.8010764122009277, "student_train_time": 0.009032011032104492, "throughput": 1590.1718277158159, "inference_time": 0.05849850203321694, "env_time": 0.3887606856651473, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 191, "reward_mean": 73.75862068965517, "student_loss": null, "teacher_policy_loss": -32.186405181884766, "teacher_value_loss": 422.0655822753906, "teacher_entropy": 0.5678902268409729, "total_time": 1.2640953063964844, "rollout_time": 0.41705918312072754, "train_time": 0.8354127407073975, "student_train_time": 0.011257410049438477, "throughput": 1582.159185213127, "inference_time": 0.05288092852333648, "env_time": 0.36417825459739106, "samples": 2000, "teacher_eval_reward": 497.0}
{"epoch": 192, "reward_mean": 57.22222222222222, "student_loss": null, "teacher_policy_loss": -25.468841552734375, "teacher_value_loss": 164.29534912109375, "teacher_entropy": 0.5634954571723938, "total_time": 1.230595588684082, "rollout_time": 0.42730116844177246, "train_time": 0.7884693145751953, "student_train_time": 0.01446843147277832, "throughput": 1625.2292941653304, "inference_time": 0.05818551076299627, "env_time": 0.3691156576787762, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 193, "reward_mean": 68.16666666666667, "student_loss": null, "teacher_policy_loss": -28.775894165039062, "teacher_value_loss": 151.1426239013672, "teacher_entropy": 0.5726920962333679, "total_time": 1.1943564414978027, "rollout_time": 0.44298553466796875, "train_time": 0.7428665161132812, "student_train_time": 0.008152008056640625, "throughput": 1674.5419796889666, "inference_time": 0.05546596875683463, "env_time": 0.3875195659111341, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 194, "reward_mean": 78.70833333333333, "student_loss": null, "teacher_policy_loss": -32.815330505371094, "teacher_value_loss": 265.75732421875, "teacher_entropy": 0.5743981003761292, "total_time": 1.447446584701538, "rollout_time": 0.43139028549194336, "train_time": 1.005955457687378, "student_train_time": 0.009670019149780273, "throughput": 1381.7435621725535, "inference_time": 0.05442923721875559, "env_time": 0.37696104827318777, "samples": 2000, "teacher_eval_reward": 95.0}
{"epoch": 195, "reward_mean": 57.8235294117647, "student_loss": null, "teacher_policy_loss": -27.42961883544922, "teacher_value_loss": 232.2950439453125, "teacher_entropy": 0.5621286034584045, "total_time": 1.1780366897583008, "rollout_time": 0.4308919906616211, "train_time": 0.7388310432434082, "student_train_time": 0.007613182067871094, "throughput": 1697.7399917912085, "inference_time": 0.05595709500266821, "env_time": 0.3749348956589529, "samples": 2000, "teacher_eval_reward": 115.0}
{"epoch": 196, "reward_mean": 72.48275862068965, "student_loss": null, "teacher_policy_loss": -30.612567901611328, "teacher_value_loss": 251.839599609375, "teacher_entropy": 0.5768480896949768, "total_time": 1.341240644454956, "rollout_time": 0.4696497917175293, "train_time": 0.8616175651550293, "student_train_time": 0.009505987167358398, "throughput": 1491.1567199134097, "inference_time": 0.06310180327091075, "env_time": 0.40654798844661855, "samples": 2000, "teacher_eval_reward": 290.0}
{"epoch": 197, "reward_mean": 68.03225806451613, "student_loss": null, "teacher_policy_loss": -31.344402313232422, "teacher_value_loss": 252.2289581298828, "teacher_entropy": 0.567664384841919, "total_time": 1.2588849067687988, "rollout_time": 0.43541884422302246, "train_time": 0.8150479793548584, "student_train_time": 0.008025646209716797, "throughput": 1588.7075849796577, "inference_time": 0.05670957849088154, "env_time": 0.3787092657321409, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 198, "reward_mean": 66.89285714285714, "student_loss": null, "teacher_policy_loss": -30.14690399169922, "teacher_value_loss": 223.83956909179688, "teacher_entropy": 0.5749936699867249, "total_time": 1.2021472454071045, "rollout_time": 0.42940807342529297, "train_time": 0.7577369213104248, "student_train_time": 0.014646053314208984, "throughput": 1663.689708262572, "inference_time": 0.05428577776183374, "env_time": 0.3751222956634592, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 199, "reward_mean": 64.34375, "student_loss": null, "teacher_policy_loss": -29.396535873413086, "teacher_value_loss": 285.09503173828125, "teacher_entropy": 0.567983090877533, "total_time": 1.3058440685272217, "rollout_time": 0.44483184814453125, "train_time": 0.8501720428466797, "student_train_time": 0.010393619537353516, "throughput": 1531.5764325947987, "inference_time": 0.057951531985054316, "env_time": 0.38688031615947693, "samples": 2000, "teacher_eval_reward": 150.0}
{"epoch": 200, "reward_mean": 64.8, "student_loss": null, "teacher_policy_loss": -28.209407806396484, "teacher_value_loss": 211.91932678222656, "teacher_entropy": 0.5730382800102234, "total_time": 1.1905364990234375, "rollout_time": 0.42722010612487793, "train_time": 0.7549641132354736, "student_train_time": 0.007997751235961914, "throughput": 1679.9148968893787, "inference_time": 0.05415442076991894, "env_time": 0.373065685354959, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 201, "reward_mean": 76.6923076923077, "student_loss": null, "teacher_policy_loss": -33.2915153503418, "teacher_value_loss": 331.9309997558594, "teacher_entropy": 0.572665810585022, "total_time": 1.2294869422912598, "rollout_time": 0.4288177490234375, "train_time": 0.785290002822876, "student_train_time": 0.014968395233154297, "throughput": 1626.6947872360643, "inference_time": 0.05511624851988017, "env_time": 0.3737015005035573, "samples": 2000, "teacher_eval_reward": 148.0}
{"epoch": 202, "reward_mean": 76.8076923076923, "student_loss": null, "teacher_policy_loss": -31.340314865112305, "teacher_value_loss": 219.67127990722656, "teacher_entropy": 0.5784938931465149, "total_time": 1.280937671661377, "rollout_time": 0.4572412967681885, "train_time": 0.802743673324585, "student_train_time": 0.020247936248779297, "throughput": 1561.3562191562364, "inference_time": 0.0658510019793539, "env_time": 0.3913902947888346, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 203, "reward_mean": 79.53846153846153, "student_loss": null, "teacher_policy_loss": -31.107831954956055, "teacher_value_loss": 201.95791625976562, "teacher_entropy": 0.5713655948638916, "total_time": -1.3175289630889893, "rollout_time": -2.121102809906006, "train_time": 0.7941560745239258, "student_train_time": 0.008983850479125977, "throughput": 200000000000.0, "inference_time": 0.05625641474580334, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 204, "reward_mean": 85.68181818181819, "student_loss": null, "teacher_policy_loss": -34.4455680847168, "teacher_value_loss": 319.18634033203125, "teacher_entropy": 0.5706490278244019, "total_time": 1.223182201385498, "rollout_time": 0.4513435363769531, "train_time": 0.7629523277282715, "student_train_time": 0.008517265319824219, "throughput": 1635.079383704734, "inference_time": 0.05737514174597891, "env_time": 0.3939683946309742, "samples": 2000, "teacher_eval_reward": 133.0}
{"epoch": 205, "reward_mean": 73.45833333333333, "student_loss": null, "teacher_policy_loss": -34.42964172363281, "teacher_value_loss": 372.034423828125, "teacher_entropy": 0.5602378249168396, "total_time": 1.2448713779449463, "rollout_time": 0.43841099739074707, "train_time": 0.7980220317840576, "student_train_time": 0.008078336715698242, "throughput": 1606.5916812238322, "inference_time": 0.058109740988584235, "env_time": 0.38030125640216284, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 206, "reward_mean": 85.1923076923077, "student_loss": null, "teacher_policy_loss": -30.859764099121094, "teacher_value_loss": 311.03582763671875, "teacher_entropy": 0.5638022422790527, "total_time": 1.275331974029541, "rollout_time": 0.47986769676208496, "train_time": 0.7809576988220215, "student_train_time": 0.014041423797607422, "throughput": 1568.2191309614834, "inference_time": 0.05904049453420157, "env_time": 0.4208272022278834, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 207, "reward_mean": 76.23076923076923, "student_loss": null, "teacher_policy_loss": -33.01069641113281, "teacher_value_loss": 294.3963928222656, "teacher_entropy": 0.569638729095459, "total_time": 1.2358224391937256, "rollout_time": 0.4406239986419678, "train_time": 0.7865171432495117, "student_train_time": 0.008321046829223633, "throughput": 1618.3554664251271, "inference_time": 0.05963786946449545, "env_time": 0.3809861291774723, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 208, "reward_mean": 96.4090909090909, "student_loss": null, "teacher_policy_loss": -38.159603118896484, "teacher_value_loss": 589.4126586914062, "teacher_entropy": 0.5709418654441833, "total_time": 1.2258491516113281, "rollout_time": 0.4229142665863037, "train_time": 0.7907931804656982, "student_train_time": 0.011725664138793945, "throughput": 1631.5221145856997, "inference_time": 0.05570657150565239, "env_time": 0.3672076950806513, "samples": 2000, "teacher_eval_reward": 484.0}
{"epoch": 209, "reward_mean": 83.3913043478261, "student_loss": null, "teacher_policy_loss": -36.79476547241211, "teacher_value_loss": 353.6343078613281, "teacher_entropy": 0.5824270248413086, "total_time": 1.259528398513794, "rollout_time": 0.4454069137573242, "train_time": 0.8062055110931396, "student_train_time": 0.007552385330200195, "throughput": 1587.8959159316619, "inference_time": 0.059307752237145905, "env_time": 0.3860991615201783, "samples": 2000, "teacher_eval_reward": 113.0}
{"epoch": 210, "reward_mean": 72.25, "student_loss": null, "teacher_policy_loss": -29.544252395629883, "teacher_value_loss": 227.591552734375, "teacher_entropy": 0.5580529570579529, "total_time": 1.3862402439117432, "rollout_time": 0.49108266830444336, "train_time": 0.8848378658294678, "student_train_time": 0.00990438461303711, "throughput": 1442.7513620267778, "inference_time": 0.06134637278410082, "env_time": 0.42973629552034254, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 211, "reward_mean": 78.75, "student_loss": null, "teacher_policy_loss": -35.935630798339844, "teacher_value_loss": 295.82476806640625, "teacher_entropy": 0.569040060043335, "total_time": 1.3267290592193604, "rollout_time": 0.43872928619384766, "train_time": 0.87471604347229, "student_train_time": 0.012864828109741211, "throughput": 1507.4667929387092, "inference_time": 0.055746670226653805, "env_time": 0.38298261596719385, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 212, "reward_mean": 87.83333333333333, "student_loss": null, "teacher_policy_loss": -38.69489288330078, "teacher_value_loss": 409.37921142578125, "teacher_entropy": 0.5672776103019714, "total_time": 1.2155349254608154, "rollout_time": 0.434983491897583, "train_time": 0.7741420269012451, "student_train_time": 0.006045103073120117, "throughput": 1645.366133138289, "inference_time": 0.0565939674834226, "env_time": 0.3783895244141604, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 213, "reward_mean": 80.36, "student_loss": null, "teacher_policy_loss": -31.500185012817383, "teacher_value_loss": 257.31658935546875, "teacher_entropy": 0.5599359273910522, "total_time": 1.2175252437591553, "rollout_time": 0.42963624000549316, "train_time": 0.7745585441589355, "student_train_time": 0.012963294982910156, "throughput": 1642.6764128724956, "inference_time": 0.05414450023727113, "env_time": 0.37549173976822203, "samples": 2000, "teacher_eval_reward": 198.0}
{"epoch": 214, "reward_mean": 56.03030303030303, "student_loss": null, "teacher_policy_loss": -27.614011764526367, "teacher_value_loss": 293.8271484375, "teacher_entropy": 0.5435277223587036, "total_time": 1.2611184120178223, "rollout_time": 0.4398007392883301, "train_time": 0.8047685623168945, "student_train_time": 0.016192197799682617, "throughput": 1585.8939025400066, "inference_time": 0.05520586950297002, "env_time": 0.38459486978536006, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 215, "reward_mean": 73.0, "student_loss": null, "teacher_policy_loss": -28.38274383544922, "teacher_value_loss": 211.545166015625, "teacher_entropy": 0.5431346297264099, "total_time": 1.3145637512207031, "rollout_time": 0.43440914154052734, "train_time": 0.862499475479126, "student_train_time": 0.017258644104003906, "throughput": 1521.4172748509163, "inference_time": 0.0562558767524024, "env_time": 0.37815326478812494, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 216, "reward_mean": 103.33333333333333, "student_loss": null, "teacher_policy_loss": -39.54133224487305, "teacher_value_loss": 359.44439697265625, "teacher_entropy": 0.5553872585296631, "total_time": 1.218003273010254, "rollout_time": 0.4400336742401123, "train_time": 0.7658941745758057, "student_train_time": 0.01171565055847168, "throughput": 1642.0317123262466, "inference_time": 0.05427116100236162, "env_time": 0.3857625132377507, "samples": 2000, "teacher_eval_reward": 171.0}
{"epoch": 217, "reward_mean": 87.70833333333333, "student_loss": null, "teacher_policy_loss": -33.435020446777344, "teacher_value_loss": 377.6163635253906, "teacher_entropy": 0.5516281723976135, "total_time": 1.3217105865478516, "rollout_time": 0.4275660514831543, "train_time": 0.8701341152191162, "student_train_time": 0.02365565299987793, "throughput": 1513.1905731524466, "inference_time": 0.05658933548420464, "env_time": 0.37097671599894966, "samples": 2000, "teacher_eval_reward": 204.0}
{"epoch": 218, "reward_mean": 88.9090909090909, "student_loss": null, "teacher_policy_loss": -35.06741714477539, "teacher_value_loss": 329.5824279785156, "teacher_entropy": 0.5523893237113953, "total_time": 1.2364356517791748, "rollout_time": 0.4227268695831299, "train_time": 0.8024966716766357, "student_train_time": 0.010858535766601562, "throughput": 1617.5528399897648, "inference_time": 0.055636425214288465, "env_time": 0.3670904443688414, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 219, "reward_mean": 93.05, "student_loss": null, "teacher_policy_loss": -37.49957275390625, "teacher_value_loss": 406.38433837890625, "teacher_entropy": 0.5494192838668823, "total_time": 1.3265080451965332, "rollout_time": 0.4399542808532715, "train_time": 0.8704366683959961, "student_train_time": 0.01574540138244629, "throughput": 1507.717957114752, "inference_time": 0.05648504551027145, "env_time": 0.38346923534300004, "samples": 2000, "teacher_eval_reward": 161.0}
{"epoch": 220, "reward_mean": 96.69565217391305, "student_loss": null, "teacher_policy_loss": -36.079593658447266, "teacher_value_loss": 394.7062683105469, "teacher_entropy": 0.546754002571106, "total_time": 1.2343623638153076, "rollout_time": 0.4426400661468506, "train_time": 0.7856855392456055, "student_train_time": 0.0056629180908203125, "throughput": 1620.2697511111505, "inference_time": 0.05690249924737145, "env_time": 0.38573756689947913, "samples": 2000, "teacher_eval_reward": 192.0}
{"epoch": 221, "reward_mean": 77.42857142857143, "student_loss": null, "teacher_policy_loss": -37.32495880126953, "teacher_value_loss": 337.9039306640625, "teacher_entropy": 0.5493541359901428, "total_time": 1.4213721752166748, "rollout_time": 0.43273043632507324, "train_time": 0.9739954471588135, "student_train_time": 0.014240741729736328, "throughput": 1407.0910032378529, "inference_time": 0.05693771126334468, "env_time": 0.37579272506172856, "samples": 2000, "teacher_eval_reward": 175.0}
{"epoch": 222, "reward_mean": 101.72727272727273, "student_loss": null, "teacher_policy_loss": -35.16850662231445, "teacher_value_loss": 249.02577209472656, "teacher_entropy": 0.5459330677986145, "total_time": 1.2360858917236328, "rollout_time": 0.4332389831542969, "train_time": 0.7951204776763916, "student_train_time": 0.007361650466918945, "throughput": 1618.0105390662973, "inference_time": 0.054834545752783015, "env_time": 0.37840443740151386, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 223, "reward_mean": 89.0, "student_loss": null, "teacher_policy_loss": -35.80399703979492, "teacher_value_loss": 336.94580078125, "teacher_entropy": 0.555143415927887, "total_time": 1.458423137664795, "rollout_time": 0.4397392272949219, "train_time": 0.9961442947387695, "student_train_time": 0.022106409072875977, "throughput": 1371.3441239024567, "inference_time": 0.05609796949829615, "env_time": 0.3836412577966257, "samples": 2000, "teacher_eval_reward": 380.0}
{"epoch": 224, "reward_mean": 110.61538461538461, "student_loss": null, "teacher_policy_loss": -46.883140563964844, "teacher_value_loss": 497.8535461425781, "teacher_entropy": 0.5629894733428955, "total_time": 1.2596054077148438, "rollout_time": 0.4290790557861328, "train_time": 0.8237395286560059, "student_train_time": 0.0064013004302978516, "throughput": 1587.7988358500052, "inference_time": 0.056489172489818884, "env_time": 0.37258988329631393, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 225, "reward_mean": 120.65, "student_loss": null, "teacher_policy_loss": -41.3105583190918, "teacher_value_loss": 465.1737365722656, "teacher_entropy": 0.5491160154342651, "total_time": 1.2594730854034424, "rollout_time": 0.4449584484100342, "train_time": 0.8042314052581787, "student_train_time": 0.009875774383544922, "throughput": 1587.9656526041185, "inference_time": 0.05744804723053676, "env_time": 0.3875104011794974, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 226, "reward_mean": 122.11111111111111, "student_loss": null, "teacher_policy_loss": -41.505863189697266, "teacher_value_loss": 280.1269836425781, "teacher_entropy": 0.5549074411392212, "total_time": 1.2217817306518555, "rollout_time": 0.43266892433166504, "train_time": 0.7811627388000488, "student_train_time": 0.007593393325805664, "throughput": 1636.9535980317391, "inference_time": 0.055697871484881034, "env_time": 0.376971052846784, "samples": 2000, "teacher_eval_reward": 141.0}
{"epoch": 227, "reward_mean": 89.78947368421052, "student_loss": null, "teacher_policy_loss": -37.54568862915039, "teacher_value_loss": 377.73193359375, "teacher_entropy": 0.5479066967964172, "total_time": 1.3073327541351318, "rollout_time": 0.42421627044677734, "train_time": 0.8710036277770996, "student_train_time": 0.011728048324584961, "throughput": 1529.8323962846807, "inference_time": 0.05379743475714349, "env_time": 0.37041883568963385, "samples": 2000, "teacher_eval_reward": 101.0}
{"epoch": 228, "reward_mean": 115.15789473684211, "student_loss": null, "teacher_policy_loss": -37.02669143676758, "teacher_value_loss": 452.4253234863281, "teacher_entropy": 0.5330954790115356, "total_time": 1.2963929176330566, "rollout_time": 0.4432535171508789, "train_time": 0.847996711730957, "student_train_time": 0.004787921905517578, "throughput": 1542.7421523187456, "inference_time": 0.05641257127535937, "env_time": 0.38684094587551954, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 229, "reward_mean": 111.72222222222223, "student_loss": null, "teacher_policy_loss": -39.412322998046875, "teacher_value_loss": 350.452392578125, "teacher_entropy": 0.5502752661705017, "total_time": 1.3691139221191406, "rollout_time": 0.4473090171813965, "train_time": 0.911301851272583, "student_train_time": 0.010080337524414062, "throughput": 1460.798818628885, "inference_time": 0.05711251649881888, "env_time": 0.3901965006825776, "samples": 2000, "teacher_eval_reward": 118.0}
{"epoch": 230, "reward_mean": 84.38095238095238, "student_loss": null, "teacher_policy_loss": -35.38801956176758, "teacher_value_loss": 307.92425537109375, "teacher_entropy": 0.544032096862793, "total_time": 1.3265435695648193, "rollout_time": 0.42568445205688477, "train_time": 0.8783438205718994, "student_train_time": 0.022144794464111328, "throughput": 1507.6775809603541, "inference_time": 0.05480283199540281, "env_time": 0.37088162006148195, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 231, "reward_mean": 91.91666666666667, "student_loss": null, "teacher_policy_loss": -31.078075408935547, "teacher_value_loss": 274.0931396484375, "teacher_entropy": 0.5059410929679871, "total_time": 1.212395191192627, "rollout_time": 0.43763256072998047, "train_time": 0.7634854316711426, "student_train_time": 0.010919332504272461, "throughput": 1649.627130269801, "inference_time": 0.06080462250611163, "env_time": 0.37682793822386884, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 232, "reward_mean": 93.14285714285714, "student_loss": null, "teacher_policy_loss": -35.26056671142578, "teacher_value_loss": 289.2996520996094, "teacher_entropy": 0.5331158638000488, "total_time": 1.2901153564453125, "rollout_time": 0.4257066249847412, "train_time": 0.8492755889892578, "student_train_time": 0.014706134796142578, "throughput": 1550.248968054028, "inference_time": 0.055694731483526994, "env_time": 0.3700118935012142, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 233, "reward_mean": 86.26086956521739, "student_loss": null, "teacher_policy_loss": -35.16646194458008, "teacher_value_loss": 328.8486633300781, "teacher_entropy": 0.551941454410553, "total_time": 1.2492618560791016, "rollout_time": 0.419405460357666, "train_time": 0.8152883052825928, "student_train_time": 0.01421499252319336, "throughput": 1600.9453824814152, "inference_time": 0.0551096062608849, "env_time": 0.3642958540967811, "samples": 2000, "teacher_eval_reward": 107.0}
{"epoch": 234, "reward_mean": 109.05263157894737, "student_loss": null, "teacher_policy_loss": -36.87128829956055, "teacher_value_loss": 418.3648681640625, "teacher_entropy": 0.5200641751289368, "total_time": 1.4037611484527588, "rollout_time": 0.4512205123901367, "train_time": 0.9389326572418213, "student_train_time": 0.01324462890625, "throughput": 1424.7438050300952, "inference_time": 0.056725091253611026, "env_time": 0.3944954211365257, "samples": 2000, "teacher_eval_reward": 106.0}
{"epoch": 235, "reward_mean": 117.11764705882354, "student_loss": null, "teacher_policy_loss": -36.457950592041016, "teacher_value_loss": 540.9581298828125, "teacher_entropy": 0.47428789734840393, "total_time": 1.3260843753814697, "rollout_time": 0.471848726272583, "train_time": 0.8451113700866699, "student_train_time": 0.008644819259643555, "throughput": 1508.199656922032, "inference_time": 0.0595085612803814, "env_time": 0.4123401649922016, "samples": 2000, "teacher_eval_reward": 101.0}
{"epoch": 236, "reward_mean": 88.04545454545455, "student_loss": null, "teacher_policy_loss": -30.555063247680664, "teacher_value_loss": 355.7141418457031, "teacher_entropy": 0.45883646607398987, "total_time": 1.3408160209655762, "rollout_time": 0.458221435546875, "train_time": 0.8696582317352295, "student_train_time": 0.012563228607177734, "throughput": 1491.6289548507323, "inference_time": 0.06122731549658056, "env_time": 0.39699412005029444, "samples": 2000, "teacher_eval_reward": 99.0}
{"epoch": 237, "reward_mean": 124.11764705882354, "student_loss": null, "teacher_policy_loss": -35.98524475097656, "teacher_value_loss": 422.086181640625, "teacher_entropy": 0.500778317451477, "total_time": 1.250411033630371, "rollout_time": 0.446577787399292, "train_time": 0.7983226776123047, "student_train_time": 0.005140066146850586, "throughput": 1599.4740498996682, "inference_time": 0.05682023946519621, "env_time": 0.3897575479340958, "samples": 2000, "teacher_eval_reward": 139.0}
{"epoch": 238, "reward_mean": 92.28571428571429, "student_loss": null, "teacher_policy_loss": -36.441280364990234, "teacher_value_loss": 401.0697937011719, "teacher_entropy": 0.5349714159965515, "total_time": 1.4715306758880615, "rollout_time": 0.47007250785827637, "train_time": 0.9897544384002686, "student_train_time": 0.011331796646118164, "throughput": 1359.128989134399, "inference_time": 0.062085936218863935, "env_time": 0.40798657163941243, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 239, "reward_mean": 142.71428571428572, "student_loss": null, "teacher_policy_loss": -43.340309143066406, "teacher_value_loss": 494.18048095703125, "teacher_entropy": 0.5094392895698547, "total_time": 1.4962468147277832, "rollout_time": 0.5365593433380127, "train_time": 0.8636419773101807, "student_train_time": 0.08373332023620605, "throughput": 1336.6778664547173, "inference_time": 0.07131008675241901, "env_time": 0.4652492565855937, "samples": 2000, "teacher_eval_reward": 30.0}
{"epoch": 240, "reward_mean": 91.63157894736842, "student_loss": null, "teacher_policy_loss": -33.370384216308594, "teacher_value_loss": 478.49713134765625, "teacher_entropy": 0.41165921092033386, "total_time": 1.2833857536315918, "rollout_time": 0.4757044315338135, "train_time": 0.8020751476287842, "student_train_time": 0.005231618881225586, "throughput": 1558.3779034016916, "inference_time": 0.06140118977873499, "env_time": 0.4143032417550785, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 241, "reward_mean": 130.41176470588235, "student_loss": null, "teacher_policy_loss": -31.556312561035156, "teacher_value_loss": 303.3248291015625, "teacher_entropy": 0.4070167541503906, "total_time": 1.2855639457702637, "rollout_time": 0.4497084617614746, "train_time": 0.8262250423431396, "student_train_time": 0.009206295013427734, "throughput": 1555.7374695987387, "inference_time": 0.05778986974110012, "env_time": 0.3919185920203745, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 242, "reward_mean": 123.23529411764706, "student_loss": null, "teacher_policy_loss": -34.88554000854492, "teacher_value_loss": 355.0473327636719, "teacher_entropy": 0.4283135235309601, "total_time": 1.3849546909332275, "rollout_time": 0.46839356422424316, "train_time": 0.9069161415100098, "student_train_time": 0.009209156036376953, "throughput": 1444.0905634626465, "inference_time": 0.06126046198551194, "env_time": 0.4071331022387312, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 243, "reward_mean": 113.3529411764706, "student_loss": null, "teacher_policy_loss": -40.69911575317383, "teacher_value_loss": 433.5828857421875, "teacher_entropy": 0.5106151700019836, "total_time": 1.2728874683380127, "rollout_time": 0.44119977951049805, "train_time": 0.8221676349639893, "student_train_time": 0.00907444953918457, "throughput": 1571.2308037813946, "inference_time": 0.05532595248951111, "env_time": 0.38587382702098694, "samples": 2000, "teacher_eval_reward": 340.0}
{"epoch": 244, "reward_mean": 107.52941176470588, "student_loss": null, "teacher_policy_loss": -36.78567123413086, "teacher_value_loss": 336.378173828125, "teacher_entropy": 0.5096504092216492, "total_time": 1.2541306018829346, "rollout_time": 0.4409916400909424, "train_time": 0.8017110824584961, "student_train_time": 0.01101231575012207, "throughput": 1594.7302434030612, "inference_time": 0.05554056352139014, "env_time": 0.38545107656955224, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 245, "reward_mean": 100.9, "student_loss": null, "teacher_policy_loss": -31.846338272094727, "teacher_value_loss": 320.4852600097656, "teacher_entropy": 0.45932692289352417, "total_time": -1.2834014892578125, "rollout_time": 0.43633532524108887, "train_time": -1.7298545837402344, "student_train_time": 0.009716033935546875, "throughput": 200000000000.0, "inference_time": 0.05854554276356794, "env_time": 0.37778978247752093, "samples": 2000, "teacher_eval_reward": 289.0}
{"epoch": 246, "reward_mean": 108.16666666666667, "student_loss": null, "teacher_policy_loss": -35.07484436035156, "teacher_value_loss": 252.48544311523438, "teacher_entropy": 0.48285070061683655, "total_time": 1.327028512954712, "rollout_time": 0.4454386234283447, "train_time": 0.8680377006530762, "student_train_time": 0.013180017471313477, "throughput": 1507.1266219795648, "inference_time": 0.05812795299880236, "env_time": 0.38731067042954237, "samples": 2000, "teacher_eval_reward": 462.0}
{"epoch": 247, "reward_mean": 100.52631578947368, "student_loss": null, "teacher_policy_loss": -38.728702545166016, "teacher_value_loss": 412.1544494628906, "teacher_entropy": 0.5176604390144348, "total_time": 1.335733413696289, "rollout_time": 0.435349702835083, "train_time": 0.8889539241790771, "student_train_time": 0.011054039001464844, "throughput": 1497.3047611839916, "inference_time": 0.05514861955089145, "env_time": 0.38020108328419155, "samples": 2000, "teacher_eval_reward": 387.0}
{"epoch": 248, "reward_mean": 139.35294117647058, "student_loss": null, "teacher_policy_loss": -42.73546600341797, "teacher_value_loss": 682.9956665039062, "teacher_entropy": 0.5226816534996033, "total_time": 1.3409998416900635, "rollout_time": 0.43128061294555664, "train_time": 0.8909416198730469, "student_train_time": 0.018398284912109375, "throughput": 1491.4244862843518, "inference_time": 0.05381219723585673, "env_time": 0.3774684157096999, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 249, "reward_mean": 104.22222222222223, "student_loss": null, "teacher_policy_loss": -36.96388244628906, "teacher_value_loss": 272.322509765625, "teacher_entropy": 0.5196295976638794, "total_time": 1.2473902702331543, "rollout_time": 0.4365875720977783, "train_time": 0.8025484085083008, "student_train_time": 0.007898092269897461, "throughput": 1603.3474428385373, "inference_time": 0.05682387947126699, "env_time": 0.37976369262651133, "samples": 2000, "teacher_eval_reward": 157.0}
{"epoch": 250, "reward_mean": 120.0, "student_loss": null, "teacher_policy_loss": -41.91196823120117, "teacher_value_loss": 385.286865234375, "teacher_entropy": 0.4959245026111603, "total_time": 1.3074512481689453, "rollout_time": 0.4869849681854248, "train_time": 0.8103258609771729, "student_train_time": 0.008804798126220703, "throughput": 1529.6937478938148, "inference_time": 0.06201831925227452, "env_time": 0.4249666489331503, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 251, "reward_mean": 133.6, "student_loss": null, "teacher_policy_loss": -41.292572021484375, "teacher_value_loss": 309.68377685546875, "teacher_entropy": 0.5309695601463318, "total_time": 1.2776453495025635, "rollout_time": 0.43103909492492676, "train_time": 0.8364171981811523, "student_train_time": 0.00975489616394043, "throughput": 1565.3796264970376, "inference_time": 0.05735508797533839, "env_time": 0.37368400694958837, "samples": 2000, "teacher_eval_reward": 162.0}
{"epoch": 252, "reward_mean": 109.47368421052632, "student_loss": null, "teacher_policy_loss": -39.492759704589844, "teacher_value_loss": 338.31182861328125, "teacher_entropy": 0.5208330154418945, "total_time": 1.3776063919067383, "rollout_time": 0.44035983085632324, "train_time": 0.9267585277557373, "student_train_time": 0.010126352310180664, "throughput": 1451.7934961319465, "inference_time": 0.055135044737653516, "env_time": 0.3852247861186697, "samples": 2000, "teacher_eval_reward": 160.0}
{"epoch": 253, "reward_mean": 114.46666666666667, "student_loss": null, "teacher_policy_loss": -43.6197624206543, "teacher_value_loss": 328.5909118652344, "teacher_entropy": 0.5178132057189941, "total_time": 1.4054100513458252, "rollout_time": 0.45095324516296387, "train_time": 0.9453177452087402, "student_train_time": 0.008732795715332031, "throughput": 1423.0722187341648, "inference_time": 0.05705406951437908, "env_time": 0.3938991756485848, "samples": 2000, "teacher_eval_reward": 142.0}
{"epoch": 254, "reward_mean": 142.2, "student_loss": null, "teacher_policy_loss": -41.95741271972656, "teacher_value_loss": 234.0636749267578, "teacher_entropy": 0.5327606201171875, "total_time": 1.3268463611602783, "rollout_time": 0.45624709129333496, "train_time": 0.8290932178497314, "student_train_time": 0.04109501838684082, "throughput": 1507.3335229642364, "inference_time": 0.06300535152058728, "env_time": 0.3932417397727477, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 255, "reward_mean": 130.21428571428572, "student_loss": null, "teacher_policy_loss": -45.51046371459961, "teacher_value_loss": 394.0350646972656, "teacher_entropy": 0.5305111408233643, "total_time": 1.207270622253418, "rollout_time": 0.4526078701019287, "train_time": 0.7397964000701904, "student_train_time": 0.014489412307739258, "throughput": 1656.629394548607, "inference_time": 0.05534483449173422, "env_time": 0.3972630356101945, "samples": 2000, "teacher_eval_reward": 182.0}
{"epoch": 256, "reward_mean": 162.21428571428572, "student_loss": null, "teacher_policy_loss": -46.241729736328125, "teacher_value_loss": 471.6231384277344, "teacher_entropy": 0.5285654664039612, "total_time": 1.3223326206207275, "rollout_time": 0.4491589069366455, "train_time": 0.8675730228424072, "student_train_time": 0.005236148834228516, "throughput": 1512.4787582273837, "inference_time": 0.06079854173640342, "env_time": 0.3883603652002421, "samples": 2000, "teacher_eval_reward": 169.0}
{"epoch": 257, "reward_mean": 127.625, "student_loss": null, "teacher_policy_loss": -42.287391662597656, "teacher_value_loss": 345.50946044921875, "teacher_entropy": 0.5207679271697998, "total_time": 1.2728044986724854, "rollout_time": 0.44281935691833496, "train_time": 0.8212828636169434, "student_train_time": 0.00834345817565918, "throughput": 1571.333226812105, "inference_time": 0.057266935233201366, "env_time": 0.3855524216851336, "samples": 2000, "teacher_eval_reward": 149.0}
{"epoch": 258, "reward_mean": 115.125, "student_loss": null, "teacher_policy_loss": -41.91080856323242, "teacher_value_loss": 414.9715576171875, "teacher_entropy": 0.5237734317779541, "total_time": 1.270634651184082, "rollout_time": 0.4375896453857422, "train_time": 0.8204421997070312, "student_train_time": 0.012225866317749023, "throughput": 1574.016573636045, "inference_time": 0.05646117351625435, "env_time": 0.38112847186948784, "samples": 2000, "teacher_eval_reward": 182.0}
{"epoch": 259, "reward_mean": 160.07692307692307, "student_loss": null, "teacher_policy_loss": -49.080875396728516, "teacher_value_loss": 566.6807250976562, "teacher_entropy": 0.5361341834068298, "total_time": 1.3274474143981934, "rollout_time": 0.4412856101989746, "train_time": 0.8801038265228271, "student_train_time": 0.005617618560791016, "throughput": 1506.6510193224585, "inference_time": 0.054029496963266865, "env_time": 0.38725611323570774, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 260, "reward_mean": 110.38888888888889, "student_loss": null, "teacher_policy_loss": -40.41106414794922, "teacher_value_loss": 309.3630065917969, "teacher_entropy": 0.5377671122550964, "total_time": 1.1959238052368164, "rollout_time": 0.43123292922973633, "train_time": 0.7532894611358643, "student_train_time": 0.010918617248535156, "throughput": 1672.3473445734787, "inference_time": 0.05553664900435251, "env_time": 0.3756962802253838, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 261, "reward_mean": 138.92857142857142, "student_loss": null, "teacher_policy_loss": -41.93095779418945, "teacher_value_loss": 423.7948913574219, "teacher_entropy": 0.5247665643692017, "total_time": 1.3112330436706543, "rollout_time": 0.43056344985961914, "train_time": 0.8654687404632568, "student_train_time": 0.014847517013549805, "throughput": 1525.2818784990482, "inference_time": 0.05510084301204188, "env_time": 0.37546260684757726, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 262, "reward_mean": 132.5, "student_loss": null, "teacher_policy_loss": -40.45615768432617, "teacher_value_loss": 364.0970458984375, "teacher_entropy": 0.5145186185836792, "total_time": 1.2468163967132568, "rollout_time": 0.427945613861084, "train_time": 0.8090982437133789, "student_train_time": 0.009412527084350586, "throughput": 1604.0854172853492, "inference_time": 0.05620558299779077, "env_time": 0.3717400308632932, "samples": 2000, "teacher_eval_reward": 213.0}
{"epoch": 263, "reward_mean": 132.05882352941177, "student_loss": null, "teacher_policy_loss": -41.42051696777344, "teacher_value_loss": 328.58935546875, "teacher_entropy": 0.5392691493034363, "total_time": 1.2212531566619873, "rollout_time": 0.4349644184112549, "train_time": 0.7743740081787109, "student_train_time": 0.011527776718139648, "throughput": 1637.6620924907468, "inference_time": 0.056011419252172345, "env_time": 0.37895299915908254, "samples": 2000, "teacher_eval_reward": 181.0}
{"epoch": 264, "reward_mean": 158.25, "student_loss": null, "teacher_policy_loss": -45.599544525146484, "teacher_value_loss": 366.5154113769531, "teacher_entropy": 0.5307219624519348, "total_time": 1.2994697093963623, "rollout_time": 0.4298827648162842, "train_time": 0.8562273979187012, "student_train_time": 0.012858390808105469, "throughput": 1539.0893574033767, "inference_time": 0.05749389774609881, "env_time": 0.37238886707018537, "samples": 2000, "teacher_eval_reward": 130.0}
{"epoch": 265, "reward_mean": 124.6, "student_loss": null, "teacher_policy_loss": -43.6564826965332, "teacher_value_loss": 407.1295166015625, "teacher_entropy": 0.5131763219833374, "total_time": 1.3060603141784668, "rollout_time": 0.45265698432922363, "train_time": 0.8475747108459473, "student_train_time": 0.005468606948852539, "throughput": 1531.32284802485, "inference_time": 0.055299866493442096, "env_time": 0.39735711783578154, "samples": 2000, "teacher_eval_reward": 185.0}
{"epoch": 266, "reward_mean": 122.11764705882354, "student_loss": null, "teacher_policy_loss": -41.82341766357422, "teacher_value_loss": 280.65423583984375, "teacher_entropy": 0.5310406684875488, "total_time": 1.273392915725708, "rollout_time": 0.48362255096435547, "train_time": 0.7765803337097168, "student_train_time": 0.012758255004882812, "throughput": 1570.6071357089322, "inference_time": 0.05786313623684691, "env_time": 0.42575941472750856, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 267, "reward_mean": 139.13333333333333, "student_loss": null, "teacher_policy_loss": -42.73936080932617, "teacher_value_loss": 421.37451171875, "teacher_entropy": 0.5297130942344666, "total_time": 1.3421227931976318, "rollout_time": 0.44406676292419434, "train_time": 0.8823957443237305, "student_train_time": 0.015220880508422852, "throughput": 1490.1766143431362, "inference_time": 0.057834516753246135, "env_time": 0.3862322461709482, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 268, "reward_mean": 129.2, "student_loss": null, "teacher_policy_loss": -41.58243179321289, "teacher_value_loss": 541.576171875, "teacher_entropy": 0.5210421681404114, "total_time": 1.3131651878356934, "rollout_time": 0.44153404235839844, "train_time": 0.8634114265441895, "student_train_time": 0.007856130599975586, "throughput": 1523.037633442233, "inference_time": 0.05564247851634718, "env_time": 0.38589156384205126, "samples": 2000, "teacher_eval_reward": 466.0}
{"epoch": 269, "reward_mean": 148.78571428571428, "student_loss": null, "teacher_policy_loss": -44.163299560546875, "teacher_value_loss": 428.80450439453125, "teacher_entropy": 0.5295734405517578, "total_time": 1.2249493598937988, "rollout_time": 0.4337451457977295, "train_time": 0.7850182056427002, "student_train_time": 0.005770683288574219, "throughput": 1632.720556034575, "inference_time": 0.056464514503204555, "env_time": 0.37728063129452494, "samples": 2000, "teacher_eval_reward": 242.0}
{"epoch": 270, "reward_mean": 125.13333333333334, "student_loss": null, "teacher_policy_loss": -43.660179138183594, "teacher_value_loss": 309.99151611328125, "teacher_entropy": 0.5370370149612427, "total_time": 1.3038616180419922, "rollout_time": 0.4786999225616455, "train_time": 0.8159372806549072, "student_train_time": 0.008840084075927734, "throughput": 1533.9051110373186, "inference_time": 0.06692397524511762, "env_time": 0.4117759473165279, "samples": 2000, "teacher_eval_reward": 154.0}
{"epoch": 271, "reward_mean": 154.0, "student_loss": null, "teacher_policy_loss": -43.6033821105957, "teacher_value_loss": 321.2869873046875, "teacher_entropy": 0.5273650288581848, "total_time": 1.2548654079437256, "rollout_time": 0.42638087272644043, "train_time": 0.8189408779144287, "student_train_time": 0.009179353713989258, "throughput": 1593.796424173715, "inference_time": 0.054627888503091526, "env_time": 0.3717529842233489, "samples": 2000, "teacher_eval_reward": 259.0}
{"epoch": 272, "reward_mean": 155.92307692307693, "student_loss": null, "teacher_policy_loss": -47.265750885009766, "teacher_value_loss": 445.8269348144531, "teacher_entropy": 0.537596583366394, "total_time": 1.1861870288848877, "rollout_time": 0.4326517581939697, "train_time": 0.7480168342590332, "student_train_time": 0.005166530609130859, "throughput": 1686.07475153405, "inference_time": 0.055761713513675204, "env_time": 0.3768900446802945, "samples": 2000, "teacher_eval_reward": 226.0}
{"epoch": 273, "reward_mean": 155.6153846153846, "student_loss": null, "teacher_policy_loss": -44.17115020751953, "teacher_value_loss": 392.3492126464844, "teacher_entropy": 0.5203782320022583, "total_time": 1.2910943031311035, "rollout_time": 0.4367868900299072, "train_time": 0.8431651592254639, "student_train_time": 0.010679960250854492, "throughput": 1549.0735224760037, "inference_time": 0.05607804676856176, "env_time": 0.38070884326134546, "samples": 2000, "teacher_eval_reward": 194.0}
{"epoch": 274, "reward_mean": 161.63636363636363, "student_loss": null, "teacher_policy_loss": -46.89496994018555, "teacher_value_loss": 353.4548645019531, "teacher_entropy": 0.5487711429595947, "total_time": -1.230515480041504, "rollout_time": 0.4320504665374756, "train_time": -1.6682112216949463, "student_train_time": 0.005288600921630859, "throughput": 200000000000.0, "inference_time": 0.056864688276618836, "env_time": 0.37518577826085675, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 275, "reward_mean": 162.76923076923077, "student_loss": null, "teacher_policy_loss": -44.17625045776367, "teacher_value_loss": 322.5711975097656, "teacher_entropy": 0.5307106971740723, "total_time": 1.3414011001586914, "rollout_time": 0.42916417121887207, "train_time": 0.893625020980835, "student_train_time": 0.018236398696899414, "throughput": 1490.978350743409, "inference_time": 0.0534040817492496, "env_time": 0.37576008946962247, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 276, "reward_mean": 200.1818181818182, "student_loss": null, "teacher_policy_loss": -51.30767822265625, "teacher_value_loss": 375.7177429199219, "teacher_entropy": 0.5408027172088623, "total_time": 1.2371788024902344, "rollout_time": 0.42485952377319336, "train_time": 0.8004992008209229, "student_train_time": 0.011459827423095703, "throughput": 1616.5812055414576, "inference_time": 0.05717401350648288, "env_time": 0.3676855102667105, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 277, "reward_mean": 145.15384615384616, "student_loss": null, "teacher_policy_loss": -45.08112335205078, "teacher_value_loss": 430.5997009277344, "teacher_entropy": 0.540890634059906, "total_time": 1.2453241348266602, "rollout_time": 0.43443799018859863, "train_time": 0.7951583862304688, "student_train_time": 0.015366792678833008, "throughput": 1606.0075799288875, "inference_time": 0.05719980047797435, "env_time": 0.3772381897106243, "samples": 2000, "teacher_eval_reward": 350.0}
{"epoch": 278, "reward_mean": 163.58333333333334, "student_loss": null, "teacher_policy_loss": -44.904319763183594, "teacher_value_loss": 292.5989990234375, "teacher_entropy": 0.5341209173202515, "total_time": 1.624541997909546, "rollout_time": 0.4428136348724365, "train_time": 1.1691911220550537, "student_train_time": 0.01204371452331543, "throughput": 1231.1162177238828, "inference_time": 0.05530755501240492, "env_time": 0.3875060798600316, "samples": 2000, "teacher_eval_reward": 344.0}
{"epoch": 279, "reward_mean": 143.78571428571428, "student_loss": null, "teacher_policy_loss": -43.7756233215332, "teacher_value_loss": 315.8293762207031, "teacher_entropy": 0.5331088900566101, "total_time": 1.300685167312622, "rollout_time": 0.43843793869018555, "train_time": 0.8496196269989014, "student_train_time": 0.012171506881713867, "throughput": 1537.6511167050899, "inference_time": 0.05725888296728954, "env_time": 0.381179055722896, "samples": 2000, "teacher_eval_reward": 347.0}
{"epoch": 280, "reward_mean": 158.71428571428572, "student_loss": null, "teacher_policy_loss": -47.09371566772461, "teacher_value_loss": 444.6058349609375, "teacher_entropy": 0.5310561060905457, "total_time": 1.336237907409668, "rollout_time": 0.459334135055542, "train_time": 0.8665881156921387, "student_train_time": 0.00994420051574707, "throughput": 1496.7394570305614, "inference_time": 0.05724961949272256, "env_time": 0.40208451556281943, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 281, "reward_mean": 174.63636363636363, "student_loss": null, "teacher_policy_loss": -49.731754302978516, "teacher_value_loss": 364.6321105957031, "teacher_entropy": 0.54251629114151, "total_time": 1.3249883651733398, "rollout_time": 0.4415576457977295, "train_time": 0.8735775947570801, "student_train_time": 0.009374856948852539, "throughput": 1509.4472167220522, "inference_time": 0.06202185298207041, "env_time": 0.3795357928156591, "samples": 2000, "teacher_eval_reward": 488.0}
{"epoch": 282, "reward_mean": 148.0, "student_loss": null, "teacher_policy_loss": -50.45741653442383, "teacher_value_loss": 596.8060302734375, "teacher_entropy": 0.53824782371521, "total_time": 1.5633959770202637, "rollout_time": 0.48632216453552246, "train_time": 1.0686097145080566, "student_train_time": 0.008106708526611328, "throughput": 1279.2664362689973, "inference_time": 0.0678315617797125, "env_time": 0.41849060275580996, "samples": 2000, "teacher_eval_reward": 191.0}
{"epoch": 283, "reward_mean": 174.83333333333334, "student_loss": null, "teacher_policy_loss": -47.20729064941406, "teacher_value_loss": 355.9832763671875, "teacher_entropy": 0.5227954983711243, "total_time": 1.5998377799987793, "rollout_time": 0.49034810066223145, "train_time": 1.0855662822723389, "student_train_time": 0.02356100082397461, "throughput": 1250.126747226538, "inference_time": 0.057725341504919925, "env_time": 0.4326227591573115, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 284, "reward_mean": 178.45454545454547, "student_loss": null, "teacher_policy_loss": -47.8532829284668, "teacher_value_loss": 370.6370849609375, "teacher_entropy": 0.537767231464386, "total_time": 1.4112815856933594, "rollout_time": 0.42360711097717285, "train_time": 0.97939133644104, "student_train_time": 0.007925987243652344, "throughput": 1417.1516303157919, "inference_time": 0.0543521952449737, "env_time": 0.36925491573219915, "samples": 2000, "teacher_eval_reward": 256.0}
{"epoch": 285, "reward_mean": 154.5, "student_loss": null, "teacher_policy_loss": -42.42853546142578, "teacher_value_loss": 447.33782958984375, "teacher_entropy": 0.5210090279579163, "total_time": 1.3967392444610596, "rollout_time": 0.4293186664581299, "train_time": 0.9515156745910645, "student_train_time": 0.015454530715942383, "throughput": 1431.9064978887398, "inference_time": 0.0579925810043278, "env_time": 0.3713260854538021, "samples": 2000, "teacher_eval_reward": 198.0}
{"epoch": 286, "reward_mean": 179.9, "student_loss": null, "teacher_policy_loss": -51.608795166015625, "teacher_value_loss": 466.128662109375, "teacher_entropy": 0.5353649854660034, "total_time": 1.2230472564697266, "rollout_time": 0.4326653480529785, "train_time": 0.7773663997650146, "student_train_time": 0.01266026496887207, "throughput": 1635.259790184162, "inference_time": 0.0564339827551521, "env_time": 0.3762313652978264, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 287, "reward_mean": 207.36363636363637, "student_loss": null, "teacher_policy_loss": -49.29104232788086, "teacher_value_loss": 513.3856201171875, "teacher_entropy": 0.5442668795585632, "total_time": 1.193157434463501, "rollout_time": 0.436598539352417, "train_time": 0.7495231628417969, "student_train_time": 0.0066759586334228516, "throughput": 1676.2247313149358, "inference_time": 0.054283963501802646, "env_time": 0.38231457585061435, "samples": 2000, "teacher_eval_reward": 169.0}
{"epoch": 288, "reward_mean": 185.0909090909091, "student_loss": null, "teacher_policy_loss": -47.43434143066406, "teacher_value_loss": 430.3319396972656, "teacher_entropy": 0.5172511339187622, "total_time": 1.2098214626312256, "rollout_time": 0.4601895809173584, "train_time": 0.7427730560302734, "student_train_time": 0.006500720977783203, "throughput": 1653.1364848249798, "inference_time": 0.058601826992344286, "env_time": 0.4015877539250141, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 289, "reward_mean": 192.5, "student_loss": null, "teacher_policy_loss": -53.825313568115234, "teacher_value_loss": 595.2117919921875, "teacher_entropy": 0.5365410447120667, "total_time": 1.2753863334655762, "rollout_time": 0.43668341636657715, "train_time": 0.822455644607544, "student_train_time": 0.015842676162719727, "throughput": 1568.1522904243836, "inference_time": 0.05698347676934645, "env_time": 0.3796999395972307, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 290, "reward_mean": 202.3, "student_loss": null, "teacher_policy_loss": -52.75719451904297, "teacher_value_loss": 524.0242919921875, "teacher_entropy": 0.5344992876052856, "total_time": 1.3437769412994385, "rollout_time": 0.4478943347930908, "train_time": 0.8696596622467041, "student_train_time": 0.025795698165893555, "throughput": 1488.3422527447083, "inference_time": 0.05819946773499396, "env_time": 0.38969486705809686, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 291, "reward_mean": 169.1, "student_loss": null, "teacher_policy_loss": -50.40950393676758, "teacher_value_loss": 316.14678955078125, "teacher_entropy": 0.5255801677703857, "total_time": 1.214428424835205, "rollout_time": 0.42633748054504395, "train_time": 0.780289888381958, "student_train_time": 0.00715947151184082, "throughput": 1646.865273489786, "inference_time": 0.05411357124103233, "env_time": 0.3722239093040116, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 292, "reward_mean": 146.53333333333333, "student_loss": null, "teacher_policy_loss": -45.942508697509766, "teacher_value_loss": 546.4158325195312, "teacher_entropy": 0.5235723853111267, "total_time": 1.230576515197754, "rollout_time": 0.4295065402984619, "train_time": 0.7877800464630127, "student_train_time": 0.01290583610534668, "throughput": 1625.254484625525, "inference_time": 0.05469644397180673, "env_time": 0.3748100963266552, "samples": 2000, "teacher_eval_reward": 386.0}
{"epoch": 293, "reward_mean": 180.72727272727272, "student_loss": null, "teacher_policy_loss": -48.05739974975586, "teacher_value_loss": 306.8907775878906, "teacher_entropy": 0.4997890591621399, "total_time": 1.2278680801391602, "rollout_time": 0.4225127696990967, "train_time": 0.7995514869689941, "student_train_time": 0.005141735076904297, "throughput": 1628.8394757955841, "inference_time": 0.054326538993336726, "env_time": 0.36818623070575995, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 294, "reward_mean": 189.66666666666666, "student_loss": null, "teacher_policy_loss": -48.69662857055664, "teacher_value_loss": 448.913330078125, "teacher_entropy": 0.5156312584877014, "total_time": 1.2000067234039307, "rollout_time": 0.42170238494873047, "train_time": 0.7691566944122314, "student_train_time": 0.00879669189453125, "throughput": 1666.6573286579712, "inference_time": 0.05514391101132787, "env_time": 0.3665584739374026, "samples": 2000, "teacher_eval_reward": 170.0}
{"epoch": 295, "reward_mean": 167.1, "student_loss": null, "teacher_policy_loss": -48.2702522277832, "teacher_value_loss": 379.87481689453125, "teacher_entropy": 0.5060824751853943, "total_time": 1.2272536754608154, "rollout_time": 0.43591928482055664, "train_time": 0.7855825424194336, "student_train_time": 0.005369901657104492, "throughput": 1629.654927901544, "inference_time": 0.056852000756407506, "env_time": 0.37906728406414913, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 296, "reward_mean": 172.41666666666666, "student_loss": null, "teacher_policy_loss": -48.53833770751953, "teacher_value_loss": 304.88775634765625, "teacher_entropy": 0.5234087705612183, "total_time": 1.3079235553741455, "rollout_time": 0.4278743267059326, "train_time": 0.8602750301361084, "student_train_time": 0.019331932067871094, "throughput": 1529.1413567575657, "inference_time": 0.05871927824591694, "env_time": 0.3691550484600157, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 297, "reward_mean": 152.0, "student_loss": null, "teacher_policy_loss": -43.58439636230469, "teacher_value_loss": 526.7550048828125, "teacher_entropy": 0.5121170282363892, "total_time": 1.305030107498169, "rollout_time": 0.42984676361083984, "train_time": 0.8660869598388672, "student_train_time": 0.00868082046508789, "throughput": 1532.531692953916, "inference_time": 0.05549145398708788, "env_time": 0.37435530962375196, "samples": 2000, "teacher_eval_reward": 461.0}
{"epoch": 298, "reward_mean": 161.36363636363637, "student_loss": null, "teacher_policy_loss": -45.55457305908203, "teacher_value_loss": 381.28094482421875, "teacher_entropy": 0.4866284132003784, "total_time": 1.3028032779693604, "rollout_time": 0.43561315536499023, "train_time": 0.8540351390838623, "student_train_time": 0.012801647186279297, "throughput": 1535.151188072952, "inference_time": 0.05792496249523538, "env_time": 0.37768819286975486, "samples": 2000, "teacher_eval_reward": 408.0}
{"epoch": 299, "reward_mean": 174.5, "student_loss": null, "teacher_policy_loss": -48.93547058105469, "teacher_value_loss": 376.6518249511719, "teacher_entropy": 0.5117855668067932, "total_time": 1.2481310367584229, "rollout_time": 0.431995153427124, "train_time": 0.7987942695617676, "student_train_time": 0.016925334930419922, "throughput": 1602.3958551614019, "inference_time": 0.055603220479497395, "env_time": 0.37639193294762663, "samples": 2000, "teacher_eval_reward": 131.0}
{"epoch": 300, "reward_mean": 166.0, "student_loss": null, "teacher_policy_loss": -46.091636657714844, "teacher_value_loss": 283.7987365722656, "teacher_entropy": 0.5114786028862, "total_time": 1.440260887145996, "rollout_time": 0.5641775131225586, "train_time": 0.840693473815918, "student_train_time": 0.034981489181518555, "throughput": 1388.6373072056247, "inference_time": 0.055233836753359355, "env_time": 0.5089436763691992, "samples": 2000, "teacher_eval_reward": 122.0}
{"epoch": 301, "reward_mean": 165.57142857142858, "student_loss": null, "teacher_policy_loss": -45.039249420166016, "teacher_value_loss": 581.3973999023438, "teacher_entropy": 0.512523889541626, "total_time": 1.2551789283752441, "rollout_time": 0.43209362030029297, "train_time": 0.8141813278198242, "student_train_time": 0.00850224494934082, "throughput": 1593.3983233680342, "inference_time": 0.054527662249711284, "env_time": 0.3775659580505817, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 302, "reward_mean": 178.33333333333334, "student_loss": null, "teacher_policy_loss": -52.4372673034668, "teacher_value_loss": 398.8087158203125, "teacher_entropy": 0.529725193977356, "total_time": 1.2060744762420654, "rollout_time": 0.4321928024291992, "train_time": 0.7659246921539307, "student_train_time": 0.007588624954223633, "throughput": 1658.2723864878387, "inference_time": 0.05579451501944277, "env_time": 0.37639828740975645, "samples": 2000, "teacher_eval_reward": 167.0}
{"epoch": 303, "reward_mean": 196.16666666666666, "student_loss": null, "teacher_policy_loss": -49.40221405029297, "teacher_value_loss": 468.2869567871094, "teacher_entropy": 0.5087956190109253, "total_time": 1.2963321208953857, "rollout_time": 0.43912768363952637, "train_time": 0.8500149250030518, "student_train_time": 0.0067768096923828125, "throughput": 1542.8145054514162, "inference_time": 0.05934578375399724, "env_time": 0.37978189988552913, "samples": 2000, "teacher_eval_reward": 338.0}
{"epoch": 304, "reward_mean": 198.375, "student_loss": null, "teacher_policy_loss": -56.297149658203125, "teacher_value_loss": 496.1302185058594, "teacher_entropy": 0.5340045094490051, "total_time": 1.308384895324707, "rollout_time": 0.4536604881286621, "train_time": 0.8485052585601807, "student_train_time": 0.005839109420776367, "throughput": 1528.6021774988867, "inference_time": 0.05836133401135157, "env_time": 0.39529915411731054, "samples": 2000, "teacher_eval_reward": 404.0}
{"epoch": 305, "reward_mean": 207.33333333333334, "student_loss": null, "teacher_policy_loss": -51.78203582763672, "teacher_value_loss": 458.3644104003906, "teacher_entropy": 0.5221607089042664, "total_time": 1.273261308670044, "rollout_time": 0.42053961753845215, "train_time": 0.8357846736907959, "student_train_time": 0.01657724380493164, "throughput": 1570.7694770754122, "inference_time": 0.05591140727574384, "env_time": 0.3646282102627083, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 306, "reward_mean": 212.11111111111111, "student_loss": null, "teacher_policy_loss": -57.41587448120117, "teacher_value_loss": 549.5386962890625, "teacher_entropy": 0.5234279632568359, "total_time": 1.362410545349121, "rollout_time": 0.4479949474334717, "train_time": 0.9011859893798828, "student_train_time": 0.012865543365478516, "throughput": 1467.9862885878463, "inference_time": 0.05803385322633403, "env_time": 0.38996109420713765, "samples": 2000, "teacher_eval_reward": 197.0}
{"epoch": 307, "reward_mean": 166.83333333333334, "student_loss": null, "teacher_policy_loss": -51.53042984008789, "teacher_value_loss": 591.3104248046875, "teacher_entropy": 0.518468976020813, "total_time": -1.22257661819458, "rollout_time": 0.4297139644622803, "train_time": -1.6738131046295166, "student_train_time": 0.021093130111694336, "throughput": 200000000000.0, "inference_time": 0.055776460521883564, "env_time": 0.3739375039403967, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 308, "reward_mean": 238.875, "student_loss": null, "teacher_policy_loss": -54.546905517578125, "teacher_value_loss": 401.0411376953125, "teacher_entropy": 0.507236897945404, "total_time": 1.236708402633667, "rollout_time": 0.44093799591064453, "train_time": 0.780980110168457, "student_train_time": 0.014378786087036133, "throughput": 1617.196095490937, "inference_time": 0.056308708488359116, "env_time": 0.3846292874222854, "samples": 2000, "teacher_eval_reward": 316.0}
{"epoch": 309, "reward_mean": 201.36363636363637, "student_loss": null, "teacher_policy_loss": -52.37777328491211, "teacher_value_loss": 609.1646728515625, "teacher_entropy": 0.524091362953186, "total_time": 1.5319430828094482, "rollout_time": 0.4314544200897217, "train_time": 0.9192352294921875, "student_train_time": 0.18053460121154785, "throughput": 1305.5315321063865, "inference_time": 0.055823804261308396, "env_time": 0.3756306158284133, "samples": 2000, "teacher_eval_reward": 167.0}
{"epoch": 310, "reward_mean": 219.5, "student_loss": null, "teacher_policy_loss": -50.66794204711914, "teacher_value_loss": 386.35137939453125, "teacher_entropy": 0.5120851993560791, "total_time": 1.2707509994506836, "rollout_time": 0.42719507217407227, "train_time": 0.8316900730133057, "student_train_time": 0.01139974594116211, "throughput": 1573.872458777962, "inference_time": 0.05528261673589441, "env_time": 0.37191245543817786, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 311, "reward_mean": 184.2, "student_loss": null, "teacher_policy_loss": -49.02391052246094, "teacher_value_loss": 340.6976318359375, "teacher_entropy": 0.5159938931465149, "total_time": 1.228929042816162, "rollout_time": 0.4352896213531494, "train_time": 0.7822608947753906, "student_train_time": 0.010759353637695312, "throughput": 1627.4332612539486, "inference_time": 0.05535801197493129, "env_time": 0.3799316093782181, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 312, "reward_mean": 173.07692307692307, "student_loss": null, "teacher_policy_loss": -48.824859619140625, "teacher_value_loss": 457.2997741699219, "teacher_entropy": 0.5251058340072632, "total_time": 1.242149829864502, "rollout_time": 0.4506824016571045, "train_time": 0.780935525894165, "student_train_time": 0.010162591934204102, "throughput": 1610.1117207560758, "inference_time": 0.05538617574438831, "env_time": 0.3952962259127162, "samples": 2000, "teacher_eval_reward": 156.0}
{"epoch": 313, "reward_mean": 193.9, "student_loss": null, "teacher_policy_loss": -46.36849594116211, "teacher_value_loss": 378.3363342285156, "teacher_entropy": 0.5095306634902954, "total_time": 1.281789779663086, "rollout_time": 0.4369380474090576, "train_time": 0.8361973762512207, "student_train_time": 0.00829625129699707, "throughput": 1560.3182610222507, "inference_time": 0.05867953373763157, "env_time": 0.37825851367142604, "samples": 2000, "teacher_eval_reward": 391.0}
{"epoch": 314, "reward_mean": 215.0, "student_loss": null, "teacher_policy_loss": -50.342864990234375, "teacher_value_loss": 518.6359252929688, "teacher_entropy": 0.5141386985778809, "total_time": 1.2749998569488525, "rollout_time": 0.4305763244628906, "train_time": 0.8234021663665771, "student_train_time": 0.02060675621032715, "throughput": 1568.6276269756722, "inference_time": 0.055565983256201434, "env_time": 0.3750103412066892, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 315, "reward_mean": 185.08333333333334, "student_loss": null, "teacher_policy_loss": -47.381656646728516, "teacher_value_loss": 498.9208679199219, "teacher_entropy": 0.5245733261108398, "total_time": 1.325735330581665, "rollout_time": 0.46471405029296875, "train_time": 0.8515710830688477, "student_train_time": 0.00909733772277832, "throughput": 1508.596741645636, "inference_time": 0.059029921518231276, "env_time": 0.4056841287747375, "samples": 2000, "teacher_eval_reward": 256.0}
{"epoch": 316, "reward_mean": 188.88888888888889, "student_loss": null, "teacher_policy_loss": -51.794837951660156, "teacher_value_loss": 327.8468017578125, "teacher_entropy": 0.5149030685424805, "total_time": 1.3526928424835205, "rollout_time": 0.4425468444824219, "train_time": 0.8958303928375244, "student_train_time": 0.013849973678588867, "throughput": 1478.532255946616, "inference_time": 0.05807502924471919, "env_time": 0.3844718152377027, "samples": 2000, "teacher_eval_reward": 217.0}
{"epoch": 317, "reward_mean": 168.71428571428572, "student_loss": null, "teacher_policy_loss": -46.8458366394043, "teacher_value_loss": 428.8443298339844, "teacher_entropy": 0.5113640427589417, "total_time": 1.2383666038513184, "rollout_time": 0.4279446601867676, "train_time": 0.7912008762359619, "student_train_time": 0.01886129379272461, "throughput": 1615.0306329159741, "inference_time": 0.05640736299847049, "env_time": 0.3715372971882971, "samples": 2000, "teacher_eval_reward": 265.0}
{"epoch": 318, "reward_mean": 219.85714285714286, "student_loss": null, "teacher_policy_loss": -56.17493438720703, "teacher_value_loss": 391.4591369628906, "teacher_entropy": 0.529741108417511, "total_time": 1.1887106895446777, "rollout_time": 0.42411112785339355, "train_time": 0.7568609714508057, "student_train_time": 0.007354259490966797, "throughput": 1682.4951753113935, "inference_time": 0.05523214122513309, "env_time": 0.36887898662826046, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 319, "reward_mean": 260.125, "student_loss": null, "teacher_policy_loss": -52.058841705322266, "teacher_value_loss": 452.6156921386719, "teacher_entropy": 0.5126408934593201, "total_time": 1.5427422523498535, "rollout_time": 0.6453983783721924, "train_time": 0.883331298828125, "student_train_time": 0.01351618766784668, "throughput": 1296.3928335751916, "inference_time": 0.06887275476401555, "env_time": 0.5765256236081768, "samples": 2000, "teacher_eval_reward": 175.0}
{"epoch": 320, "reward_mean": 195.3, "student_loss": null, "teacher_policy_loss": -51.138404846191406, "teacher_value_loss": 433.1665344238281, "teacher_entropy": 0.52973473072052, "total_time": -1.3834013938903809, "rollout_time": -2.1757380962371826, "train_time": 0.7846798896789551, "student_train_time": 0.007302045822143555, "throughput": 200000000000.0, "inference_time": 0.05376980599703529, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 188.0}
{"epoch": 321, "reward_mean": 215.9090909090909, "student_loss": null, "teacher_policy_loss": -51.81978225708008, "teacher_value_loss": 357.4651794433594, "teacher_entropy": 0.5220209956169128, "total_time": 1.236327886581421, "rollout_time": 0.4392082691192627, "train_time": 0.7857606410980225, "student_train_time": 0.010997772216796875, "throughput": 1617.6938348694976, "inference_time": 0.05529243025011965, "env_time": 0.38391583886914304, "samples": 2000, "teacher_eval_reward": 214.0}
{"epoch": 322, "reward_mean": 172.66666666666666, "student_loss": null, "teacher_policy_loss": -50.927642822265625, "teacher_value_loss": 522.08251953125, "teacher_entropy": 0.5016725659370422, "total_time": 1.3084638118743896, "rollout_time": 0.4366116523742676, "train_time": 0.8584868907928467, "student_train_time": 0.012986898422241211, "throughput": 1528.5099838832964, "inference_time": 0.05614561099901039, "env_time": 0.3804660413752572, "samples": 2000, "teacher_eval_reward": 394.0}
{"epoch": 323, "reward_mean": 218.36363636363637, "student_loss": null, "teacher_policy_loss": -48.279876708984375, "teacher_value_loss": 385.0449523925781, "teacher_entropy": 0.5203440189361572, "total_time": 1.3131468296051025, "rollout_time": 0.436495304107666, "train_time": 0.8617804050445557, "student_train_time": 0.014496326446533203, "throughput": 1523.0589260162567, "inference_time": 0.05403883074995974, "env_time": 0.3824564733577063, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 324, "reward_mean": 164.8, "student_loss": null, "teacher_policy_loss": -50.332130432128906, "teacher_value_loss": 307.46697998046875, "teacher_entropy": 0.5242174863815308, "total_time": 1.2079482078552246, "rollout_time": 0.43391895294189453, "train_time": 0.7647976875305176, "student_train_time": 0.008849143981933594, "throughput": 1655.7001260435702, "inference_time": 0.05926414250188827, "env_time": 0.37465481044000626, "samples": 2000, "teacher_eval_reward": 354.0}
{"epoch": 325, "reward_mean": 222.7, "student_loss": null, "teacher_policy_loss": -50.5387077331543, "teacher_value_loss": 307.69293212890625, "teacher_entropy": 0.5186425447463989, "total_time": 1.2878451347351074, "rollout_time": 0.4347090721130371, "train_time": 0.8393325805664062, "student_train_time": 0.013381481170654297, "throughput": 1552.9817569341312, "inference_time": 0.05724520298826974, "env_time": 0.37746386912476737, "samples": 2000, "teacher_eval_reward": 336.0}
{"epoch": 326, "reward_mean": 188.1, "student_loss": null, "teacher_policy_loss": -47.74885177612305, "teacher_value_loss": 460.46612548828125, "teacher_entropy": 0.5117170810699463, "total_time": 1.2771573066711426, "rollout_time": 0.4371826648712158, "train_time": 0.828169584274292, "student_train_time": 0.011394739151000977, "throughput": 1565.9778083350725, "inference_time": 0.055399354996552574, "env_time": 0.38178330987466325, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 327, "reward_mean": 187.36363636363637, "student_loss": null, "teacher_policy_loss": -49.07256317138672, "teacher_value_loss": 512.0106201171875, "teacher_entropy": 0.5066380500793457, "total_time": 1.37156081199646, "rollout_time": 0.45206189155578613, "train_time": 0.8858642578125, "student_train_time": 0.033272504806518555, "throughput": 1458.1927264958647, "inference_time": 0.05852871948900429, "env_time": 0.39353317206678184, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 328, "reward_mean": 271.25, "student_loss": null, "teacher_policy_loss": -56.3316650390625, "teacher_value_loss": 667.8179321289062, "teacher_entropy": 0.5251336693763733, "total_time": 1.2995455265045166, "rollout_time": 0.44469618797302246, "train_time": 0.8398895263671875, "student_train_time": 0.014588594436645508, "throughput": 1538.999565009121, "inference_time": 0.0559518964992094, "env_time": 0.38874429147381306, "samples": 2000, "teacher_eval_reward": 247.0}
{"epoch": 329, "reward_mean": 186.7, "student_loss": null, "teacher_policy_loss": -48.76156997680664, "teacher_value_loss": 367.22998046875, "teacher_entropy": 0.5325076580047607, "total_time": 1.3701071739196777, "rollout_time": 0.44086194038391113, "train_time": 0.9067263603210449, "student_train_time": 0.022141218185424805, "throughput": 1459.739820410027, "inference_time": 0.0564447257311258, "env_time": 0.38441721465278533, "samples": 2000, "teacher_eval_reward": 154.0}
{"epoch": 330, "reward_mean": 186.5, "student_loss": null, "teacher_policy_loss": -50.925846099853516, "teacher_value_loss": 418.5545654296875, "teacher_entropy": 0.5242514610290527, "total_time": 1.2241852283477783, "rollout_time": 0.43500685691833496, "train_time": 0.7750458717346191, "student_train_time": 0.013766288757324219, "throughput": 1633.7396937057476, "inference_time": 0.058328763481767965, "env_time": 0.376678093436567, "samples": 2000, "teacher_eval_reward": 284.0}
{"epoch": 331, "reward_mean": 227.33333333333334, "student_loss": null, "teacher_policy_loss": -52.736549377441406, "teacher_value_loss": 441.3263854980469, "teacher_entropy": 0.5228848457336426, "total_time": 1.2726192474365234, "rollout_time": 0.4461967945098877, "train_time": 0.8115696907043457, "student_train_time": 0.014476537704467773, "throughput": 1571.5619609153816, "inference_time": 0.0608735562509537, "env_time": 0.385323238258934, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 332, "reward_mean": 233.1, "student_loss": null, "teacher_policy_loss": -53.019935607910156, "teacher_value_loss": 429.7108459472656, "teacher_entropy": 0.5428439974784851, "total_time": -1.3968279361724854, "rollout_time": 0.4434995651245117, "train_time": -1.849623203277588, "student_train_time": 0.008920669555664062, "throughput": 200000000000.0, "inference_time": 0.05801851826163329, "env_time": 0.38548104686287843, "samples": 2000, "teacher_eval_reward": 214.0}
{"epoch": 333, "reward_mean": 211.5, "student_loss": null, "teacher_policy_loss": -52.069000244140625, "teacher_value_loss": 476.62530517578125, "teacher_entropy": 0.5183019638061523, "total_time": 1.3177087306976318, "rollout_time": 0.44539833068847656, "train_time": 0.8306128978729248, "student_train_time": 0.04131293296813965, "throughput": 1517.7861035656522, "inference_time": 0.056584247001410404, "env_time": 0.38881408368706616, "samples": 2000, "teacher_eval_reward": 194.0}
{"epoch": 334, "reward_mean": 224.2, "student_loss": null, "teacher_policy_loss": -53.222694396972656, "teacher_value_loss": 412.6532897949219, "teacher_entropy": 0.5291526913642883, "total_time": 1.2689969539642334, "rollout_time": 0.4453465938568115, "train_time": 0.8159668445587158, "student_train_time": 0.0072689056396484375, "throughput": 1576.047912291813, "inference_time": 0.058250982732715784, "env_time": 0.38709561112409574, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 335, "reward_mean": 230.125, "student_loss": null, "teacher_policy_loss": -56.27778244018555, "teacher_value_loss": 483.5092468261719, "teacher_entropy": 0.5269037485122681, "total_time": 1.2959380149841309, "rollout_time": 0.4434781074523926, "train_time": 0.8451483249664307, "student_train_time": 0.006933689117431641, "throughput": 1543.2836886295759, "inference_time": 0.05618958878767444, "env_time": 0.38728851866471814, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 336, "reward_mean": 239.22222222222223, "student_loss": null, "teacher_policy_loss": -51.93785095214844, "teacher_value_loss": 556.3221435546875, "teacher_entropy": 0.5197219252586365, "total_time": 1.3215925693511963, "rollout_time": 0.4331512451171875, "train_time": 0.8758361339569092, "student_train_time": 0.012247562408447266, "throughput": 1513.3256999029975, "inference_time": 0.05697444226098014, "env_time": 0.37617680285620736, "samples": 2000, "teacher_eval_reward": 240.0}
{"epoch": 337, "reward_mean": 191.88888888888889, "student_loss": null, "teacher_policy_loss": -50.997955322265625, "teacher_value_loss": 415.9884338378906, "teacher_entropy": 0.5289219617843628, "total_time": 1.1990199089050293, "rollout_time": 0.4161996841430664, "train_time": 0.7687346935272217, "student_train_time": 0.013636589050292969, "throughput": 1668.0290169880857, "inference_time": 0.05271518148128962, "env_time": 0.3634845026617768, "samples": 2000, "teacher_eval_reward": 187.0}
{"epoch": 338, "reward_mean": 275.125, "student_loss": null, "teacher_policy_loss": -54.483036041259766, "teacher_value_loss": 374.2963562011719, "teacher_entropy": 0.5202786922454834, "total_time": 1.3085262775421143, "rollout_time": 0.48485422134399414, "train_time": 0.8140244483947754, "student_train_time": 0.009248971939086914, "throughput": 1528.4370167611182, "inference_time": 0.06415540375928686, "env_time": 0.4206988175847073, "samples": 2000, "teacher_eval_reward": 231.0}
{"epoch": 339, "reward_mean": 180.2, "student_loss": null, "teacher_policy_loss": -51.29582977294922, "teacher_value_loss": 486.3628845214844, "teacher_entropy": 0.5204885005950928, "total_time": 1.3634216785430908, "rollout_time": 0.4500429630279541, "train_time": 0.900611162185669, "student_train_time": 0.012387990951538086, "throughput": 1466.897608769971, "inference_time": 0.059307783513759205, "env_time": 0.3907351795141949, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 340, "reward_mean": 213.55555555555554, "student_loss": null, "teacher_policy_loss": -51.16464614868164, "teacher_value_loss": 451.97760009765625, "teacher_entropy": 0.5211150646209717, "total_time": 1.298957347869873, "rollout_time": 0.42917633056640625, "train_time": 0.8619439601898193, "student_train_time": 0.007463216781616211, "throughput": 1539.696436745786, "inference_time": 0.05573155699312338, "env_time": 0.3734447735732829, "samples": 2000, "teacher_eval_reward": 148.0}
{"epoch": 341, "reward_mean": 215.5, "student_loss": null, "teacher_policy_loss": -46.49799346923828, "teacher_value_loss": 396.42767333984375, "teacher_entropy": 0.5123087167739868, "total_time": 1.2379591464996338, "rollout_time": 0.44052577018737793, "train_time": 0.7898638248443604, "student_train_time": 0.007167339324951172, "throughput": 1615.5621981993988, "inference_time": 0.05745228923024115, "env_time": 0.3830734809571368, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 342, "reward_mean": 234.44444444444446, "student_loss": null, "teacher_policy_loss": -55.276851654052734, "teacher_value_loss": 474.7176208496094, "teacher_entropy": 0.5191405415534973, "total_time": 1.3471529483795166, "rollout_time": 0.44277119636535645, "train_time": 0.881819486618042, "student_train_time": 0.022198200225830078, "throughput": 1484.61242088791, "inference_time": 0.057390251015931426, "env_time": 0.385380945349425, "samples": 2000, "teacher_eval_reward": 201.0}
{"epoch": 343, "reward_mean": 218.0, "student_loss": null, "teacher_policy_loss": -53.30032730102539, "teacher_value_loss": 356.82562255859375, "teacher_entropy": 0.5265986323356628, "total_time": 1.392134428024292, "rollout_time": 0.45900869369506836, "train_time": 0.9267206192016602, "student_train_time": 0.005937099456787109, "throughput": 1436.6428699262806, "inference_time": 0.05949650299589848, "env_time": 0.3995121906991699, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 344, "reward_mean": 187.375, "student_loss": null, "teacher_policy_loss": -54.62882995605469, "teacher_value_loss": 431.5440368652344, "teacher_entropy": 0.5050211548805237, "total_time": 1.2248773574829102, "rollout_time": 0.4348299503326416, "train_time": 0.777585506439209, "student_train_time": 0.012093544006347656, "throughput": 1632.8165328404355, "inference_time": 0.05769918525402318, "env_time": 0.3771307650786184, "samples": 2000, "teacher_eval_reward": 484.0}
{"epoch": 345, "reward_mean": 239.44444444444446, "student_loss": null, "teacher_policy_loss": -51.1027717590332, "teacher_value_loss": 250.6100311279297, "teacher_entropy": 0.5255740880966187, "total_time": -1.3623018264770508, "rollout_time": -2.1034703254699707, "train_time": 0.734490156173706, "student_train_time": 0.00632023811340332, "throughput": 200000000000.0, "inference_time": 0.05644953526370955, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 162.0}
{"epoch": 346, "reward_mean": 188.7, "student_loss": null, "teacher_policy_loss": -52.424034118652344, "teacher_value_loss": 518.3721923828125, "teacher_entropy": 0.4968793988227844, "total_time": 1.3217809200286865, "rollout_time": 0.42775392532348633, "train_time": 0.8778858184814453, "student_train_time": 0.01578044891357422, "throughput": 1513.110054544133, "inference_time": 0.05775181226454151, "env_time": 0.3700021130589448, "samples": 2000, "teacher_eval_reward": 254.0}
{"epoch": 347, "reward_mean": 225.3, "student_loss": null, "teacher_policy_loss": -48.124141693115234, "teacher_value_loss": 346.7594909667969, "teacher_entropy": 0.5065079927444458, "total_time": 1.21525239944458, "rollout_time": 0.42531490325927734, "train_time": 0.7792603969573975, "student_train_time": 0.010323286056518555, "throughput": 1645.7486534600398, "inference_time": 0.05465425300371862, "env_time": 0.3706606502555587, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 348, "reward_mean": 197.0, "student_loss": null, "teacher_policy_loss": -57.48689270019531, "teacher_value_loss": 457.5107421875, "teacher_entropy": 0.5192567110061646, "total_time": 1.2201533317565918, "rollout_time": 0.421344518661499, "train_time": 0.790168046951294, "student_train_time": 0.008285284042358398, "throughput": 1639.1382525020058, "inference_time": 0.05406590351140039, "env_time": 0.36727861515009863, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 349, "reward_mean": 192.9090909090909, "student_loss": null, "teacher_policy_loss": -47.9249153137207, "teacher_value_loss": 416.9794921875, "teacher_entropy": 0.49494343996047974, "total_time": 1.2132713794708252, "rollout_time": 0.4310462474822998, "train_time": 0.7766401767730713, "student_train_time": 0.005216121673583984, "throughput": 1648.4358189280874, "inference_time": 0.053281055497791385, "env_time": 0.3777651919845084, "samples": 2000, "teacher_eval_reward": 188.0}
{"epoch": 350, "reward_mean": 283.875, "student_loss": null, "teacher_policy_loss": -53.33930587768555, "teacher_value_loss": 542.6480712890625, "teacher_entropy": 0.5102983117103577, "total_time": 1.3618924617767334, "rollout_time": 0.4562242031097412, "train_time": 0.8895485401153564, "student_train_time": 0.0157468318939209, "throughput": 1468.5447317850542, "inference_time": 0.061537500237136555, "env_time": 0.39468670287260466, "samples": 2000, "teacher_eval_reward": 251.0}
{"epoch": 351, "reward_mean": 246.14285714285714, "student_loss": null, "teacher_policy_loss": -55.12118911743164, "teacher_value_loss": 337.052978515625, "teacher_entropy": 0.5228720903396606, "total_time": 1.2982184886932373, "rollout_time": 0.4445075988769531, "train_time": 0.8449013233184814, "student_train_time": 0.008336305618286133, "throughput": 1540.572729027425, "inference_time": 0.05615169825432531, "env_time": 0.3883559006226278, "samples": 2000, "teacher_eval_reward": 182.0}
{"epoch": 352, "reward_mean": 225.7, "student_loss": null, "teacher_policy_loss": -51.90199661254883, "teacher_value_loss": 479.2657775878906, "teacher_entropy": 0.4932512044906616, "total_time": 1.2268757820129395, "rollout_time": 0.43126487731933594, "train_time": 0.7872488498687744, "student_train_time": 0.007925033569335938, "throughput": 1630.1568824829135, "inference_time": 0.05554453924014524, "env_time": 0.3757203380791907, "samples": 2000, "teacher_eval_reward": 221.0}
{"epoch": 353, "reward_mean": 274.85714285714283, "student_loss": null, "teacher_policy_loss": -55.695228576660156, "teacher_value_loss": 563.00927734375, "teacher_entropy": 0.49735841155052185, "total_time": 1.2826406955718994, "rollout_time": 0.4532325267791748, "train_time": 0.8212080001831055, "student_train_time": 0.0076770782470703125, "throughput": 1559.2831312031985, "inference_time": 0.05711639522451151, "env_time": 0.3961161315546633, "samples": 2000, "teacher_eval_reward": 284.0}
{"epoch": 354, "reward_mean": 221.4, "student_loss": null, "teacher_policy_loss": -52.02503967285156, "teacher_value_loss": 420.38385009765625, "teacher_entropy": 0.5124327540397644, "total_time": 1.310669183731079, "rollout_time": 0.4250004291534424, "train_time": 0.875046968460083, "student_train_time": 0.010168790817260742, "throughput": 1525.9380664666307, "inference_time": 0.056463738722413837, "env_time": 0.36853669043102855, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 355, "reward_mean": 185.88888888888889, "student_loss": null, "teacher_policy_loss": -50.4025764465332, "teacher_value_loss": 475.869384765625, "teacher_entropy": 0.49752625823020935, "total_time": 1.2934823036193848, "rollout_time": 0.4339487552642822, "train_time": 0.8519904613494873, "student_train_time": 0.007150411605834961, "throughput": 1546.2136547238858, "inference_time": 0.056181649511017895, "env_time": 0.37776710575326433, "samples": 2000, "teacher_eval_reward": 143.0}
{"epoch": 356, "reward_mean": 238.88888888888889, "student_loss": null, "teacher_policy_loss": -54.136985778808594, "teacher_value_loss": 340.0899353027344, "teacher_entropy": 0.499416321516037, "total_time": 1.4532945156097412, "rollout_time": 0.6163170337677002, "train_time": 0.8293907642364502, "student_train_time": 0.0072269439697265625, "throughput": 1376.1835460865852, "inference_time": 0.06942866497593059, "env_time": 0.5468883687917696, "samples": 2000, "teacher_eval_reward": 204.0}
{"epoch": 357, "reward_mean": 227.125, "student_loss": null, "teacher_policy_loss": -53.74837112426758, "teacher_value_loss": 222.75942993164062, "teacher_entropy": 0.5034270882606506, "total_time": 1.2549359798431396, "rollout_time": 0.42859625816345215, "train_time": 0.8187038898468018, "student_train_time": 0.007278919219970703, "throughput": 1593.7067963020627, "inference_time": 0.056599267254568986, "env_time": 0.37199699090888316, "samples": 2000, "teacher_eval_reward": 160.0}
{"epoch": 358, "reward_mean": 211.11111111111111, "student_loss": null, "teacher_policy_loss": -49.56696701049805, "teacher_value_loss": 353.450927734375, "teacher_entropy": 0.4809282422065735, "total_time": 1.1548614501953125, "rollout_time": 0.4333508014678955, "train_time": 0.7125017642974854, "student_train_time": 0.00865793228149414, "throughput": 1731.8094734755896, "inference_time": 0.05585090325803321, "env_time": 0.3774998982098623, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 359, "reward_mean": 269.57142857142856, "student_loss": null, "teacher_policy_loss": -56.53057861328125, "teacher_value_loss": 314.7975769042969, "teacher_entropy": 0.49707165360450745, "total_time": 1.1383514404296875, "rollout_time": 0.4183659553527832, "train_time": 0.710662841796875, "student_train_time": 0.008962631225585938, "throughput": 1756.926665147514, "inference_time": 0.0536330569857455, "env_time": 0.3647328983670377, "samples": 2000, "teacher_eval_reward": 196.0}
{"epoch": 360, "reward_mean": 242.0, "student_loss": null, "teacher_policy_loss": -50.10693359375, "teacher_value_loss": 619.5131225585938, "teacher_entropy": 0.49011534452438354, "total_time": 1.2930045127868652, "rollout_time": 0.4501762390136719, "train_time": 0.8314714431762695, "student_train_time": 0.011001348495483398, "throughput": 1546.7850113603383, "inference_time": 0.05650420975507586, "env_time": 0.393672029258596, "samples": 2000, "teacher_eval_reward": 130.0}
{"epoch": 361, "reward_mean": 249.66666666666666, "student_loss": null, "teacher_policy_loss": -51.394710540771484, "teacher_value_loss": 606.5537109375, "teacher_entropy": 0.4819251596927643, "total_time": 1.1772704124450684, "rollout_time": 0.43126869201660156, "train_time": 0.7367856502532959, "student_train_time": 0.008808135986328125, "throughput": 1698.8450392176321, "inference_time": 0.05777275747550448, "env_time": 0.3734959345410971, "samples": 2000, "teacher_eval_reward": 193.0}
{"epoch": 362, "reward_mean": 194.11111111111111, "student_loss": null, "teacher_policy_loss": -52.33125686645508, "teacher_value_loss": 396.8470764160156, "teacher_entropy": 0.4920501112937927, "total_time": 1.1735248565673828, "rollout_time": 0.44213247299194336, "train_time": 0.7167873382568359, "student_train_time": 0.014207601547241211, "throughput": 1704.2672669500134, "inference_time": 0.058655317235206894, "env_time": 0.38347715575673647, "samples": 2000, "teacher_eval_reward": 226.0}
{"epoch": 363, "reward_mean": 187.4, "student_loss": null, "teacher_policy_loss": -48.38654327392578, "teacher_value_loss": 443.02606201171875, "teacher_entropy": 0.4858439862728119, "total_time": 1.3806037902832031, "rollout_time": 0.4473559856414795, "train_time": 0.8668050765991211, "student_train_time": 0.06606388092041016, "throughput": 1448.6415393584716, "inference_time": 0.057300866507830506, "env_time": 0.390055119133649, "samples": 2000, "teacher_eval_reward": 138.0}
{"epoch": 364, "reward_mean": 258.0, "student_loss": null, "teacher_policy_loss": -52.74446105957031, "teacher_value_loss": 592.9181518554688, "teacher_entropy": 0.45839518308639526, "total_time": 1.1948018074035645, "rollout_time": 0.4291822910308838, "train_time": 0.7526650428771973, "student_train_time": 0.012512922286987305, "throughput": 1673.9177892157861, "inference_time": 0.05703717400137975, "env_time": 0.37214511702950404, "samples": 2000, "teacher_eval_reward": 169.0}
{"epoch": 365, "reward_mean": 251.71428571428572, "student_loss": null, "teacher_policy_loss": -60.5924072265625, "teacher_value_loss": 515.9117431640625, "teacher_entropy": 0.48580366373062134, "total_time": 1.2580344676971436, "rollout_time": 0.44075584411621094, "train_time": 0.7910764217376709, "student_train_time": 0.02582263946533203, "throughput": 1589.781561121325, "inference_time": 0.05814682125492254, "env_time": 0.3826090228612884, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 366, "reward_mean": 224.55555555555554, "student_loss": null, "teacher_policy_loss": -51.032230377197266, "teacher_value_loss": 372.21038818359375, "teacher_entropy": 0.4851992428302765, "total_time": 1.253476858139038, "rollout_time": 0.44951653480529785, "train_time": 0.7952377796173096, "student_train_time": 0.008360147476196289, "throughput": 1595.561965913978, "inference_time": 0.05870183823117259, "env_time": 0.39081469657412526, "samples": 2000, "teacher_eval_reward": 172.0}
{"epoch": 367, "reward_mean": 218.85714285714286, "student_loss": null, "teacher_policy_loss": -57.0167236328125, "teacher_value_loss": 459.9083251953125, "teacher_entropy": 0.4832267463207245, "total_time": 1.356095552444458, "rollout_time": 0.43955183029174805, "train_time": 0.9030683040618896, "student_train_time": 0.012841463088989258, "throughput": 1474.8223282606145, "inference_time": 0.05901389652717626, "env_time": 0.3805379337645718, "samples": 2000, "teacher_eval_reward": 205.0}
{"epoch": 368, "reward_mean": 332.0, "student_loss": null, "teacher_policy_loss": -55.01892852783203, "teacher_value_loss": 313.32159423828125, "teacher_entropy": 0.4759509861469269, "total_time": 1.2649743556976318, "rollout_time": 0.4286503791809082, "train_time": 0.8280458450317383, "student_train_time": 0.007800102233886719, "throughput": 1581.0597195047503, "inference_time": 0.057536205740689184, "env_time": 0.371114173440219, "samples": 2000, "teacher_eval_reward": 309.0}
{"epoch": 369, "reward_mean": 234.66666666666666, "student_loss": null, "teacher_policy_loss": -54.46682357788086, "teacher_value_loss": 643.633056640625, "teacher_entropy": 0.4857836961746216, "total_time": 1.2272989749908447, "rollout_time": 0.4372129440307617, "train_time": 0.7810397148132324, "student_train_time": 0.008688926696777344, "throughput": 1629.5947774379258, "inference_time": 0.05608664096780558, "env_time": 0.38112630306295614, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 370, "reward_mean": 280.85714285714283, "student_loss": null, "teacher_policy_loss": -57.30461883544922, "teacher_value_loss": 447.689697265625, "teacher_entropy": 0.49662041664123535, "total_time": 1.3980164527893066, "rollout_time": 0.4356091022491455, "train_time": 0.9503633975982666, "student_train_time": 0.011679410934448242, "throughput": 1430.5983280880725, "inference_time": 0.05498654928578617, "env_time": 0.38062255296335934, "samples": 2000, "teacher_eval_reward": 255.0}
{"epoch": 371, "reward_mean": 256.625, "student_loss": null, "teacher_policy_loss": -54.33903121948242, "teacher_value_loss": 425.9183349609375, "teacher_entropy": 0.4917120933532715, "total_time": 1.2899467945098877, "rollout_time": 0.45378923416137695, "train_time": 0.825800895690918, "student_train_time": 0.009998321533203125, "throughput": 1550.4515446002526, "inference_time": 0.05946266525006649, "env_time": 0.39432656891131046, "samples": 2000, "teacher_eval_reward": 314.0}
{"epoch": 372, "reward_mean": 226.0, "student_loss": null, "teacher_policy_loss": -51.73289108276367, "teacher_value_loss": 542.9969482421875, "teacher_entropy": 0.48862314224243164, "total_time": -1.3482694625854492, "rollout_time": -2.1485493183135986, "train_time": 0.7947189807891846, "student_train_time": 0.005196571350097656, "throughput": 200000000000.0, "inference_time": 0.05512660074782616, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 208.0}
{"epoch": 373, "reward_mean": 252.0, "student_loss": null, "teacher_policy_loss": -50.2591552734375, "teacher_value_loss": 660.9840698242188, "teacher_entropy": 0.4712458848953247, "total_time": 1.238938331604004, "rollout_time": 0.43174052238464355, "train_time": 0.7964715957641602, "student_train_time": 0.010331392288208008, "throughput": 1614.285351402987, "inference_time": 0.05498451474431931, "env_time": 0.37675600764032424, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 374, "reward_mean": 269.0, "student_loss": null, "teacher_policy_loss": -53.58053207397461, "teacher_value_loss": 483.32342529296875, "teacher_entropy": 0.47792521119117737, "total_time": 1.2221672534942627, "rollout_time": 0.4256916046142578, "train_time": 0.7824850082397461, "student_train_time": 0.013563156127929688, "throughput": 1636.437234168939, "inference_time": 0.056528152031205536, "env_time": 0.3691634525830523, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 375, "reward_mean": 238.0, "student_loss": null, "teacher_policy_loss": -56.14662170410156, "teacher_value_loss": 401.2502136230469, "teacher_entropy": 0.4913310110569, "total_time": 1.2210125923156738, "rollout_time": 0.43340516090393066, "train_time": 0.7800238132476807, "student_train_time": 0.007226467132568359, "throughput": 1637.9847452735614, "inference_time": 0.055878550742818334, "env_time": 0.37752661016111233, "samples": 2000, "teacher_eval_reward": 246.0}
{"epoch": 376, "reward_mean": 234.55555555555554, "student_loss": null, "teacher_policy_loss": -57.14399337768555, "teacher_value_loss": 424.1195373535156, "teacher_entropy": 0.5045362710952759, "total_time": 1.2427575588226318, "rollout_time": 0.4709312915802002, "train_time": 0.7631723880767822, "student_train_time": 0.008300065994262695, "throughput": 1609.324349549535, "inference_time": 0.05760913200901996, "env_time": 0.41332215957118024, "samples": 2000, "teacher_eval_reward": 150.0}
{"epoch": 377, "reward_mean": 288.5, "student_loss": null, "teacher_policy_loss": -61.267486572265625, "teacher_value_loss": 415.5052490234375, "teacher_entropy": 0.4836727976799011, "total_time": 1.2540371417999268, "rollout_time": 0.4279632568359375, "train_time": 0.8164968490600586, "student_train_time": 0.00921320915222168, "throughput": 1594.8490944449927, "inference_time": 0.055706181257846765, "env_time": 0.37225707557809073, "samples": 2000, "teacher_eval_reward": 135.0}
{"epoch": 378, "reward_mean": 255.11111111111111, "student_loss": null, "teacher_policy_loss": -53.75190353393555, "teacher_value_loss": 469.3492126464844, "teacher_entropy": 0.4822576940059662, "total_time": 1.231480360031128, "rollout_time": 0.42790842056274414, "train_time": 0.7953999042510986, "student_train_time": 0.007822513580322266, "throughput": 1624.0616293299604, "inference_time": 0.055036189487509546, "env_time": 0.3728722310752346, "samples": 2000, "teacher_eval_reward": 460.0}
{"epoch": 379, "reward_mean": 214.44444444444446, "student_loss": null, "teacher_policy_loss": -53.13988494873047, "teacher_value_loss": 310.8624572753906, "teacher_entropy": 0.498341828584671, "total_time": 1.230123519897461, "rollout_time": 0.44289541244506836, "train_time": 0.7770318984985352, "student_train_time": 0.009827613830566406, "throughput": 1625.8529876468938, "inference_time": 0.05709901048521715, "env_time": 0.3857964019598512, "samples": 2000, "teacher_eval_reward": 187.0}
{"epoch": 380, "reward_mean": 275.7142857142857, "student_loss": null, "teacher_policy_loss": -55.47087097167969, "teacher_value_loss": 388.84130859375, "teacher_entropy": 0.49426501989364624, "total_time": 1.407529354095459, "rollout_time": 0.4651341438293457, "train_time": 0.9271869659423828, "student_train_time": 0.014819860458374023, "throughput": 1420.9295132500374, "inference_time": 0.05705559574744257, "env_time": 0.40807854808190314, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 381, "reward_mean": 200.4, "student_loss": null, "teacher_policy_loss": -50.01348114013672, "teacher_value_loss": 392.90338134765625, "teacher_entropy": 0.497487872838974, "total_time": 1.2422583103179932, "rollout_time": 0.4368610382080078, "train_time": 0.7946739196777344, "student_train_time": 0.010326385498046875, "throughput": 1609.9711174305125, "inference_time": 0.05574723298832396, "env_time": 0.38111380521968385, "samples": 2000, "teacher_eval_reward": 177.0}
{"epoch": 382, "reward_mean": 212.54545454545453, "student_loss": null, "teacher_policy_loss": -48.49443817138672, "teacher_value_loss": 421.08770751953125, "teacher_entropy": 0.4954877197742462, "total_time": 1.284935712814331, "rollout_time": 0.42734289169311523, "train_time": 0.8520758152008057, "student_train_time": 0.0051577091217041016, "throughput": 1556.4981034105583, "inference_time": 0.05691693674452836, "env_time": 0.3704259549485869, "samples": 2000, "teacher_eval_reward": 146.0}
{"epoch": 383, "reward_mean": 206.4, "student_loss": null, "teacher_policy_loss": -51.72319793701172, "teacher_value_loss": 446.3856201171875, "teacher_entropy": 0.48742735385894775, "total_time": 1.2145519256591797, "rollout_time": 0.42990899085998535, "train_time": 0.7791352272033691, "student_train_time": 0.005151510238647461, "throughput": 1646.6978131993246, "inference_time": 0.055248075264898944, "env_time": 0.3746609155950864, "samples": 2000, "teacher_eval_reward": 235.0}
{"epoch": 384, "reward_mean": 155.58333333333334, "student_loss": null, "teacher_policy_loss": -48.88188552856445, "teacher_value_loss": 473.2337646484375, "teacher_entropy": 0.5004878044128418, "total_time": 1.2739126682281494, "rollout_time": 0.45020103454589844, "train_time": 0.8156654834747314, "student_train_time": 0.0076792240142822266, "throughput": 1569.9663327641963, "inference_time": 0.0549122839975098, "env_time": 0.39528875054838863, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 385, "reward_mean": 210.0, "student_loss": null, "teacher_policy_loss": -49.731292724609375, "teacher_value_loss": 283.5013122558594, "teacher_entropy": 0.5046411752700806, "total_time": 1.2353832721710205, "rollout_time": 0.4492316246032715, "train_time": 0.7770392894744873, "student_train_time": 0.008707046508789062, "throughput": 1618.9307764263863, "inference_time": 0.058262015755644825, "env_time": 0.39096960884762666, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 386, "reward_mean": 197.8181818181818, "student_loss": null, "teacher_policy_loss": -46.87557601928711, "teacher_value_loss": 408.8179016113281, "teacher_entropy": 0.5015708804130554, "total_time": 1.2291312217712402, "rollout_time": 0.4510629177093506, "train_time": 0.7664597034454346, "student_train_time": 0.011247396469116211, "throughput": 1627.1655658684667, "inference_time": 0.06474257697936991, "env_time": 0.38632034072998067, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 387, "reward_mean": 196.72727272727272, "student_loss": null, "teacher_policy_loss": -50.46323776245117, "teacher_value_loss": 354.1655578613281, "teacher_entropy": 0.4944544732570648, "total_time": 1.2037086486816406, "rollout_time": 0.4252324104309082, "train_time": 0.7689247131347656, "student_train_time": 0.009200572967529297, "throughput": 1661.5316357413365, "inference_time": 0.05556646828154044, "env_time": 0.36966594214936777, "samples": 2000, "teacher_eval_reward": 198.0}
{"epoch": 388, "reward_mean": 185.9, "student_loss": null, "teacher_policy_loss": -51.819522857666016, "teacher_value_loss": 389.1463928222656, "teacher_entropy": 0.5046724081039429, "total_time": 1.345672607421875, "rollout_time": 0.4476492404937744, "train_time": 0.8879594802856445, "student_train_time": 0.0096893310546875, "throughput": 1486.2456060777865, "inference_time": 0.05671170901496225, "env_time": 0.39093753147881216, "samples": 2000, "teacher_eval_reward": 182.0}
{"epoch": 389, "reward_mean": 225.375, "student_loss": null, "teacher_policy_loss": -54.01104736328125, "teacher_value_loss": 331.01446533203125, "teacher_entropy": 0.5152013897895813, "total_time": 1.2099082469940186, "rollout_time": 0.429030179977417, "train_time": 0.773045539855957, "student_train_time": 0.007465839385986328, "throughput": 1653.0179085636792, "inference_time": 0.05618049373788381, "env_time": 0.3728496862395332, "samples": 2000, "teacher_eval_reward": 294.0}
{"epoch": 390, "reward_mean": 171.1818181818182, "student_loss": null, "teacher_policy_loss": -50.941593170166016, "teacher_value_loss": 426.88623046875, "teacher_entropy": 0.5021800398826599, "total_time": 1.2000508308410645, "rollout_time": 0.43062782287597656, "train_time": 0.7562949657440186, "student_train_time": 0.012768268585205078, "throughput": 1666.5960712666524, "inference_time": 0.05554138077150128, "env_time": 0.3750864421044753, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 391, "reward_mean": 201.7, "student_loss": null, "teacher_policy_loss": -50.6899299621582, "teacher_value_loss": 259.82977294921875, "teacher_entropy": 0.5075058341026306, "total_time": 1.1944916248321533, "rollout_time": 0.43280029296875, "train_time": 0.7542343139648438, "student_train_time": 0.007007122039794922, "throughput": 1674.352467963963, "inference_time": 0.05553742602114653, "env_time": 0.37726286694760347, "samples": 2000, "teacher_eval_reward": 174.0}
{"epoch": 392, "reward_mean": 197.4, "student_loss": null, "teacher_policy_loss": -51.659515380859375, "teacher_value_loss": 378.65081787109375, "teacher_entropy": 0.4962812662124634, "total_time": 1.2795350551605225, "rollout_time": 0.4608004093170166, "train_time": 0.8116734027862549, "student_train_time": 0.0066907405853271484, "throughput": 1563.067765852724, "inference_time": 0.059518572988054075, "env_time": 0.4012818363289625, "samples": 2000, "teacher_eval_reward": 147.0}
{"epoch": 393, "reward_mean": 222.44444444444446, "student_loss": null, "teacher_policy_loss": -52.35591506958008, "teacher_value_loss": 419.3155517578125, "teacher_entropy": 0.5095235109329224, "total_time": 1.28849458694458, "rollout_time": 0.4422297477722168, "train_time": 0.8342916965484619, "student_train_time": 0.011607885360717773, "throughput": 1552.1989927350953, "inference_time": 0.05488003050049883, "env_time": 0.38734971727171796, "samples": 2000, "teacher_eval_reward": 180.0}
{"epoch": 394, "reward_mean": 248.0, "student_loss": null, "teacher_policy_loss": -54.389461517333984, "teacher_value_loss": 332.10345458984375, "teacher_entropy": 0.5045603513717651, "total_time": 1.1796283721923828, "rollout_time": 0.4275240898132324, "train_time": 0.739518404006958, "student_train_time": 0.012219905853271484, "throughput": 1695.4492170130889, "inference_time": 0.05666397797540412, "env_time": 0.3708601118378283, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 395, "reward_mean": 207.58333333333334, "student_loss": null, "teacher_policy_loss": -49.40529251098633, "teacher_value_loss": 444.0606994628906, "teacher_entropy": 0.5033868551254272, "total_time": 1.3067452907562256, "rollout_time": 0.4956486225128174, "train_time": 0.8037073612213135, "student_train_time": 0.006994724273681641, "throughput": 1530.5201512091016, "inference_time": 0.06474256649744348, "env_time": 0.4309060560153739, "samples": 2000, "teacher_eval_reward": 240.0}
{"epoch": 396, "reward_mean": 272.4, "student_loss": null, "teacher_policy_loss": -59.460506439208984, "teacher_value_loss": 376.867431640625, "teacher_entropy": 0.4867914021015167, "total_time": 1.2339048385620117, "rollout_time": 0.44185924530029297, "train_time": 0.7759902477264404, "student_train_time": 0.01558828353881836, "throughput": 1620.8705383883516, "inference_time": 0.05865121597889811, "env_time": 0.38320802932139486, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 397, "reward_mean": 240.44444444444446, "student_loss": null, "teacher_policy_loss": -57.720909118652344, "teacher_value_loss": 501.4096374511719, "teacher_entropy": 0.4996948838233948, "total_time": 1.588557481765747, "rollout_time": 0.4693024158477783, "train_time": 1.1016864776611328, "student_train_time": 0.017192840576171875, "throughput": 1259.003859134463, "inference_time": 0.06403545751345519, "env_time": 0.40526695833432314, "samples": 2000, "teacher_eval_reward": 204.0}
{"epoch": 398, "reward_mean": 263.57142857142856, "student_loss": null, "teacher_policy_loss": -57.09442138671875, "teacher_value_loss": 515.3909301757812, "teacher_entropy": 0.4826561510562897, "total_time": 1.2613444328308105, "rollout_time": 0.4432995319366455, "train_time": 0.8116931915283203, "student_train_time": 0.005971431732177734, "throughput": 1585.6097255778418, "inference_time": 0.0564450067213329, "env_time": 0.3868545252153126, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 399, "reward_mean": 298.0, "student_loss": null, "teacher_policy_loss": -54.8128662109375, "teacher_value_loss": 713.2174072265625, "teacher_entropy": 0.4668687880039215, "total_time": 1.2392468452453613, "rollout_time": 0.43730974197387695, "train_time": 0.7938218116760254, "student_train_time": 0.007761716842651367, "throughput": 1613.8834709754822, "inference_time": 0.05612312523044238, "env_time": 0.38118661674343457, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 400, "reward_mean": 253.44444444444446, "student_loss": null, "teacher_policy_loss": -52.09373474121094, "teacher_value_loss": 754.8911743164062, "teacher_entropy": 0.4819272756576538, "total_time": 1.224987268447876, "rollout_time": 0.4501354694366455, "train_time": 0.7655093669891357, "student_train_time": 0.008990764617919922, "throughput": 1632.6700297335387, "inference_time": 0.05952781002270058, "env_time": 0.39060765941394493, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 401, "reward_mean": 186.11111111111111, "student_loss": null, "teacher_policy_loss": -54.74922561645508, "teacher_value_loss": 566.3399658203125, "teacher_entropy": 0.4938430190086365, "total_time": 1.2684121131896973, "rollout_time": 0.4283154010772705, "train_time": 0.8273093700408936, "student_train_time": 0.012292146682739258, "throughput": 1576.774598100113, "inference_time": 0.05724608623677341, "env_time": 0.3710693148404971, "samples": 2000, "teacher_eval_reward": 218.0}
{"epoch": 402, "reward_mean": 259.125, "student_loss": null, "teacher_policy_loss": -51.61922836303711, "teacher_value_loss": 619.9310302734375, "teacher_entropy": 0.470683217048645, "total_time": 1.346508264541626, "rollout_time": 0.473801851272583, "train_time": 0.8631649017333984, "student_train_time": 0.009171724319458008, "throughput": 1485.323226501572, "inference_time": 0.06202489622046414, "env_time": 0.41177695505211886, "samples": 2000, "teacher_eval_reward": 200.0}
{"epoch": 403, "reward_mean": 227.88888888888889, "student_loss": null, "teacher_policy_loss": -50.404056549072266, "teacher_value_loss": 383.3450012207031, "teacher_entropy": 0.4895990788936615, "total_time": 1.3130440711975098, "rollout_time": 0.4449276924133301, "train_time": 0.8576505184173584, "student_train_time": 0.010057449340820312, "throughput": 1523.1781201189838, "inference_time": 0.0578653244774614, "env_time": 0.3870623679358687, "samples": 2000, "teacher_eval_reward": 260.0}
{"epoch": 404, "reward_mean": 242.22222222222223, "student_loss": null, "teacher_policy_loss": -52.60608673095703, "teacher_value_loss": 415.04156494140625, "teacher_entropy": 0.4931592047214508, "total_time": 1.2480618953704834, "rollout_time": 0.44278860092163086, "train_time": 0.7902061939239502, "student_train_time": 0.014658451080322266, "throughput": 1602.4846262983665, "inference_time": 0.05591018122322566, "env_time": 0.3868784196984052, "samples": 2000, "teacher_eval_reward": 215.0}
{"epoch": 405, "reward_mean": 258.2, "student_loss": null, "teacher_policy_loss": -58.54132843017578, "teacher_value_loss": 659.9039916992188, "teacher_entropy": 0.48633095622062683, "total_time": 1.274796962738037, "rollout_time": 0.4480447769165039, "train_time": 0.8012878894805908, "student_train_time": 0.025040149688720703, "throughput": 1568.8772867048222, "inference_time": 0.05926012751478993, "env_time": 0.388784649401714, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 406, "reward_mean": 364.14285714285717, "student_loss": null, "teacher_policy_loss": -57.139408111572266, "teacher_value_loss": 801.0167846679688, "teacher_entropy": 0.47894367575645447, "total_time": 1.3631081581115723, "rollout_time": 0.4402296543121338, "train_time": 0.9057471752166748, "student_train_time": 0.015272378921508789, "throughput": 1467.23500119812, "inference_time": 0.05676959474112664, "env_time": 0.38346005957100715, "samples": 2000, "teacher_eval_reward": 219.0}
{"epoch": 407, "reward_mean": 392.75, "student_loss": null, "teacher_policy_loss": -61.3978271484375, "teacher_value_loss": 714.5896606445312, "teacher_entropy": 0.47495025396347046, "total_time": 1.2352867126464844, "rollout_time": 0.4490041732788086, "train_time": 0.7727553844451904, "student_train_time": 0.013155221939086914, "throughput": 1619.0573245260528, "inference_time": 0.05699963880215364, "env_time": 0.39200453447665495, "samples": 2000, "teacher_eval_reward": 227.0}
{"epoch": 408, "reward_mean": 316.125, "student_loss": null, "teacher_policy_loss": -59.290748596191406, "teacher_value_loss": 845.6221923828125, "teacher_entropy": 0.5013515949249268, "total_time": 1.2485249042510986, "rollout_time": 0.48267579078674316, "train_time": 0.7504894733428955, "student_train_time": 0.014996051788330078, "throughput": 1601.890353320311, "inference_time": 0.0636338819967932, "env_time": 0.41904190878994996, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 409, "reward_mean": 203.22222222222223, "student_loss": null, "teacher_policy_loss": -49.23698043823242, "teacher_value_loss": 349.369384765625, "teacher_entropy": 0.5053763389587402, "total_time": 1.212634801864624, "rollout_time": 0.45688462257385254, "train_time": 0.7487969398498535, "student_train_time": 0.006536960601806641, "throughput": 1649.3011720632408, "inference_time": 0.05581666226316884, "env_time": 0.4010679603106837, "samples": 2000, "teacher_eval_reward": 147.0}
{"epoch": 410, "reward_mean": 242.42857142857142, "student_loss": null, "teacher_policy_loss": -55.7340087890625, "teacher_value_loss": 558.2808837890625, "teacher_entropy": 0.46933290362358093, "total_time": 1.4656496047973633, "rollout_time": 0.4868800640106201, "train_time": 0.9658546447753906, "student_train_time": 0.012489557266235352, "throughput": 1364.5826352039405, "inference_time": 0.06505316247785231, "env_time": 0.4218269015327678, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 411, "reward_mean": 318.42857142857144, "student_loss": null, "teacher_policy_loss": -55.169002532958984, "teacher_value_loss": 777.1076049804688, "teacher_entropy": 0.4804803431034088, "total_time": 1.4167683124542236, "rollout_time": 0.46606874465942383, "train_time": 0.9377784729003906, "student_train_time": 0.012466907501220703, "throughput": 1411.6634190776488, "inference_time": 0.06019559902779292, "env_time": 0.4058731456316309, "samples": 2000, "teacher_eval_reward": 212.0}
{"epoch": 412, "reward_mean": 246.5, "student_loss": null, "teacher_policy_loss": -57.23484420776367, "teacher_value_loss": 654.1282348632812, "teacher_entropy": 0.49435147643089294, "total_time": 1.2363858222961426, "rollout_time": 0.4586331844329834, "train_time": 0.771430253982544, "student_train_time": 0.005961418151855469, "throughput": 1617.6180314699163, "inference_time": 0.05927855176923913, "env_time": 0.39935463266374427, "samples": 2000, "teacher_eval_reward": 282.0}
{"epoch": 413, "reward_mean": 335.2857142857143, "student_loss": null, "teacher_policy_loss": -58.301822662353516, "teacher_value_loss": 772.885498046875, "teacher_entropy": 0.4850563108921051, "total_time": 1.3288614749908447, "rollout_time": 0.4467768669128418, "train_time": 0.8703985214233398, "student_train_time": 0.011286497116088867, "throughput": 1505.0477703206643, "inference_time": 0.05817607794597279, "env_time": 0.388600788966869, "samples": 2000, "teacher_eval_reward": 176.0}
{"epoch": 414, "reward_mean": 276.3333333333333, "student_loss": null, "teacher_policy_loss": -53.16636657714844, "teacher_value_loss": 640.0249633789062, "teacher_entropy": 0.4599266052246094, "total_time": 1.2988204956054688, "rollout_time": 0.4272580146789551, "train_time": 0.8627879619598389, "student_train_time": 0.008423805236816406, "throughput": 1539.8586692825968, "inference_time": 0.056834021754184505, "env_time": 0.3704239929247706, "samples": 2000, "teacher_eval_reward": 144.0}
{"epoch": 415, "reward_mean": 256.8888888888889, "student_loss": null, "teacher_policy_loss": -49.932838439941406, "teacher_value_loss": 511.5449523925781, "teacher_entropy": 0.45859384536743164, "total_time": 1.2087645530700684, "rollout_time": 0.4565541744232178, "train_time": 0.7405071258544922, "student_train_time": 0.01124715805053711, "throughput": 1654.5819406437097, "inference_time": 0.059410924988696934, "env_time": 0.39714324943452084, "samples": 2000, "teacher_eval_reward": 173.0}
{"epoch": 416, "reward_mean": 271.2857142857143, "student_loss": null, "teacher_policy_loss": -55.839542388916016, "teacher_value_loss": 612.1995239257812, "teacher_entropy": 0.48320505023002625, "total_time": 1.4447829723358154, "rollout_time": 0.45368194580078125, "train_time": 0.9550175666809082, "student_train_time": 0.035657405853271484, "throughput": 1384.2909546245219, "inference_time": 0.055758638483894174, "env_time": 0.3979233073168871, "samples": 2000, "teacher_eval_reward": 235.0}
{"epoch": 417, "reward_mean": 291.0, "student_loss": null, "teacher_policy_loss": -58.0728874206543, "teacher_value_loss": 359.8837890625, "teacher_entropy": 0.5049906373023987, "total_time": 1.2508854866027832, "rollout_time": 0.4423220157623291, "train_time": 0.8003015518188477, "student_train_time": 0.007897377014160156, "throughput": 1598.8673794846713, "inference_time": 0.056834514491129084, "env_time": 0.3854875012712, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 418, "reward_mean": 220.625, "student_loss": null, "teacher_policy_loss": -53.575706481933594, "teacher_value_loss": 326.09417724609375, "teacher_entropy": 0.49233728647232056, "total_time": 1.3053510189056396, "rollout_time": 0.5157513618469238, "train_time": 0.7723798751831055, "student_train_time": 0.01685309410095215, "throughput": 1532.1549307685298, "inference_time": 0.07045734974417428, "env_time": 0.44529401210274955, "samples": 2000, "teacher_eval_reward": 162.0}
{"epoch": 419, "reward_mean": 269.6666666666667, "student_loss": null, "teacher_policy_loss": -53.57221221923828, "teacher_value_loss": 421.3883972167969, "teacher_entropy": 0.5015028119087219, "total_time": 1.3461947441101074, "rollout_time": 0.43828821182250977, "train_time": 0.9020159244537354, "student_train_time": 0.005528450012207031, "throughput": 1485.669149096319, "inference_time": 0.058343361770312185, "env_time": 0.3799448500521976, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 420, "reward_mean": 221.1, "student_loss": null, "teacher_policy_loss": -51.351810455322266, "teacher_value_loss": 439.01177978515625, "teacher_entropy": 0.4960111081600189, "total_time": 1.3635644912719727, "rollout_time": 0.4606039524078369, "train_time": 0.8868725299835205, "student_train_time": 0.015697240829467773, "throughput": 1466.7439734620411, "inference_time": 0.05773423321079463, "env_time": 0.4028697191970423, "samples": 2000, "teacher_eval_reward": 272.0}
{"epoch": 421, "reward_mean": 223.125, "student_loss": null, "teacher_policy_loss": -51.71587371826172, "teacher_value_loss": 438.5497741699219, "teacher_entropy": 0.4827862083911896, "total_time": 1.287126064300537, "rollout_time": 0.434462308883667, "train_time": 0.8444406986236572, "student_train_time": 0.007777214050292969, "throughput": 1553.8493512574933, "inference_time": 0.057161472281222814, "env_time": 0.3773008366024442, "samples": 2000, "teacher_eval_reward": 424.0}
{"epoch": 422, "reward_mean": 238.66666666666666, "student_loss": null, "teacher_policy_loss": -53.1165771484375, "teacher_value_loss": 477.4713134765625, "teacher_entropy": 0.48937639594078064, "total_time": 1.2819609642028809, "rollout_time": 0.4238467216491699, "train_time": 0.8495278358459473, "student_train_time": 0.008224010467529297, "throughput": 1560.1099065006192, "inference_time": 0.054689754511855426, "env_time": 0.3691569671373145, "samples": 2000, "teacher_eval_reward": 185.0}
{"epoch": 423, "reward_mean": 287.57142857142856, "student_loss": null, "teacher_policy_loss": -57.07703399658203, "teacher_value_loss": 584.5570068359375, "teacher_entropy": 0.48102205991744995, "total_time": -1.3943893909454346, "rollout_time": 0.42568302154541016, "train_time": -1.8350014686584473, "student_train_time": 0.014568328857421875, "throughput": 200000000000.0, "inference_time": 0.05390203781462333, "env_time": 0.37178098373078683, "samples": 2000, "teacher_eval_reward": 207.0}
{"epoch": 424, "reward_mean": 280.3333333333333, "student_loss": null, "teacher_policy_loss": -57.37458038330078, "teacher_value_loss": 551.0839233398438, "teacher_entropy": 0.48848509788513184, "total_time": 1.2692477703094482, "rollout_time": 0.43463587760925293, "train_time": 0.8206741809844971, "student_train_time": 0.01358652114868164, "throughput": 1575.7364690996394, "inference_time": 0.057148279000102775, "env_time": 0.37748759860915015, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 425, "reward_mean": 286.42857142857144, "student_loss": null, "teacher_policy_loss": -57.31018829345703, "teacher_value_loss": 521.046142578125, "teacher_entropy": 0.4935343563556671, "total_time": 1.4586162567138672, "rollout_time": 0.44512295722961426, "train_time": 1.005565881729126, "student_train_time": 0.007404804229736328, "throughput": 1371.1625595794621, "inference_time": 0.05662909526290605, "env_time": 0.3884938619667082, "samples": 2000, "teacher_eval_reward": 289.0}
{"epoch": 426, "reward_mean": 257.7142857142857, "student_loss": null, "teacher_policy_loss": -54.97515869140625, "teacher_value_loss": 395.05462646484375, "teacher_entropy": 0.4877493977546692, "total_time": 1.3173727989196777, "rollout_time": 0.44065165519714355, "train_time": 0.8609395027160645, "student_train_time": 0.015412569046020508, "throughput": 1518.1731409970787, "inference_time": 0.05678109627115191, "env_time": 0.38387055892599165, "samples": 2000, "teacher_eval_reward": 290.0}
{"epoch": 427, "reward_mean": 315.6666666666667, "student_loss": null, "teacher_policy_loss": -57.41556167602539, "teacher_value_loss": 490.1501159667969, "teacher_entropy": 0.488664835691452, "total_time": 1.2754604816436768, "rollout_time": 0.42680954933166504, "train_time": 0.8410730361938477, "student_train_time": 0.0072290897369384766, "throughput": 1568.0611267725162, "inference_time": 0.05586717021833465, "env_time": 0.3709423791133304, "samples": 2000, "teacher_eval_reward": 245.0}
{"epoch": 428, "reward_mean": 360.1666666666667, "student_loss": null, "teacher_policy_loss": -63.1963996887207, "teacher_value_loss": 599.564697265625, "teacher_entropy": 0.4777981638908386, "total_time": 1.1731798648834229, "rollout_time": 0.4168581962585449, "train_time": 0.7504715919494629, "student_train_time": 0.005499839782714844, "throughput": 1704.7684330984807, "inference_time": 0.0550500825047493, "env_time": 0.3618081137537956, "samples": 2000, "teacher_eval_reward": 386.0}
{"epoch": 429, "reward_mean": 301.1666666666667, "student_loss": null, "teacher_policy_loss": -60.120155334472656, "teacher_value_loss": 581.5858154296875, "teacher_entropy": 0.4887823462486267, "total_time": 1.2323384284973145, "rollout_time": 0.42054080963134766, "train_time": 0.7980294227600098, "student_train_time": 0.013412952423095703, "throughput": 1622.9308067904324, "inference_time": 0.053637411236195476, "env_time": 0.3669033983951522, "samples": 2000, "teacher_eval_reward": 329.0}
{"epoch": 430, "reward_mean": 331.2857142857143, "student_loss": null, "teacher_policy_loss": -57.716827392578125, "teacher_value_loss": 579.4180297851562, "teacher_entropy": 0.48826539516448975, "total_time": 1.1823227405548096, "rollout_time": 0.43310117721557617, "train_time": 0.7401621341705322, "student_train_time": 0.00865793228149414, "throughput": 1691.5854964114892, "inference_time": 0.05667488994549785, "env_time": 0.3764262872700783, "samples": 2000, "teacher_eval_reward": 154.0}
{"epoch": 431, "reward_mean": 264.14285714285717, "student_loss": null, "teacher_policy_loss": -57.70738220214844, "teacher_value_loss": 415.5489807128906, "teacher_entropy": 0.47569480538368225, "total_time": 1.3893377780914307, "rollout_time": 0.43126583099365234, "train_time": 0.9515395164489746, "student_train_time": 0.006163358688354492, "throughput": 1439.5347420462804, "inference_time": 0.05691623194979911, "env_time": 0.37434959904385323, "samples": 2000, "teacher_eval_reward": 224.0}
{"epoch": 432, "reward_mean": 316.7142857142857, "student_loss": null, "teacher_policy_loss": -56.755245208740234, "teacher_value_loss": 407.5915222167969, "teacher_entropy": 0.48187586665153503, "total_time": 1.2033541202545166, "rollout_time": 0.43348073959350586, "train_time": 0.7566311359405518, "student_train_time": 0.012875795364379883, "throughput": 1662.0211509950104, "inference_time": 0.05512088748400856, "env_time": 0.3783598521094973, "samples": 2000, "teacher_eval_reward": 246.0}
{"epoch": 433, "reward_mean": 297.0, "student_loss": null, "teacher_policy_loss": -59.06407165527344, "teacher_value_loss": 356.5063171386719, "teacher_entropy": 0.4896709620952606, "total_time": 1.199686050415039, "rollout_time": 0.43970489501953125, "train_time": 0.7500791549682617, "student_train_time": 0.009545087814331055, "throughput": 1667.1028218658432, "inference_time": 0.05937499205356289, "env_time": 0.38032990296596836, "samples": 2000, "teacher_eval_reward": 265.0}
{"epoch": 434, "reward_mean": 356.7142857142857, "student_loss": null, "teacher_policy_loss": -57.81114959716797, "teacher_value_loss": 571.0772705078125, "teacher_entropy": 0.48937639594078064, "total_time": 1.3479933738708496, "rollout_time": 0.4617197513580322, "train_time": 0.8737790584564209, "student_train_time": 0.012126684188842773, "throughput": 1483.686818323796, "inference_time": 0.05917344277986558, "env_time": 0.40254630857816665, "samples": 2000, "teacher_eval_reward": 391.0}
{"epoch": 435, "reward_mean": 231.66666666666666, "student_loss": null, "teacher_policy_loss": -60.33700942993164, "teacher_value_loss": 511.0390930175781, "teacher_entropy": 0.4925742745399475, "total_time": 1.3373775482177734, "rollout_time": 0.44538116455078125, "train_time": 0.885441780090332, "student_train_time": 0.006088972091674805, "throughput": 1495.4640166236197, "inference_time": 0.0554835939892655, "env_time": 0.38989757056151575, "samples": 2000, "teacher_eval_reward": 381.0}
{"epoch": 436, "reward_mean": 350.2857142857143, "student_loss": null, "teacher_policy_loss": -54.935543060302734, "teacher_value_loss": 570.2630615234375, "teacher_entropy": 0.4821891784667969, "total_time": 1.3068244457244873, "rollout_time": 0.4239940643310547, "train_time": 0.8679211139678955, "student_train_time": 0.01455068588256836, "throughput": 1530.427446887271, "inference_time": 0.05610467472070013, "env_time": 0.36788938961035456, "samples": 2000, "teacher_eval_reward": 430.0}
{"epoch": 437, "reward_mean": 269.4, "student_loss": null, "teacher_policy_loss": -57.74563217163086, "teacher_value_loss": 343.1512451171875, "teacher_entropy": 0.4830128848552704, "total_time": 1.2983591556549072, "rollout_time": 0.42168664932250977, "train_time": 0.8697993755340576, "student_train_time": 0.006513118743896484, "throughput": 1540.4058201377854, "inference_time": 0.05353110451687826, "env_time": 0.3681555448056315, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 438, "reward_mean": 285.0, "student_loss": null, "teacher_policy_loss": -54.82441329956055, "teacher_value_loss": 410.4001159667969, "teacher_entropy": 0.4875296652317047, "total_time": 1.4133846759796143, "rollout_time": 0.5488550662994385, "train_time": 0.8581171035766602, "student_train_time": 0.006043434143066406, "throughput": 1415.0429348710773, "inference_time": 0.07617164272232912, "env_time": 0.47268342357710935, "samples": 2000, "teacher_eval_reward": 182.0}
{"epoch": 439, "reward_mean": 277.2857142857143, "student_loss": null, "teacher_policy_loss": -53.63386535644531, "teacher_value_loss": 499.5224914550781, "teacher_entropy": 0.47054970264434814, "total_time": 1.2263381481170654, "rollout_time": 0.42501401901245117, "train_time": 0.7883822917938232, "student_train_time": 0.012534856796264648, "throughput": 1630.8715528998462, "inference_time": 0.054791981219750596, "env_time": 0.3702220377927006, "samples": 2000, "teacher_eval_reward": 267.0}
{"epoch": 440, "reward_mean": 286.2857142857143, "student_loss": null, "teacher_policy_loss": -57.45850372314453, "teacher_value_loss": 669.076904296875, "teacher_entropy": 0.4814789891242981, "total_time": 1.228222131729126, "rollout_time": 0.44812703132629395, "train_time": 0.7713561058044434, "student_train_time": 0.008291244506835938, "throughput": 1628.369940854545, "inference_time": 0.05925439052771253, "env_time": 0.3888726407985814, "samples": 2000, "teacher_eval_reward": 203.0}
{"epoch": 441, "reward_mean": 333.8, "student_loss": null, "teacher_policy_loss": -60.00200271606445, "teacher_value_loss": 419.7717590332031, "teacher_entropy": 0.4881093502044678, "total_time": 1.2844810485839844, "rollout_time": 0.4440727233886719, "train_time": 0.8259885311126709, "student_train_time": 0.014001131057739258, "throughput": 1557.0490527710049, "inference_time": 0.058267948268621694, "env_time": 0.3858047751200502, "samples": 2000, "teacher_eval_reward": 166.0}
{"epoch": 442, "reward_mean": 268.0, "student_loss": null, "teacher_policy_loss": -58.07440185546875, "teacher_value_loss": 451.1789855957031, "teacher_entropy": 0.4874088764190674, "total_time": 1.3531615734100342, "rollout_time": 0.43698620796203613, "train_time": 0.9061048030853271, "student_train_time": 0.00970768928527832, "throughput": 1478.0200970087415, "inference_time": 0.05527201172662899, "env_time": 0.38171419623540714, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 443, "reward_mean": 365.2, "student_loss": null, "teacher_policy_loss": -59.92900085449219, "teacher_value_loss": 378.88433837890625, "teacher_entropy": 0.5000611543655396, "total_time": 1.3371868133544922, "rollout_time": 0.4367256164550781, "train_time": 0.8929657936096191, "student_train_time": 0.0071260929107666016, "throughput": 1495.677327973914, "inference_time": 0.05662849446343898, "env_time": 0.38009712199163914, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 444, "reward_mean": 314.14285714285717, "student_loss": null, "teacher_policy_loss": -57.441410064697266, "teacher_value_loss": 572.426513671875, "teacher_entropy": 0.4713565707206726, "total_time": 1.229895830154419, "rollout_time": 0.4254631996154785, "train_time": 0.7951598167419434, "student_train_time": 0.008902788162231445, "throughput": 1626.1539806577691, "inference_time": 0.054004374558644486, "env_time": 0.37145882505683403, "samples": 2000, "teacher_eval_reward": 410.0}
{"epoch": 445, "reward_mean": 270.25, "student_loss": null, "teacher_policy_loss": -56.85308837890625, "teacher_value_loss": 461.40423583984375, "teacher_entropy": 0.482086181640625, "total_time": 1.2018978595733643, "rollout_time": 0.43279314041137695, "train_time": 0.7584264278411865, "student_train_time": 0.010306596755981445, "throughput": 1664.0349128418757, "inference_time": 0.05533220174947928, "env_time": 0.37746093866189767, "samples": 2000, "teacher_eval_reward": 241.0}
{"epoch": 446, "reward_mean": 253.44444444444446, "student_loss": null, "teacher_policy_loss": -54.237388610839844, "teacher_value_loss": 337.83740234375, "teacher_entropy": 0.47750213742256165, "total_time": 1.26578688621521, "rollout_time": 0.43442225456237793, "train_time": 0.8223462104797363, "student_train_time": 0.008656024932861328, "throughput": 1580.0448098969787, "inference_time": 0.05651106469485967, "env_time": 0.37791118986751826, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 447, "reward_mean": 247.66666666666666, "student_loss": null, "teacher_policy_loss": -54.384159088134766, "teacher_value_loss": 343.6029052734375, "teacher_entropy": 0.46242985129356384, "total_time": 1.2656068801879883, "rollout_time": 0.43737339973449707, "train_time": 0.8154425621032715, "student_train_time": 0.01242208480834961, "throughput": 1580.269538123029, "inference_time": 0.05910423298882961, "env_time": 0.37826916674566746, "samples": 2000, "teacher_eval_reward": 416.0}
{"epoch": 448, "reward_mean": 306.875, "student_loss": null, "teacher_policy_loss": -57.61601638793945, "teacher_value_loss": 456.29510498046875, "teacher_entropy": 0.4873400628566742, "total_time": 1.1957769393920898, "rollout_time": 0.42813754081726074, "train_time": 0.7386293411254883, "student_train_time": 0.028539657592773438, "throughput": 1672.5527430030234, "inference_time": 0.05308395271822519, "env_time": 0.37505358809903555, "samples": 2000, "teacher_eval_reward": 244.0}
{"epoch": 449, "reward_mean": 226.875, "student_loss": null, "teacher_policy_loss": -53.565643310546875, "teacher_value_loss": 474.510498046875, "teacher_entropy": 0.4639691710472107, "total_time": 1.1863086223602295, "rollout_time": 0.42230796813964844, "train_time": 0.7512753009796143, "student_train_time": 0.012324094772338867, "throughput": 1685.9019333610545, "inference_time": 0.05452751299162628, "env_time": 0.36778045514802216, "samples": 2000, "teacher_eval_reward": 239.0}
{"epoch": 450, "reward_mean": 281.57142857142856, "student_loss": null, "teacher_policy_loss": -52.686214447021484, "teacher_value_loss": 465.84674072265625, "teacher_entropy": 0.4760255515575409, "total_time": 1.3776443004608154, "rollout_time": 0.5764448642730713, "train_time": 0.7927758693695068, "student_train_time": 0.008075714111328125, "throughput": 1451.7535472189807, "inference_time": 0.06903904173486808, "env_time": 0.5074058225382032, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 451, "reward_mean": 384.75, "student_loss": null, "teacher_policy_loss": -62.39564895629883, "teacher_value_loss": 297.4288635253906, "teacher_entropy": 0.4794118106365204, "total_time": 1.1979494094848633, "rollout_time": 0.4438142776489258, "train_time": 0.7455654144287109, "student_train_time": 0.008198976516723633, "throughput": 1669.5195841868072, "inference_time": 0.059483081471626065, "env_time": 0.3843311961772997, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 452, "reward_mean": 304.125, "student_loss": null, "teacher_policy_loss": -60.52164840698242, "teacher_value_loss": 426.4288024902344, "teacher_entropy": 0.4813171625137329, "total_time": 1.2091026306152344, "rollout_time": 0.42322683334350586, "train_time": 0.7660770416259766, "student_train_time": 0.019439697265625, "throughput": 1654.1193024965373, "inference_time": 0.05267487550918304, "env_time": 0.3705519578343228, "samples": 2000, "teacher_eval_reward": 203.0}
{"epoch": 453, "reward_mean": 306.0, "student_loss": null, "teacher_policy_loss": -61.72220230102539, "teacher_value_loss": 572.7119750976562, "teacher_entropy": 0.46696457266807556, "total_time": 1.371140956878662, "rollout_time": 0.43438053131103516, "train_time": 0.9247293472290039, "student_train_time": 0.011674642562866211, "throughput": 1458.6392376119418, "inference_time": 0.05642305229957856, "env_time": 0.3779574790114566, "samples": 2000, "teacher_eval_reward": 373.0}
{"epoch": 454, "reward_mean": 302.85714285714283, "student_loss": null, "teacher_policy_loss": -55.77790832519531, "teacher_value_loss": 309.388427734375, "teacher_entropy": 0.47311222553253174, "total_time": 1.3481295108795166, "rollout_time": 0.43644189834594727, "train_time": 0.9061398506164551, "student_train_time": 0.005139350891113281, "throughput": 1483.5369924475613, "inference_time": 0.054773559953900985, "env_time": 0.3816683383920463, "samples": 2000, "teacher_eval_reward": 376.0}
{"epoch": 455, "reward_mean": 361.3333333333333, "student_loss": null, "teacher_policy_loss": -65.7881851196289, "teacher_value_loss": 670.2152709960938, "teacher_entropy": 0.4713083803653717, "total_time": 1.2506022453308105, "rollout_time": 0.4289529323577881, "train_time": 0.8142261505126953, "student_train_time": 0.007055521011352539, "throughput": 1599.2294972019324, "inference_time": 0.053713581981355674, "env_time": 0.3752393503764324, "samples": 2000, "teacher_eval_reward": 185.0}
{"epoch": 456, "reward_mean": 290.5, "student_loss": null, "teacher_policy_loss": -57.925838470458984, "teacher_value_loss": 520.1008911132812, "teacher_entropy": 0.4642294645309448, "total_time": 1.192063808441162, "rollout_time": 0.42331719398498535, "train_time": 0.7619354724884033, "student_train_time": 0.006302833557128906, "throughput": 1677.7625374059128, "inference_time": 0.056145243484934326, "env_time": 0.367171950500051, "samples": 2000, "teacher_eval_reward": 410.0}
{"epoch": 457, "reward_mean": 321.4, "student_loss": null, "teacher_policy_loss": -61.073524475097656, "teacher_value_loss": 374.2279052734375, "teacher_entropy": 0.4634459614753723, "total_time": 1.2209341526031494, "rollout_time": 0.4400920867919922, "train_time": 0.7701160907745361, "student_train_time": 0.010372161865234375, "throughput": 1638.089978673958, "inference_time": 0.05565523125551408, "env_time": 0.3844368555364781, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 458, "reward_mean": 268.375, "student_loss": null, "teacher_policy_loss": -59.9469108581543, "teacher_value_loss": 555.7843017578125, "teacher_entropy": 0.45298826694488525, "total_time": 1.1724684238433838, "rollout_time": 0.42494940757751465, "train_time": 0.741011381149292, "student_train_time": 0.006147623062133789, "throughput": 1705.8028679731476, "inference_time": 0.05629868100913882, "env_time": 0.36865072656837583, "samples": 2000, "teacher_eval_reward": 184.0}
{"epoch": 459, "reward_mean": 301.85714285714283, "student_loss": null, "teacher_policy_loss": -58.69742202758789, "teacher_value_loss": 675.771240234375, "teacher_entropy": 0.45678433775901794, "total_time": -1.1608061790466309, "rollout_time": 0.4523775577545166, "train_time": -1.6308262348175049, "student_train_time": 0.017212390899658203, "throughput": 200000000000.0, "inference_time": 0.05849306222808082, "env_time": 0.3938844955264358, "samples": 2000, "teacher_eval_reward": 220.0}
{"epoch": 460, "reward_mean": 334.5, "student_loss": null, "teacher_policy_loss": -55.935523986816406, "teacher_value_loss": 583.7418212890625, "teacher_entropy": 0.443345308303833, "total_time": 1.2837703227996826, "rollout_time": 0.4259014129638672, "train_time": 0.8501482009887695, "student_train_time": 0.007355451583862305, "throughput": 1557.9110721599666, "inference_time": 0.05397682846887619, "env_time": 0.371924584494991, "samples": 2000, "teacher_eval_reward": 253.0}
{"epoch": 461, "reward_mean": 384.4, "student_loss": null, "teacher_policy_loss": -60.0251350402832, "teacher_value_loss": 415.2655334472656, "teacher_entropy": 0.46359768509864807, "total_time": 1.1887147426605225, "rollout_time": 0.41698360443115234, "train_time": 0.7617490291595459, "student_train_time": 0.009595155715942383, "throughput": 1682.4894385710227, "inference_time": 0.05486960023699794, "env_time": 0.3621140041941544, "samples": 2000, "teacher_eval_reward": 468.0}
{"epoch": 462, "reward_mean": 296.625, "student_loss": null, "teacher_policy_loss": -55.14159393310547, "teacher_value_loss": 525.2996215820312, "teacher_entropy": 0.46601441502571106, "total_time": 1.2004914283752441, "rollout_time": 0.4149153232574463, "train_time": 0.7742898464202881, "student_train_time": 0.010922670364379883, "throughput": 1665.9844066582116, "inference_time": 0.05222623994995956, "env_time": 0.3626890833074867, "samples": 2000, "teacher_eval_reward": 196.0}
{"epoch": 463, "reward_mean": 341.3333333333333, "student_loss": null, "teacher_policy_loss": -60.40324401855469, "teacher_value_loss": 670.4470825195312, "teacher_entropy": 0.46924448013305664, "total_time": 1.20955491065979, "rollout_time": 0.46683406829833984, "train_time": 0.7353944778442383, "student_train_time": 0.006919384002685547, "throughput": 1653.5007897318499, "inference_time": 0.062296997202793136, "env_time": 0.4045370710955467, "samples": 2000, "teacher_eval_reward": 272.0}
{"epoch": 464, "reward_mean": 273.25, "student_loss": null, "teacher_policy_loss": -55.40193176269531, "teacher_value_loss": 522.4364624023438, "teacher_entropy": 0.47034066915512085, "total_time": 1.350294589996338, "rollout_time": 0.43288564682006836, "train_time": 0.9045381546020508, "student_train_time": 0.012511730194091797, "throughput": 1481.1582708077237, "inference_time": 0.0585121363055805, "env_time": 0.37437351051448786, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 465, "reward_mean": 291.2857142857143, "student_loss": null, "teacher_policy_loss": -58.19281005859375, "teacher_value_loss": 537.5236206054688, "teacher_entropy": 0.47191914916038513, "total_time": 1.327092170715332, "rollout_time": 0.4383869171142578, "train_time": 0.8705036640167236, "student_train_time": 0.017801761627197266, "throughput": 1507.0543283530606, "inference_time": 0.05632570875059173, "env_time": 0.3820612083636661, "samples": 2000, "teacher_eval_reward": 247.0}
{"epoch": 466, "reward_mean": 382.25, "student_loss": null, "teacher_policy_loss": -66.41714477539062, "teacher_value_loss": 570.35205078125, "teacher_entropy": 0.4732629954814911, "total_time": 1.297316074371338, "rollout_time": 0.42839646339416504, "train_time": 0.862379789352417, "student_train_time": 0.0061702728271484375, "throughput": 1541.644352914669, "inference_time": 0.05632790424169798, "env_time": 0.37206855915246706, "samples": 2000, "teacher_eval_reward": 278.0}
{"epoch": 467, "reward_mean": 315.6666666666667, "student_loss": null, "teacher_policy_loss": -56.717567443847656, "teacher_value_loss": 502.8667297363281, "teacher_entropy": 0.4694896936416626, "total_time": 1.2320024967193604, "rollout_time": 0.43526172637939453, "train_time": 0.7886505126953125, "student_train_time": 0.007729053497314453, "throughput": 1623.3733335165334, "inference_time": 0.05717263228325464, "env_time": 0.3780890940961399, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 468, "reward_mean": 386.75, "student_loss": null, "teacher_policy_loss": -67.6670150756836, "teacher_value_loss": 365.28887939453125, "teacher_entropy": 0.47648388147354126, "total_time": 1.2102875709533691, "rollout_time": 0.4312307834625244, "train_time": 0.7713167667388916, "student_train_time": 0.007367610931396484, "throughput": 1652.4998256609028, "inference_time": 0.056277644751389744, "env_time": 0.37495313871113467, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 469, "reward_mean": 363.85714285714283, "student_loss": null, "teacher_policy_loss": -59.96116256713867, "teacher_value_loss": 511.1544494628906, "teacher_entropy": 0.47429129481315613, "total_time": 1.2314848899841309, "rollout_time": 0.4308316707611084, "train_time": 0.7925176620483398, "student_train_time": 0.007771492004394531, "throughput": 1624.0556553038766, "inference_time": 0.05445731675354182, "env_time": 0.3763743540075666, "samples": 2000, "teacher_eval_reward": 323.0}
{"epoch": 470, "reward_mean": 290.0, "student_loss": null, "teacher_policy_loss": -55.5151252746582, "teacher_value_loss": 524.9773559570312, "teacher_entropy": 0.47163695096969604, "total_time": 1.2483036518096924, "rollout_time": 0.42572665214538574, "train_time": 0.8145883083343506, "student_train_time": 0.007631778717041016, "throughput": 1602.1742763473915, "inference_time": 0.05550075900464435, "env_time": 0.3702258931407414, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 471, "reward_mean": 289.0, "student_loss": null, "teacher_policy_loss": -62.2239875793457, "teacher_value_loss": 340.66845703125, "teacher_entropy": 0.4749291241168976, "total_time": 1.3029875755310059, "rollout_time": 0.4411332607269287, "train_time": 0.8453388214111328, "student_train_time": 0.01615595817565918, "throughput": 1534.9340527555999, "inference_time": 0.058277993255615, "env_time": 0.3828552674713137, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 472, "reward_mean": 342.42857142857144, "student_loss": null, "teacher_policy_loss": -61.98507308959961, "teacher_value_loss": 745.7229614257812, "teacher_entropy": 0.4798593521118164, "total_time": 1.2456445693969727, "rollout_time": 0.42797303199768066, "train_time": 0.8069479465484619, "student_train_time": 0.010365962982177734, "throughput": 1605.594444142455, "inference_time": 0.054205526732403086, "env_time": 0.3737675052652776, "samples": 2000, "teacher_eval_reward": 376.0}
{"epoch": 473, "reward_mean": 226.25, "student_loss": null, "teacher_policy_loss": -55.67169189453125, "teacher_value_loss": 657.5838623046875, "teacher_entropy": 0.45597073435783386, "total_time": 1.1890332698822021, "rollout_time": 0.4233694076538086, "train_time": 0.7599070072174072, "student_train_time": 0.005394935607910156, "throughput": 1682.0387205802413, "inference_time": 0.05438704352127388, "env_time": 0.3689823641325347, "samples": 2000, "teacher_eval_reward": 420.0}
{"epoch": 474, "reward_mean": 276.57142857142856, "student_loss": null, "teacher_policy_loss": -56.105445861816406, "teacher_value_loss": 491.095947265625, "teacher_entropy": 0.4643549919128418, "total_time": 1.209261417388916, "rollout_time": 0.43078088760375977, "train_time": 0.7661702632904053, "student_train_time": 0.011905193328857422, "throughput": 1653.9021019280324, "inference_time": 0.05505764747977082, "env_time": 0.37572324012398894, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 475, "reward_mean": 333.1666666666667, "student_loss": null, "teacher_policy_loss": -57.50939178466797, "teacher_value_loss": 369.0186462402344, "teacher_entropy": 0.4790714979171753, "total_time": 1.2493870258331299, "rollout_time": 0.43040037155151367, "train_time": 0.7904424667358398, "student_train_time": 0.02701544761657715, "throughput": 1600.7849918773875, "inference_time": 0.054939038469456136, "env_time": 0.37546133308205754, "samples": 2000, "teacher_eval_reward": 203.0}
{"epoch": 476, "reward_mean": 293.55555555555554, "student_loss": null, "teacher_policy_loss": -55.247257232666016, "teacher_value_loss": 450.7091979980469, "teacher_entropy": 0.4661637544631958, "total_time": 1.2264626026153564, "rollout_time": 0.44109582901000977, "train_time": 0.7795283794403076, "student_train_time": 0.005484342575073242, "throughput": 1630.7060612652374, "inference_time": 0.05481437725757132, "env_time": 0.38628145175243844, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 477, "reward_mean": 298.0, "student_loss": null, "teacher_policy_loss": -60.45258331298828, "teacher_value_loss": 536.1644287109375, "teacher_entropy": 0.4722635746002197, "total_time": 1.3160057067871094, "rollout_time": 0.4346592426300049, "train_time": 0.8725705146789551, "student_train_time": 0.008378028869628906, "throughput": 1519.7502485629727, "inference_time": 0.05800004199409159, "env_time": 0.3766592006359133, "samples": 2000, "teacher_eval_reward": 494.0}
{"epoch": 478, "reward_mean": 338.6, "student_loss": null, "teacher_policy_loss": -64.56817626953125, "teacher_value_loss": 685.8773803710938, "teacher_entropy": 0.47678396105766296, "total_time": 1.2689416408538818, "rollout_time": 0.4425642490386963, "train_time": 0.8187916278839111, "student_train_time": 0.0071752071380615234, "throughput": 1576.1166121510385, "inference_time": 0.057231987737395684, "env_time": 0.3853322613013006, "samples": 2000, "teacher_eval_reward": 316.0}
{"epoch": 479, "reward_mean": 406.5, "student_loss": null, "teacher_policy_loss": -62.020206451416016, "teacher_value_loss": 731.900634765625, "teacher_entropy": 0.4775579869747162, "total_time": 1.2167282104492188, "rollout_time": 0.42586255073547363, "train_time": 0.7799818515777588, "student_train_time": 0.010530948638916016, "throughput": 1643.7524689771067, "inference_time": 0.05310333051238558, "env_time": 0.37275922022308805, "samples": 2000, "teacher_eval_reward": 209.0}
{"epoch": 480, "reward_mean": 282.0, "student_loss": null, "teacher_policy_loss": -60.456600189208984, "teacher_value_loss": 521.5182495117188, "teacher_entropy": 0.4670502841472626, "total_time": 1.2608821392059326, "rollout_time": 0.44832277297973633, "train_time": 0.7948684692382812, "student_train_time": 0.017322778701782227, "throughput": 1586.191078302959, "inference_time": 0.05897607321458054, "env_time": 0.3893466997651558, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 481, "reward_mean": 304.55555555555554, "student_loss": null, "teacher_policy_loss": -57.286285400390625, "teacher_value_loss": 422.3467712402344, "teacher_entropy": 0.47394466400146484, "total_time": 1.2684276103973389, "rollout_time": 0.4527583122253418, "train_time": 0.801997184753418, "student_train_time": 0.013320446014404297, "throughput": 1576.7553336161563, "inference_time": 0.05744004526968638, "env_time": 0.3953182669556554, "samples": 2000, "teacher_eval_reward": 248.0}
{"epoch": 482, "reward_mean": 246.8, "student_loss": null, "teacher_policy_loss": -58.485321044921875, "teacher_value_loss": 332.39959716796875, "teacher_entropy": 0.47218137979507446, "total_time": 1.3622856140136719, "rollout_time": 0.4306163787841797, "train_time": 0.9131412506103516, "student_train_time": 0.018117427825927734, "throughput": 1468.1209134312476, "inference_time": 0.055178334298034315, "env_time": 0.3754380444861454, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 483, "reward_mean": 320.5, "student_loss": null, "teacher_policy_loss": -58.28028869628906, "teacher_value_loss": 639.9152221679688, "teacher_entropy": 0.4706321656703949, "total_time": 1.3133769035339355, "rollout_time": 0.44776344299316406, "train_time": 0.8539464473724365, "student_train_time": 0.011311054229736328, "throughput": 1522.7921205394664, "inference_time": 0.05588525325401861, "env_time": 0.39187818973914545, "samples": 2000, "teacher_eval_reward": 493.0}
{"epoch": 484, "reward_mean": 284.6666666666667, "student_loss": null, "teacher_policy_loss": -59.03646469116211, "teacher_value_loss": 589.4608154296875, "teacher_entropy": 0.4732570946216583, "total_time": 1.318760633468628, "rollout_time": 0.44258737564086914, "train_time": 0.8645563125610352, "student_train_time": 0.011242151260375977, "throughput": 1516.5754491317837, "inference_time": 0.05677882099735143, "env_time": 0.3858085546435177, "samples": 2000, "teacher_eval_reward": 293.0}
{"epoch": 485, "reward_mean": 356.0, "student_loss": null, "teacher_policy_loss": -61.42936325073242, "teacher_value_loss": 640.859375, "teacher_entropy": 0.4691329896450043, "total_time": 1.3506410121917725, "rollout_time": 0.4453885555267334, "train_time": 0.891944408416748, "student_train_time": 0.012886285781860352, "throughput": 1480.7783725998893, "inference_time": 0.05851130471819488, "env_time": 0.3868772508085385, "samples": 2000, "teacher_eval_reward": 471.0}
{"epoch": 486, "reward_mean": 375.8333333333333, "student_loss": null, "teacher_policy_loss": -60.42747497558594, "teacher_value_loss": 532.934814453125, "teacher_entropy": 0.4728870093822479, "total_time": 1.3414218425750732, "rollout_time": 0.4388570785522461, "train_time": 0.8898520469665527, "student_train_time": 0.01234292984008789, "throughput": 1490.9552957335784, "inference_time": 0.05877668574612471, "env_time": 0.3800803928061214, "samples": 2000, "teacher_eval_reward": 435.0}
{"epoch": 487, "reward_mean": 363.0, "student_loss": null, "teacher_policy_loss": -61.54275131225586, "teacher_value_loss": 533.956298828125, "teacher_entropy": 0.4810354709625244, "total_time": 1.3183391094207764, "rollout_time": 0.43870997428894043, "train_time": 0.8664124011993408, "student_train_time": 0.012856721878051758, "throughput": 1517.0603570114197, "inference_time": 0.05592088619232527, "env_time": 0.38278908809661516, "samples": 2000, "teacher_eval_reward": 203.0}
{"epoch": 488, "reward_mean": 289.6666666666667, "student_loss": null, "teacher_policy_loss": -55.56966018676758, "teacher_value_loss": 556.5222778320312, "teacher_entropy": 0.4583233594894409, "total_time": 1.2697193622589111, "rollout_time": 0.4316880702972412, "train_time": 0.8296458721160889, "student_train_time": 0.008031368255615234, "throughput": 1575.1512180155096, "inference_time": 0.057132741505483864, "env_time": 0.37455532879175735, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 489, "reward_mean": 304.8, "student_loss": null, "teacher_policy_loss": -62.745121002197266, "teacher_value_loss": 606.301513671875, "teacher_entropy": 0.4802358150482178, "total_time": 1.3239564895629883, "rollout_time": 0.4266951084136963, "train_time": 0.8880429267883301, "student_train_time": 0.008847951889038086, "throughput": 1510.623661552624, "inference_time": 0.05494395458481449, "env_time": 0.3717511538288818, "samples": 2000, "teacher_eval_reward": 200.0}
{"epoch": 490, "reward_mean": 322.57142857142856, "student_loss": null, "teacher_policy_loss": -56.994956970214844, "teacher_value_loss": 516.634521484375, "teacher_entropy": 0.46250441670417786, "total_time": 1.1633899211883545, "rollout_time": 0.4306004047393799, "train_time": 0.7218236923217773, "student_train_time": 0.010613203048706055, "throughput": 1719.1140851186703, "inference_time": 0.05403105552068155, "env_time": 0.37656934921869833, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 491, "reward_mean": 275.42857142857144, "student_loss": null, "teacher_policy_loss": -58.63936996459961, "teacher_value_loss": 398.69781494140625, "teacher_entropy": 0.4816288352012634, "total_time": -1.4156906604766846, "rollout_time": 0.4365360736846924, "train_time": -1.8589286804199219, "student_train_time": 0.006144046783447266, "throughput": 200000000000.0, "inference_time": 0.05556788095054799, "env_time": 0.3809681927341444, "samples": 2000, "teacher_eval_reward": 435.0}
{"epoch": 492, "reward_mean": 284.0, "student_loss": null, "teacher_policy_loss": -56.73484420776367, "teacher_value_loss": 514.1444702148438, "teacher_entropy": 0.48503243923187256, "total_time": 1.230855941772461, "rollout_time": 0.4227936267852783, "train_time": 0.8005349636077881, "student_train_time": 0.0071680545806884766, "throughput": 1624.8855224437996, "inference_time": 0.05372162199273589, "env_time": 0.36907200479254243, "samples": 2000, "teacher_eval_reward": 230.0}
{"epoch": 493, "reward_mean": 297.0, "student_loss": null, "teacher_policy_loss": -56.61560821533203, "teacher_value_loss": 417.52886962890625, "teacher_entropy": 0.4836568534374237, "total_time": 1.2231695652008057, "rollout_time": 0.43241381645202637, "train_time": 0.778693437576294, "student_train_time": 0.01133275032043457, "throughput": 1635.0962752017651, "inference_time": 0.05511886176827829, "env_time": 0.3772949546837481, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 494, "reward_mean": 349.1666666666667, "student_loss": null, "teacher_policy_loss": -59.83467483520508, "teacher_value_loss": 578.1427001953125, "teacher_entropy": 0.47104060649871826, "total_time": 1.2046208381652832, "rollout_time": 0.41585683822631836, "train_time": 0.7833743095397949, "student_train_time": 0.005008220672607422, "throughput": 1660.2734542149642, "inference_time": 0.05597933570788882, "env_time": 0.35987750251842954, "samples": 2000, "teacher_eval_reward": 296.0}
{"epoch": 495, "reward_mean": 351.0, "student_loss": null, "teacher_policy_loss": -58.66318130493164, "teacher_value_loss": 563.1461791992188, "teacher_entropy": 0.45913267135620117, "total_time": 1.220639705657959, "rollout_time": 0.43484044075012207, "train_time": 0.7737762928009033, "student_train_time": 0.01165151596069336, "throughput": 1638.4851244224797, "inference_time": 0.05464985098660691, "env_time": 0.38019058976351516, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 496, "reward_mean": 314.8333333333333, "student_loss": null, "teacher_policy_loss": -63.11484909057617, "teacher_value_loss": 539.2098999023438, "teacher_entropy": 0.4699002802371979, "total_time": 1.2024919986724854, "rollout_time": 0.4389686584472656, "train_time": 0.75244140625, "student_train_time": 0.01068878173828125, "throughput": 1663.212730070503, "inference_time": 0.05763493723497959, "env_time": 0.38133372121228604, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 497, "reward_mean": 354.3333333333333, "student_loss": null, "teacher_policy_loss": -61.12400436401367, "teacher_value_loss": 616.0178833007812, "teacher_entropy": 0.4802348017692566, "total_time": 1.1882691383361816, "rollout_time": 0.43250489234924316, "train_time": 0.748028039932251, "student_train_time": 0.0073659420013427734, "throughput": 1683.120376921012, "inference_time": 0.05656629680743208, "env_time": 0.3759385955418111, "samples": 2000, "teacher_eval_reward": 202.0}
{"epoch": 498, "reward_mean": 338.0, "student_loss": null, "teacher_policy_loss": -59.74185562133789, "teacher_value_loss": 473.1943054199219, "teacher_entropy": 0.4685107171535492, "total_time": 1.369499921798706, "rollout_time": 0.4339771270751953, "train_time": 0.9288430213928223, "student_train_time": 0.006316423416137695, "throughput": 1460.3870859468125, "inference_time": 0.0574660445763584, "env_time": 0.3765110824988369, "samples": 2000, "teacher_eval_reward": 314.0}
{"epoch": 499, "reward_mean": 302.5, "student_loss": null, "teacher_policy_loss": -59.806522369384766, "teacher_value_loss": 592.5587158203125, "teacher_entropy": 0.4680827558040619, "total_time": 1.2567253112792969, "rollout_time": 0.4329826831817627, "train_time": 0.8121411800384521, "student_train_time": 0.011174440383911133, "throughput": 1591.437669035311, "inference_time": 0.05687819125887472, "env_time": 0.376104491922888, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 500, "reward_mean": 282.5, "student_loss": null, "teacher_policy_loss": -60.69426727294922, "teacher_value_loss": 534.7074584960938, "teacher_entropy": 0.47000065445899963, "total_time": 1.3499391078948975, "rollout_time": 0.43668031692504883, "train_time": 0.9072921276092529, "student_train_time": 0.00560450553894043, "throughput": 1481.5483071075785, "inference_time": 0.05702839246077929, "env_time": 0.37965192446426954, "samples": 2000, "teacher_eval_reward": 464.0}
