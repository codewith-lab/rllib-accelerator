{"epoch": 1, "reward_mean": 23.426829268292682, "student_loss": null, "teacher_policy_loss": -11.40467357635498, "teacher_value_loss": 250.59934997558594, "teacher_entropy": 0.5588455200195312, "total_time": 1.3739540576934814, "rollout_time": 0.45676660537719727, "train_time": 0.9104061126708984, "student_train_time": 0.006369352340698242, "throughput": 1455.6527482130589, "inference_time": 0.055500354266769136, "env_time": 0.40126625111042813, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 2, "reward_mean": 23.42528735632184, "student_loss": null, "teacher_policy_loss": -12.081127166748047, "teacher_value_loss": 156.26177978515625, "teacher_entropy": 0.5010480284690857, "total_time": 1.450488567352295, "rollout_time": 0.46565747261047363, "train_time": 0.9730954170227051, "student_train_time": 0.01135396957397461, "throughput": 1378.8457524010526, "inference_time": 0.06160565284335462, "env_time": 0.404051819767119, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 3, "reward_mean": 21.19148936170213, "student_loss": null, "teacher_policy_loss": -11.02739429473877, "teacher_value_loss": 139.01036071777344, "teacher_entropy": 0.5798757672309875, "total_time": 1.2003660202026367, "rollout_time": 0.44025254249572754, "train_time": 0.7347872257232666, "student_train_time": 0.024965524673461914, "throughput": 1666.1584602856178, "inference_time": 0.056213310002931394, "env_time": 0.38403923249279615, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 4, "reward_mean": 22.21590909090909, "student_loss": null, "teacher_policy_loss": -11.593992233276367, "teacher_value_loss": 114.92537689208984, "teacher_entropy": 0.5269296169281006, "total_time": 1.306605339050293, "rollout_time": 0.4527261257171631, "train_time": 0.8488197326660156, "student_train_time": 0.004703998565673828, "throughput": 1530.6840866375928, "inference_time": 0.05717056677895016, "env_time": 0.3955555589382129, "samples": 2000, "teacher_eval_reward": 35.0}
{"epoch": 5, "reward_mean": 23.651162790697676, "student_loss": null, "teacher_policy_loss": -13.738395690917969, "teacher_value_loss": 130.8329315185547, "teacher_entropy": 0.5782261490821838, "total_time": 1.221111536026001, "rollout_time": 0.4432036876678467, "train_time": 0.7697916030883789, "student_train_time": 0.007702350616455078, "throughput": 1637.8520233367235, "inference_time": 0.05770642129573389, "env_time": 0.3854972663721128, "samples": 2000, "teacher_eval_reward": 209.0}
{"epoch": 6, "reward_mean": 22.36263736263736, "student_loss": null, "teacher_policy_loss": -12.166776657104492, "teacher_value_loss": 86.58645629882812, "teacher_entropy": 0.5829863548278809, "total_time": 1.4323716163635254, "rollout_time": 0.45637989044189453, "train_time": 0.9627432823181152, "student_train_time": 0.012879371643066406, "throughput": 1396.2856964993186, "inference_time": 0.05722414403317089, "env_time": 0.39915574640872364, "samples": 2000, "teacher_eval_reward": 12.0}
{"epoch": 7, "reward_mean": 22.54022988505747, "student_loss": null, "teacher_policy_loss": -11.486111640930176, "teacher_value_loss": 75.4731216430664, "teacher_entropy": 0.5442904829978943, "total_time": 1.299083948135376, "rollout_time": 0.47393202781677246, "train_time": 0.8064558506011963, "student_train_time": 0.018050670623779297, "throughput": 1539.5463879533538, "inference_time": 0.06126991727796849, "env_time": 0.412662110538804, "samples": 2000, "teacher_eval_reward": 12.0}
{"epoch": 8, "reward_mean": 22.288888888888888, "student_loss": null, "teacher_policy_loss": -11.413871765136719, "teacher_value_loss": 54.58891677856445, "teacher_entropy": 0.5923787951469421, "total_time": 1.2636537551879883, "rollout_time": 0.4408717155456543, "train_time": 0.8157603740692139, "student_train_time": 0.006335735321044922, "throughput": 1582.7120299282208, "inference_time": 0.055501422963061486, "env_time": 0.3853702925825928, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 9, "reward_mean": 21.138297872340427, "student_loss": null, "teacher_policy_loss": -9.99500846862793, "teacher_value_loss": 62.005714416503906, "teacher_entropy": 0.5496059060096741, "total_time": 1.1915223598480225, "rollout_time": 0.4430513381958008, "train_time": 0.7408616542816162, "student_train_time": 0.007251262664794922, "throughput": 1678.524942037259, "inference_time": 0.05578663152118679, "env_time": 0.387264706674614, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 10, "reward_mean": 21.978021978021978, "student_loss": null, "teacher_policy_loss": -10.319084167480469, "teacher_value_loss": 66.83792114257812, "teacher_entropy": 0.5560907125473022, "total_time": 1.2461576461791992, "rollout_time": 0.4408578872680664, "train_time": 0.797344446182251, "student_train_time": 0.007610321044921875, "throughput": 1604.933377516184, "inference_time": 0.05644676317933772, "env_time": 0.3844111240887287, "samples": 2000, "teacher_eval_reward": 12.0}
{"epoch": 11, "reward_mean": 22.208791208791208, "student_loss": null, "teacher_policy_loss": -12.577338218688965, "teacher_value_loss": 58.65114974975586, "teacher_entropy": 0.6549131870269775, "total_time": -1.3044476509094238, "rollout_time": -2.1409287452697754, "train_time": 0.8272347450256348, "student_train_time": 0.008866310119628906, "throughput": 200000000000.0, "inference_time": 0.056613417729749926, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 12, "reward_mean": 24.01219512195122, "student_loss": null, "teacher_policy_loss": -14.317767143249512, "teacher_value_loss": 95.12881469726562, "teacher_entropy": 0.6552773714065552, "total_time": 1.37371826171875, "rollout_time": 0.4426736831665039, "train_time": 0.9024848937988281, "student_train_time": 0.028010845184326172, "throughput": 1455.902608077487, "inference_time": 0.05499720523584983, "env_time": 0.3876764779306541, "samples": 2000, "teacher_eval_reward": 15.0}
{"epoch": 13, "reward_mean": 21.70212765957447, "student_loss": null, "teacher_policy_loss": -12.767888069152832, "teacher_value_loss": 84.09109497070312, "teacher_entropy": 0.6786239147186279, "total_time": 1.3636574745178223, "rollout_time": 0.45090675354003906, "train_time": 0.9020226001739502, "student_train_time": 0.010369300842285156, "throughput": 1466.6439610923433, "inference_time": 0.0561416002419719, "env_time": 0.39476515329806716, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 14, "reward_mean": 22.584269662921347, "student_loss": null, "teacher_policy_loss": -12.045953750610352, "teacher_value_loss": 65.18134307861328, "teacher_entropy": 0.6385461091995239, "total_time": 1.247408151626587, "rollout_time": 0.4680140018463135, "train_time": 0.7686502933502197, "student_train_time": 0.010321617126464844, "throughput": 1603.3244591131247, "inference_time": 0.05583761402158416, "env_time": 0.4121763878247293, "samples": 2000, "teacher_eval_reward": 45.0}
{"epoch": 15, "reward_mean": 23.51764705882353, "student_loss": null, "teacher_policy_loss": -13.713323593139648, "teacher_value_loss": 80.96990966796875, "teacher_entropy": 0.6602446436882019, "total_time": 1.5279595851898193, "rollout_time": 0.46042895317077637, "train_time": 1.0595777034759521, "student_train_time": 0.007600307464599609, "throughput": 1308.9351442181887, "inference_time": 0.057728200479687075, "env_time": 0.4027007526910893, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 16, "reward_mean": 21.88888888888889, "student_loss": null, "teacher_policy_loss": -12.08240795135498, "teacher_value_loss": 56.057796478271484, "teacher_entropy": 0.6114956736564636, "total_time": 1.1997485160827637, "rollout_time": 0.4476585388183594, "train_time": 0.7463631629943848, "student_train_time": 0.005084514617919922, "throughput": 1667.016023099654, "inference_time": 0.053289113004211686, "env_time": 0.3943694258141477, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 17, "reward_mean": 24.49397590361446, "student_loss": null, "teacher_policy_loss": -13.910085678100586, "teacher_value_loss": 62.836097717285156, "teacher_entropy": 0.6486323475837708, "total_time": 1.3147189617156982, "rollout_time": 0.4543342590332031, "train_time": 0.8522775173187256, "student_train_time": 0.007682085037231445, "throughput": 1521.237662374638, "inference_time": 0.06049170450933161, "env_time": 0.3938425545238715, "samples": 2000, "teacher_eval_reward": 15.0}
{"epoch": 18, "reward_mean": 23.388235294117646, "student_loss": null, "teacher_policy_loss": -10.880193710327148, "teacher_value_loss": 54.02094268798828, "teacher_entropy": 0.564670205116272, "total_time": 1.221684455871582, "rollout_time": 0.4396824836730957, "train_time": 0.7734866142272949, "student_train_time": 0.008092403411865234, "throughput": 1637.0839379904749, "inference_time": 0.0552181200018822, "env_time": 0.3844643636712135, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 19, "reward_mean": 27.493150684931507, "student_loss": null, "teacher_policy_loss": -13.375535011291504, "teacher_value_loss": 105.61103820800781, "teacher_entropy": 0.5829899311065674, "total_time": 1.2292799949645996, "rollout_time": 0.43625688552856445, "train_time": 0.7880840301513672, "student_train_time": 0.00458216667175293, "throughput": 1626.9686387091945, "inference_time": 0.05468823423507274, "env_time": 0.3815686512934917, "samples": 2000, "teacher_eval_reward": 25.0}
{"epoch": 20, "reward_mean": 23.416666666666668, "student_loss": null, "teacher_policy_loss": -12.368484497070312, "teacher_value_loss": 58.809993743896484, "teacher_entropy": 0.6565704345703125, "total_time": 1.276836633682251, "rollout_time": 0.468414306640625, "train_time": 0.7965219020843506, "student_train_time": 0.011341333389282227, "throughput": 1566.3710981037789, "inference_time": 0.059619738696710556, "env_time": 0.40879456794391444, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 21, "reward_mean": 21.92391304347826, "student_loss": null, "teacher_policy_loss": -11.123282432556152, "teacher_value_loss": 73.06636810302734, "teacher_entropy": 0.4820590615272522, "total_time": 1.2791540622711182, "rollout_time": 0.43980979919433594, "train_time": 0.8313784599304199, "student_train_time": 0.007601261138916016, "throughput": 1563.5333217400187, "inference_time": 0.0559684902545996, "env_time": 0.38384130893973634, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 22, "reward_mean": 25.636363636363637, "student_loss": null, "teacher_policy_loss": -13.082524299621582, "teacher_value_loss": 122.2798080444336, "teacher_entropy": 0.44251564145088196, "total_time": 1.3507611751556396, "rollout_time": 0.483903169631958, "train_time": 0.857842206954956, "student_train_time": 0.008594751358032227, "throughput": 1480.6466433783548, "inference_time": 0.05856379855867999, "env_time": 0.425339371073278, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 23, "reward_mean": 23.136363636363637, "student_loss": null, "teacher_policy_loss": -11.449540138244629, "teacher_value_loss": 68.35235595703125, "teacher_entropy": 0.5045282244682312, "total_time": 1.3222382068634033, "rollout_time": 0.4818148612976074, "train_time": 0.8352770805358887, "student_train_time": 0.004779338836669922, "throughput": 1512.5867560160546, "inference_time": 0.05839858946092136, "env_time": 0.42341627183668606, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 24, "reward_mean": 24.54320987654321, "student_loss": null, "teacher_policy_loss": -14.58853530883789, "teacher_value_loss": 87.42254638671875, "teacher_entropy": 0.6552597880363464, "total_time": 1.3292338848114014, "rollout_time": 0.4551708698272705, "train_time": 0.8688712120056152, "student_train_time": 0.004820823669433594, "throughput": 1504.6261029403192, "inference_time": 0.058584985505149234, "env_time": 0.3965858843221213, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 25, "reward_mean": 23.71764705882353, "student_loss": null, "teacher_policy_loss": -11.027853965759277, "teacher_value_loss": 58.10993194580078, "teacher_entropy": 0.5773118138313293, "total_time": 1.2559247016906738, "rollout_time": 0.4534153938293457, "train_time": 0.7895245552062988, "student_train_time": 0.012622356414794922, "throughput": 1592.452156811378, "inference_time": 0.05634024201572174, "env_time": 0.39707515181362396, "samples": 2000, "teacher_eval_reward": 12.0}
{"epoch": 26, "reward_mean": 23.152941176470588, "student_loss": null, "teacher_policy_loss": -11.114764213562012, "teacher_value_loss": 95.0390625, "teacher_entropy": 0.51606285572052, "total_time": 1.2574288845062256, "rollout_time": 0.44614624977111816, "train_time": 0.8022000789642334, "student_train_time": 0.008713722229003906, "throughput": 1590.5472067991914, "inference_time": 0.05547204829781549, "env_time": 0.3906742014733027, "samples": 2000, "teacher_eval_reward": 20.0}
{"epoch": 27, "reward_mean": 22.704545454545453, "student_loss": null, "teacher_policy_loss": -11.139802932739258, "teacher_value_loss": 65.4549560546875, "teacher_entropy": 0.564899742603302, "total_time": 1.2875995635986328, "rollout_time": 0.44763708114624023, "train_time": 0.8308885097503662, "student_train_time": 0.008609533309936523, "throughput": 1553.2779417929617, "inference_time": 0.05754678002631408, "env_time": 0.39009030111992615, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 28, "reward_mean": 22.96629213483146, "student_loss": null, "teacher_policy_loss": -12.537174224853516, "teacher_value_loss": 61.0433464050293, "teacher_entropy": 0.64972984790802, "total_time": 1.2514278888702393, "rollout_time": 0.43334507942199707, "train_time": 0.8078532218933105, "student_train_time": 0.0098724365234375, "throughput": 1598.1743876633234, "inference_time": 0.054344261279766215, "env_time": 0.37900081814223086, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 29, "reward_mean": 21.391304347826086, "student_loss": null, "teacher_policy_loss": -10.55725383758545, "teacher_value_loss": 52.20506286621094, "teacher_entropy": 0.4956238865852356, "total_time": 1.3745973110198975, "rollout_time": 0.4529991149902344, "train_time": 0.9120974540710449, "student_train_time": 0.009043216705322266, "throughput": 1454.97156437479, "inference_time": 0.0551218402088125, "env_time": 0.3978772747814219, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 30, "reward_mean": 22.51685393258427, "student_loss": null, "teacher_policy_loss": -10.189151763916016, "teacher_value_loss": 58.48898696899414, "teacher_entropy": 0.4312536418437958, "total_time": 1.3044657707214355, "rollout_time": 0.46439695358276367, "train_time": 0.8285424709320068, "student_train_time": 0.011141777038574219, "throughput": 1533.1946953992506, "inference_time": 0.05993914826649416, "env_time": 0.4044578053162695, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 31, "reward_mean": 22.886363636363637, "student_loss": null, "teacher_policy_loss": -11.596536636352539, "teacher_value_loss": 53.219825744628906, "teacher_entropy": 0.5281388163566589, "total_time": 1.3117790222167969, "rollout_time": 0.4574136734008789, "train_time": 0.842221736907959, "student_train_time": 0.011711835861206055, "throughput": 1524.6470374409305, "inference_time": 0.058081064529687865, "env_time": 0.39933260887119104, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 32, "reward_mean": 22.875, "student_loss": null, "teacher_policy_loss": -12.413429260253906, "teacher_value_loss": 49.07073974609375, "teacher_entropy": 0.6209529638290405, "total_time": 1.3612949848175049, "rollout_time": 0.441129207611084, "train_time": 0.9087097644805908, "student_train_time": 0.011065959930419922, "throughput": 1469.189281019881, "inference_time": 0.055112692220063764, "env_time": 0.3860165153910202, "samples": 2000, "teacher_eval_reward": 37.0}
{"epoch": 33, "reward_mean": 23.151162790697676, "student_loss": null, "teacher_policy_loss": -12.513472557067871, "teacher_value_loss": 58.61020278930664, "teacher_entropy": 0.6152252554893494, "total_time": -1.3250370025634766, "rollout_time": 0.438678503036499, "train_time": -1.7701656818389893, "student_train_time": 0.006024360656738281, "throughput": 200000000000.0, "inference_time": 0.05593685466556053, "env_time": 0.3827416483709385, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 34, "reward_mean": 24.5375, "student_loss": null, "teacher_policy_loss": -14.963138580322266, "teacher_value_loss": 120.66342163085938, "teacher_entropy": 0.6367583870887756, "total_time": 1.1793229579925537, "rollout_time": 0.43156957626342773, "train_time": 0.7362067699432373, "student_train_time": 0.011152267456054688, "throughput": 1695.8882945892994, "inference_time": 0.05550376692735881, "env_time": 0.3760658093360689, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 35, "reward_mean": 22.831460674157302, "student_loss": null, "teacher_policy_loss": -13.149517059326172, "teacher_value_loss": 61.09291076660156, "teacher_entropy": 0.6313620805740356, "total_time": 1.3229403495788574, "rollout_time": 0.46785759925842285, "train_time": 0.8437035083770752, "student_train_time": 0.010895013809204102, "throughput": 1511.7839595992946, "inference_time": 0.057073133533776854, "env_time": 0.410784465724646, "samples": 2000, "teacher_eval_reward": 57.0}
{"epoch": 36, "reward_mean": 21.67391304347826, "student_loss": null, "teacher_policy_loss": -12.560718536376953, "teacher_value_loss": 53.1943473815918, "teacher_entropy": 0.6460074186325073, "total_time": 1.273366928100586, "rollout_time": 0.474196195602417, "train_time": 0.7917702198028564, "student_train_time": 0.007038593292236328, "throughput": 1570.6391895879487, "inference_time": 0.06134796572769119, "env_time": 0.4128482298747258, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 37, "reward_mean": 22.67816091954023, "student_loss": null, "teacher_policy_loss": -12.528144836425781, "teacher_value_loss": 43.38005447387695, "teacher_entropy": 0.6694626212120056, "total_time": 1.3033573627471924, "rollout_time": 0.44068264961242676, "train_time": 0.852924108505249, "student_train_time": 0.009330987930297852, "throughput": 1534.4985628380825, "inference_time": 0.054776669248894905, "env_time": 0.38590598036353185, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 38, "reward_mean": 25.63157894736842, "student_loss": null, "teacher_policy_loss": -14.931535720825195, "teacher_value_loss": 93.24555969238281, "teacher_entropy": 0.6487805843353271, "total_time": 1.2532167434692383, "rollout_time": 0.4559648036956787, "train_time": 0.7878539562225342, "student_train_time": 0.00902867317199707, "throughput": 1595.8931369393185, "inference_time": 0.05919947907386813, "env_time": 0.3967653246218106, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 39, "reward_mean": 21.98936170212766, "student_loss": null, "teacher_policy_loss": -11.543706893920898, "teacher_value_loss": 44.72816848754883, "teacher_entropy": 0.6228248476982117, "total_time": 1.347125768661499, "rollout_time": 0.45573973655700684, "train_time": 0.8760020732879639, "student_train_time": 0.01500558853149414, "throughput": 1484.6423745476975, "inference_time": 0.06011368073995982, "env_time": 0.395626055817047, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 40, "reward_mean": 21.48421052631579, "student_loss": null, "teacher_policy_loss": -11.685295104980469, "teacher_value_loss": 38.405784606933594, "teacher_entropy": 0.6878136396408081, "total_time": 1.2818899154663086, "rollout_time": 0.45639705657958984, "train_time": 0.8134422302246094, "student_train_time": 0.01161336898803711, "throughput": 1560.1963755775917, "inference_time": 0.05841125698862015, "env_time": 0.3979857995909697, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 41, "reward_mean": 22.61627906976744, "student_loss": null, "teacher_policy_loss": -11.796344757080078, "teacher_value_loss": 38.75578308105469, "teacher_entropy": 0.6710065603256226, "total_time": 1.272118091583252, "rollout_time": 0.4731011390686035, "train_time": 0.7916860580444336, "student_train_time": 0.0069408416748046875, "throughput": 1572.1810838417064, "inference_time": 0.0592586414750258, "env_time": 0.4138424975935777, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 42, "reward_mean": 20.510204081632654, "student_loss": null, "teacher_policy_loss": -11.263935089111328, "teacher_value_loss": 32.13846969604492, "teacher_entropy": 0.6884959936141968, "total_time": 1.318584680557251, "rollout_time": 0.47960901260375977, "train_time": 0.830376386642456, "student_train_time": 0.008225679397583008, "throughput": 1516.7778220772093, "inference_time": 0.0621460807742551, "env_time": 0.41746293182950467, "samples": 2000, "teacher_eval_reward": 24.0}
{"epoch": 43, "reward_mean": 24.73170731707317, "student_loss": null, "teacher_policy_loss": -13.49046802520752, "teacher_value_loss": 51.42877197265625, "teacher_entropy": 0.6692823767662048, "total_time": 1.2373676300048828, "rollout_time": 0.45400047302246094, "train_time": 0.777064323425293, "student_train_time": 0.005925178527832031, "throughput": 1616.3345084371633, "inference_time": 0.05700134000107937, "env_time": 0.39699913302138157, "samples": 2000, "teacher_eval_reward": 19.0}
{"epoch": 44, "reward_mean": 24.175, "student_loss": null, "teacher_policy_loss": -13.229586601257324, "teacher_value_loss": 64.23055267333984, "teacher_entropy": 0.6252071261405945, "total_time": 1.331169605255127, "rollout_time": 0.467454195022583, "train_time": 0.8561491966247559, "student_train_time": 0.007161855697631836, "throughput": 1502.4381507093437, "inference_time": 0.059700369518395746, "env_time": 0.40775382550418726, "samples": 2000, "teacher_eval_reward": 43.0}
{"epoch": 45, "reward_mean": 23.06741573033708, "student_loss": null, "teacher_policy_loss": -12.520082473754883, "teacher_value_loss": 59.28961944580078, "teacher_entropy": 0.6196478009223938, "total_time": 1.2935011386871338, "rollout_time": 0.46629834175109863, "train_time": 0.8221426010131836, "student_train_time": 0.004690885543823242, "throughput": 1546.191139831498, "inference_time": 0.056925679184132605, "env_time": 0.40937266256696603, "samples": 2000, "teacher_eval_reward": 107.0}
{"epoch": 46, "reward_mean": 23.160919540229884, "student_loss": null, "teacher_policy_loss": -13.452896118164062, "teacher_value_loss": 79.79925537109375, "teacher_entropy": 0.6108700633049011, "total_time": 1.3988852500915527, "rollout_time": 0.4558894634246826, "train_time": 0.9354367256164551, "student_train_time": 0.007174253463745117, "throughput": 1429.7098349339992, "inference_time": 0.05642987169449043, "env_time": 0.3994595917301922, "samples": 2000, "teacher_eval_reward": 99.0}
{"epoch": 47, "reward_mean": 24.88607594936709, "student_loss": null, "teacher_policy_loss": -14.440755844116211, "teacher_value_loss": 82.46672821044922, "teacher_entropy": 0.6069742441177368, "total_time": 1.2599449157714844, "rollout_time": 0.4554879665374756, "train_time": 0.7988982200622559, "student_train_time": 0.005184173583984375, "throughput": 1587.3709834174522, "inference_time": 0.056556516987257055, "env_time": 0.39893144955021853, "samples": 2000, "teacher_eval_reward": 39.0}
{"epoch": 48, "reward_mean": 25.3625, "student_loss": null, "teacher_policy_loss": -14.901832580566406, "teacher_value_loss": 118.15753173828125, "teacher_entropy": 0.6054618954658508, "total_time": 1.4177722930908203, "rollout_time": 0.4948761463165283, "train_time": 0.9080700874328613, "student_train_time": 0.014385700225830078, "throughput": 1410.6637643763595, "inference_time": 0.05731671521789394, "env_time": 0.4375594310986344, "samples": 2000, "teacher_eval_reward": 23.0}
{"epoch": 49, "reward_mean": 22.988372093023255, "student_loss": null, "teacher_policy_loss": -13.313949584960938, "teacher_value_loss": 77.66675567626953, "teacher_entropy": 0.5940451622009277, "total_time": 1.2676630020141602, "rollout_time": 0.4529433250427246, "train_time": 0.7956416606903076, "student_train_time": 0.018590450286865234, "throughput": 1577.7063752923661, "inference_time": 0.056745834755929536, "env_time": 0.3961974902867951, "samples": 2000, "teacher_eval_reward": 37.0}
{"epoch": 50, "reward_mean": 23.186046511627907, "student_loss": null, "teacher_policy_loss": -12.96049976348877, "teacher_value_loss": 71.01473236083984, "teacher_entropy": 0.6081035733222961, "total_time": 1.3111867904663086, "rollout_time": 0.45560169219970703, "train_time": 0.848059892654419, "student_train_time": 0.0071637630462646484, "throughput": 1525.335684085654, "inference_time": 0.05810604172438616, "env_time": 0.39749565047532087, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 51, "reward_mean": 26.38157894736842, "student_loss": null, "teacher_policy_loss": -15.240804672241211, "teacher_value_loss": 86.17242431640625, "teacher_entropy": 0.6295467019081116, "total_time": 1.2802345752716064, "rollout_time": 0.45606541633605957, "train_time": 0.810992956161499, "student_train_time": 0.012285232543945312, "throughput": 1562.2137056997485, "inference_time": 0.05674840076244436, "env_time": 0.3993170155736152, "samples": 2000, "teacher_eval_reward": 141.0}
{"epoch": 52, "reward_mean": 23.804878048780488, "student_loss": null, "teacher_policy_loss": -13.199973106384277, "teacher_value_loss": 62.58201217651367, "teacher_entropy": 0.6176354885101318, "total_time": -1.4120123386383057, "rollout_time": -2.202688217163086, "train_time": 0.7846801280975342, "student_train_time": 0.005582094192504883, "throughput": 200000000000.0, "inference_time": 0.054406410241426784, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 271.0}
{"epoch": 53, "reward_mean": 24.070588235294117, "student_loss": null, "teacher_policy_loss": -13.409285545349121, "teacher_value_loss": 55.15781784057617, "teacher_entropy": 0.6442565321922302, "total_time": 1.2034380435943604, "rollout_time": 0.43126344680786133, "train_time": 0.7608003616333008, "student_train_time": 0.01101827621459961, "throughput": 1661.9052477570958, "inference_time": 0.054218096051044995, "env_time": 0.37704535075681633, "samples": 2000, "teacher_eval_reward": 13.0}
{"epoch": 54, "reward_mean": 25.468354430379748, "student_loss": null, "teacher_policy_loss": -13.927003860473633, "teacher_value_loss": 77.31165313720703, "teacher_entropy": 0.6028017997741699, "total_time": 1.3344981670379639, "rollout_time": 0.4397163391113281, "train_time": 0.8822071552276611, "student_train_time": 0.012223243713378906, "throughput": 1498.6907059147006, "inference_time": 0.056310462054170785, "env_time": 0.38340587705715734, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 55, "reward_mean": 23.53488372093023, "student_loss": null, "teacher_policy_loss": -12.031116485595703, "teacher_value_loss": 59.27552795410156, "teacher_entropy": 0.5874321460723877, "total_time": 1.2104158401489258, "rollout_time": 0.4376800060272217, "train_time": 0.7609913349151611, "student_train_time": 0.011366844177246094, "throughput": 1652.3247083034921, "inference_time": 0.056657414252185845, "env_time": 0.38102259177503583, "samples": 2000, "teacher_eval_reward": 12.0}
{"epoch": 56, "reward_mean": 24.5625, "student_loss": null, "teacher_policy_loss": -13.875147819519043, "teacher_value_loss": 61.31717300415039, "teacher_entropy": 0.6466663479804993, "total_time": 1.2134361267089844, "rollout_time": 0.43167543411254883, "train_time": 0.7742092609405518, "student_train_time": 0.007163047790527344, "throughput": 1648.2120121347396, "inference_time": 0.053985702457794105, "env_time": 0.3776897316547547, "samples": 2000, "teacher_eval_reward": 22.0}
{"epoch": 57, "reward_mean": 24.341463414634145, "student_loss": null, "teacher_policy_loss": -12.299006462097168, "teacher_value_loss": 56.6924934387207, "teacher_entropy": 0.6363691687583923, "total_time": 1.387033462524414, "rollout_time": 0.5984361171722412, "train_time": 0.769972562789917, "student_train_time": 0.018242359161376953, "throughput": 1441.9262793847677, "inference_time": 0.09463995554506255, "env_time": 0.5037961616271787, "samples": 2000, "teacher_eval_reward": 14.0}
{"epoch": 58, "reward_mean": 24.12987012987013, "student_loss": null, "teacher_policy_loss": -14.102319717407227, "teacher_value_loss": 185.354248046875, "teacher_entropy": 0.6053757667541504, "total_time": 1.395015001296997, "rollout_time": 0.5891914367675781, "train_time": 0.7921755313873291, "student_train_time": 0.013204336166381836, "throughput": 1433.6763390648316, "inference_time": 0.09828339278465137, "env_time": 0.49090804398292676, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 59, "reward_mean": 24.579545454545453, "student_loss": null, "teacher_policy_loss": -11.226862907409668, "teacher_value_loss": 56.123695373535156, "teacher_entropy": 0.6328717470169067, "total_time": 1.377458095550537, "rollout_time": 0.6026322841644287, "train_time": 0.7641375064849854, "student_train_time": 0.010280132293701172, "throughput": 1451.9497953951534, "inference_time": 0.057745406509639, "env_time": 0.5448868776547897, "samples": 2000, "teacher_eval_reward": 46.0}
{"epoch": 60, "reward_mean": 25.243589743589745, "student_loss": null, "teacher_policy_loss": -14.564446449279785, "teacher_value_loss": 87.3176498413086, "teacher_entropy": 0.679124653339386, "total_time": 1.424971580505371, "rollout_time": 0.5752115249633789, "train_time": 0.837073802947998, "student_train_time": 0.01231074333190918, "throughput": 1403.5367633722865, "inference_time": 0.09437725879070058, "env_time": 0.4808342661726783, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 61, "reward_mean": 23.837209302325583, "student_loss": null, "teacher_policy_loss": -12.375460624694824, "teacher_value_loss": 65.51522064208984, "teacher_entropy": 0.6029093861579895, "total_time": 1.289370059967041, "rollout_time": 0.45534682273864746, "train_time": 0.8247406482696533, "student_train_time": 0.008909463882446289, "throughput": 1551.1450607524764, "inference_time": 0.05852151239923842, "env_time": 0.39682531033940904, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 62, "reward_mean": 23.6144578313253, "student_loss": null, "teacher_policy_loss": -11.736800193786621, "teacher_value_loss": 49.739479064941406, "teacher_entropy": 0.5770309567451477, "total_time": 1.2495453357696533, "rollout_time": 0.4512021541595459, "train_time": 0.7898843288421631, "student_train_time": 0.008055925369262695, "throughput": 1600.5821819726987, "inference_time": 0.05900242374264053, "env_time": 0.39219973041690537, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 63, "reward_mean": 24.475609756097562, "student_loss": null, "teacher_policy_loss": -13.282048225402832, "teacher_value_loss": 59.44193649291992, "teacher_entropy": 0.637158215045929, "total_time": 1.571106195449829, "rollout_time": 0.4704151153564453, "train_time": 1.0803253650665283, "student_train_time": 0.019898176193237305, "throughput": 1272.9884242022054, "inference_time": 0.05837311782488541, "env_time": 0.4120419975315599, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 64, "reward_mean": 25.576923076923077, "student_loss": null, "teacher_policy_loss": -14.397220611572266, "teacher_value_loss": 72.77403259277344, "teacher_entropy": 0.6731258034706116, "total_time": 1.26564621925354, "rollout_time": 0.4413774013519287, "train_time": 0.8166382312774658, "student_train_time": 0.0072672367095947266, "throughput": 1580.2204198733918, "inference_time": 0.05603393152159697, "env_time": 0.38534346983033174, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 65, "reward_mean": 26.4, "student_loss": null, "teacher_policy_loss": -14.198151588439941, "teacher_value_loss": 81.8946762084961, "teacher_entropy": 0.6280004978179932, "total_time": 1.7078466415405273, "rollout_time": 0.5000333786010742, "train_time": 1.1957964897155762, "student_train_time": 0.011643648147583008, "throughput": 1171.065335348812, "inference_time": 0.06400987077176978, "env_time": 0.43602350782930444, "samples": 2000, "teacher_eval_reward": 35.0}
{"epoch": 66, "reward_mean": 26.636363636363637, "student_loss": null, "teacher_policy_loss": -14.143351554870605, "teacher_value_loss": 71.72356414794922, "teacher_entropy": 0.646450400352478, "total_time": 1.16886568069458, "rollout_time": 0.43912529945373535, "train_time": 0.7236406803131104, "student_train_time": 0.00574183464050293, "throughput": 1711.0605889391254, "inference_time": 0.055635970460571116, "env_time": 0.38348932899316424, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 67, "reward_mean": 25.907894736842106, "student_loss": null, "teacher_policy_loss": -14.803996086120605, "teacher_value_loss": 77.6230697631836, "teacher_entropy": 0.6627583503723145, "total_time": 1.3596553802490234, "rollout_time": 0.44261932373046875, "train_time": 0.9038505554199219, "student_train_time": 0.012779712677001953, "throughput": 1470.9609722087785, "inference_time": 0.05789822498081776, "env_time": 0.384721098749651, "samples": 2000, "teacher_eval_reward": 21.0}
{"epoch": 68, "reward_mean": 28.5, "student_loss": null, "teacher_policy_loss": -15.17996597290039, "teacher_value_loss": 83.20465850830078, "teacher_entropy": 0.6324991583824158, "total_time": 1.219294786453247, "rollout_time": 0.4304659366607666, "train_time": 0.7762680053710938, "student_train_time": 0.012195587158203125, "throughput": 1640.2924233094705, "inference_time": 0.054140217765962007, "env_time": 0.3763257188948046, "samples": 2000, "teacher_eval_reward": 42.0}
{"epoch": 69, "reward_mean": 24.555555555555557, "student_loss": null, "teacher_policy_loss": -13.45832347869873, "teacher_value_loss": 52.66648483276367, "teacher_entropy": 0.6356348991394043, "total_time": 1.3509128093719482, "rollout_time": 0.43510961532592773, "train_time": 0.9096970558166504, "student_train_time": 0.005546092987060547, "throughput": 1480.4804470910437, "inference_time": 0.05472003676004533, "env_time": 0.3803895785658824, "samples": 2000, "teacher_eval_reward": 109.0}
{"epoch": 70, "reward_mean": 23.71764705882353, "student_loss": null, "teacher_policy_loss": -13.580252647399902, "teacher_value_loss": 69.43289184570312, "teacher_entropy": 0.6434063911437988, "total_time": 1.1733505725860596, "rollout_time": 0.4359316825866699, "train_time": 0.7264902591705322, "student_train_time": 0.010565757751464844, "throughput": 1704.5204108027226, "inference_time": 0.054443298240585136, "env_time": 0.3814883843460848, "samples": 2000, "teacher_eval_reward": 33.0}
{"epoch": 71, "reward_mean": 25.1875, "student_loss": null, "teacher_policy_loss": -14.383615493774414, "teacher_value_loss": 91.65695190429688, "teacher_entropy": 0.6263934373855591, "total_time": 1.3666951656341553, "rollout_time": 0.4388465881347656, "train_time": 0.9200236797332764, "student_train_time": 0.007454872131347656, "throughput": 1463.3841183392108, "inference_time": 0.05536113179550739, "env_time": 0.38348545633925823, "samples": 2000, "teacher_eval_reward": 26.0}
{"epoch": 72, "reward_mean": 24.1125, "student_loss": null, "teacher_policy_loss": -12.591893196105957, "teacher_value_loss": 49.106048583984375, "teacher_entropy": 0.6169070601463318, "total_time": -1.3337223529815674, "rollout_time": 0.4531569480895996, "train_time": -1.7977259159088135, "student_train_time": 0.010484695434570312, "throughput": 200000000000.0, "inference_time": 0.057773773254666594, "env_time": 0.395383174834933, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 73, "reward_mean": 25.240506329113924, "student_loss": null, "teacher_policy_loss": -13.8836669921875, "teacher_value_loss": 61.02409744262695, "teacher_entropy": 0.6429625153541565, "total_time": 1.3217108249664307, "rollout_time": 0.4371495246887207, "train_time": 0.8792450428009033, "student_train_time": 0.004948616027832031, "throughput": 1513.1903001935366, "inference_time": 0.054191485043702414, "env_time": 0.3829580396450183, "samples": 2000, "teacher_eval_reward": 30.0}
{"epoch": 74, "reward_mean": 28.054794520547944, "student_loss": null, "teacher_policy_loss": -14.81655216217041, "teacher_value_loss": 73.71159362792969, "teacher_entropy": 0.6259759664535522, "total_time": 1.2062184810638428, "rollout_time": 0.4303872585296631, "train_time": 0.7691817283630371, "student_train_time": 0.006292581558227539, "throughput": 1658.0744130500052, "inference_time": 0.054042180241594906, "env_time": 0.3763450782880682, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 75, "reward_mean": 28.140845070422536, "student_loss": null, "teacher_policy_loss": -15.077882766723633, "teacher_value_loss": 82.2911148071289, "teacher_entropy": 0.6277062892913818, "total_time": 1.2964723110198975, "rollout_time": 0.4446265697479248, "train_time": 0.8461635112762451, "student_train_time": 0.00522160530090332, "throughput": 1542.6476778564268, "inference_time": 0.05508659173756314, "env_time": 0.38953997801036166, "samples": 2000, "teacher_eval_reward": 45.0}
{"epoch": 76, "reward_mean": 24.047619047619047, "student_loss": null, "teacher_policy_loss": -13.239909172058105, "teacher_value_loss": 67.7477798461914, "teacher_entropy": 0.6516712307929993, "total_time": 1.2553741931915283, "rollout_time": 0.4508492946624756, "train_time": 0.796959638595581, "student_train_time": 0.007069110870361328, "throughput": 1593.1504812245782, "inference_time": 0.056716197741479846, "env_time": 0.39413309692099574, "samples": 2000, "teacher_eval_reward": 53.0}
{"epoch": 77, "reward_mean": 25.225, "student_loss": null, "teacher_policy_loss": -14.047776222229004, "teacher_value_loss": 72.31278228759766, "teacher_entropy": 0.6551458239555359, "total_time": 1.346299409866333, "rollout_time": 0.4593677520751953, "train_time": 0.8797645568847656, "student_train_time": 0.006758213043212891, "throughput": 1485.5536482769235, "inference_time": 0.059232475721728406, "env_time": 0.4001352763534669, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 78, "reward_mean": 26.116883116883116, "student_loss": null, "teacher_policy_loss": -15.057676315307617, "teacher_value_loss": 109.7148208618164, "teacher_entropy": 0.6474950909614563, "total_time": 1.2533998489379883, "rollout_time": 0.4683709144592285, "train_time": 0.775303840637207, "student_train_time": 0.009312152862548828, "throughput": 1595.659997641303, "inference_time": 0.060649543533145334, "env_time": 0.4077213709260832, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 79, "reward_mean": 25.157894736842106, "student_loss": null, "teacher_policy_loss": -13.98778247833252, "teacher_value_loss": 53.49681091308594, "teacher_entropy": 0.6680094003677368, "total_time": 1.3064124584197998, "rollout_time": 0.43628454208374023, "train_time": 0.8589074611663818, "student_train_time": 0.010611534118652344, "throughput": 1530.910079056613, "inference_time": 0.05512796078437532, "env_time": 0.3811565812993649, "samples": 2000, "teacher_eval_reward": 35.0}
{"epoch": 80, "reward_mean": 26.151898734177216, "student_loss": null, "teacher_policy_loss": -14.27002239227295, "teacher_value_loss": 69.5254898071289, "teacher_entropy": 0.6608477830886841, "total_time": 1.3954081535339355, "rollout_time": 0.4498288631439209, "train_time": 0.9397256374359131, "student_train_time": 0.00549769401550293, "throughput": 1433.2724048766001, "inference_time": 0.057233066521803266, "env_time": 0.39259579662211763, "samples": 2000, "teacher_eval_reward": 37.0}
{"epoch": 81, "reward_mean": 25.0, "student_loss": null, "teacher_policy_loss": -14.400221824645996, "teacher_value_loss": 70.20022583007812, "teacher_entropy": 0.6600278615951538, "total_time": 1.3489601612091064, "rollout_time": 0.4516618251800537, "train_time": 0.8919353485107422, "student_train_time": 0.004724740982055664, "throughput": 1482.6234736297552, "inference_time": 0.059174570233153645, "env_time": 0.39248725494690007, "samples": 2000, "teacher_eval_reward": 218.0}
{"epoch": 82, "reward_mean": 28.043478260869566, "student_loss": null, "teacher_policy_loss": -17.42088508605957, "teacher_value_loss": 122.9603042602539, "teacher_entropy": 0.6674754023551941, "total_time": 1.222790241241455, "rollout_time": 0.4421665668487549, "train_time": 0.7705497741699219, "student_train_time": 0.009713172912597656, "throughput": 1635.6035013572498, "inference_time": 0.05756213953100087, "env_time": 0.384604427317754, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 83, "reward_mean": 25.775, "student_loss": null, "teacher_policy_loss": -14.279718399047852, "teacher_value_loss": 93.837158203125, "teacher_entropy": 0.6581947207450867, "total_time": 1.2673020362854004, "rollout_time": 0.46294093132019043, "train_time": 0.7949550151824951, "student_train_time": 0.009044170379638672, "throughput": 1578.1557535109916, "inference_time": 0.05696842625729914, "env_time": 0.4059725050628913, "samples": 2000, "teacher_eval_reward": 47.0}
{"epoch": 84, "reward_mean": 24.91358024691358, "student_loss": null, "teacher_policy_loss": -14.014324188232422, "teacher_value_loss": 88.68579864501953, "teacher_entropy": 0.6482689380645752, "total_time": 1.2556540966033936, "rollout_time": 0.4465198516845703, "train_time": 0.7919092178344727, "student_train_time": 0.01686263084411621, "throughput": 1592.7953449999477, "inference_time": 0.055673466054940945, "env_time": 0.39084638562962937, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 85, "reward_mean": 26.85135135135135, "student_loss": null, "teacher_policy_loss": -15.47205924987793, "teacher_value_loss": 110.26709747314453, "teacher_entropy": 0.6473124623298645, "total_time": 1.3175978660583496, "rollout_time": 0.45510292053222656, "train_time": 0.8497929573059082, "student_train_time": 0.012278556823730469, "throughput": 1517.9138123402442, "inference_time": 0.05661218952627678, "env_time": 0.3984907310059498, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 86, "reward_mean": 24.353658536585368, "student_loss": null, "teacher_policy_loss": -14.457735061645508, "teacher_value_loss": 111.24962615966797, "teacher_entropy": 0.6487364768981934, "total_time": 1.2917487621307373, "rollout_time": 0.4637901782989502, "train_time": 0.8215131759643555, "student_train_time": 0.0058977603912353516, "throughput": 1548.2886909843085, "inference_time": 0.05791186009264493, "env_time": 0.40587831820630527, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 87, "reward_mean": 26.931506849315067, "student_loss": null, "teacher_policy_loss": -16.827415466308594, "teacher_value_loss": 135.79641723632812, "teacher_entropy": 0.6519352197647095, "total_time": 1.5776607990264893, "rollout_time": 0.45114803314208984, "train_time": 1.1113049983978271, "student_train_time": 0.014847993850708008, "throughput": 1267.699622906343, "inference_time": 0.05500840070817503, "env_time": 0.3961396324339148, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 88, "reward_mean": 30.666666666666668, "student_loss": null, "teacher_policy_loss": -16.518417358398438, "teacher_value_loss": 96.77932739257812, "teacher_entropy": 0.6498181223869324, "total_time": 1.3811297416687012, "rollout_time": 0.44922590255737305, "train_time": 0.9258420467376709, "student_train_time": 0.005697727203369141, "throughput": 1448.0898786406342, "inference_time": 0.05638226277915237, "env_time": 0.3928436397782207, "samples": 2000, "teacher_eval_reward": 57.0}
{"epoch": 89, "reward_mean": 25.525641025641026, "student_loss": null, "teacher_policy_loss": -14.498552322387695, "teacher_value_loss": 74.57439422607422, "teacher_entropy": 0.6427322030067444, "total_time": 1.2192153930664062, "rollout_time": 0.4511282444000244, "train_time": 0.7625763416290283, "student_train_time": 0.005150794982910156, "throughput": 1640.3992365695692, "inference_time": 0.05591062026906002, "env_time": 0.3952176241309644, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 90, "reward_mean": 25.333333333333332, "student_loss": null, "teacher_policy_loss": -13.271842002868652, "teacher_value_loss": 46.80839538574219, "teacher_entropy": 0.6481868624687195, "total_time": 1.3361034393310547, "rollout_time": 0.47638630867004395, "train_time": 0.8498790264129639, "student_train_time": 0.009390592575073242, "throughput": 1496.8900918340107, "inference_time": 0.0590443007331487, "env_time": 0.41734200793689524, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 91, "reward_mean": 29.147058823529413, "student_loss": null, "teacher_policy_loss": -17.258813858032227, "teacher_value_loss": 118.42988586425781, "teacher_entropy": 0.6541945338249207, "total_time": -1.4026625156402588, "rollout_time": -2.1966283321380615, "train_time": 0.7882668972015381, "student_train_time": 0.005339384078979492, "throughput": 200000000000.0, "inference_time": 0.059930576473561814, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 92, "reward_mean": 29.970149253731343, "student_loss": null, "teacher_policy_loss": -17.955698013305664, "teacher_value_loss": 156.74710083007812, "teacher_entropy": 0.654624879360199, "total_time": 1.282264232635498, "rollout_time": 0.4451327323913574, "train_time": 0.8244485855102539, "student_train_time": 0.012275218963623047, "throughput": 1559.7409247619003, "inference_time": 0.05547074027163035, "env_time": 0.3896619921197271, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 93, "reward_mean": 28.21917808219178, "student_loss": null, "teacher_policy_loss": -16.065723419189453, "teacher_value_loss": 108.70264434814453, "teacher_entropy": 0.6517080068588257, "total_time": 1.2535016536712646, "rollout_time": 0.4444618225097656, "train_time": 0.8024108409881592, "student_train_time": 0.006226301193237305, "throughput": 1595.5304040823446, "inference_time": 0.056783045238262275, "env_time": 0.38767877727150335, "samples": 2000, "teacher_eval_reward": 100.0}
{"epoch": 94, "reward_mean": 26.554054054054053, "student_loss": null, "teacher_policy_loss": -15.2927885055542, "teacher_value_loss": 101.04259490966797, "teacher_entropy": 0.6548867225646973, "total_time": 1.2626910209655762, "rollout_time": 0.44957542419433594, "train_time": 0.8042476177215576, "student_train_time": 0.008455276489257812, "throughput": 1583.918763016629, "inference_time": 0.05741598998065456, "env_time": 0.3921594342136814, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 95, "reward_mean": 26.558441558441558, "student_loss": null, "teacher_policy_loss": -14.840587615966797, "teacher_value_loss": 80.0523910522461, "teacher_entropy": 0.6514993906021118, "total_time": 1.2470755577087402, "rollout_time": 0.4523601531982422, "train_time": 0.784306526184082, "student_train_time": 0.009955167770385742, "throughput": 1603.752064289202, "inference_time": 0.05524202702326875, "env_time": 0.39711812617497344, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 96, "reward_mean": 28.10144927536232, "student_loss": null, "teacher_policy_loss": -15.759319305419922, "teacher_value_loss": 79.40631103515625, "teacher_entropy": 0.6538057923316956, "total_time": 1.2005648612976074, "rollout_time": 0.4431283473968506, "train_time": 0.7497575283050537, "student_train_time": 0.007317543029785156, "throughput": 1665.882506204903, "inference_time": 0.055273021243920084, "env_time": 0.3878553261529305, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 97, "reward_mean": 28.680555555555557, "student_loss": null, "teacher_policy_loss": -16.609621047973633, "teacher_value_loss": 114.15243530273438, "teacher_entropy": 0.6610615253448486, "total_time": 1.225841760635376, "rollout_time": 0.43121790885925293, "train_time": 0.7844841480255127, "student_train_time": 0.009779214859008789, "throughput": 1631.5319515329318, "inference_time": 0.05309685223437555, "env_time": 0.3781210566248774, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 98, "reward_mean": 26.643835616438356, "student_loss": null, "teacher_policy_loss": -15.257301330566406, "teacher_value_loss": 85.06830596923828, "teacher_entropy": 0.6544278860092163, "total_time": 1.2565851211547852, "rollout_time": 0.45575380325317383, "train_time": 0.7940576076507568, "student_train_time": 0.006410360336303711, "throughput": 1591.6152167726023, "inference_time": 0.055162996766739525, "env_time": 0.4005908064864343, "samples": 2000, "teacher_eval_reward": 82.0}
{"epoch": 99, "reward_mean": 27.444444444444443, "student_loss": null, "teacher_policy_loss": -15.13365650177002, "teacher_value_loss": 77.50997924804688, "teacher_entropy": 0.6566572189331055, "total_time": 1.2915430068969727, "rollout_time": 0.4299662113189697, "train_time": 0.852358341217041, "student_train_time": 0.008860349655151367, "throughput": 1548.5353482770563, "inference_time": 0.05487010373872181, "env_time": 0.3750961075802479, "samples": 2000, "teacher_eval_reward": 152.0}
{"epoch": 100, "reward_mean": 27.324324324324323, "student_loss": null, "teacher_policy_loss": -15.617118835449219, "teacher_value_loss": 81.21810150146484, "teacher_entropy": 0.6643062829971313, "total_time": 1.1795680522918701, "rollout_time": 0.4190175533294678, "train_time": 0.7553637027740479, "student_train_time": 0.004828929901123047, "throughput": 1695.5359176726192, "inference_time": 0.052236943198295194, "env_time": 0.3667806101311726, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 101, "reward_mean": 26.68, "student_loss": null, "teacher_policy_loss": -15.884580612182617, "teacher_value_loss": 92.96512603759766, "teacher_entropy": 0.6608469486236572, "total_time": 1.3474245071411133, "rollout_time": 0.44600939750671387, "train_time": 0.8882889747619629, "student_train_time": 0.012754440307617188, "throughput": 1484.3132133936642, "inference_time": 0.05597437447613629, "env_time": 0.3900350230305776, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 102, "reward_mean": 27.783783783783782, "student_loss": null, "teacher_policy_loss": -16.228675842285156, "teacher_value_loss": 102.04402923583984, "teacher_entropy": 0.6558140516281128, "total_time": 1.2101759910583496, "rollout_time": 0.43642306327819824, "train_time": 0.7684130668640137, "student_train_time": 0.004809379577636719, "throughput": 1652.6521884233682, "inference_time": 0.055952088039703085, "env_time": 0.38047097523849516, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 103, "reward_mean": 27.6056338028169, "student_loss": null, "teacher_policy_loss": -16.206756591796875, "teacher_value_loss": 115.51778411865234, "teacher_entropy": 0.6485477685928345, "total_time": 1.4125659465789795, "rollout_time": 0.45196986198425293, "train_time": 0.9485814571380615, "student_train_time": 0.011651754379272461, "throughput": 1415.8630999449595, "inference_time": 0.05738741351888166, "env_time": 0.39458244846537127, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 104, "reward_mean": 27.904109589041095, "student_loss": null, "teacher_policy_loss": -14.846029281616211, "teacher_value_loss": 62.092533111572266, "teacher_entropy": 0.6450084447860718, "total_time": 1.2441105842590332, "rollout_time": 0.4429941177368164, "train_time": 0.7859055995941162, "student_train_time": 0.014844417572021484, "throughput": 1607.5741379462333, "inference_time": 0.055703238236674224, "env_time": 0.3872908795001422, "samples": 2000, "teacher_eval_reward": 41.0}
{"epoch": 105, "reward_mean": 26.373333333333335, "student_loss": null, "teacher_policy_loss": -15.137754440307617, "teacher_value_loss": 77.80209350585938, "teacher_entropy": 0.6334189176559448, "total_time": 1.35845947265625, "rollout_time": 0.44794201850891113, "train_time": 0.9034123420715332, "student_train_time": 0.006742954254150391, "throughput": 1472.2559194860044, "inference_time": 0.05698108849901473, "env_time": 0.3909609300098964, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 106, "reward_mean": 28.098591549295776, "student_loss": null, "teacher_policy_loss": -15.429685592651367, "teacher_value_loss": 74.88530731201172, "teacher_entropy": 0.6476730108261108, "total_time": 1.2206180095672607, "rollout_time": 0.43187928199768066, "train_time": 0.7785065174102783, "student_train_time": 0.009871721267700195, "throughput": 1638.5142479661179, "inference_time": 0.05690790900916909, "env_time": 0.3749713729885116, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 107, "reward_mean": 29.939393939393938, "student_loss": null, "teacher_policy_loss": -17.36986541748047, "teacher_value_loss": 139.53660583496094, "teacher_entropy": 0.6325861215591431, "total_time": 1.3473780155181885, "rollout_time": 0.4546482563018799, "train_time": 0.8835201263427734, "student_train_time": 0.008784294128417969, "throughput": 1484.3644300006033, "inference_time": 0.05872828947940434, "env_time": 0.39591996682247554, "samples": 2000, "teacher_eval_reward": 32.0}
{"epoch": 108, "reward_mean": 28.27777777777778, "student_loss": null, "teacher_policy_loss": -14.231725692749023, "teacher_value_loss": 63.34664535522461, "teacher_entropy": 0.6132885813713074, "total_time": 1.1979479789733887, "rollout_time": 0.4479236602783203, "train_time": 0.7432620525360107, "student_train_time": 0.006408214569091797, "throughput": 1669.5215778183872, "inference_time": 0.05576177422335604, "env_time": 0.39216188605496427, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 109, "reward_mean": 26.43421052631579, "student_loss": null, "teacher_policy_loss": -13.61025333404541, "teacher_value_loss": 49.84650802612305, "teacher_entropy": 0.6333068609237671, "total_time": -0.7822957038879395, "rollout_time": 0.43687963485717773, "train_time": -1.2353923320770264, "student_train_time": 0.015849828720092773, "throughput": 200000000000.0, "inference_time": 0.055005418242217274, "env_time": 0.38187421661496046, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 110, "reward_mean": 26.038961038961038, "student_loss": null, "teacher_policy_loss": -14.551416397094727, "teacher_value_loss": 54.243778228759766, "teacher_entropy": 0.6442788243293762, "total_time": 1.1657969951629639, "rollout_time": 0.4317622184753418, "train_time": 0.7288539409637451, "student_train_time": 0.004828691482543945, "throughput": 1715.5645522318619, "inference_time": 0.052296762998594204, "env_time": 0.3794654554767476, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 111, "reward_mean": 27.309859154929576, "student_loss": null, "teacher_policy_loss": -13.825064659118652, "teacher_value_loss": 49.76155471801758, "teacher_entropy": 0.6216063499450684, "total_time": 1.4019043445587158, "rollout_time": 0.4648308753967285, "train_time": 0.927274227142334, "student_train_time": 0.009428977966308594, "throughput": 1426.6308594895963, "inference_time": 0.054880721982044633, "env_time": 0.4099501534146839, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 112, "reward_mean": 24.55421686746988, "student_loss": null, "teacher_policy_loss": -13.295741081237793, "teacher_value_loss": 50.133201599121094, "teacher_entropy": 0.6466145515441895, "total_time": 1.1969199180603027, "rollout_time": 0.4411201477050781, "train_time": 0.7508401870727539, "student_train_time": 0.0046062469482421875, "throughput": 1670.9555667192406, "inference_time": 0.05647099020825408, "env_time": 0.38464915749682405, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 113, "reward_mean": 30.166666666666668, "student_loss": null, "teacher_policy_loss": -16.525054931640625, "teacher_value_loss": 93.70104217529297, "teacher_entropy": 0.6543774604797363, "total_time": 1.2777979373931885, "rollout_time": 0.4373660087585449, "train_time": 0.8318824768066406, "student_train_time": 0.008052587509155273, "throughput": 1565.192697117795, "inference_time": 0.05450867273066251, "env_time": 0.3828573360278824, "samples": 2000, "teacher_eval_reward": 32.0}
{"epoch": 114, "reward_mean": 28.757142857142856, "student_loss": null, "teacher_policy_loss": -15.356887817382812, "teacher_value_loss": 80.86351013183594, "teacher_entropy": 0.6422025561332703, "total_time": 1.2107343673706055, "rollout_time": 0.4270057678222656, "train_time": 0.7779154777526855, "student_train_time": 0.005392313003540039, "throughput": 1651.8900048600012, "inference_time": 0.05379616253230779, "env_time": 0.37320960528995784, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 115, "reward_mean": 27.694444444444443, "student_loss": null, "teacher_policy_loss": -14.60086727142334, "teacher_value_loss": 64.54412078857422, "teacher_entropy": 0.6364436149597168, "total_time": 1.2648494243621826, "rollout_time": 0.4286952018737793, "train_time": 0.825101375579834, "student_train_time": 0.010642290115356445, "throughput": 1581.2158834704985, "inference_time": 0.05399106002005283, "env_time": 0.37470414185372647, "samples": 2000, "teacher_eval_reward": 55.0}
{"epoch": 116, "reward_mean": 28.43661971830986, "student_loss": null, "teacher_policy_loss": -15.56081485748291, "teacher_value_loss": 80.93130493164062, "teacher_entropy": 0.6595726609230042, "total_time": 1.1760149002075195, "rollout_time": 0.42525267601013184, "train_time": 0.7405972480773926, "student_train_time": 0.009713411331176758, "throughput": 1700.658724347013, "inference_time": 0.05311545097720227, "env_time": 0.37213722503292956, "samples": 2000, "teacher_eval_reward": 24.0}
{"epoch": 117, "reward_mean": 30.723076923076924, "student_loss": null, "teacher_policy_loss": -16.711381912231445, "teacher_value_loss": 127.66100311279297, "teacher_entropy": 0.6300238966941833, "total_time": 1.2689714431762695, "rollout_time": 0.42914676666259766, "train_time": 0.8292875289916992, "student_train_time": 0.010125160217285156, "throughput": 1576.0795963965481, "inference_time": 0.05469548200562713, "env_time": 0.37445128465697053, "samples": 2000, "teacher_eval_reward": 22.0}
{"epoch": 118, "reward_mean": 30.153846153846153, "student_loss": null, "teacher_policy_loss": -15.290773391723633, "teacher_value_loss": 74.43474578857422, "teacher_entropy": 0.6282216310501099, "total_time": 1.2863366603851318, "rollout_time": 0.4645810127258301, "train_time": 0.8113918304443359, "student_train_time": 0.009988546371459961, "throughput": 1554.802923366264, "inference_time": 0.06018295896319614, "env_time": 0.40439805376263394, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 119, "reward_mean": 25.468354430379748, "student_loss": null, "teacher_policy_loss": -14.19706916809082, "teacher_value_loss": 65.6402587890625, "teacher_entropy": 0.6598668098449707, "total_time": 1.2246339321136475, "rollout_time": 0.4592931270599365, "train_time": 0.7599530220031738, "student_train_time": 0.004970550537109375, "throughput": 1633.1410942926557, "inference_time": 0.05825746625487227, "env_time": 0.40103566080506425, "samples": 2000, "teacher_eval_reward": 35.0}
{"epoch": 120, "reward_mean": 24.646341463414632, "student_loss": null, "teacher_policy_loss": -13.392912864685059, "teacher_value_loss": 50.498023986816406, "teacher_entropy": 0.6525153517723083, "total_time": 1.367424488067627, "rollout_time": 0.45723628997802734, "train_time": 0.9039855003356934, "student_train_time": 0.0057811737060546875, "throughput": 1462.6036153749856, "inference_time": 0.056709532775130356, "env_time": 0.400526757202897, "samples": 2000, "teacher_eval_reward": 28.0}
{"epoch": 121, "reward_mean": 28.897058823529413, "student_loss": null, "teacher_policy_loss": -15.317190170288086, "teacher_value_loss": 105.64364624023438, "teacher_entropy": 0.6279375553131104, "total_time": 1.4297165870666504, "rollout_time": 0.43815088272094727, "train_time": 0.9856283664703369, "student_train_time": 0.005507230758666992, "throughput": 1398.878643566275, "inference_time": 0.05415230172184238, "env_time": 0.3839985809991049, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 122, "reward_mean": 30.772727272727273, "student_loss": null, "teacher_policy_loss": -15.355828285217285, "teacher_value_loss": 83.59648895263672, "teacher_entropy": 0.6366986036300659, "total_time": 1.3009116649627686, "rollout_time": 0.45026636123657227, "train_time": 0.8441116809844971, "student_train_time": 0.006119489669799805, "throughput": 1537.3834010914484, "inference_time": 0.05588167275345768, "env_time": 0.3943846884831146, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 123, "reward_mean": 28.0, "student_loss": null, "teacher_policy_loss": -16.06024742126465, "teacher_value_loss": 117.6602783203125, "teacher_entropy": 0.6627646684646606, "total_time": 1.1895689964294434, "rollout_time": 0.4345064163208008, "train_time": 0.7417023181915283, "student_train_time": 0.012941598892211914, "throughput": 1681.2812085747946, "inference_time": 0.054794309467979474, "env_time": 0.3797121068528213, "samples": 2000, "teacher_eval_reward": 57.0}
{"epoch": 124, "reward_mean": 29.82089552238806, "student_loss": null, "teacher_policy_loss": -16.31290054321289, "teacher_value_loss": 114.99873352050781, "teacher_entropy": 0.6661102175712585, "total_time": 1.385545015335083, "rollout_time": 0.46697139739990234, "train_time": 0.9088602066040039, "student_train_time": 0.00934910774230957, "throughput": 1443.4752951828966, "inference_time": 0.05813612597194151, "env_time": 0.40883527142796083, "samples": 2000, "teacher_eval_reward": 39.0}
{"epoch": 125, "reward_mean": 28.591549295774648, "student_loss": null, "teacher_policy_loss": -14.763925552368164, "teacher_value_loss": 54.306480407714844, "teacher_entropy": 0.6530656218528748, "total_time": 1.243694543838501, "rollout_time": 0.458585262298584, "train_time": 0.7573912143707275, "student_train_time": 0.027181625366210938, "throughput": 1608.1119032871695, "inference_time": 0.05680153295361379, "env_time": 0.4017837293449702, "samples": 2000, "teacher_eval_reward": 29.0}
{"epoch": 126, "reward_mean": 27.31081081081081, "student_loss": null, "teacher_policy_loss": -15.106138229370117, "teacher_value_loss": 70.11127471923828, "teacher_entropy": 0.651928722858429, "total_time": 1.4187114238739014, "rollout_time": 0.4450995922088623, "train_time": 0.956221342086792, "student_train_time": 0.0168306827545166, "throughput": 1409.729960825187, "inference_time": 0.05907770703015558, "env_time": 0.3860218851787067, "samples": 2000, "teacher_eval_reward": 48.0}
{"epoch": 127, "reward_mean": 28.91176470588235, "student_loss": null, "teacher_policy_loss": -16.034509658813477, "teacher_value_loss": 71.36134338378906, "teacher_entropy": 0.6553727984428406, "total_time": 1.2161130905151367, "rollout_time": 0.4391458034515381, "train_time": 0.7650103569030762, "student_train_time": 0.01159811019897461, "throughput": 1644.5838924016634, "inference_time": 0.05607931547820044, "env_time": 0.38306648797333764, "samples": 2000, "teacher_eval_reward": 310.0}
{"epoch": 128, "reward_mean": 27.971830985915492, "student_loss": null, "teacher_policy_loss": -15.859504699707031, "teacher_value_loss": 82.0250473022461, "teacher_entropy": 0.6527494192123413, "total_time": 1.5142078399658203, "rollout_time": 0.46967387199401855, "train_time": 0.7888479232788086, "student_train_time": 0.25527024269104004, "throughput": 1320.822642184408, "inference_time": 0.06205463771948416, "env_time": 0.4076192342745344, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 129, "reward_mean": 33.152542372881356, "student_loss": null, "teacher_policy_loss": -18.994047164916992, "teacher_value_loss": 134.00128173828125, "teacher_entropy": 0.6412791609764099, "total_time": -1.3353891372680664, "rollout_time": 0.4649696350097656, "train_time": -1.81076979637146, "student_train_time": 0.010046243667602539, "throughput": 200000000000.0, "inference_time": 0.05515617250784999, "env_time": 0.40981346250191564, "samples": 2000, "teacher_eval_reward": 60.0}
{"epoch": 130, "reward_mean": 29.154929577464788, "student_loss": null, "teacher_policy_loss": -16.128719329833984, "teacher_value_loss": 110.53520202636719, "teacher_entropy": 0.6251301765441895, "total_time": 1.2302985191345215, "rollout_time": 0.43538880348205566, "train_time": 0.774409294128418, "student_train_time": 0.02013874053955078, "throughput": 1625.6217242356274, "inference_time": 0.05517610621427593, "env_time": 0.38021269726777973, "samples": 2000, "teacher_eval_reward": 255.0}
{"epoch": 131, "reward_mean": 28.880597014925375, "student_loss": null, "teacher_policy_loss": -16.47062873840332, "teacher_value_loss": 89.20650482177734, "teacher_entropy": 0.6298284530639648, "total_time": 1.2536735534667969, "rollout_time": 0.4408833980560303, "train_time": 0.800652027130127, "student_train_time": 0.011720418930053711, "throughput": 1595.3116299449555, "inference_time": 0.05589351252638153, "env_time": 0.38498988552964875, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 132, "reward_mean": 26.714285714285715, "student_loss": null, "teacher_policy_loss": -14.574158668518066, "teacher_value_loss": 76.49454498291016, "teacher_entropy": 0.5994873642921448, "total_time": 1.3593571186065674, "rollout_time": 0.46219420433044434, "train_time": 0.8844742774963379, "student_train_time": 0.011349201202392578, "throughput": 1471.2837212712247, "inference_time": 0.05632599733871757, "env_time": 0.40586820699172677, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 133, "reward_mean": 30.076923076923077, "student_loss": null, "teacher_policy_loss": -17.25714111328125, "teacher_value_loss": 106.8560562133789, "teacher_entropy": 0.6113840937614441, "total_time": 1.256822109222412, "rollout_time": 0.4591643810272217, "train_time": 0.787161111831665, "student_train_time": 0.010114192962646484, "throughput": 1591.3150996662425, "inference_time": 0.058662201028710115, "env_time": 0.40050217999851156, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 134, "reward_mean": 34.779661016949156, "student_loss": null, "teacher_policy_loss": -18.277536392211914, "teacher_value_loss": 91.0551986694336, "teacher_entropy": 0.6281377673149109, "total_time": 1.2323024272918701, "rollout_time": 0.4324021339416504, "train_time": 0.789867639541626, "student_train_time": 0.009672880172729492, "throughput": 1622.9782200423283, "inference_time": 0.0543360062638385, "env_time": 0.3780661276778119, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 135, "reward_mean": 27.283783783783782, "student_loss": null, "teacher_policy_loss": -14.34036922454834, "teacher_value_loss": 66.62276458740234, "teacher_entropy": 0.60301274061203, "total_time": 1.2138042449951172, "rollout_time": 0.4462094306945801, "train_time": 0.7613580226898193, "student_train_time": 0.005806922912597656, "throughput": 1647.7121481874908, "inference_time": 0.05577507719681307, "env_time": 0.390434353497767, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 136, "reward_mean": 29.13235294117647, "student_loss": null, "teacher_policy_loss": -15.259016036987305, "teacher_value_loss": 64.03434753417969, "teacher_entropy": 0.6046909093856812, "total_time": 1.2772657871246338, "rollout_time": 0.43155574798583984, "train_time": 0.8326988220214844, "student_train_time": 0.012660503387451172, "throughput": 1565.844807056468, "inference_time": 0.05565382195527491, "env_time": 0.37590192603056494, "samples": 2000, "teacher_eval_reward": 116.0}
{"epoch": 137, "reward_mean": 33.81666666666667, "student_loss": null, "teacher_policy_loss": -18.273208618164062, "teacher_value_loss": 116.79199981689453, "teacher_entropy": 0.6197170615196228, "total_time": 1.4396791458129883, "rollout_time": 0.4423835277557373, "train_time": 0.9862377643585205, "student_train_time": 0.010699272155761719, "throughput": 1389.1984237019687, "inference_time": 0.05628746623369807, "env_time": 0.38609606152203924, "samples": 2000, "teacher_eval_reward": 254.0}
{"epoch": 138, "reward_mean": 30.323076923076922, "student_loss": null, "teacher_policy_loss": -16.126192092895508, "teacher_value_loss": 72.71375274658203, "teacher_entropy": 0.6187176704406738, "total_time": 1.2082607746124268, "rollout_time": 0.4505789279937744, "train_time": 0.7438759803771973, "student_train_time": 0.013448476791381836, "throughput": 1655.2718105423385, "inference_time": 0.057650051719974726, "env_time": 0.3929288762737997, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 139, "reward_mean": 27.383561643835616, "student_loss": null, "teacher_policy_loss": -15.324193954467773, "teacher_value_loss": 83.11217498779297, "teacher_entropy": 0.6115321516990662, "total_time": 1.7193145751953125, "rollout_time": 0.430649995803833, "train_time": 1.2816600799560547, "student_train_time": 0.0066356658935546875, "throughput": 1163.2542577455913, "inference_time": 0.05455698173136625, "env_time": 0.37609301407246676, "samples": 2000, "teacher_eval_reward": 215.0}
{"epoch": 140, "reward_mean": 30.134328358208954, "student_loss": null, "teacher_policy_loss": -15.519920349121094, "teacher_value_loss": 62.55408477783203, "teacher_entropy": 0.6229285001754761, "total_time": 1.197803258895874, "rollout_time": 0.4300055503845215, "train_time": 0.7588942050933838, "student_train_time": 0.008556842803955078, "throughput": 1669.7232914891088, "inference_time": 0.0537697852760175, "env_time": 0.376235765108504, "samples": 2000, "teacher_eval_reward": 271.0}
{"epoch": 141, "reward_mean": 32.274193548387096, "student_loss": null, "teacher_policy_loss": -17.07660484313965, "teacher_value_loss": 80.09432983398438, "teacher_entropy": 0.6279463171958923, "total_time": 1.2493023872375488, "rollout_time": 0.4349057674407959, "train_time": 0.800194501876831, "student_train_time": 0.013843297958374023, "throughput": 1600.8934429577052, "inference_time": 0.05416783022337768, "env_time": 0.3807379372174182, "samples": 2000, "teacher_eval_reward": 93.0}
{"epoch": 142, "reward_mean": 31.951612903225808, "student_loss": null, "teacher_policy_loss": -17.61132049560547, "teacher_value_loss": 96.40299987792969, "teacher_entropy": 0.6272650957107544, "total_time": 2.366318702697754, "rollout_time": 0.4816124439239502, "train_time": 1.296057939529419, "student_train_time": 0.588273286819458, "throughput": 845.1946889993612, "inference_time": 0.05703066425121506, "env_time": 0.42458177967273514, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 143, "reward_mean": 29.159420289855074, "student_loss": null, "teacher_policy_loss": -15.348531723022461, "teacher_value_loss": 73.8108139038086, "teacher_entropy": 0.6363266706466675, "total_time": 1.4015140533447266, "rollout_time": 0.4443657398223877, "train_time": 0.9499087333679199, "student_train_time": 0.006883144378662109, "throughput": 1427.0281451883989, "inference_time": 0.05795981776645931, "env_time": 0.3864059220559284, "samples": 2000, "teacher_eval_reward": 170.0}
{"epoch": 144, "reward_mean": 28.614285714285714, "student_loss": null, "teacher_policy_loss": -15.960561752319336, "teacher_value_loss": 104.99565887451172, "teacher_entropy": 0.637731671333313, "total_time": 1.226863145828247, "rollout_time": 0.4337775707244873, "train_time": 0.7816324234008789, "student_train_time": 0.010984182357788086, "throughput": 1630.173672426857, "inference_time": 0.05471300651151978, "env_time": 0.3790645642129675, "samples": 2000, "teacher_eval_reward": 82.0}
{"epoch": 145, "reward_mean": 33.793103448275865, "student_loss": null, "teacher_policy_loss": -18.520891189575195, "teacher_value_loss": 116.47241973876953, "teacher_entropy": 0.6481738090515137, "total_time": -1.3879368305206299, "rollout_time": -2.2186381816864014, "train_time": 0.8197672367095947, "student_train_time": 0.010563850402832031, "throughput": 200000000000.0, "inference_time": 0.05800550025560369, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 178.0}
{"epoch": 146, "reward_mean": 30.62121212121212, "student_loss": null, "teacher_policy_loss": -17.004486083984375, "teacher_value_loss": 88.85028839111328, "teacher_entropy": 0.6475391983985901, "total_time": 1.3502044677734375, "rollout_time": 0.44601893424987793, "train_time": 0.8947858810424805, "student_train_time": 0.008931875228881836, "throughput": 1481.2571338162668, "inference_time": 0.05381134901290352, "env_time": 0.3922075852369744, "samples": 2000, "teacher_eval_reward": 306.0}
{"epoch": 147, "reward_mean": 27.704225352112676, "student_loss": null, "teacher_policy_loss": -14.264077186584473, "teacher_value_loss": 51.64186096191406, "teacher_entropy": 0.641421377658844, "total_time": 1.2602379322052002, "rollout_time": 0.44651269912719727, "train_time": 0.8067395687103271, "student_train_time": 0.0065534114837646484, "throughput": 1587.0019056642288, "inference_time": 0.05567213068934507, "env_time": 0.3908405684378522, "samples": 2000, "teacher_eval_reward": 299.0}
{"epoch": 148, "reward_mean": 32.983333333333334, "student_loss": null, "teacher_policy_loss": -18.682302474975586, "teacher_value_loss": 136.39178466796875, "teacher_entropy": 0.6463073492050171, "total_time": 1.4507465362548828, "rollout_time": 0.44519948959350586, "train_time": 0.9893224239349365, "student_train_time": 0.015872478485107422, "throughput": 1378.600568754774, "inference_time": 0.05496372473862721, "env_time": 0.39023576485487865, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 149, "reward_mean": 31.584615384615386, "student_loss": null, "teacher_policy_loss": -15.841699600219727, "teacher_value_loss": 71.43008422851562, "teacher_entropy": 0.6393365859985352, "total_time": 1.2904245853424072, "rollout_time": 0.4469795227050781, "train_time": 0.8241791725158691, "student_train_time": 0.018875837326049805, "throughput": 1549.8774765433586, "inference_time": 0.0548241282303934, "env_time": 0.3921553944746847, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 150, "reward_mean": 32.285714285714285, "student_loss": null, "teacher_policy_loss": -17.146472930908203, "teacher_value_loss": 105.11396026611328, "teacher_entropy": 0.6399074196815491, "total_time": 1.242222547531128, "rollout_time": 0.4311060905456543, "train_time": 0.8058416843414307, "student_train_time": 0.004925727844238281, "throughput": 1610.0174674617904, "inference_time": 0.05445730201427068, "env_time": 0.3766487885313836, "samples": 2000, "teacher_eval_reward": 107.0}
{"epoch": 151, "reward_mean": 30.296875, "student_loss": null, "teacher_policy_loss": -16.30953598022461, "teacher_value_loss": 77.10132598876953, "teacher_entropy": 0.6431154608726501, "total_time": 1.3004815578460693, "rollout_time": 0.4544203281402588, "train_time": 0.832979679107666, "student_train_time": 0.012678861618041992, "throughput": 1537.8918585454703, "inference_time": 0.05378978128101153, "env_time": 0.40063054685924726, "samples": 2000, "teacher_eval_reward": 203.0}
{"epoch": 152, "reward_mean": 32.903225806451616, "student_loss": null, "teacher_policy_loss": -18.538053512573242, "teacher_value_loss": 129.60595703125, "teacher_entropy": 0.6391391158103943, "total_time": 1.3444936275482178, "rollout_time": 0.4486086368560791, "train_time": 0.880976676940918, "student_train_time": 0.014548540115356445, "throughput": 1487.548887566798, "inference_time": 0.05594215271048597, "env_time": 0.39266648414559313, "samples": 2000, "teacher_eval_reward": 308.0}
{"epoch": 153, "reward_mean": 30.93548387096774, "student_loss": null, "teacher_policy_loss": -17.478357315063477, "teacher_value_loss": 106.54361724853516, "teacher_entropy": 0.6317488551139832, "total_time": 1.4242100715637207, "rollout_time": 0.4704437255859375, "train_time": 0.944709062576294, "student_train_time": 0.008640050888061523, "throughput": 1404.2872185309623, "inference_time": 0.06081719698704546, "env_time": 0.40962652859889204, "samples": 2000, "teacher_eval_reward": 155.0}
{"epoch": 154, "reward_mean": 28.135135135135137, "student_loss": null, "teacher_policy_loss": -15.650397300720215, "teacher_value_loss": 97.06831359863281, "teacher_entropy": 0.6246379613876343, "total_time": 1.2488055229187012, "rollout_time": 0.44420814514160156, "train_time": 0.7933931350708008, "student_train_time": 0.010841608047485352, "throughput": 1601.5303930796297, "inference_time": 0.056431804467138136, "env_time": 0.3877763406744634, "samples": 2000, "teacher_eval_reward": 265.0}
{"epoch": 155, "reward_mean": 31.58730158730159, "student_loss": null, "teacher_policy_loss": -19.290760040283203, "teacher_value_loss": 173.3761444091797, "teacher_entropy": 0.6234369874000549, "total_time": 1.226278305053711, "rollout_time": 0.440016508102417, "train_time": 0.7735440731048584, "student_train_time": 0.011616945266723633, "throughput": 1630.9511403387341, "inference_time": 0.056280852577401674, "env_time": 0.3837356555250153, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 156, "reward_mean": 33.71186440677966, "student_loss": null, "teacher_policy_loss": -17.235692977905273, "teacher_value_loss": 82.7240982055664, "teacher_entropy": 0.6229187846183777, "total_time": 1.4015769958496094, "rollout_time": 0.44251251220703125, "train_time": 0.9217395782470703, "student_train_time": 0.03685903549194336, "throughput": 1426.964059714492, "inference_time": 0.05769978047464974, "env_time": 0.3848127317323815, "samples": 2000, "teacher_eval_reward": 326.0}
{"epoch": 157, "reward_mean": 31.90625, "student_loss": null, "teacher_policy_loss": -17.457923889160156, "teacher_value_loss": 102.98397827148438, "teacher_entropy": 0.6147344708442688, "total_time": 1.4063785076141357, "rollout_time": 0.4753286838531494, "train_time": 0.9218945503234863, "student_train_time": 0.008787870407104492, "throughput": 1422.092266891165, "inference_time": 0.05842785826098407, "env_time": 0.41690082559216535, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 158, "reward_mean": 34.89090909090909, "student_loss": null, "teacher_policy_loss": -19.204666137695312, "teacher_value_loss": 116.1128158569336, "teacher_entropy": 0.6260615587234497, "total_time": 1.2360572814941406, "rollout_time": 0.43140244483947754, "train_time": 0.796173095703125, "student_train_time": 0.008127689361572266, "throughput": 1618.0479901242188, "inference_time": 0.05493350128199381, "env_time": 0.3764689435574837, "samples": 2000, "teacher_eval_reward": 168.0}
{"epoch": 159, "reward_mean": 29.085714285714285, "student_loss": null, "teacher_policy_loss": -15.043645858764648, "teacher_value_loss": 75.31643676757812, "teacher_entropy": 0.6154131293296814, "total_time": 1.2711262702941895, "rollout_time": 0.4340221881866455, "train_time": 0.8262436389923096, "student_train_time": 0.010429620742797852, "throughput": 1573.4078090740113, "inference_time": 0.056040408488115645, "env_time": 0.37798177969852986, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 160, "reward_mean": 31.714285714285715, "student_loss": null, "teacher_policy_loss": -17.636310577392578, "teacher_value_loss": 119.12986755371094, "teacher_entropy": 0.6213549375534058, "total_time": 1.3746774196624756, "rollout_time": 0.5609376430511475, "train_time": 0.8027400970458984, "student_train_time": 0.010640859603881836, "throughput": 1454.886776630884, "inference_time": 0.06136250625604589, "env_time": 0.49957513679510157, "samples": 2000, "teacher_eval_reward": 155.0}
{"epoch": 161, "reward_mean": 31.390625, "student_loss": null, "teacher_policy_loss": -17.491514205932617, "teacher_value_loss": 119.36139678955078, "teacher_entropy": 0.6259494423866272, "total_time": 1.1808857917785645, "rollout_time": 0.433457612991333, "train_time": 0.7346646785736084, "student_train_time": 0.012401103973388672, "throughput": 1693.643884890634, "inference_time": 0.05544560972157342, "env_time": 0.3780120032697596, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 162, "reward_mean": 35.55555555555556, "student_loss": null, "teacher_policy_loss": -20.758831024169922, "teacher_value_loss": 212.9522247314453, "teacher_entropy": 0.6283817291259766, "total_time": 1.3618199825286865, "rollout_time": 0.44783782958984375, "train_time": 0.8952980041503906, "student_train_time": 0.018326759338378906, "throughput": 1468.6228911741425, "inference_time": 0.052038084766536485, "env_time": 0.39579974482330726, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 163, "reward_mean": 34.68333333333333, "student_loss": null, "teacher_policy_loss": -18.510478973388672, "teacher_value_loss": 122.68997955322266, "teacher_entropy": 0.625654399394989, "total_time": 1.282350778579712, "rollout_time": 0.4484074115753174, "train_time": 0.8252413272857666, "student_train_time": 0.00829458236694336, "throughput": 1559.635657737216, "inference_time": 0.0547415882574569, "env_time": 0.3936658233178605, "samples": 2000, "teacher_eval_reward": 102.0}
{"epoch": 164, "reward_mean": 32.56666666666667, "student_loss": null, "teacher_policy_loss": -18.31554412841797, "teacher_value_loss": 128.9853057861328, "teacher_entropy": 0.625428318977356, "total_time": 1.376025676727295, "rollout_time": 0.4528317451477051, "train_time": 0.9003362655639648, "student_train_time": 0.02246379852294922, "throughput": 1453.4612499068694, "inference_time": 0.059607788985886145, "env_time": 0.39322395616181893, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 165, "reward_mean": 29.7, "student_loss": null, "teacher_policy_loss": -14.699462890625, "teacher_value_loss": 78.88774108886719, "teacher_entropy": 0.6188157200813293, "total_time": 1.2347595691680908, "rollout_time": 0.45111083984375, "train_time": 0.775876522064209, "student_train_time": 0.0074083805084228516, "throughput": 1619.7485323782375, "inference_time": 0.056581183736852836, "env_time": 0.39452965610689716, "samples": 2000, "teacher_eval_reward": 26.0}
{"epoch": 166, "reward_mean": 31.129032258064516, "student_loss": null, "teacher_policy_loss": -16.74207878112793, "teacher_value_loss": 101.17109680175781, "teacher_entropy": 0.5939047336578369, "total_time": 1.4455134868621826, "rollout_time": 0.4460330009460449, "train_time": 0.9867069721221924, "student_train_time": 0.012408256530761719, "throughput": 1383.5913799334085, "inference_time": 0.05842787700930785, "env_time": 0.3876051239367371, "samples": 2000, "teacher_eval_reward": 28.0}
{"epoch": 167, "reward_mean": 34.09836065573771, "student_loss": null, "teacher_policy_loss": -17.781993865966797, "teacher_value_loss": 136.9827117919922, "teacher_entropy": 0.5970897078514099, "total_time": 1.2325596809387207, "rollout_time": 0.4494633674621582, "train_time": 0.7677156925201416, "student_train_time": 0.015000104904174805, "throughput": 1622.6394802049624, "inference_time": 0.05742934080444684, "env_time": 0.39203402665771137, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 168, "reward_mean": 31.317460317460316, "student_loss": null, "teacher_policy_loss": -17.692171096801758, "teacher_value_loss": 106.44790649414062, "teacher_entropy": 0.6345295310020447, "total_time": 1.3601861000061035, "rollout_time": 0.46777939796447754, "train_time": 0.8848516941070557, "student_train_time": 0.007088422775268555, "throughput": 1470.3870301211175, "inference_time": 0.05800505396473454, "env_time": 0.409774343999743, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 169, "reward_mean": 31.793650793650794, "student_loss": null, "teacher_policy_loss": -16.666545867919922, "teacher_value_loss": 83.4458999633789, "teacher_entropy": 0.6438679099082947, "total_time": 1.2635514736175537, "rollout_time": 0.44138574600219727, "train_time": 0.8165748119354248, "student_train_time": 0.005230903625488281, "throughput": 1582.8401468077836, "inference_time": 0.05645695232306025, "env_time": 0.384928793679137, "samples": 2000, "teacher_eval_reward": 78.0}
{"epoch": 170, "reward_mean": 30.53846153846154, "student_loss": null, "teacher_policy_loss": -15.954730033874512, "teacher_value_loss": 81.13226318359375, "teacher_entropy": 0.6396287679672241, "total_time": 1.408543348312378, "rollout_time": 0.4727742671966553, "train_time": 0.9240896701812744, "student_train_time": 0.011304140090942383, "throughput": 1419.9066023749044, "inference_time": 0.057637401989268255, "env_time": 0.415136865207387, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 171, "reward_mean": 34.3728813559322, "student_loss": null, "teacher_policy_loss": -18.919300079345703, "teacher_value_loss": 134.20947265625, "teacher_entropy": 0.6503898501396179, "total_time": 1.2037568092346191, "rollout_time": 0.44058942794799805, "train_time": 0.7557215690612793, "student_train_time": 0.0070896148681640625, "throughput": 1661.4651602857007, "inference_time": 0.05685568052831513, "env_time": 0.3837337474196829, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 172, "reward_mean": 33.60344827586207, "student_loss": null, "teacher_policy_loss": -18.021015167236328, "teacher_value_loss": 117.64344024658203, "teacher_entropy": 0.6433364152908325, "total_time": 1.4641244411468506, "rollout_time": 0.4580209255218506, "train_time": 0.9981584548950195, "student_train_time": 0.00731658935546875, "throughput": 1366.0041071600426, "inference_time": 0.05981814426377241, "env_time": 0.3982027812580782, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 173, "reward_mean": 31.634920634920636, "student_loss": null, "teacher_policy_loss": -16.113582611083984, "teacher_value_loss": 69.96302795410156, "teacher_entropy": 0.6369774341583252, "total_time": 1.2694041728973389, "rollout_time": 0.46236419677734375, "train_time": 0.7727644443511963, "student_train_time": 0.03386044502258301, "throughput": 1575.5423234785183, "inference_time": 0.0574719662527059, "env_time": 0.40489223052463785, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 174, "reward_mean": 38.075471698113205, "student_loss": null, "teacher_policy_loss": -18.438383102416992, "teacher_value_loss": 94.00567626953125, "teacher_entropy": 0.6457020044326782, "total_time": 1.303455114364624, "rollout_time": 0.4666624069213867, "train_time": 0.8285112380981445, "student_train_time": 0.007880210876464844, "throughput": 1534.383484294287, "inference_time": 0.05911740750161698, "env_time": 0.40754499941976974, "samples": 2000, "teacher_eval_reward": 71.0}
{"epoch": 175, "reward_mean": 36.72222222222222, "student_loss": null, "teacher_policy_loss": -19.361143112182617, "teacher_value_loss": 125.76555633544922, "teacher_entropy": 0.6416300535202026, "total_time": 1.4487416744232178, "rollout_time": 0.4443199634552002, "train_time": 0.9971585273742676, "student_train_time": 0.006907463073730469, "throughput": 1380.508364816835, "inference_time": 0.05867285269596323, "env_time": 0.38564711075923697, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 176, "reward_mean": 32.983050847457626, "student_loss": null, "teacher_policy_loss": -17.83043098449707, "teacher_value_loss": 101.03691864013672, "teacher_entropy": 0.6196330785751343, "total_time": 1.2550995349884033, "rollout_time": 0.4425926208496094, "train_time": 0.8009810447692871, "student_train_time": 0.011127471923828125, "throughput": 1593.4991164015364, "inference_time": 0.05552027922385605, "env_time": 0.3870723416257533, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 177, "reward_mean": 33.57377049180328, "student_loss": null, "teacher_policy_loss": -16.44941520690918, "teacher_value_loss": 103.0684814453125, "teacher_entropy": 0.627960205078125, "total_time": -1.1641674041748047, "rollout_time": 0.43921971321105957, "train_time": -1.6106717586517334, "student_train_time": 0.006917476654052734, "throughput": 200000000000.0, "inference_time": 0.05496003804182692, "env_time": 0.38425967516923265, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 178, "reward_mean": 31.12121212121212, "student_loss": null, "teacher_policy_loss": -15.85122299194336, "teacher_value_loss": 88.90239715576172, "teacher_entropy": 0.6310135722160339, "total_time": 1.2956974506378174, "rollout_time": 0.5099735260009766, "train_time": 0.7737884521484375, "student_train_time": 0.01150369644165039, "throughput": 1543.5702208223718, "inference_time": 0.06719819977661246, "env_time": 0.4427753262243641, "samples": 2000, "teacher_eval_reward": 358.0}
{"epoch": 179, "reward_mean": 33.706896551724135, "student_loss": null, "teacher_policy_loss": -19.039321899414062, "teacher_value_loss": 128.57711791992188, "teacher_entropy": 0.6391003131866455, "total_time": 1.2507269382476807, "rollout_time": 0.43421077728271484, "train_time": 0.8058812618255615, "student_train_time": 0.010219573974609375, "throughput": 1599.0700598502192, "inference_time": 0.05509227175207343, "env_time": 0.3791185055306414, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 180, "reward_mean": 32.459016393442624, "student_loss": null, "teacher_policy_loss": -18.377893447875977, "teacher_value_loss": 125.45980834960938, "teacher_entropy": 0.631190299987793, "total_time": 1.1985983848571777, "rollout_time": 0.4294295310974121, "train_time": 0.7588386535644531, "student_train_time": 0.009975671768188477, "throughput": 1668.615630779709, "inference_time": 0.055979114229558036, "env_time": 0.3734504168678541, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 181, "reward_mean": 29.197183098591548, "student_loss": null, "teacher_policy_loss": -16.18105125427246, "teacher_value_loss": 103.8347396850586, "teacher_entropy": 0.6249799728393555, "total_time": 1.2746217250823975, "rollout_time": 0.4508509635925293, "train_time": 0.8161625862121582, "student_train_time": 0.007218122482299805, "throughput": 1569.092979229356, "inference_time": 0.05355036227228993, "env_time": 0.39730060132023937, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 182, "reward_mean": 33.96551724137931, "student_loss": null, "teacher_policy_loss": -17.558984756469727, "teacher_value_loss": 89.37549591064453, "teacher_entropy": 0.6241089105606079, "total_time": 1.2447395324707031, "rollout_time": 0.4341607093811035, "train_time": 0.7920198440551758, "student_train_time": 0.018164873123168945, "throughput": 1606.7618548518085, "inference_time": 0.054740036503062584, "env_time": 0.37942067287804093, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 183, "reward_mean": 28.82857142857143, "student_loss": null, "teacher_policy_loss": -16.27540397644043, "teacher_value_loss": 117.23029327392578, "teacher_entropy": 0.6133527755737305, "total_time": 1.2214012145996094, "rollout_time": 0.44414258003234863, "train_time": 0.7663905620574951, "student_train_time": 0.010505437850952148, "throughput": 1637.4635755177508, "inference_time": 0.055336165700282436, "env_time": 0.3888064143320662, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 184, "reward_mean": 33.59322033898305, "student_loss": null, "teacher_policy_loss": -17.47651481628418, "teacher_value_loss": 100.6420669555664, "teacher_entropy": 0.6147259473800659, "total_time": 1.3140921592712402, "rollout_time": 0.4292416572570801, "train_time": 0.8755121231079102, "student_train_time": 0.008945465087890625, "throughput": 1521.9632701477692, "inference_time": 0.05497206127438403, "env_time": 0.37426959598269605, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 185, "reward_mean": 38.68, "student_loss": null, "teacher_policy_loss": -20.803165435791016, "teacher_value_loss": 134.10104370117188, "teacher_entropy": 0.6144441366195679, "total_time": 1.2711081504821777, "rollout_time": 0.44922566413879395, "train_time": 0.8126118183135986, "student_train_time": 0.008855342864990234, "throughput": 1573.4302382069748, "inference_time": 0.05792037978062581, "env_time": 0.39130528435816814, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 186, "reward_mean": 36.10526315789474, "student_loss": null, "teacher_policy_loss": -18.542325973510742, "teacher_value_loss": 99.90678405761719, "teacher_entropy": 0.6043338179588318, "total_time": 1.2960081100463867, "rollout_time": 0.4414830207824707, "train_time": 0.835329532623291, "student_train_time": 0.018788576126098633, "throughput": 1543.2002195791938, "inference_time": 0.053217143313304405, "env_time": 0.3882658774691663, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 187, "reward_mean": 32.88709677419355, "student_loss": null, "teacher_policy_loss": -17.603679656982422, "teacher_value_loss": 105.56539154052734, "teacher_entropy": 0.5975726246833801, "total_time": 1.2943401336669922, "rollout_time": 0.44647789001464844, "train_time": 0.8419225215911865, "student_train_time": 0.005484819412231445, "throughput": 1545.1888943084878, "inference_time": 0.05682466701546218, "env_time": 0.38965322299918626, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 188, "reward_mean": 34.85964912280702, "student_loss": null, "teacher_policy_loss": -18.379886627197266, "teacher_value_loss": 97.6528091430664, "teacher_entropy": 0.6063166856765747, "total_time": 1.2354507446289062, "rollout_time": 0.43729162216186523, "train_time": 0.7902669906616211, "student_train_time": 0.0075342655181884766, "throughput": 1618.8423607294376, "inference_time": 0.05438864445386571, "env_time": 0.3829029777079995, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 189, "reward_mean": 34.310344827586206, "student_loss": null, "teacher_policy_loss": -18.855987548828125, "teacher_value_loss": 113.8930435180664, "teacher_entropy": 0.6089596152305603, "total_time": 1.286090612411499, "rollout_time": 0.44039392471313477, "train_time": 0.8258028030395508, "student_train_time": 0.01952815055847168, "throughput": 1555.1003799412524, "inference_time": 0.053484390569792595, "env_time": 0.38690953414334217, "samples": 2000, "teacher_eval_reward": 78.0}
{"epoch": 190, "reward_mean": 32.28813559322034, "student_loss": null, "teacher_policy_loss": -20.13081169128418, "teacher_value_loss": 254.32281494140625, "teacher_entropy": 0.5926069617271423, "total_time": 1.3653349876403809, "rollout_time": 0.4447784423828125, "train_time": 0.9001865386962891, "student_train_time": 0.019956111907958984, "throughput": 1464.84197512324, "inference_time": 0.05542342426815594, "env_time": 0.38935501811465656, "samples": 2000, "teacher_eval_reward": 235.0}
{"epoch": 191, "reward_mean": 40.40384615384615, "student_loss": null, "teacher_policy_loss": -19.332416534423828, "teacher_value_loss": 106.03932189941406, "teacher_entropy": 0.6027944087982178, "total_time": 1.3446896076202393, "rollout_time": 0.4655752182006836, "train_time": 0.8672034740447998, "student_train_time": 0.011502504348754883, "throughput": 1487.3320866512047, "inference_time": 0.06106371428359125, "env_time": 0.40451150391709234, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 192, "reward_mean": 31.265625, "student_loss": null, "teacher_policy_loss": -15.825539588928223, "teacher_value_loss": 79.7440414428711, "teacher_entropy": 0.6045427322387695, "total_time": 1.3759856224060059, "rollout_time": 0.4600710868835449, "train_time": 0.9010298252105713, "student_train_time": 0.014525651931762695, "throughput": 1453.5035595087556, "inference_time": 0.05846000322890177, "env_time": 0.40161108365464315, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 193, "reward_mean": 33.26315789473684, "student_loss": null, "teacher_policy_loss": -19.02615737915039, "teacher_value_loss": 150.06373596191406, "teacher_entropy": 0.6147647500038147, "total_time": -1.3870928287506104, "rollout_time": -2.1716809272766113, "train_time": 0.7751560211181641, "student_train_time": 0.009065866470336914, "throughput": 200000000000.0, "inference_time": 0.056488632970285835, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 194, "reward_mean": 32.06060606060606, "student_loss": null, "teacher_policy_loss": -15.366827964782715, "teacher_value_loss": 86.25444793701172, "teacher_entropy": 0.5946457982063293, "total_time": 1.2922182083129883, "rollout_time": 0.4632077217102051, "train_time": 0.8195540904998779, "student_train_time": 0.009031534194946289, "throughput": 1547.7262177036123, "inference_time": 0.05593082175255404, "env_time": 0.40727689995765104, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 195, "reward_mean": 30.59375, "student_loss": null, "teacher_policy_loss": -15.99569034576416, "teacher_value_loss": 75.65715789794922, "teacher_entropy": 0.6076974868774414, "total_time": 1.2593209743499756, "rollout_time": 0.4413118362426758, "train_time": 0.8058516979217529, "student_train_time": 0.011760711669921875, "throughput": 1588.1574600409886, "inference_time": 0.05536760007998964, "env_time": 0.38594423616268614, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 196, "reward_mean": 37.509433962264154, "student_loss": null, "teacher_policy_loss": -19.763608932495117, "teacher_value_loss": 112.14429473876953, "teacher_entropy": 0.625124990940094, "total_time": 1.2592048645019531, "rollout_time": 0.45395946502685547, "train_time": 0.7929980754852295, "student_train_time": 0.011871099472045898, "throughput": 1588.303902233613, "inference_time": 0.05717128376090841, "env_time": 0.39678818126594706, "samples": 2000, "teacher_eval_reward": 295.0}
{"epoch": 197, "reward_mean": 35.6140350877193, "student_loss": null, "teacher_policy_loss": -18.686847686767578, "teacher_value_loss": 100.62973022460938, "teacher_entropy": 0.6270632147789001, "total_time": 1.2120964527130127, "rollout_time": 0.4382498264312744, "train_time": 0.7655384540557861, "student_train_time": 0.007950305938720703, "throughput": 1650.0337044328755, "inference_time": 0.054595217985479394, "env_time": 0.383654608445795, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 198, "reward_mean": 33.53333333333333, "student_loss": null, "teacher_policy_loss": -17.092113494873047, "teacher_value_loss": 82.02791595458984, "teacher_entropy": 0.6209691166877747, "total_time": 1.3127219676971436, "rollout_time": 0.4296681880950928, "train_time": 0.8590087890625, "student_train_time": 0.02365565299987793, "throughput": 1523.551863391546, "inference_time": 0.05648288575139304, "env_time": 0.37318530234369973, "samples": 2000, "teacher_eval_reward": 195.0}
{"epoch": 199, "reward_mean": 33.78947368421053, "student_loss": null, "teacher_policy_loss": -18.220684051513672, "teacher_value_loss": 118.18120574951172, "teacher_entropy": 0.621117115020752, "total_time": 1.2093636989593506, "rollout_time": 0.43174290657043457, "train_time": 0.7713513374328613, "student_train_time": 0.005922079086303711, "throughput": 1653.7622236561149, "inference_time": 0.05630905076941417, "env_time": 0.3754338558010204, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 200, "reward_mean": 38.9811320754717, "student_loss": null, "teacher_policy_loss": -19.56875228881836, "teacher_value_loss": 124.62953186035156, "teacher_entropy": 0.6263775825500488, "total_time": 1.270249366760254, "rollout_time": 0.4557945728302002, "train_time": 0.8029601573944092, "student_train_time": 0.011001825332641602, "throughput": 1574.4939949082288, "inference_time": 0.05643003601471719, "env_time": 0.399364536815483, "samples": 2000, "teacher_eval_reward": 175.0}
{"epoch": 201, "reward_mean": 37.333333333333336, "student_loss": null, "teacher_policy_loss": -17.8439998626709, "teacher_value_loss": 82.36383056640625, "teacher_entropy": 0.6255549192428589, "total_time": 1.4511606693267822, "rollout_time": 0.533534049987793, "train_time": 0.9059832096099854, "student_train_time": 0.011255741119384766, "throughput": 1378.2071429263815, "inference_time": 0.0644184014545317, "env_time": 0.46911564853326126, "samples": 2000, "teacher_eval_reward": 146.0}
{"epoch": 202, "reward_mean": 36.83018867924528, "student_loss": null, "teacher_policy_loss": -19.72394561767578, "teacher_value_loss": 105.06613159179688, "teacher_entropy": 0.6243695020675659, "total_time": 1.2350184917449951, "rollout_time": 0.4415125846862793, "train_time": 0.7808685302734375, "student_train_time": 0.012264013290405273, "throughput": 1619.4089508523384, "inference_time": 0.05663817826825834, "env_time": 0.38487440641802095, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 203, "reward_mean": 38.84905660377358, "student_loss": null, "teacher_policy_loss": -19.11294937133789, "teacher_value_loss": 101.84208679199219, "teacher_entropy": 0.6153827905654907, "total_time": 1.8299894332885742, "rollout_time": 0.4601869583129883, "train_time": 0.9207029342651367, "student_train_time": 0.4487423896789551, "throughput": 1092.9024854563827, "inference_time": 0.059982281034535845, "env_time": 0.40020467727845244, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 204, "reward_mean": 36.51851851851852, "student_loss": null, "teacher_policy_loss": -18.318288803100586, "teacher_value_loss": 82.65788269042969, "teacher_entropy": 0.6215408444404602, "total_time": 1.2121899127960205, "rollout_time": 0.4412527084350586, "train_time": 0.763035774230957, "student_train_time": 0.007510185241699219, "throughput": 1649.9064865065802, "inference_time": 0.05469853272916225, "env_time": 0.38655417570589634, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 205, "reward_mean": 38.113207547169814, "student_loss": null, "teacher_policy_loss": -19.588945388793945, "teacher_value_loss": 129.9752960205078, "teacher_entropy": 0.6134101748466492, "total_time": 1.3191325664520264, "rollout_time": 0.44661903381347656, "train_time": 0.863173246383667, "student_train_time": 0.00897669792175293, "throughput": 1516.1478465953219, "inference_time": 0.05534430252191669, "env_time": 0.3912747312915599, "samples": 2000, "teacher_eval_reward": 162.0}
{"epoch": 206, "reward_mean": 41.170212765957444, "student_loss": null, "teacher_policy_loss": -20.881607055664062, "teacher_value_loss": 108.05106353759766, "teacher_entropy": 0.6198425889015198, "total_time": 1.4924719333648682, "rollout_time": 0.5855498313903809, "train_time": 0.9000186920166016, "student_train_time": 0.006518363952636719, "throughput": 1340.0587007963888, "inference_time": 0.07637890080513898, "env_time": 0.5091709305852419, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 207, "reward_mean": 32.80952380952381, "student_loss": null, "teacher_policy_loss": -18.127058029174805, "teacher_value_loss": 181.349609375, "teacher_entropy": 0.6077021956443787, "total_time": 1.2985799312591553, "rollout_time": 0.44629454612731934, "train_time": 0.8448967933654785, "student_train_time": 0.006911277770996094, "throughput": 1540.143930963664, "inference_time": 0.05756719675264321, "env_time": 0.3887273493746761, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 208, "reward_mean": 32.5, "student_loss": null, "teacher_policy_loss": -17.323930740356445, "teacher_value_loss": 91.78317260742188, "teacher_entropy": 0.6038609743118286, "total_time": 1.200376033782959, "rollout_time": 0.4443631172180176, "train_time": 0.7484674453735352, "student_train_time": 0.007199525833129883, "throughput": 1666.1445611314343, "inference_time": 0.0599883332488389, "env_time": 0.3843747839691787, "samples": 2000, "teacher_eval_reward": 93.0}
{"epoch": 209, "reward_mean": 34.96491228070175, "student_loss": null, "teacher_policy_loss": -18.763456344604492, "teacher_value_loss": 110.22230529785156, "teacher_entropy": 0.6019589304924011, "total_time": 1.357980728149414, "rollout_time": 0.44317102432250977, "train_time": 0.9007956981658936, "student_train_time": 0.013582468032836914, "throughput": 1472.7749507354913, "inference_time": 0.05578005097595451, "env_time": 0.38739097334655526, "samples": 2000, "teacher_eval_reward": 233.0}
{"epoch": 210, "reward_mean": 40.770833333333336, "student_loss": null, "teacher_policy_loss": -22.5257625579834, "teacher_value_loss": 194.549560546875, "teacher_entropy": 0.6132687926292419, "total_time": 1.3340821266174316, "rollout_time": 0.44613146781921387, "train_time": 0.8812201023101807, "student_train_time": 0.006322145462036133, "throughput": 1499.158080373211, "inference_time": 0.06049341602738423, "env_time": 0.38563805179182964, "samples": 2000, "teacher_eval_reward": 154.0}
{"epoch": 211, "reward_mean": 36.14545454545455, "student_loss": null, "teacher_policy_loss": -18.28193473815918, "teacher_value_loss": 95.2217025756836, "teacher_entropy": 0.6140432357788086, "total_time": 1.2569003105163574, "rollout_time": 0.43457984924316406, "train_time": 0.8153162002563477, "student_train_time": 0.006601572036743164, "throughput": 1591.2160918938462, "inference_time": 0.05938250496365072, "env_time": 0.37519734427951335, "samples": 2000, "teacher_eval_reward": 90.0}
{"epoch": 212, "reward_mean": 34.09836065573771, "student_loss": null, "teacher_policy_loss": -18.211673736572266, "teacher_value_loss": 96.99191284179688, "teacher_entropy": 0.6026706099510193, "total_time": 1.2588765621185303, "rollout_time": 0.4549269676208496, "train_time": 0.7965734004974365, "student_train_time": 0.007023811340332031, "throughput": 1588.71811596385, "inference_time": 0.055487713989350596, "env_time": 0.399439253631499, "samples": 2000, "teacher_eval_reward": 283.0}
{"epoch": 213, "reward_mean": 33.63793103448276, "student_loss": null, "teacher_policy_loss": -17.59991455078125, "teacher_value_loss": 83.03897094726562, "teacher_entropy": 0.5987330079078674, "total_time": 1.362314224243164, "rollout_time": 0.45563817024230957, "train_time": 0.8943033218383789, "student_train_time": 0.012016773223876953, "throughput": 1468.0900811346246, "inference_time": 0.057764012926782016, "env_time": 0.39787415731552755, "samples": 2000, "teacher_eval_reward": 198.0}
{"epoch": 214, "reward_mean": 34.101694915254235, "student_loss": null, "teacher_policy_loss": -17.25813102722168, "teacher_value_loss": 75.51374816894531, "teacher_entropy": 0.5985429286956787, "total_time": 1.4681322574615479, "rollout_time": 0.46096277236938477, "train_time": 0.9951038360595703, "student_train_time": 0.011627197265625, "throughput": 1362.2750878439726, "inference_time": 0.05875525927149283, "env_time": 0.40220751309789193, "samples": 2000, "teacher_eval_reward": 216.0}
{"epoch": 215, "reward_mean": 33.982142857142854, "student_loss": null, "teacher_policy_loss": -17.978660583496094, "teacher_value_loss": 92.48358154296875, "teacher_entropy": 0.5966001749038696, "total_time": 1.2279953956604004, "rollout_time": 0.4428389072418213, "train_time": 0.7774996757507324, "student_train_time": 0.007236480712890625, "throughput": 1628.670601752888, "inference_time": 0.05794068723116652, "env_time": 0.38489822001065477, "samples": 2000, "teacher_eval_reward": 71.0}
{"epoch": 216, "reward_mean": 33.41269841269841, "student_loss": null, "teacher_policy_loss": -16.16744041442871, "teacher_value_loss": 66.42610168457031, "teacher_entropy": 0.595896303653717, "total_time": 1.3660674095153809, "rollout_time": 0.46620869636535645, "train_time": 0.8853650093078613, "student_train_time": 0.014121294021606445, "throughput": 1464.0565949154075, "inference_time": 0.05931709129436058, "env_time": 0.40689160507099587, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 217, "reward_mean": 33.6271186440678, "student_loss": null, "teacher_policy_loss": -17.374393463134766, "teacher_value_loss": 80.49417877197266, "teacher_entropy": 0.6009438037872314, "total_time": 1.267737627029419, "rollout_time": 0.44167137145996094, "train_time": 0.8100762367248535, "student_train_time": 0.015531301498413086, "throughput": 1577.613504054801, "inference_time": 0.05747871624225809, "env_time": 0.38419265521770285, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 218, "reward_mean": 33.58620689655172, "student_loss": null, "teacher_policy_loss": -17.809606552124023, "teacher_value_loss": 74.5449447631836, "teacher_entropy": 0.5990915894508362, "total_time": 1.2720208168029785, "rollout_time": 0.472820520401001, "train_time": 0.7928354740142822, "student_train_time": 0.005992412567138672, "throughput": 1572.301312667729, "inference_time": 0.0556901137370005, "env_time": 0.4171304066640005, "samples": 2000, "teacher_eval_reward": 227.0}
{"epoch": 219, "reward_mean": 40.98, "student_loss": null, "teacher_policy_loss": -21.472864151000977, "teacher_value_loss": 139.84805297851562, "teacher_entropy": 0.6016323566436768, "total_time": 1.4958395957946777, "rollout_time": 0.4598844051361084, "train_time": 1.025883436203003, "student_train_time": 0.009641647338867188, "throughput": 1337.0417560965036, "inference_time": 0.05803715949514299, "env_time": 0.4018472456409654, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 220, "reward_mean": 34.37931034482759, "student_loss": null, "teacher_policy_loss": -19.124473571777344, "teacher_value_loss": 121.53074645996094, "teacher_entropy": 0.5965877771377563, "total_time": 1.430891513824463, "rollout_time": 0.4492318630218506, "train_time": 0.9492340087890625, "student_train_time": 0.03190350532531738, "throughput": 1397.7300030625197, "inference_time": 0.058052269005202106, "env_time": 0.3911795940166485, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 221, "reward_mean": 36.886792452830186, "student_loss": null, "teacher_policy_loss": -18.994319915771484, "teacher_value_loss": 101.18085479736328, "teacher_entropy": 0.6022518277168274, "total_time": 1.3287878036499023, "rollout_time": 0.45211100578308105, "train_time": 0.8633937835693359, "student_train_time": 0.012915372848510742, "throughput": 1505.1312139578781, "inference_time": 0.05579208024391846, "env_time": 0.3963189255391626, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 222, "reward_mean": 38.490196078431374, "student_loss": null, "teacher_policy_loss": -19.599184036254883, "teacher_value_loss": 113.80208587646484, "teacher_entropy": 0.6009678840637207, "total_time": 1.2365386486053467, "rollout_time": 0.43517398834228516, "train_time": 0.7937169075012207, "student_train_time": 0.007283210754394531, "throughput": 1617.4181067900608, "inference_time": 0.055241055923033855, "env_time": 0.3799329324192513, "samples": 2000, "teacher_eval_reward": 302.0}
{"epoch": 223, "reward_mean": 34.53333333333333, "student_loss": null, "teacher_policy_loss": -17.626216888427734, "teacher_value_loss": 95.04492950439453, "teacher_entropy": 0.6056283116340637, "total_time": -1.447505235671997, "rollout_time": -2.198676824569702, "train_time": 0.7410285472869873, "student_train_time": 0.009650707244873047, "throughput": 200000000000.0, "inference_time": 0.054752280042521306, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 224, "reward_mean": 35.41509433962264, "student_loss": null, "teacher_policy_loss": -18.807296752929688, "teacher_value_loss": 120.07780456542969, "teacher_entropy": 0.6077873706817627, "total_time": 1.2103877067565918, "rollout_time": 0.455855131149292, "train_time": 0.7412848472595215, "student_train_time": 0.012860774993896484, "throughput": 1652.3631137656612, "inference_time": 0.05581586850894382, "env_time": 0.40003926264034817, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 225, "reward_mean": 38.19642857142857, "student_loss": null, "teacher_policy_loss": -18.37903594970703, "teacher_value_loss": 95.5218734741211, "teacher_entropy": 0.6124376058578491, "total_time": 1.3004302978515625, "rollout_time": 0.44650936126708984, "train_time": 0.8410134315490723, "student_train_time": 0.01241302490234375, "throughput": 1537.9524787327662, "inference_time": 0.058360194467240945, "env_time": 0.3881491667998489, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 226, "reward_mean": 40.3, "student_loss": null, "teacher_policy_loss": -19.398265838623047, "teacher_value_loss": 114.62515258789062, "teacher_entropy": 0.608949601650238, "total_time": 1.180978775024414, "rollout_time": 0.4228086471557617, "train_time": 0.7511763572692871, "student_train_time": 0.0066144466400146484, "throughput": 1693.5105374426857, "inference_time": 0.054471834699143074, "env_time": 0.36833681245661865, "samples": 2000, "teacher_eval_reward": 100.0}
{"epoch": 227, "reward_mean": 39.64, "student_loss": null, "teacher_policy_loss": -19.78508949279785, "teacher_value_loss": 133.74461364746094, "teacher_entropy": 0.6114672422409058, "total_time": 1.359898328781128, "rollout_time": 0.46056151390075684, "train_time": 0.8896970748901367, "student_train_time": 0.00926971435546875, "throughput": 1470.698182115271, "inference_time": 0.055959445768166916, "env_time": 0.4046020681325899, "samples": 2000, "teacher_eval_reward": 281.0}
{"epoch": 228, "reward_mean": 34.50877192982456, "student_loss": null, "teacher_policy_loss": -17.24326515197754, "teacher_value_loss": 67.89315795898438, "teacher_entropy": 0.6141200661659241, "total_time": 1.3601768016815186, "rollout_time": 0.43696165084838867, "train_time": 0.9082615375518799, "student_train_time": 0.014581918716430664, "throughput": 1470.3970818554617, "inference_time": 0.055504256024505594, "env_time": 0.3814573948238831, "samples": 2000, "teacher_eval_reward": 58.0}
{"epoch": 229, "reward_mean": 37.113207547169814, "student_loss": null, "teacher_policy_loss": -19.505191802978516, "teacher_value_loss": 117.25749969482422, "teacher_entropy": 0.6102913618087769, "total_time": 1.2200663089752197, "rollout_time": 0.45799732208251953, "train_time": 0.7553060054779053, "student_train_time": 0.006401538848876953, "throughput": 1639.2551661227958, "inference_time": 0.057380218777325354, "env_time": 0.4006171033051942, "samples": 2000, "teacher_eval_reward": 53.0}
{"epoch": 230, "reward_mean": 35.06896551724138, "student_loss": null, "teacher_policy_loss": -17.328994750976562, "teacher_value_loss": 82.00767517089844, "teacher_entropy": 0.5979861617088318, "total_time": 1.3688879013061523, "rollout_time": 0.45877528190612793, "train_time": 0.899134635925293, "student_train_time": 0.010593891143798828, "throughput": 1461.0400151039828, "inference_time": 0.058069885808436084, "env_time": 0.40070539609769185, "samples": 2000, "teacher_eval_reward": 71.0}
{"epoch": 231, "reward_mean": 38.660377358490564, "student_loss": null, "teacher_policy_loss": -18.928131103515625, "teacher_value_loss": 105.42770385742188, "teacher_entropy": 0.5961709022521973, "total_time": 1.197571039199829, "rollout_time": 0.43852925300598145, "train_time": 0.7527196407318115, "student_train_time": 0.0059583187103271484, "throughput": 1670.0470657142168, "inference_time": 0.055723727793520084, "env_time": 0.38280552521246136, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 232, "reward_mean": 35.654545454545456, "student_loss": null, "teacher_policy_loss": -17.98603057861328, "teacher_value_loss": 93.73528289794922, "teacher_entropy": 0.6073285937309265, "total_time": 1.223254919052124, "rollout_time": 0.42945337295532227, "train_time": 0.7846062183380127, "student_train_time": 0.008841514587402344, "throughput": 1634.9821847025642, "inference_time": 0.05441376698581735, "env_time": 0.3750396059695049, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 233, "reward_mean": 37.094339622641506, "student_loss": null, "teacher_policy_loss": -19.836563110351562, "teacher_value_loss": 119.99159240722656, "teacher_entropy": 0.6034978032112122, "total_time": 1.3096206188201904, "rollout_time": 0.4666128158569336, "train_time": 0.8311223983764648, "student_train_time": 0.011506319046020508, "throughput": 1527.1598287767931, "inference_time": 0.058140405530139105, "env_time": 0.4084724103267945, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 234, "reward_mean": 42.270833333333336, "student_loss": null, "teacher_policy_loss": -20.34141731262207, "teacher_value_loss": 128.93222045898438, "teacher_entropy": 0.6075194478034973, "total_time": 1.3690195083618164, "rollout_time": 0.5939280986785889, "train_time": 0.76397705078125, "student_train_time": 0.010729312896728516, "throughput": 1460.8995619012192, "inference_time": 0.06750219106470468, "env_time": 0.5264259076138842, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 235, "reward_mean": 45.25, "student_loss": null, "teacher_policy_loss": -22.06204605102539, "teacher_value_loss": 144.62074279785156, "teacher_entropy": 0.6126623749732971, "total_time": 1.292891025543213, "rollout_time": 0.45178651809692383, "train_time": 0.8271679878234863, "student_train_time": 0.01355743408203125, "throughput": 1546.9207848818446, "inference_time": 0.05694346702512121, "env_time": 0.3948430510718026, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 236, "reward_mean": 38.301886792452834, "student_loss": null, "teacher_policy_loss": -18.462600708007812, "teacher_value_loss": 89.94192504882812, "teacher_entropy": 0.6011560559272766, "total_time": 1.2027778625488281, "rollout_time": 0.4300572872161865, "train_time": 0.7602813243865967, "student_train_time": 0.012061119079589844, "throughput": 1662.8174347686813, "inference_time": 0.055842295978436596, "env_time": 0.3742149912377499, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 237, "reward_mean": 35.57142857142857, "student_loss": null, "teacher_policy_loss": -18.447208404541016, "teacher_value_loss": 138.16085815429688, "teacher_entropy": 0.6006942391395569, "total_time": 1.3520605564117432, "rollout_time": 0.42496204376220703, "train_time": 0.9177343845367432, "student_train_time": 0.009012460708618164, "throughput": 1479.2236860365444, "inference_time": 0.055359947498800466, "env_time": 0.36960209626340657, "samples": 2000, "teacher_eval_reward": 101.0}
{"epoch": 238, "reward_mean": 43.82608695652174, "student_loss": null, "teacher_policy_loss": -21.437519073486328, "teacher_value_loss": 128.21499633789062, "teacher_entropy": 0.6048890948295593, "total_time": 1.1867005825042725, "rollout_time": 0.4484996795654297, "train_time": 0.7322366237640381, "student_train_time": 0.00551152229309082, "throughput": 1685.3450899800157, "inference_time": 0.0558267604210414, "env_time": 0.3926729191443883, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 239, "reward_mean": 34.035714285714285, "student_loss": null, "teacher_policy_loss": -18.163949966430664, "teacher_value_loss": 99.50019073486328, "teacher_entropy": 0.5995380878448486, "total_time": 1.15639328956604, "rollout_time": 0.4400625228881836, "train_time": 0.7081689834594727, "student_train_time": 0.0077631473541259766, "throughput": 1729.5153976122954, "inference_time": 0.054414375037595164, "env_time": 0.38564814785058843, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 240, "reward_mean": 40.34615384615385, "student_loss": null, "teacher_policy_loss": -20.100933074951172, "teacher_value_loss": 147.8840789794922, "teacher_entropy": 0.5973346829414368, "total_time": 1.257350206375122, "rollout_time": 0.43016791343688965, "train_time": 0.8184232711791992, "student_train_time": 0.008404731750488281, "throughput": 1590.6467345847107, "inference_time": 0.05371866350651544, "env_time": 0.3764492499303742, "samples": 2000, "teacher_eval_reward": 104.0}
{"epoch": 241, "reward_mean": 38.03846153846154, "student_loss": null, "teacher_policy_loss": -18.725666046142578, "teacher_value_loss": 88.23770904541016, "teacher_entropy": 0.60163813829422, "total_time": 1.2129788398742676, "rollout_time": 0.44778013229370117, "train_time": 0.758934497833252, "student_train_time": 0.0058972835540771484, "throughput": 1648.833379655091, "inference_time": 0.05548363452362537, "env_time": 0.3922964977700758, "samples": 2000, "teacher_eval_reward": 289.0}
{"epoch": 242, "reward_mean": 41.38775510204081, "student_loss": null, "teacher_policy_loss": -21.24332046508789, "teacher_value_loss": 143.93736267089844, "teacher_entropy": 0.5972154140472412, "total_time": 1.2114794254302979, "rollout_time": 0.43445801734924316, "train_time": 0.7675778865814209, "student_train_time": 0.009044885635375977, "throughput": 1650.8740949435708, "inference_time": 0.05746373924012005, "env_time": 0.3769942781091231, "samples": 2000, "teacher_eval_reward": 289.0}
{"epoch": 243, "reward_mean": 36.24528301886792, "student_loss": null, "teacher_policy_loss": -19.15984535217285, "teacher_value_loss": 115.0279541015625, "teacher_entropy": 0.5833157896995544, "total_time": 1.3698711395263672, "rollout_time": 0.4681875705718994, "train_time": 0.8850898742675781, "student_train_time": 0.016231536865234375, "throughput": 1459.9913395441704, "inference_time": 0.06058791054056201, "env_time": 0.4075996600313374, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 244, "reward_mean": 35.6140350877193, "student_loss": null, "teacher_policy_loss": -18.224647521972656, "teacher_value_loss": 101.2294921875, "teacher_entropy": 0.5862740278244019, "total_time": 1.213862657546997, "rollout_time": 0.4523937702178955, "train_time": 0.7561328411102295, "student_train_time": 0.00493931770324707, "throughput": 1647.6328582688657, "inference_time": 0.056288762509211665, "env_time": 0.39610500770868384, "samples": 2000, "teacher_eval_reward": 82.0}
{"epoch": 245, "reward_mean": 36.55357142857143, "student_loss": null, "teacher_policy_loss": -17.37322235107422, "teacher_value_loss": 87.66120147705078, "teacher_entropy": 0.5830044746398926, "total_time": 1.5306580066680908, "rollout_time": 0.45236730575561523, "train_time": 1.058422565460205, "student_train_time": 0.01947188377380371, "throughput": 1306.627601519927, "inference_time": 0.056547003245214, "env_time": 0.39582030251040123, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 246, "reward_mean": 37.705882352941174, "student_loss": null, "teacher_policy_loss": -19.57826805114746, "teacher_value_loss": 98.01481628417969, "teacher_entropy": 0.5884799957275391, "total_time": 1.2100353240966797, "rollout_time": 0.445162296295166, "train_time": 0.7484767436981201, "student_train_time": 0.016035079956054688, "throughput": 1652.84430972546, "inference_time": 0.05644437821138126, "env_time": 0.38871791808378475, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 247, "reward_mean": 47.44186046511628, "student_loss": null, "teacher_policy_loss": -22.37126922607422, "teacher_value_loss": 161.67803955078125, "teacher_entropy": 0.5884377360343933, "total_time": 1.2899444103240967, "rollout_time": 0.4873058795928955, "train_time": 0.788811206817627, "student_train_time": 0.013458967208862305, "throughput": 1550.4544102776513, "inference_time": 0.05854134951005108, "env_time": 0.42876453008284443, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 248, "reward_mean": 41.875, "student_loss": null, "teacher_policy_loss": -19.730140686035156, "teacher_value_loss": 107.13751983642578, "teacher_entropy": 0.5901638269424438, "total_time": 1.2977817058563232, "rollout_time": 0.4446711540222168, "train_time": 0.844994068145752, "student_train_time": 0.007758140563964844, "throughput": 1541.0912258778742, "inference_time": 0.0573464672670525, "env_time": 0.3873246867551643, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 249, "reward_mean": 49.625, "student_loss": null, "teacher_policy_loss": -24.617578506469727, "teacher_value_loss": 258.60162353515625, "teacher_entropy": 0.5906409025192261, "total_time": 1.1925420761108398, "rollout_time": 0.4478471279144287, "train_time": 0.7389876842498779, "student_train_time": 0.00532078742980957, "throughput": 1677.0896726113601, "inference_time": 0.05729750474529283, "env_time": 0.3905496231691359, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 250, "reward_mean": 40.816326530612244, "student_loss": null, "teacher_policy_loss": -20.210952758789062, "teacher_value_loss": 98.55207061767578, "teacher_entropy": 0.5924711227416992, "total_time": 1.2754669189453125, "rollout_time": 0.4290347099304199, "train_time": 0.8382256031036377, "student_train_time": 0.007785797119140625, "throughput": 1568.0532127433034, "inference_time": 0.055025496001690044, "env_time": 0.3740092139287299, "samples": 2000, "teacher_eval_reward": 58.0}
{"epoch": 251, "reward_mean": 43.06666666666667, "student_loss": null, "teacher_policy_loss": -22.24466323852539, "teacher_value_loss": 148.48138427734375, "teacher_entropy": 0.5934023261070251, "total_time": 1.2577569484710693, "rollout_time": 0.45522260665893555, "train_time": 0.7933764457702637, "student_train_time": 0.008700847625732422, "throughput": 1590.132340299294, "inference_time": 0.05843022903354722, "env_time": 0.3967923776253883, "samples": 2000, "teacher_eval_reward": 93.0}
{"epoch": 252, "reward_mean": 33.93103448275862, "student_loss": null, "teacher_policy_loss": -17.24131202697754, "teacher_value_loss": 124.74882507324219, "teacher_entropy": 0.5817846655845642, "total_time": 1.251462459564209, "rollout_time": 0.43236541748046875, "train_time": 0.8115975856781006, "student_train_time": 0.007056713104248047, "throughput": 1598.130239317327, "inference_time": 0.05483354274656449, "env_time": 0.37753187473390426, "samples": 2000, "teacher_eval_reward": 68.0}
{"epoch": 253, "reward_mean": 41.42, "student_loss": null, "teacher_policy_loss": -19.59544563293457, "teacher_value_loss": 156.54637145996094, "teacher_entropy": 0.591687023639679, "total_time": 1.1808130741119385, "rollout_time": 0.44235920906066895, "train_time": 0.7300457954406738, "student_train_time": 0.008048057556152344, "throughput": 1693.7481840672815, "inference_time": 0.05696180400082085, "env_time": 0.3853974050598481, "samples": 2000, "teacher_eval_reward": 328.0}
{"epoch": 254, "reward_mean": 38.86538461538461, "student_loss": null, "teacher_policy_loss": -19.28548812866211, "teacher_value_loss": 132.96336364746094, "teacher_entropy": 0.5927942395210266, "total_time": 1.2399427890777588, "rollout_time": 0.44022035598754883, "train_time": 0.7918155193328857, "student_train_time": 0.007544755935668945, "throughput": 1612.9776451117993, "inference_time": 0.05452878895084723, "env_time": 0.3856915670367016, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 255, "reward_mean": 35.61818181818182, "student_loss": null, "teacher_policy_loss": -17.427051544189453, "teacher_value_loss": 105.63471984863281, "teacher_entropy": 0.6005440354347229, "total_time": 1.2079856395721436, "rollout_time": 0.42772412300109863, "train_time": 0.7737212181091309, "student_train_time": 0.006183624267578125, "throughput": 1655.6488210475582, "inference_time": 0.05441296222306846, "env_time": 0.37331116077803017, "samples": 2000, "teacher_eval_reward": 78.0}
{"epoch": 256, "reward_mean": 36.517857142857146, "student_loss": null, "teacher_policy_loss": -18.1848201751709, "teacher_value_loss": 111.60169219970703, "teacher_entropy": 0.5910351276397705, "total_time": 1.2510156631469727, "rollout_time": 0.46895742416381836, "train_time": 0.7737791538238525, "student_train_time": 0.00786447525024414, "throughput": 1598.7010066436192, "inference_time": 0.05488617444461852, "env_time": 0.41407124971919984, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 257, "reward_mean": 48.095238095238095, "student_loss": null, "teacher_policy_loss": -23.072328567504883, "teacher_value_loss": 148.40553283691406, "teacher_entropy": 0.6116013526916504, "total_time": 1.2491497993469238, "rollout_time": 0.4274466037750244, "train_time": 0.8144056797027588, "student_train_time": 0.006934404373168945, "throughput": 1601.0889975290659, "inference_time": 0.05436412450399075, "env_time": 0.37308247927103366, "samples": 2000, "teacher_eval_reward": 106.0}
{"epoch": 258, "reward_mean": 44.24444444444445, "student_loss": null, "teacher_policy_loss": -22.83401107788086, "teacher_value_loss": 214.337158203125, "teacher_entropy": 0.6104416251182556, "total_time": 1.2639939785003662, "rollout_time": 0.44357895851135254, "train_time": 0.8149919509887695, "student_train_time": 0.005021333694458008, "throughput": 1582.2860187774388, "inference_time": 0.05735191424355435, "env_time": 0.3862270442677982, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 259, "reward_mean": 35.68421052631579, "student_loss": null, "teacher_policy_loss": -17.85572624206543, "teacher_value_loss": 106.64960479736328, "teacher_entropy": 0.5945470333099365, "total_time": 1.2652435302734375, "rollout_time": 0.44708776473999023, "train_time": 0.8108382225036621, "student_train_time": 0.0069577693939208984, "throughput": 1580.7233565286606, "inference_time": 0.058095155753107974, "env_time": 0.38899260898688226, "samples": 2000, "teacher_eval_reward": 115.0}
{"epoch": 260, "reward_mean": 38.02040816326531, "student_loss": null, "teacher_policy_loss": -19.425567626953125, "teacher_value_loss": 93.04692077636719, "teacher_entropy": 0.6146597266197205, "total_time": 1.2445955276489258, "rollout_time": 0.44364428520202637, "train_time": 0.7846014499664307, "student_train_time": 0.01532435417175293, "throughput": 1606.9477638072935, "inference_time": 0.05464839278465661, "env_time": 0.38899589241736976, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 261, "reward_mean": 44.744680851063826, "student_loss": null, "teacher_policy_loss": -21.456058502197266, "teacher_value_loss": 155.88778686523438, "teacher_entropy": 0.6058863401412964, "total_time": 1.354227066040039, "rollout_time": 0.4366011619567871, "train_time": 0.9109954833984375, "student_train_time": 0.006272315979003906, "throughput": 1476.8572052309491, "inference_time": 0.05439300925536372, "env_time": 0.3822081527014234, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 262, "reward_mean": 39.18, "student_loss": null, "teacher_policy_loss": -19.110736846923828, "teacher_value_loss": 95.37815856933594, "teacher_entropy": 0.5956196188926697, "total_time": 1.2559611797332764, "rollout_time": 0.4514126777648926, "train_time": 0.7940008640289307, "student_train_time": 0.010099649429321289, "throughput": 1592.4059057499949, "inference_time": 0.05804138371786394, "env_time": 0.39337129404702864, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 263, "reward_mean": 38.886792452830186, "student_loss": null, "teacher_policy_loss": -18.417871475219727, "teacher_value_loss": 108.8492431640625, "teacher_entropy": 0.5909221768379211, "total_time": 1.3679094314575195, "rollout_time": 0.4493906497955322, "train_time": 0.8963885307312012, "student_train_time": 0.0217587947845459, "throughput": 1462.0851015472438, "inference_time": 0.05581704025280487, "env_time": 0.39357360954272735, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 264, "reward_mean": 41.276595744680854, "student_loss": null, "teacher_policy_loss": -21.661787033081055, "teacher_value_loss": 145.96719360351562, "teacher_entropy": 0.5984600782394409, "total_time": 1.2083179950714111, "rollout_time": 0.4420931339263916, "train_time": 0.7546408176422119, "student_train_time": 0.011095762252807617, "throughput": 1655.1934243781586, "inference_time": 0.05322333395815804, "env_time": 0.38886979996823356, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 265, "reward_mean": 39.30769230769231, "student_loss": null, "teacher_policy_loss": -18.82925796508789, "teacher_value_loss": 97.25316619873047, "teacher_entropy": 0.5869618058204651, "total_time": 1.3100109100341797, "rollout_time": 0.44895005226135254, "train_time": 0.8475234508514404, "student_train_time": 0.013183355331420898, "throughput": 1526.7048424412112, "inference_time": 0.05519389769688132, "env_time": 0.3937561545644712, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 266, "reward_mean": 37.56603773584906, "student_loss": null, "teacher_policy_loss": -19.70663833618164, "teacher_value_loss": 121.83426666259766, "teacher_entropy": 0.5881675481796265, "total_time": 1.2381160259246826, "rollout_time": 0.44484829902648926, "train_time": 0.7842123508453369, "student_train_time": 0.008614063262939453, "throughput": 1615.3574932577962, "inference_time": 0.0588761109738698, "env_time": 0.38597218805261946, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 267, "reward_mean": 36.767857142857146, "student_loss": null, "teacher_policy_loss": -18.412368774414062, "teacher_value_loss": 90.16558074951172, "teacher_entropy": 0.5882967710494995, "total_time": 1.2168993949890137, "rollout_time": 0.4431192874908447, "train_time": 0.7622027397155762, "student_train_time": 0.011213064193725586, "throughput": 1643.5212378571823, "inference_time": 0.05917476746617467, "env_time": 0.38394452002467006, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 268, "reward_mean": 43.79545454545455, "student_loss": null, "teacher_policy_loss": -21.733152389526367, "teacher_value_loss": 114.37745666503906, "teacher_entropy": 0.593181848526001, "total_time": 1.2587788105010986, "rollout_time": 0.4456667900085449, "train_time": 0.8017275333404541, "student_train_time": 0.011013269424438477, "throughput": 1588.8414893191868, "inference_time": 0.0555196813056682, "env_time": 0.3901471087028767, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 269, "reward_mean": 40.411764705882355, "student_loss": null, "teacher_policy_loss": -18.649599075317383, "teacher_value_loss": 82.97164154052734, "teacher_entropy": 0.5827041864395142, "total_time": -1.3153913021087646, "rollout_time": 0.459958553314209, "train_time": -1.792046308517456, "student_train_time": 0.016173362731933594, "throughput": 200000000000.0, "inference_time": 0.05465053904663364, "env_time": 0.40530801426757535, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 270, "reward_mean": 40.791666666666664, "student_loss": null, "teacher_policy_loss": -20.051637649536133, "teacher_value_loss": 89.04843139648438, "teacher_entropy": 0.5859292149543762, "total_time": 1.467050313949585, "rollout_time": 0.4328138828277588, "train_time": 1.0220160484313965, "student_train_time": 0.011765718460083008, "throughput": 1363.279760061951, "inference_time": 0.05550441927698557, "env_time": 0.3773094635507732, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 271, "reward_mean": 37.98039215686274, "student_loss": null, "teacher_policy_loss": -19.047945022583008, "teacher_value_loss": 90.01274871826172, "teacher_entropy": 0.574199914932251, "total_time": 1.2112741470336914, "rollout_time": 0.4428427219390869, "train_time": 0.7571394443511963, "student_train_time": 0.010917425155639648, "throughput": 1651.1538737104495, "inference_time": 0.058517111483524786, "env_time": 0.3843256104555621, "samples": 2000, "teacher_eval_reward": 170.0}
{"epoch": 272, "reward_mean": 38.58, "student_loss": null, "teacher_policy_loss": -19.473398208618164, "teacher_value_loss": 107.08055114746094, "teacher_entropy": 0.5836378931999207, "total_time": 1.4377167224884033, "rollout_time": 0.43822169303894043, "train_time": 0.9930696487426758, "student_train_time": 0.006003618240356445, "throughput": 1391.0946215735707, "inference_time": 0.05836501722842513, "env_time": 0.3798566758105153, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 273, "reward_mean": 44.977777777777774, "student_loss": null, "teacher_policy_loss": -21.574007034301758, "teacher_value_loss": 124.43803405761719, "teacher_entropy": 0.5868451595306396, "total_time": 1.2923133373260498, "rollout_time": 0.43381571769714355, "train_time": 0.8528995513916016, "student_train_time": 0.00516200065612793, "throughput": 1547.6122873870806, "inference_time": 0.05535198779216444, "env_time": 0.3784637299049791, "samples": 2000, "teacher_eval_reward": 70.0}
{"epoch": 274, "reward_mean": 41.86274509803921, "student_loss": null, "teacher_policy_loss": -19.41374969482422, "teacher_value_loss": 110.55956268310547, "teacher_entropy": 0.5772213339805603, "total_time": 1.2422707080841064, "rollout_time": 0.45045971870422363, "train_time": 0.7821171283721924, "student_train_time": 0.009274959564208984, "throughput": 1609.955050042597, "inference_time": 0.05992491843971948, "env_time": 0.39053480026450416, "samples": 2000, "teacher_eval_reward": 313.0}
{"epoch": 275, "reward_mean": 40.40816326530612, "student_loss": null, "teacher_policy_loss": -20.59393882751465, "teacher_value_loss": 113.34392547607422, "teacher_entropy": 0.5898705124855042, "total_time": 1.2575714588165283, "rollout_time": 0.4482154846191406, "train_time": 0.7962877750396729, "student_train_time": 0.012658119201660156, "throughput": 1590.3668821190918, "inference_time": 0.05794828076432168, "env_time": 0.39026720385481894, "samples": 2000, "teacher_eval_reward": 229.0}
{"epoch": 276, "reward_mean": 42.93617021276596, "student_loss": null, "teacher_policy_loss": -21.261581420898438, "teacher_value_loss": 135.0717010498047, "teacher_entropy": 0.5885264277458191, "total_time": 1.335914134979248, "rollout_time": 0.45889735221862793, "train_time": 0.863253116607666, "student_train_time": 0.013315200805664062, "throughput": 1497.102207119822, "inference_time": 0.05877876281738281, "env_time": 0.4001185894012451, "samples": 2000, "teacher_eval_reward": 318.0}
{"epoch": 277, "reward_mean": 41.06521739130435, "student_loss": null, "teacher_policy_loss": -20.791051864624023, "teacher_value_loss": 91.58512878417969, "teacher_entropy": 0.5902565717697144, "total_time": 1.371830940246582, "rollout_time": 0.45673656463623047, "train_time": 0.9036605358123779, "student_train_time": 0.011005640029907227, "throughput": 1457.9055926822198, "inference_time": 0.05778916925373778, "env_time": 0.3989473953824927, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 278, "reward_mean": 46.20454545454545, "student_loss": null, "teacher_policy_loss": -20.299543380737305, "teacher_value_loss": 83.7486343383789, "teacher_entropy": 0.5879389643669128, "total_time": 1.2487938404083252, "rollout_time": 0.43962979316711426, "train_time": 0.798288106918335, "student_train_time": 0.010514259338378906, "throughput": 1601.545375452884, "inference_time": 0.054137935185281094, "env_time": 0.38549185798183316, "samples": 2000, "teacher_eval_reward": 70.0}
{"epoch": 279, "reward_mean": 44.355555555555554, "student_loss": null, "teacher_policy_loss": -20.582721710205078, "teacher_value_loss": 93.110595703125, "teacher_entropy": 0.5804554224014282, "total_time": 1.3372509479522705, "rollout_time": 0.44600963592529297, "train_time": 0.8799228668212891, "student_train_time": 0.010864019393920898, "throughput": 1495.605595241937, "inference_time": 0.05979201421723701, "env_time": 0.38621762170805596, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 280, "reward_mean": 41.795918367346935, "student_loss": null, "teacher_policy_loss": -20.569801330566406, "teacher_value_loss": 116.0811538696289, "teacher_entropy": 0.5884495973587036, "total_time": 1.3127622604370117, "rollout_time": 0.45755577087402344, "train_time": 0.8290994167327881, "student_train_time": 0.025644540786743164, "throughput": 1523.5051008658722, "inference_time": 0.05471289996057749, "env_time": 0.40284287091344595, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 281, "reward_mean": 40.75, "student_loss": null, "teacher_policy_loss": -20.05735969543457, "teacher_value_loss": 106.2262954711914, "teacher_entropy": 0.5880314707756042, "total_time": 1.33951735496521, "rollout_time": 0.47544384002685547, "train_time": 0.8557963371276855, "student_train_time": 0.007854223251342773, "throughput": 1493.0750934928678, "inference_time": 0.0592819295143272, "env_time": 0.41616191051252827, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 282, "reward_mean": 44.77777777777778, "student_loss": null, "teacher_policy_loss": -22.986072540283203, "teacher_value_loss": 213.10476684570312, "teacher_entropy": 0.587762713432312, "total_time": 1.3217267990112305, "rollout_time": 0.44330930709838867, "train_time": 0.8679647445678711, "student_train_time": 0.01008152961730957, "throughput": 1513.1720121708802, "inference_time": 0.05690715476885089, "env_time": 0.3864021523295378, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 283, "reward_mean": 44.08695652173913, "student_loss": null, "teacher_policy_loss": -20.03067398071289, "teacher_value_loss": 81.78006744384766, "teacher_entropy": 0.595248281955719, "total_time": 1.2419726848602295, "rollout_time": 0.4767615795135498, "train_time": 0.7583944797515869, "student_train_time": 0.0064640045166015625, "throughput": 1610.3413741543584, "inference_time": 0.06105847096478101, "env_time": 0.4157031085487688, "samples": 2000, "teacher_eval_reward": 100.0}
{"epoch": 284, "reward_mean": 41.333333333333336, "student_loss": null, "teacher_policy_loss": -20.736103057861328, "teacher_value_loss": 114.46004486083984, "teacher_entropy": 0.5836184024810791, "total_time": -1.3924095630645752, "rollout_time": -2.1865971088409424, "train_time": 0.7848389148712158, "student_train_time": 0.008983135223388672, "throughput": 200000000000.0, "inference_time": 0.05456554425472859, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 239.0}
{"epoch": 285, "reward_mean": 42.829787234042556, "student_loss": null, "teacher_policy_loss": -21.746809005737305, "teacher_value_loss": 134.9761962890625, "teacher_entropy": 0.5780500769615173, "total_time": 1.381805181503296, "rollout_time": 0.5820944309234619, "train_time": 0.7939600944519043, "student_train_time": 0.005387306213378906, "throughput": 1447.3820382003175, "inference_time": 0.07595720098288439, "env_time": 0.5061372299405775, "samples": 2000, "teacher_eval_reward": 51.0}
{"epoch": 286, "reward_mean": 45.59090909090909, "student_loss": null, "teacher_policy_loss": -23.168811798095703, "teacher_value_loss": 173.6885528564453, "teacher_entropy": 0.5777322053909302, "total_time": 1.3092193603515625, "rollout_time": 0.4413607120513916, "train_time": 0.8592784404754639, "student_train_time": 0.008197307586669922, "throughput": 1527.6278831249053, "inference_time": 0.05406347123425803, "env_time": 0.38729724081713357, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 287, "reward_mean": 42.04347826086956, "student_loss": null, "teacher_policy_loss": -20.894287109375, "teacher_value_loss": 101.85220336914062, "teacher_entropy": 0.5731582045555115, "total_time": 1.229750394821167, "rollout_time": 0.4347646236419678, "train_time": 0.7885286808013916, "student_train_time": 0.0058231353759765625, "throughput": 1626.3462963074262, "inference_time": 0.05473412772153097, "env_time": 0.3800304959204368, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 288, "reward_mean": 38.30909090909091, "student_loss": null, "teacher_policy_loss": -18.224756240844727, "teacher_value_loss": 93.16099548339844, "teacher_entropy": 0.5750673413276672, "total_time": 1.360978364944458, "rollout_time": 0.443845272064209, "train_time": 0.9068887233734131, "student_train_time": 0.00988912582397461, "throughput": 1469.5310752288267, "inference_time": 0.05555004527013807, "env_time": 0.3882952267940709, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 289, "reward_mean": 36.0, "student_loss": null, "teacher_policy_loss": -18.570974349975586, "teacher_value_loss": 100.26289367675781, "teacher_entropy": 0.5739203095436096, "total_time": 1.214024543762207, "rollout_time": 0.42958879470825195, "train_time": 0.7774250507354736, "student_train_time": 0.006654977798461914, "throughput": 1647.4131517984724, "inference_time": 0.0535892298030376, "env_time": 0.37599956490521436, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 290, "reward_mean": 36.61224489795919, "student_loss": null, "teacher_policy_loss": -20.66301155090332, "teacher_value_loss": 144.82545471191406, "teacher_entropy": 0.5854763984680176, "total_time": 1.2522976398468018, "rollout_time": 0.43799853324890137, "train_time": 0.8085241317749023, "student_train_time": 0.005411386489868164, "throughput": 1597.0644169262089, "inference_time": 0.055283468258494395, "env_time": 0.382715064990407, "samples": 2000, "teacher_eval_reward": 344.0}
{"epoch": 291, "reward_mean": 47.08510638297872, "student_loss": null, "teacher_policy_loss": -19.288318634033203, "teacher_value_loss": 93.68409729003906, "teacher_entropy": 0.5863330364227295, "total_time": 1.2732911109924316, "rollout_time": 0.4467306137084961, "train_time": 0.8171274662017822, "student_train_time": 0.009077310562133789, "throughput": 1570.7327120513353, "inference_time": 0.05844938472182548, "env_time": 0.3882812289866706, "samples": 2000, "teacher_eval_reward": 186.0}
{"epoch": 292, "reward_mean": 43.130434782608695, "student_loss": null, "teacher_policy_loss": -20.456695556640625, "teacher_value_loss": 108.26797485351562, "teacher_entropy": 0.5809750556945801, "total_time": 1.339470624923706, "rollout_time": 0.4444141387939453, "train_time": 0.8626699447631836, "student_train_time": 0.03201770782470703, "throughput": 1493.127182325418, "inference_time": 0.05660578475726652, "env_time": 0.3878083540366788, "samples": 2000, "teacher_eval_reward": 470.0}
{"epoch": 293, "reward_mean": 44.06521739130435, "student_loss": null, "teacher_policy_loss": -20.539159774780273, "teacher_value_loss": 107.94519805908203, "teacher_entropy": 0.5837320685386658, "total_time": 1.3528869152069092, "rollout_time": 0.45421624183654785, "train_time": 0.8855075836181641, "student_train_time": 0.012744426727294922, "throughput": 1478.320159297366, "inference_time": 0.05798800046250108, "env_time": 0.3962282413740468, "samples": 2000, "teacher_eval_reward": 316.0}
{"epoch": 294, "reward_mean": 51.0, "student_loss": null, "teacher_policy_loss": -24.116762161254883, "teacher_value_loss": 150.0037384033203, "teacher_entropy": 0.5861567258834839, "total_time": 1.3581581115722656, "rollout_time": 0.4378650188446045, "train_time": 0.9108560085296631, "student_train_time": 0.009033918380737305, "throughput": 1472.582597680552, "inference_time": 0.056835517249055556, "env_time": 0.38102950159554894, "samples": 2000, "teacher_eval_reward": 231.0}
{"epoch": 295, "reward_mean": 40.166666666666664, "student_loss": null, "teacher_policy_loss": -18.795303344726562, "teacher_value_loss": 95.12290954589844, "teacher_entropy": 0.5604748129844666, "total_time": 1.3421499729156494, "rollout_time": 0.4353506565093994, "train_time": 0.8852362632751465, "student_train_time": 0.02116990089416504, "throughput": 1490.146436955369, "inference_time": 0.05431841220706701, "env_time": 0.3810322443023324, "samples": 2000, "teacher_eval_reward": 161.0}
{"epoch": 296, "reward_mean": 39.708333333333336, "student_loss": null, "teacher_policy_loss": -19.64151382446289, "teacher_value_loss": 119.3775634765625, "teacher_entropy": 0.5727749466896057, "total_time": 1.285987377166748, "rollout_time": 0.45520782470703125, "train_time": 0.8175032138824463, "student_train_time": 0.012871503829956055, "throughput": 1555.2252187780762, "inference_time": 0.056337687758059474, "env_time": 0.3988701369489718, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 297, "reward_mean": 46.88095238095238, "student_loss": null, "teacher_policy_loss": -22.646812438964844, "teacher_value_loss": 109.86817169189453, "teacher_entropy": 0.5704649686813354, "total_time": 1.545452356338501, "rollout_time": 0.46071648597717285, "train_time": 1.0793719291687012, "student_train_time": 0.004965782165527344, "throughput": 1294.1194801620525, "inference_time": 0.055922663039382314, "env_time": 0.40479382293779054, "samples": 2000, "teacher_eval_reward": 189.0}
{"epoch": 298, "reward_mean": 40.12, "student_loss": null, "teacher_policy_loss": -19.45993995666504, "teacher_value_loss": 127.86384582519531, "teacher_entropy": 0.5606507658958435, "total_time": -1.377995491027832, "rollout_time": -2.2176461219787598, "train_time": 0.8310253620147705, "student_train_time": 0.008225440979003906, "throughput": 200000000000.0, "inference_time": 0.05410513403330697, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 299, "reward_mean": 44.111111111111114, "student_loss": null, "teacher_policy_loss": -21.500938415527344, "teacher_value_loss": 130.0879669189453, "teacher_entropy": 0.5731326937675476, "total_time": 1.2174077033996582, "rollout_time": 0.4398629665374756, "train_time": 0.766735315322876, "student_train_time": 0.010451793670654297, "throughput": 1642.8350128021389, "inference_time": 0.05668071046420664, "env_time": 0.38318225607326895, "samples": 2000, "teacher_eval_reward": 202.0}
{"epoch": 300, "reward_mean": 49.142857142857146, "student_loss": null, "teacher_policy_loss": -23.517040252685547, "teacher_value_loss": 134.41070556640625, "teacher_entropy": 0.5820041298866272, "total_time": 1.3310019969940186, "rollout_time": 0.4360392093658447, "train_time": 0.8816018104553223, "student_train_time": 0.012932300567626953, "throughput": 1502.6273473044141, "inference_time": 0.05616358427141677, "env_time": 0.37987562509442796, "samples": 2000, "teacher_eval_reward": 193.0}
{"epoch": 301, "reward_mean": 50.05, "student_loss": null, "teacher_policy_loss": -22.069732666015625, "teacher_value_loss": 97.69178771972656, "teacher_entropy": 0.5741490721702576, "total_time": 1.2477266788482666, "rollout_time": 0.42925000190734863, "train_time": 0.8059043884277344, "student_train_time": 0.012166500091552734, "throughput": 1602.9151527369206, "inference_time": 0.05536368872890307, "env_time": 0.37388631317844556, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 302, "reward_mean": 39.549019607843135, "student_loss": null, "teacher_policy_loss": -20.09340476989746, "teacher_value_loss": 118.29695129394531, "teacher_entropy": 0.5699896216392517, "total_time": 1.2769372463226318, "rollout_time": 0.4470405578613281, "train_time": 0.8240647315979004, "student_train_time": 0.005434751510620117, "throughput": 1566.2476803458192, "inference_time": 0.056255423040056485, "env_time": 0.39078513482127164, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 303, "reward_mean": 40.36734693877551, "student_loss": null, "teacher_policy_loss": -20.694765090942383, "teacher_value_loss": 129.17274475097656, "teacher_entropy": 0.5669835209846497, "total_time": 1.213670253753662, "rollout_time": 0.43956899642944336, "train_time": 0.7668869495391846, "student_train_time": 0.006859779357910156, "throughput": 1647.8940583855974, "inference_time": 0.057257090744315065, "env_time": 0.3823119056851283, "samples": 2000, "teacher_eval_reward": 229.0}
{"epoch": 304, "reward_mean": 43.45652173913044, "student_loss": null, "teacher_policy_loss": -19.854572296142578, "teacher_value_loss": 73.46493530273438, "teacher_entropy": 0.5731505155563354, "total_time": 1.284717082977295, "rollout_time": 0.4512965679168701, "train_time": 0.8272790908813477, "student_train_time": 0.005764961242675781, "throughput": 1556.7629842401234, "inference_time": 0.05515252475743182, "env_time": 0.3961440431594383, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 305, "reward_mean": 48.714285714285715, "student_loss": null, "teacher_policy_loss": -23.73526954650879, "teacher_value_loss": 168.14199829101562, "teacher_entropy": 0.5805790424346924, "total_time": 1.228687047958374, "rollout_time": 0.43239760398864746, "train_time": 0.78997802734375, "student_train_time": 0.005873918533325195, "throughput": 1627.7537907828234, "inference_time": 0.05547689801096567, "env_time": 0.3769207059776818, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 306, "reward_mean": 42.723404255319146, "student_loss": null, "teacher_policy_loss": -19.910993576049805, "teacher_value_loss": 78.44620513916016, "teacher_entropy": 0.5773090124130249, "total_time": 1.3415021896362305, "rollout_time": 0.4801008701324463, "train_time": 0.8466453552246094, "student_train_time": 0.014332771301269531, "throughput": 1490.865997425119, "inference_time": 0.06180850225064205, "env_time": 0.41829236788180424, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 307, "reward_mean": 48.285714285714285, "student_loss": null, "teacher_policy_loss": -23.37506675720215, "teacher_value_loss": 139.3837127685547, "teacher_entropy": 0.5842569470405579, "total_time": 1.2808969020843506, "rollout_time": 0.4403231143951416, "train_time": 0.8307793140411377, "student_train_time": 0.009430170059204102, "throughput": 1561.4059154530569, "inference_time": 0.05464635968564835, "env_time": 0.38567675470949325, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 308, "reward_mean": 43.81818181818182, "student_loss": null, "teacher_policy_loss": -23.881847381591797, "teacher_value_loss": 223.33778381347656, "teacher_entropy": 0.5690208077430725, "total_time": 1.3687195777893066, "rollout_time": 0.4569058418273926, "train_time": 0.899691104888916, "student_train_time": 0.011756420135498047, "throughput": 1461.2196920791537, "inference_time": 0.05749982621091476, "env_time": 0.3994060156164778, "samples": 2000, "teacher_eval_reward": 359.0}
{"epoch": 309, "reward_mean": 43.43478260869565, "student_loss": null, "teacher_policy_loss": -20.10015296936035, "teacher_value_loss": 105.71537017822266, "teacher_entropy": 0.5738832354545593, "total_time": 1.3280978202819824, "rollout_time": 0.4389979839324951, "train_time": 0.8735427856445312, "student_train_time": 0.015172958374023438, "throughput": 1505.9131710459092, "inference_time": 0.05663763229858887, "env_time": 0.38236035163390625, "samples": 2000, "teacher_eval_reward": 172.0}
{"epoch": 310, "reward_mean": 42.97826086956522, "student_loss": null, "teacher_policy_loss": -20.43511199951172, "teacher_value_loss": 106.7333755493164, "teacher_entropy": 0.5729791522026062, "total_time": 1.3910737037658691, "rollout_time": 0.5006661415100098, "train_time": 0.8771493434906006, "student_train_time": 0.012894630432128906, "throughput": 1437.7383416749706, "inference_time": 0.05909129328028939, "env_time": 0.4415748482297204, "samples": 2000, "teacher_eval_reward": 367.0}
{"epoch": 311, "reward_mean": 40.0, "student_loss": null, "teacher_policy_loss": -18.753141403198242, "teacher_value_loss": 109.42996978759766, "teacher_entropy": 0.5728812217712402, "total_time": 1.2533845901489258, "rollout_time": 0.4305915832519531, "train_time": 0.8061308860778809, "student_train_time": 0.016297340393066406, "throughput": 1595.679423314405, "inference_time": 0.053201905291643925, "env_time": 0.3773896779603092, "samples": 2000, "teacher_eval_reward": 167.0}
{"epoch": 312, "reward_mean": 37.62264150943396, "student_loss": null, "teacher_policy_loss": -17.6765193939209, "teacher_value_loss": 103.97308349609375, "teacher_entropy": 0.5701720714569092, "total_time": 1.2236590385437012, "rollout_time": 0.45119619369506836, "train_time": 0.7649533748626709, "student_train_time": 0.0071599483489990234, "throughput": 1634.4422236934859, "inference_time": 0.05435366648634954, "env_time": 0.3968425272087188, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 313, "reward_mean": 46.58139534883721, "student_loss": null, "teacher_policy_loss": -22.98996353149414, "teacher_value_loss": 149.11123657226562, "teacher_entropy": 0.5836743712425232, "total_time": 1.3234245777130127, "rollout_time": 0.4435575008392334, "train_time": 0.8715980052947998, "student_train_time": 0.007906198501586914, "throughput": 1511.2308126060086, "inference_time": 0.05715342476287333, "env_time": 0.38640407607636007, "samples": 2000, "teacher_eval_reward": 226.0}
{"epoch": 314, "reward_mean": 44.355555555555554, "student_loss": null, "teacher_policy_loss": -20.889781951904297, "teacher_value_loss": 109.3697738647461, "teacher_entropy": 0.5820745229721069, "total_time": 1.2768115997314453, "rollout_time": 0.43889737129211426, "train_time": 0.826866626739502, "student_train_time": 0.01067662239074707, "throughput": 1566.401809335586, "inference_time": 0.05876242325393832, "env_time": 0.38013494803817593, "samples": 2000, "teacher_eval_reward": 441.0}
{"epoch": 315, "reward_mean": 43.12765957446808, "student_loss": null, "teacher_policy_loss": -20.239120483398438, "teacher_value_loss": 93.23868560791016, "teacher_entropy": 0.5734313726425171, "total_time": 1.3307814598083496, "rollout_time": 0.4317646026611328, "train_time": 0.8776957988739014, "student_train_time": 0.02096843719482422, "throughput": 1502.876362801167, "inference_time": 0.05410146800750226, "env_time": 0.37766313465363055, "samples": 2000, "teacher_eval_reward": 149.0}
{"epoch": 316, "reward_mean": 47.19047619047619, "student_loss": null, "teacher_policy_loss": -23.00559425354004, "teacher_value_loss": 143.37484741210938, "teacher_entropy": 0.5741324424743652, "total_time": 1.2309694290161133, "rollout_time": 0.44454240798950195, "train_time": 0.7752797603607178, "student_train_time": 0.00961756706237793, "throughput": 1624.7357187404368, "inference_time": 0.053945340263453545, "env_time": 0.3905970677260484, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 317, "reward_mean": 43.08695652173913, "student_loss": null, "teacher_policy_loss": -20.660734176635742, "teacher_value_loss": 107.33146667480469, "teacher_entropy": 0.5640372633934021, "total_time": 1.3789844512939453, "rollout_time": 0.4502401351928711, "train_time": 0.9199259281158447, "student_train_time": 0.008456230163574219, "throughput": 1450.3426765423903, "inference_time": 0.05614502019852807, "env_time": 0.394095114994343, "samples": 2000, "teacher_eval_reward": 206.0}
{"epoch": 318, "reward_mean": 41.326530612244895, "student_loss": null, "teacher_policy_loss": -19.55225372314453, "teacher_value_loss": 84.67508697509766, "teacher_entropy": 0.5658572316169739, "total_time": 1.2865688800811768, "rollout_time": 0.44303202629089355, "train_time": 0.8309929370880127, "student_train_time": 0.012181520462036133, "throughput": 1554.5222886735835, "inference_time": 0.05568436382054642, "env_time": 0.38734766247034713, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 319, "reward_mean": 46.95348837209303, "student_loss": null, "teacher_policy_loss": -21.01469612121582, "teacher_value_loss": 82.16307830810547, "teacher_entropy": 0.5648348331451416, "total_time": 1.5435433387756348, "rollout_time": 0.4562704563140869, "train_time": 1.0716853141784668, "student_train_time": 0.015117406845092773, "throughput": 1295.720016249388, "inference_time": 0.05561421976744896, "env_time": 0.40065623654663796, "samples": 2000, "teacher_eval_reward": 227.0}
{"epoch": 320, "reward_mean": 42.17391304347826, "student_loss": null, "teacher_policy_loss": -20.18987464904785, "teacher_value_loss": 89.24653625488281, "teacher_entropy": 0.5491077899932861, "total_time": 1.432281732559204, "rollout_time": 0.44115495681762695, "train_time": 0.9823687076568604, "student_train_time": 0.007847070693969727, "throughput": 1396.373321348165, "inference_time": 0.056358975438342895, "env_time": 0.38479598137928406, "samples": 2000, "teacher_eval_reward": 244.0}
{"epoch": 321, "reward_mean": 38.37735849056604, "student_loss": null, "teacher_policy_loss": -18.315567016601562, "teacher_value_loss": 91.05719757080078, "teacher_entropy": 0.5450959205627441, "total_time": 1.2928073406219482, "rollout_time": 0.4556267261505127, "train_time": 0.8185384273529053, "student_train_time": 0.018152952194213867, "throughput": 1547.0209188616093, "inference_time": 0.056899143988630385, "env_time": 0.3987275821618823, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 322, "reward_mean": 44.348837209302324, "student_loss": null, "teacher_policy_loss": -20.77345848083496, "teacher_value_loss": 83.97490692138672, "teacher_entropy": 0.5577977895736694, "total_time": 1.3822994232177734, "rollout_time": 0.42601966857910156, "train_time": 0.9459812641143799, "student_train_time": 0.009940385818481445, "throughput": 1446.8645261706886, "inference_time": 0.05531658225845604, "env_time": 0.3707030863206455, "samples": 2000, "teacher_eval_reward": 431.0}
{"epoch": 323, "reward_mean": 43.604166666666664, "student_loss": null, "teacher_policy_loss": -19.078611373901367, "teacher_value_loss": 76.43424987792969, "teacher_entropy": 0.5580273866653442, "total_time": 1.291558027267456, "rollout_time": 0.43787550926208496, "train_time": 0.8461272716522217, "student_train_time": 0.007187604904174805, "throughput": 1548.51733934974, "inference_time": 0.053786334730830276, "env_time": 0.3840891745312547, "samples": 2000, "teacher_eval_reward": 246.0}
{"epoch": 324, "reward_mean": 45.30952380952381, "student_loss": null, "teacher_policy_loss": -22.78708839416504, "teacher_value_loss": 156.7570037841797, "teacher_entropy": 0.5567489266395569, "total_time": 1.246898889541626, "rollout_time": 0.43665146827697754, "train_time": 0.8007426261901855, "student_train_time": 0.009143590927124023, "throughput": 1603.9792935698438, "inference_time": 0.05508151400499628, "env_time": 0.38156995427198126, "samples": 2000, "teacher_eval_reward": 82.0}
{"epoch": 325, "reward_mean": 48.72093023255814, "student_loss": null, "teacher_policy_loss": -22.479766845703125, "teacher_value_loss": 136.1524200439453, "teacher_entropy": 0.5586076974868774, "total_time": 1.2193169593811035, "rollout_time": 0.45880818367004395, "train_time": 0.7447149753570557, "student_train_time": 0.015423297882080078, "throughput": 1640.2625950640042, "inference_time": 0.05642870126212074, "env_time": 0.4023794824079232, "samples": 2000, "teacher_eval_reward": 57.0}
{"epoch": 326, "reward_mean": 50.666666666666664, "student_loss": null, "teacher_policy_loss": -24.181468963623047, "teacher_value_loss": 165.49160766601562, "teacher_entropy": 0.5594130754470825, "total_time": 1.2552134990692139, "rollout_time": 0.4277222156524658, "train_time": 0.8195831775665283, "student_train_time": 0.00754857063293457, "throughput": 1593.3544384943855, "inference_time": 0.05365319400880253, "env_time": 0.3740690216436633, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 327, "reward_mean": 43.04347826086956, "student_loss": null, "teacher_policy_loss": -21.11574363708496, "teacher_value_loss": 129.90895080566406, "teacher_entropy": 0.5642627477645874, "total_time": 1.467365026473999, "rollout_time": 0.4233283996582031, "train_time": 1.0368759632110596, "student_train_time": 0.006786823272705078, "throughput": 1362.9873711832254, "inference_time": 0.056589156985864975, "env_time": 0.36673924267233815, "samples": 2000, "teacher_eval_reward": 328.0}
{"epoch": 328, "reward_mean": 44.15555555555556, "student_loss": null, "teacher_policy_loss": -21.287792205810547, "teacher_value_loss": 123.47813415527344, "teacher_entropy": 0.5618888735771179, "total_time": 1.4148838520050049, "rollout_time": 0.4331071376800537, "train_time": 0.9737744331359863, "student_train_time": 0.007630825042724609, "throughput": 1413.5435902854063, "inference_time": 0.05534895774508186, "env_time": 0.37775817993497185, "samples": 2000, "teacher_eval_reward": 71.0}
{"epoch": 329, "reward_mean": 48.166666666666664, "student_loss": null, "teacher_policy_loss": -23.62944984436035, "teacher_value_loss": 171.74595642089844, "teacher_entropy": 0.562018871307373, "total_time": 1.2072269916534424, "rollout_time": 0.4600200653076172, "train_time": 0.741246223449707, "student_train_time": 0.0055806636810302734, "throughput": 1656.6892670787288, "inference_time": 0.05641474146977998, "env_time": 0.4036053238378372, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 330, "reward_mean": 45.17391304347826, "student_loss": null, "teacher_policy_loss": -22.339723587036133, "teacher_value_loss": 160.60398864746094, "teacher_entropy": 0.5555675029754639, "total_time": 1.247239112854004, "rollout_time": 0.441455602645874, "train_time": 0.7979288101196289, "student_train_time": 0.0074841976165771484, "throughput": 1603.5417582627645, "inference_time": 0.05579158524960803, "env_time": 0.385664017396266, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 331, "reward_mean": 45.348837209302324, "student_loss": null, "teacher_policy_loss": -23.095861434936523, "teacher_value_loss": 149.5514678955078, "teacher_entropy": 0.5664375424385071, "total_time": 1.2730679512023926, "rollout_time": 0.4556722640991211, "train_time": 0.803708553314209, "student_train_time": 0.013312578201293945, "throughput": 1571.0080503645006, "inference_time": 0.056383763016128796, "env_time": 0.3992885010829923, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 332, "reward_mean": 47.95238095238095, "student_loss": null, "teacher_policy_loss": -21.482032775878906, "teacher_value_loss": 141.88650512695312, "teacher_entropy": 0.5609220266342163, "total_time": 1.3002047538757324, "rollout_time": 0.4457540512084961, "train_time": 0.8375904560089111, "student_train_time": 0.016479969024658203, "throughput": 1538.2192643414614, "inference_time": 0.05761843948494061, "env_time": 0.3881356117235555, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 333, "reward_mean": 49.325, "student_loss": null, "teacher_policy_loss": -22.80877685546875, "teacher_value_loss": 120.53121948242188, "teacher_entropy": 0.5656082630157471, "total_time": 1.257901668548584, "rollout_time": 0.44918227195739746, "train_time": 0.7987940311431885, "student_train_time": 0.009560823440551758, "throughput": 1589.9493974816633, "inference_time": 0.056513231009375886, "env_time": 0.3926690409480216, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 334, "reward_mean": 44.68888888888889, "student_loss": null, "teacher_policy_loss": -21.395200729370117, "teacher_value_loss": 108.86550903320312, "teacher_entropy": 0.5623826384544373, "total_time": 1.2500414848327637, "rollout_time": 0.43064188957214355, "train_time": 0.8107309341430664, "student_train_time": 0.008312702178955078, "throughput": 1599.9469011762992, "inference_time": 0.055217311301021255, "env_time": 0.3754245782711223, "samples": 2000, "teacher_eval_reward": 266.0}
{"epoch": 335, "reward_mean": 42.608695652173914, "student_loss": null, "teacher_policy_loss": -19.535018920898438, "teacher_value_loss": 71.76142883300781, "teacher_entropy": 0.5745916962623596, "total_time": 1.226158857345581, "rollout_time": 0.43227052688598633, "train_time": 0.780841588973999, "student_train_time": 0.012662410736083984, "throughput": 1631.1100213635036, "inference_time": 0.053837903034946066, "env_time": 0.37843262385104026, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 336, "reward_mean": 44.62222222222222, "student_loss": null, "teacher_policy_loss": -21.947097778320312, "teacher_value_loss": 135.65150451660156, "teacher_entropy": 0.5671356320381165, "total_time": -1.389291763305664, "rollout_time": 0.4441349506378174, "train_time": -1.8488929271697998, "student_train_time": 0.015102624893188477, "throughput": 200000000000.0, "inference_time": 0.05610806351614883, "env_time": 0.38802688712166855, "samples": 2000, "teacher_eval_reward": 246.0}
{"epoch": 337, "reward_mean": 55.08108108108108, "student_loss": null, "teacher_policy_loss": -24.962467193603516, "teacher_value_loss": 136.12132263183594, "teacher_entropy": 0.5855147838592529, "total_time": 1.3579394817352295, "rollout_time": 0.44165635108947754, "train_time": 0.9043114185333252, "student_train_time": 0.011609077453613281, "throughput": 1472.8196851926862, "inference_time": 0.057432837325904984, "env_time": 0.38422351376357256, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 338, "reward_mean": 44.266666666666666, "student_loss": null, "teacher_policy_loss": -21.033632278442383, "teacher_value_loss": 120.36585998535156, "teacher_entropy": 0.5765517354011536, "total_time": 1.1951351165771484, "rollout_time": 0.4329984188079834, "train_time": 0.7542681694030762, "student_train_time": 0.007222175598144531, "throughput": 1673.4509531675164, "inference_time": 0.05632021323071967, "env_time": 0.3766782055772637, "samples": 2000, "teacher_eval_reward": 108.0}
{"epoch": 339, "reward_mean": 45.04545454545455, "student_loss": null, "teacher_policy_loss": -20.04924201965332, "teacher_value_loss": 114.14877319335938, "teacher_entropy": 0.5700464844703674, "total_time": 1.3523979187011719, "rollout_time": 0.44971299171447754, "train_time": 0.8940765857696533, "student_train_time": 0.008240461349487305, "throughput": 1478.8546864378334, "inference_time": 0.0572707635074039, "env_time": 0.39244222820707364, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 340, "reward_mean": 49.82051282051282, "student_loss": null, "teacher_policy_loss": -22.639739990234375, "teacher_value_loss": 101.751708984375, "teacher_entropy": 0.5718176364898682, "total_time": 1.2170534133911133, "rollout_time": 0.42484402656555176, "train_time": 0.7804429531097412, "student_train_time": 0.01141047477722168, "throughput": 1643.3132498493542, "inference_time": 0.0529758844859316, "env_time": 0.37186814207962016, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 341, "reward_mean": 44.723404255319146, "student_loss": null, "teacher_policy_loss": -20.382192611694336, "teacher_value_loss": 126.7180404663086, "teacher_entropy": 0.5679032802581787, "total_time": 1.318549633026123, "rollout_time": 0.43674492835998535, "train_time": 0.8688976764678955, "student_train_time": 0.012485742568969727, "throughput": 1516.8181385860476, "inference_time": 0.05347590374185529, "env_time": 0.38326902461813006, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 342, "reward_mean": 46.525, "student_loss": null, "teacher_policy_loss": -22.59146499633789, "teacher_value_loss": 108.48356628417969, "teacher_entropy": 0.5797134637832642, "total_time": 1.2076995372772217, "rollout_time": 0.43706345558166504, "train_time": 0.7592413425445557, "student_train_time": 0.011049032211303711, "throughput": 1656.0410418878132, "inference_time": 0.05384849100482825, "env_time": 0.3832149645768368, "samples": 2000, "teacher_eval_reward": 202.0}
{"epoch": 343, "reward_mean": 51.675, "student_loss": null, "teacher_policy_loss": -25.223360061645508, "teacher_value_loss": 224.27235412597656, "teacher_entropy": 0.5740605592727661, "total_time": 1.3446850776672363, "rollout_time": 0.4592902660369873, "train_time": 0.8734941482543945, "student_train_time": 0.011532306671142578, "throughput": 1487.3370971511083, "inference_time": 0.05712710847728886, "env_time": 0.40216315755969845, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 344, "reward_mean": 45.733333333333334, "student_loss": null, "teacher_policy_loss": -21.749109268188477, "teacher_value_loss": 156.66627502441406, "teacher_entropy": 0.5657277703285217, "total_time": 1.2933106422424316, "rollout_time": 0.45541977882385254, "train_time": 0.8233678340911865, "student_train_time": 0.01415562629699707, "throughput": 1546.41888396763, "inference_time": 0.05728933319915086, "env_time": 0.3981304456247017, "samples": 2000, "teacher_eval_reward": 71.0}
{"epoch": 345, "reward_mean": 41.91489361702128, "student_loss": null, "teacher_policy_loss": -20.894210815429688, "teacher_value_loss": 113.77359008789062, "teacher_entropy": 0.5714799761772156, "total_time": 1.2823021411895752, "rollout_time": 0.44582176208496094, "train_time": 0.8261644840240479, "student_train_time": 0.009952545166015625, "throughput": 1559.6948143162467, "inference_time": 0.05873505102863419, "env_time": 0.38708671105632675, "samples": 2000, "teacher_eval_reward": 236.0}
{"epoch": 346, "reward_mean": 45.81818181818182, "student_loss": null, "teacher_policy_loss": -21.231712341308594, "teacher_value_loss": 135.45062255859375, "teacher_entropy": 0.5717646479606628, "total_time": 1.221195936203003, "rollout_time": 0.4387848377227783, "train_time": 0.7727971076965332, "student_train_time": 0.009256839752197266, "throughput": 1637.738826922803, "inference_time": 0.056875976457376964, "env_time": 0.38190886126540136, "samples": 2000, "teacher_eval_reward": 481.0}
{"epoch": 347, "reward_mean": 42.76086956521739, "student_loss": null, "teacher_policy_loss": -21.17839813232422, "teacher_value_loss": 115.96279907226562, "teacher_entropy": 0.5615526437759399, "total_time": 1.2449872493743896, "rollout_time": 0.43982505798339844, "train_time": 0.7936651706695557, "student_train_time": 0.01111459732055664, "throughput": 1606.442155134526, "inference_time": 0.05499753403273644, "env_time": 0.384827523950662, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 348, "reward_mean": 44.86363636363637, "student_loss": null, "teacher_policy_loss": -20.101625442504883, "teacher_value_loss": 91.90607452392578, "teacher_entropy": 0.5710916519165039, "total_time": -1.216677188873291, "rollout_time": 0.4452512264251709, "train_time": -1.6723730564117432, "student_train_time": 0.01002955436706543, "throughput": 200000000000.0, "inference_time": 0.05545426706521539, "env_time": 0.3897969593599555, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 349, "reward_mean": 53.78378378378378, "student_loss": null, "teacher_policy_loss": -25.874906539916992, "teacher_value_loss": 190.72569274902344, "teacher_entropy": 0.569133460521698, "total_time": 1.224139928817749, "rollout_time": 0.4329843521118164, "train_time": 0.772597074508667, "student_train_time": 0.018169879913330078, "throughput": 1633.800150552692, "inference_time": 0.05464543274320022, "env_time": 0.3783389193686162, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 350, "reward_mean": 52.282051282051285, "student_loss": null, "teacher_policy_loss": -22.005218505859375, "teacher_value_loss": 111.00948333740234, "teacher_entropy": 0.565591037273407, "total_time": 1.300612449645996, "rollout_time": 0.4318816661834717, "train_time": 0.8586184978485107, "student_train_time": 0.009676218032836914, "throughput": 1537.737087280969, "inference_time": 0.05506952202085813, "env_time": 0.37681214416261355, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 351, "reward_mean": 48.707317073170735, "student_loss": null, "teacher_policy_loss": -22.263916015625, "teacher_value_loss": 116.16192626953125, "teacher_entropy": 0.5655800104141235, "total_time": 1.265735149383545, "rollout_time": 0.42679882049560547, "train_time": 0.8216152191162109, "student_train_time": 0.016767024993896484, "throughput": 1580.109394113031, "inference_time": 0.0542184817022644, "env_time": 0.37258033879334107, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 352, "reward_mean": 50.82051282051282, "student_loss": null, "teacher_policy_loss": -24.240798950195312, "teacher_value_loss": 154.0557403564453, "teacher_entropy": 0.5611526370048523, "total_time": 1.3027689456939697, "rollout_time": 0.4388394355773926, "train_time": 0.8540699481964111, "student_train_time": 0.009459733963012695, "throughput": 1535.1916443898833, "inference_time": 0.05728402577005909, "env_time": 0.3815554098073335, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 353, "reward_mean": 48.325581395348834, "student_loss": null, "teacher_policy_loss": -21.82860565185547, "teacher_value_loss": 159.1561737060547, "teacher_entropy": 0.5493743419647217, "total_time": 1.2054338455200195, "rollout_time": 0.43669843673706055, "train_time": 0.7619302272796631, "student_train_time": 0.006453514099121094, "throughput": 1659.1536793437285, "inference_time": 0.055237161801414913, "env_time": 0.38146127493564563, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 354, "reward_mean": 47.0, "student_loss": null, "teacher_policy_loss": -22.323671340942383, "teacher_value_loss": 152.74949645996094, "teacher_entropy": 0.5617043375968933, "total_time": 1.3037779331207275, "rollout_time": 0.43738603591918945, "train_time": 0.8586959838867188, "student_train_time": 0.007335662841796875, "throughput": 1534.003567012975, "inference_time": 0.0556819674820872, "env_time": 0.38170406843710225, "samples": 2000, "teacher_eval_reward": 339.0}
{"epoch": 355, "reward_mean": 42.369565217391305, "student_loss": null, "teacher_policy_loss": -18.855735778808594, "teacher_value_loss": 104.34774780273438, "teacher_entropy": 0.5467647314071655, "total_time": 1.323227882385254, "rollout_time": 0.4395604133605957, "train_time": 0.8774662017822266, "student_train_time": 0.0058383941650390625, "throughput": 1511.4554542145795, "inference_time": 0.055632094516113284, "env_time": 0.3839283188444824, "samples": 2000, "teacher_eval_reward": 104.0}
{"epoch": 356, "reward_mean": 46.92857142857143, "student_loss": null, "teacher_policy_loss": -22.012714385986328, "teacher_value_loss": 107.45891571044922, "teacher_entropy": 0.5606085658073425, "total_time": 1.4477856159210205, "rollout_time": 0.4611999988555908, "train_time": 0.8740332126617432, "student_train_time": 0.11195707321166992, "throughput": 1381.4199961695874, "inference_time": 0.054263883735984564, "env_time": 0.40693611511960626, "samples": 2000, "teacher_eval_reward": 339.0}
{"epoch": 357, "reward_mean": 45.55555555555556, "student_loss": null, "teacher_policy_loss": -20.572900772094727, "teacher_value_loss": 88.66236877441406, "teacher_entropy": 0.5546935200691223, "total_time": 1.3274071216583252, "rollout_time": 0.44457578659057617, "train_time": 0.870136022567749, "student_train_time": 0.01223444938659668, "throughput": 1506.69675291587, "inference_time": 0.055810165305956616, "env_time": 0.38876562128461956, "samples": 2000, "teacher_eval_reward": 108.0}
{"epoch": 358, "reward_mean": 50.76923076923077, "student_loss": null, "teacher_policy_loss": -23.659992218017578, "teacher_value_loss": 125.7025375366211, "teacher_entropy": 0.5696771144866943, "total_time": 1.4479281902313232, "rollout_time": 0.4492166042327881, "train_time": 0.9861197471618652, "student_train_time": 0.012160062789916992, "throughput": 1381.2839707751507, "inference_time": 0.05698761148232734, "env_time": 0.39222899275046075, "samples": 2000, "teacher_eval_reward": 99.0}
{"epoch": 359, "reward_mean": 44.81818181818182, "student_loss": null, "teacher_policy_loss": -21.037126541137695, "teacher_value_loss": 89.56333923339844, "teacher_entropy": 0.5598137974739075, "total_time": 1.30745267868042, "rollout_time": 0.45035552978515625, "train_time": 0.8498904705047607, "student_train_time": 0.006827592849731445, "throughput": 1529.692074223712, "inference_time": 0.05580406815352035, "env_time": 0.3945514616316359, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 360, "reward_mean": 49.926829268292686, "student_loss": null, "teacher_policy_loss": -22.016571044921875, "teacher_value_loss": 99.89804077148438, "teacher_entropy": 0.5676583051681519, "total_time": 1.3215651512145996, "rollout_time": 0.43372297286987305, "train_time": 0.8766918182373047, "student_train_time": 0.010771751403808594, "throughput": 1513.3570964411986, "inference_time": 0.05480224950588308, "env_time": 0.37892072336398996, "samples": 2000, "teacher_eval_reward": 109.0}
{"epoch": 361, "reward_mean": 46.5609756097561, "student_loss": null, "teacher_policy_loss": -23.317848205566406, "teacher_value_loss": 177.328125, "teacher_entropy": 0.5614745020866394, "total_time": 1.2560069561004639, "rollout_time": 0.42502903938293457, "train_time": 0.821448802947998, "student_train_time": 0.009168148040771484, "throughput": 1592.3478690033835, "inference_time": 0.05461049375298899, "env_time": 0.3704185456299456, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 362, "reward_mean": 50.11904761904762, "student_loss": null, "teacher_policy_loss": -22.27614974975586, "teacher_value_loss": 127.7015609741211, "teacher_entropy": 0.5700789093971252, "total_time": -1.3919801712036133, "rollout_time": 0.4304502010345459, "train_time": -1.8274080753326416, "student_train_time": 0.004626274108886719, "throughput": 200000000000.0, "inference_time": 0.053178422482233145, "env_time": 0.37727177855231275, "samples": 2000, "teacher_eval_reward": 164.0}
{"epoch": 363, "reward_mean": 46.11904761904762, "student_loss": null, "teacher_policy_loss": -22.008983612060547, "teacher_value_loss": 101.77349853515625, "teacher_entropy": 0.5496198534965515, "total_time": 1.2582082748413086, "rollout_time": 0.4283487796783447, "train_time": 0.8238239288330078, "student_train_time": 0.0056591033935546875, "throughput": 1589.5619509037563, "inference_time": 0.05393857375383959, "env_time": 0.37441020592450514, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 364, "reward_mean": 47.25, "student_loss": null, "teacher_policy_loss": -21.392812728881836, "teacher_value_loss": 114.13175964355469, "teacher_entropy": 0.5505630373954773, "total_time": 1.2288267612457275, "rollout_time": 0.44131946563720703, "train_time": 0.7820920944213867, "student_train_time": 0.005018711090087891, "throughput": 1627.5687208931654, "inference_time": 0.05701681297978212, "env_time": 0.3843026526574249, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 365, "reward_mean": 44.18604651162791, "student_loss": null, "teacher_policy_loss": -20.112117767333984, "teacher_value_loss": 86.1173095703125, "teacher_entropy": 0.5539573431015015, "total_time": 1.3137462139129639, "rollout_time": 0.43477678298950195, "train_time": 0.8728227615356445, "student_train_time": 0.005755186080932617, "throughput": 1522.3640447594855, "inference_time": 0.05574962070750189, "env_time": 0.37902716228200006, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 366, "reward_mean": 51.5, "student_loss": null, "teacher_policy_loss": -24.63514518737793, "teacher_value_loss": 123.70404815673828, "teacher_entropy": 0.549725353717804, "total_time": 1.3424363136291504, "rollout_time": 0.43427038192749023, "train_time": 0.903069019317627, "student_train_time": 0.00473332405090332, "throughput": 1489.828589777334, "inference_time": 0.05385254547945806, "env_time": 0.3804178364480322, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 367, "reward_mean": 51.31707317073171, "student_loss": null, "teacher_policy_loss": -21.564476013183594, "teacher_value_loss": 113.32832336425781, "teacher_entropy": 0.5508950352668762, "total_time": 1.2599689960479736, "rollout_time": 0.44925379753112793, "train_time": 0.8010315895080566, "student_train_time": 0.009277582168579102, "throughput": 1587.340645899393, "inference_time": 0.05754151897963311, "env_time": 0.3917122785514948, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 368, "reward_mean": 59.84848484848485, "student_loss": null, "teacher_policy_loss": -26.150959014892578, "teacher_value_loss": 152.09237670898438, "teacher_entropy": 0.5563819408416748, "total_time": 1.3152186870574951, "rollout_time": 0.43976497650146484, "train_time": 0.8629727363586426, "student_train_time": 0.01211404800415039, "throughput": 1520.659658869772, "inference_time": 0.05511938275412831, "env_time": 0.38464559374733653, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 369, "reward_mean": 49.95, "student_loss": null, "teacher_policy_loss": -22.176292419433594, "teacher_value_loss": 96.74562072753906, "teacher_entropy": 0.5529292225837708, "total_time": 1.7100889682769775, "rollout_time": 0.5113229751586914, "train_time": 1.0976645946502686, "student_train_time": 0.10067224502563477, "throughput": 1169.5297947071876, "inference_time": 0.06761835556972073, "env_time": 0.4437046195889707, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 370, "reward_mean": 51.473684210526315, "student_loss": null, "teacher_policy_loss": -23.30970001220703, "teacher_value_loss": 93.12366485595703, "teacher_entropy": 0.553260862827301, "total_time": 1.1995768547058105, "rollout_time": 0.4372279644012451, "train_time": 0.7554209232330322, "student_train_time": 0.0065615177154541016, "throughput": 1667.2545757732953, "inference_time": 0.05565128997841384, "env_time": 0.3815766744228313, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 371, "reward_mean": 50.26829268292683, "student_loss": null, "teacher_policy_loss": -21.93244171142578, "teacher_value_loss": 115.19508361816406, "teacher_entropy": 0.5517335534095764, "total_time": 1.2796554565429688, "rollout_time": 0.4402039051055908, "train_time": 0.8267276287078857, "student_train_time": 0.012363910675048828, "throughput": 1562.920698516041, "inference_time": 0.05631382423416653, "env_time": 0.3838900808714243, "samples": 2000, "teacher_eval_reward": 90.0}
{"epoch": 372, "reward_mean": 61.303030303030305, "student_loss": null, "teacher_policy_loss": -27.41547393798828, "teacher_value_loss": 192.64193725585938, "teacher_entropy": 0.5686034560203552, "total_time": 1.2179365158081055, "rollout_time": 0.4348015785217285, "train_time": 0.7720189094543457, "student_train_time": 0.010743379592895508, "throughput": 1642.1217149179508, "inference_time": 0.055413764766854, "env_time": 0.3793878137548745, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 373, "reward_mean": 48.142857142857146, "student_loss": null, "teacher_policy_loss": -21.010225296020508, "teacher_value_loss": 88.09889221191406, "teacher_entropy": 0.5474803447723389, "total_time": 1.2819161415100098, "rollout_time": 0.4427039623260498, "train_time": 0.8253037929534912, "student_train_time": 0.01355123519897461, "throughput": 1560.1644563459015, "inference_time": 0.055025465779181104, "env_time": 0.3876784965468687, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 374, "reward_mean": 45.95454545454545, "student_loss": null, "teacher_policy_loss": -20.381502151489258, "teacher_value_loss": 75.89965057373047, "teacher_entropy": 0.553844153881073, "total_time": -1.4526257514953613, "rollout_time": 0.4384298324584961, "train_time": -1.8992183208465576, "student_train_time": 0.007706642150878906, "throughput": 200000000000.0, "inference_time": 0.05324064849082788, "env_time": 0.3851891839676682, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 375, "reward_mean": 46.75609756097561, "student_loss": null, "teacher_policy_loss": -22.58446502685547, "teacher_value_loss": 133.1360321044922, "teacher_entropy": 0.5570368766784668, "total_time": 1.2651472091674805, "rollout_time": 0.44844889640808105, "train_time": 0.8010432720184326, "student_train_time": 0.015293598175048828, "throughput": 1580.8437038058862, "inference_time": 0.05593352173855237, "env_time": 0.3925153746695287, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 376, "reward_mean": 47.26190476190476, "student_loss": null, "teacher_policy_loss": -21.456710815429688, "teacher_value_loss": 84.3552017211914, "teacher_entropy": 0.5651388764381409, "total_time": 1.200272560119629, "rollout_time": 0.4222450256347656, "train_time": 0.766179084777832, "student_train_time": 0.011492013931274414, "throughput": 1666.2881969080954, "inference_time": 0.05458921249191917, "env_time": 0.36765581314284645, "samples": 2000, "teacher_eval_reward": 101.0}
{"epoch": 377, "reward_mean": 45.86046511627907, "student_loss": null, "teacher_policy_loss": -20.604724884033203, "teacher_value_loss": 76.22345733642578, "teacher_entropy": 0.5548932552337646, "total_time": 1.3810133934020996, "rollout_time": 0.43302059173583984, "train_time": 0.9311277866363525, "student_train_time": 0.016449689865112305, "throughput": 1448.2118779985465, "inference_time": 0.0525515454573906, "env_time": 0.38046904627844924, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 378, "reward_mean": 49.04761904761905, "student_loss": null, "teacher_policy_loss": -22.007354736328125, "teacher_value_loss": 106.99188995361328, "teacher_entropy": 0.5584815740585327, "total_time": 1.2724902629852295, "rollout_time": 0.4297139644622803, "train_time": 0.8276379108428955, "student_train_time": 0.014781713485717773, "throughput": 1571.7212604111023, "inference_time": 0.05367684229531733, "env_time": 0.37603712216696294, "samples": 2000, "teacher_eval_reward": 209.0}
{"epoch": 379, "reward_mean": 54.542857142857144, "student_loss": null, "teacher_policy_loss": -25.20383644104004, "teacher_value_loss": 133.78924560546875, "teacher_entropy": 0.5607379078865051, "total_time": 1.3362481594085693, "rollout_time": 0.4470820426940918, "train_time": 0.8815689086914062, "student_train_time": 0.007234811782836914, "throughput": 1496.7279737060298, "inference_time": 0.056464676305040484, "env_time": 0.3906173663890513, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 380, "reward_mean": 47.81818181818182, "student_loss": null, "teacher_policy_loss": -20.735143661499023, "teacher_value_loss": 100.78067779541016, "teacher_entropy": 0.5541121363639832, "total_time": 1.2880513668060303, "rollout_time": 0.4253666400909424, "train_time": 0.815781831741333, "student_train_time": 0.0465090274810791, "throughput": 1552.7331064128152, "inference_time": 0.05446821948316938, "env_time": 0.370898420607773, "samples": 2000, "teacher_eval_reward": 340.0}
{"epoch": 381, "reward_mean": 47.92307692307692, "student_loss": null, "teacher_policy_loss": -22.399044036865234, "teacher_value_loss": 99.5953369140625, "teacher_entropy": 0.5585731863975525, "total_time": 1.2582242488861084, "rollout_time": 0.4343078136444092, "train_time": 0.8143637180328369, "student_train_time": 0.009199142456054688, "throughput": 1589.541770292996, "inference_time": 0.054976372310193256, "env_time": 0.3793314413342159, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 382, "reward_mean": 53.15384615384615, "student_loss": null, "teacher_policy_loss": -22.029098510742188, "teacher_value_loss": 95.43869018554688, "teacher_entropy": 0.5604433417320251, "total_time": 1.2782471179962158, "rollout_time": 0.42875075340270996, "train_time": 0.8442935943603516, "student_train_time": 0.004837751388549805, "throughput": 1564.642682813325, "inference_time": 0.054754465261794394, "env_time": 0.37399628814091557, "samples": 2000, "teacher_eval_reward": 269.0}
{"epoch": 383, "reward_mean": 46.06818181818182, "student_loss": null, "teacher_policy_loss": -20.45928955078125, "teacher_value_loss": 84.4274673461914, "teacher_entropy": 0.5640859603881836, "total_time": 1.2890288829803467, "rollout_time": 0.43388915061950684, "train_time": 0.8425045013427734, "student_train_time": 0.012277603149414062, "throughput": 1551.5556140028657, "inference_time": 0.05552771349721297, "env_time": 0.37836143712229386, "samples": 2000, "teacher_eval_reward": 120.0}
{"epoch": 384, "reward_mean": 49.475, "student_loss": null, "teacher_policy_loss": -21.900585174560547, "teacher_value_loss": 110.35736083984375, "teacher_entropy": 0.5705186724662781, "total_time": 1.432236671447754, "rollout_time": 0.43909192085266113, "train_time": 0.981611967086792, "student_train_time": 0.011170387268066406, "throughput": 1396.4172541248588, "inference_time": 0.054766557756011025, "env_time": 0.3843253630966501, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 385, "reward_mean": 49.76923076923077, "student_loss": null, "teacher_policy_loss": -22.446605682373047, "teacher_value_loss": 116.74431610107422, "teacher_entropy": 0.5576931238174438, "total_time": 1.2867071628570557, "rollout_time": 0.42693662643432617, "train_time": 0.8545634746551514, "student_train_time": 0.004827260971069336, "throughput": 1554.355223731809, "inference_time": 0.053822951260372065, "env_time": 0.3731136751739541, "samples": 2000, "teacher_eval_reward": 60.0}
{"epoch": 386, "reward_mean": 51.7, "student_loss": null, "teacher_policy_loss": -21.838850021362305, "teacher_value_loss": 109.08643341064453, "teacher_entropy": 0.5608673095703125, "total_time": 1.2137258052825928, "rollout_time": 0.4351317882537842, "train_time": 0.7719788551330566, "student_train_time": 0.0062487125396728516, "throughput": 1647.8186352265438, "inference_time": 0.05302708777526277, "env_time": 0.3821047004785214, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 387, "reward_mean": 45.0, "student_loss": null, "teacher_policy_loss": -20.60431480407715, "teacher_value_loss": 104.73202514648438, "teacher_entropy": 0.5584502220153809, "total_time": 1.2652196884155273, "rollout_time": 0.4265248775482178, "train_time": 0.8325023651123047, "student_train_time": 0.0057790279388427734, "throughput": 1580.7531437521811, "inference_time": 0.058395055233631865, "env_time": 0.3681298223145859, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 388, "reward_mean": 53.62162162162162, "student_loss": null, "teacher_policy_loss": -22.561443328857422, "teacher_value_loss": 81.33634185791016, "teacher_entropy": 0.5643876194953918, "total_time": 1.2202503681182861, "rollout_time": 0.42673659324645996, "train_time": 0.7875876426696777, "student_train_time": 0.0055239200592041016, "throughput": 1639.0079054711894, "inference_time": 0.05510131253140571, "env_time": 0.37163528071505425, "samples": 2000, "teacher_eval_reward": 287.0}
{"epoch": 389, "reward_mean": 51.025, "student_loss": null, "teacher_policy_loss": -24.448623657226562, "teacher_value_loss": 150.06298828125, "teacher_entropy": 0.5567733645439148, "total_time": 1.2503955364227295, "rollout_time": 0.430023193359375, "train_time": 0.8057503700256348, "student_train_time": 0.01426386833190918, "throughput": 1599.4938735320684, "inference_time": 0.0554094877334137, "env_time": 0.3746137056259613, "samples": 2000, "teacher_eval_reward": 419.0}
{"epoch": 390, "reward_mean": 47.95, "student_loss": null, "teacher_policy_loss": -22.94611358642578, "teacher_value_loss": 138.9048309326172, "teacher_entropy": 0.5538790822029114, "total_time": 1.2880499362945557, "rollout_time": 0.4749150276184082, "train_time": 0.8031909465789795, "student_train_time": 0.009589195251464844, "throughput": 1552.7348308820795, "inference_time": 0.06911595347810362, "env_time": 0.4057990741403046, "samples": 2000, "teacher_eval_reward": 307.0}
{"epoch": 391, "reward_mean": 51.6, "student_loss": null, "teacher_policy_loss": -23.818973541259766, "teacher_value_loss": 158.36683654785156, "teacher_entropy": 0.5549014806747437, "total_time": 1.2578988075256348, "rollout_time": 0.4317634105682373, "train_time": 0.8147866725921631, "student_train_time": 0.01098179817199707, "throughput": 1589.9530137357588, "inference_time": 0.05482912475054036, "env_time": 0.37693428581769695, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 392, "reward_mean": 47.595238095238095, "student_loss": null, "teacher_policy_loss": -22.348039627075195, "teacher_value_loss": 137.1926727294922, "teacher_entropy": 0.5528623461723328, "total_time": 1.4174764156341553, "rollout_time": 0.42766833305358887, "train_time": 0.9838757514953613, "student_train_time": 0.005567312240600586, "throughput": 1410.9582197917794, "inference_time": 0.05633616852355772, "env_time": 0.37133216453003115, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 393, "reward_mean": 52.63157894736842, "student_loss": null, "teacher_policy_loss": -23.246599197387695, "teacher_value_loss": 141.51388549804688, "teacher_entropy": 0.5501905679702759, "total_time": 1.3266310691833496, "rollout_time": 0.4314460754394531, "train_time": 0.8850600719451904, "student_train_time": 0.009771108627319336, "throughput": 1507.5781401917295, "inference_time": 0.05349254193242814, "env_time": 0.377953533507025, "samples": 2000, "teacher_eval_reward": 488.0}
{"epoch": 394, "reward_mean": 52.10526315789474, "student_loss": null, "teacher_policy_loss": -24.68684959411621, "teacher_value_loss": 147.26016235351562, "teacher_entropy": 0.5587464570999146, "total_time": 1.5016741752624512, "rollout_time": 0.4304230213165283, "train_time": 1.0600743293762207, "student_train_time": 0.010743856430053711, "throughput": 1331.8468366484728, "inference_time": 0.05549707552563632, "env_time": 0.374925945790892, "samples": 2000, "teacher_eval_reward": 219.0}
{"epoch": 395, "reward_mean": 45.044444444444444, "student_loss": null, "teacher_policy_loss": -20.4477481842041, "teacher_value_loss": 117.5336685180664, "teacher_entropy": 0.538975715637207, "total_time": 1.4038736820220947, "rollout_time": 0.45168089866638184, "train_time": 0.9404902458190918, "student_train_time": 0.011268377304077148, "throughput": 1424.6295985257477, "inference_time": 0.05609141402419482, "env_time": 0.395589484642187, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 396, "reward_mean": 48.75, "student_loss": null, "teacher_policy_loss": -22.10953140258789, "teacher_value_loss": 104.93119049072266, "teacher_entropy": 0.5466265678405762, "total_time": 1.2629334926605225, "rollout_time": 0.4387974739074707, "train_time": 0.816758394241333, "student_train_time": 0.006959438323974609, "throughput": 1583.6146650816565, "inference_time": 0.055887149515911005, "env_time": 0.3829103243915597, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 397, "reward_mean": 40.97959183673469, "student_loss": null, "teacher_policy_loss": -18.64691925048828, "teacher_value_loss": 65.4425277709961, "teacher_entropy": 0.5322182178497314, "total_time": 1.283351182937622, "rollout_time": 0.43494319915771484, "train_time": 0.8403704166412354, "student_train_time": 0.007682085037231445, "throughput": 1558.4198827182684, "inference_time": 0.054741449290304445, "env_time": 0.3802017498674104, "samples": 2000, "teacher_eval_reward": 190.0}
{"epoch": 398, "reward_mean": 48.34146341463415, "student_loss": null, "teacher_policy_loss": -23.79047393798828, "teacher_value_loss": 158.46499633789062, "teacher_entropy": 0.5507685542106628, "total_time": 1.1994233131408691, "rollout_time": 0.43062400817871094, "train_time": 0.7625629901885986, "student_train_time": 0.005826711654663086, "throughput": 1667.468005739109, "inference_time": 0.055151399721580674, "env_time": 0.37547260845713026, "samples": 2000, "teacher_eval_reward": 262.0}
{"epoch": 399, "reward_mean": 50.75, "student_loss": null, "teacher_policy_loss": -23.707822799682617, "teacher_value_loss": 174.74705505371094, "teacher_entropy": 0.5541919469833374, "total_time": 1.375342845916748, "rollout_time": 0.43447399139404297, "train_time": 0.9190497398376465, "student_train_time": 0.02146005630493164, "throughput": 1454.182864976391, "inference_time": 0.05457247573394852, "env_time": 0.37990151566009445, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 400, "reward_mean": 50.025, "student_loss": null, "teacher_policy_loss": -22.019601821899414, "teacher_value_loss": 153.6165008544922, "teacher_entropy": 0.5617374181747437, "total_time": 1.2502694129943848, "rollout_time": 0.43755364418029785, "train_time": 0.8076083660125732, "student_train_time": 0.004754781723022461, "throughput": 1599.6552256765337, "inference_time": 0.05586567301361356, "env_time": 0.3816879711666843, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 401, "reward_mean": 45.61363636363637, "student_loss": null, "teacher_policy_loss": -20.118953704833984, "teacher_value_loss": 109.74024200439453, "teacher_entropy": 0.5598178505897522, "total_time": 1.3309760093688965, "rollout_time": 0.4335041046142578, "train_time": 0.8843896389007568, "student_train_time": 0.012718439102172852, "throughput": 1502.6566864629904, "inference_time": 0.05572558455787657, "env_time": 0.37777852005638124, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 402, "reward_mean": 50.175, "student_loss": null, "teacher_policy_loss": -22.452823638916016, "teacher_value_loss": 171.97618103027344, "teacher_entropy": 0.5564355254173279, "total_time": 1.44315505027771, "rollout_time": 0.4670712947845459, "train_time": 0.9642744064331055, "student_train_time": 0.011362314224243164, "throughput": 1385.852476222243, "inference_time": 0.05827091949140595, "env_time": 0.40880037529313995, "samples": 2000, "teacher_eval_reward": 105.0}
{"epoch": 403, "reward_mean": 45.44186046511628, "student_loss": null, "teacher_policy_loss": -20.842004776000977, "teacher_value_loss": 104.29161834716797, "teacher_entropy": 0.5482401847839355, "total_time": 1.3044664859771729, "rollout_time": 0.47435760498046875, "train_time": 0.8232250213623047, "student_train_time": 0.006440401077270508, "throughput": 1533.1938547288967, "inference_time": 0.05856257393679698, "env_time": 0.41579503104367177, "samples": 2000, "teacher_eval_reward": 431.0}
{"epoch": 404, "reward_mean": 46.36363636363637, "student_loss": null, "teacher_policy_loss": -20.18048858642578, "teacher_value_loss": 99.5029525756836, "teacher_entropy": 0.5534704327583313, "total_time": 1.2247734069824219, "rollout_time": 0.4280436038970947, "train_time": 0.7889668941497803, "student_train_time": 0.007397651672363281, "throughput": 1632.9551152874633, "inference_time": 0.055736262263963, "env_time": 0.3723073416331317, "samples": 2000, "teacher_eval_reward": 145.0}
{"epoch": 405, "reward_mean": 54.77777777777778, "student_loss": null, "teacher_policy_loss": -24.421541213989258, "teacher_value_loss": 123.81309509277344, "teacher_entropy": 0.5555787086486816, "total_time": 1.3199477195739746, "rollout_time": 0.43011999130249023, "train_time": 0.8810460567474365, "student_train_time": 0.008424758911132812, "throughput": 1515.2115272001217, "inference_time": 0.05288293102057651, "env_time": 0.3772370602819137, "samples": 2000, "teacher_eval_reward": 317.0}
{"epoch": 406, "reward_mean": 57.857142857142854, "student_loss": null, "teacher_policy_loss": -26.836002349853516, "teacher_value_loss": 186.90496826171875, "teacher_entropy": 0.5642139911651611, "total_time": 1.3470370769500732, "rollout_time": 0.4603843688964844, "train_time": 0.8787188529968262, "student_train_time": 0.0075643062591552734, "throughput": 1484.7401264769553, "inference_time": 0.058586517021467444, "env_time": 0.40179785187501693, "samples": 2000, "teacher_eval_reward": 103.0}
{"epoch": 407, "reward_mean": 49.97560975609756, "student_loss": null, "teacher_policy_loss": -22.56312370300293, "teacher_value_loss": 139.58804321289062, "teacher_entropy": 0.5574013590812683, "total_time": 1.2456529140472412, "rollout_time": 0.4293241500854492, "train_time": 0.8096225261688232, "student_train_time": 0.006348371505737305, "throughput": 1605.5836882376934, "inference_time": 0.054896415012990474, "env_time": 0.37442773507245874, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 408, "reward_mean": 54.166666666666664, "student_loss": null, "teacher_policy_loss": -24.476465225219727, "teacher_value_loss": 119.61621856689453, "teacher_entropy": 0.547289252281189, "total_time": 1.3429617881774902, "rollout_time": 0.46689629554748535, "train_time": 0.8621401786804199, "student_train_time": 0.013543367385864258, "throughput": 1489.2456491365735, "inference_time": 0.056396314492303645, "env_time": 0.4104999810551817, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 409, "reward_mean": 53.67567567567568, "student_loss": null, "teacher_policy_loss": -24.495458602905273, "teacher_value_loss": 138.08798217773438, "teacher_entropy": 0.5502814650535583, "total_time": 1.2625412940979004, "rollout_time": 0.4249308109283447, "train_time": 0.8323299884796143, "student_train_time": 0.004856109619140625, "throughput": 1584.1066025717773, "inference_time": 0.054363315995942685, "env_time": 0.37056749493240204, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 410, "reward_mean": 49.16279069767442, "student_loss": null, "teacher_policy_loss": -22.583913803100586, "teacher_value_loss": 98.47339630126953, "teacher_entropy": 0.5475934743881226, "total_time": 1.357581377029419, "rollout_time": 0.456190824508667, "train_time": 0.8868834972381592, "student_train_time": 0.014002561569213867, "throughput": 1473.2081876198718, "inference_time": 0.05704806774338067, "env_time": 0.3991427567652863, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 411, "reward_mean": 54.02777777777778, "student_loss": null, "teacher_policy_loss": -23.924488067626953, "teacher_value_loss": 123.72762298583984, "teacher_entropy": 0.5608541965484619, "total_time": 1.2988717555999756, "rollout_time": 0.4526238441467285, "train_time": 0.802757978439331, "student_train_time": 0.04307413101196289, "throughput": 1539.797898735706, "inference_time": 0.059386805769463535, "env_time": 0.393237038377265, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 412, "reward_mean": 44.34090909090909, "student_loss": null, "teacher_policy_loss": -19.792682647705078, "teacher_value_loss": 70.12159729003906, "teacher_entropy": 0.5547969341278076, "total_time": 1.210400104522705, "rollout_time": 0.4374856948852539, "train_time": 0.7651112079620361, "student_train_time": 0.007450580596923828, "throughput": 1652.3461891046816, "inference_time": 0.0551320944850886, "env_time": 0.3823536004001653, "samples": 2000, "teacher_eval_reward": 155.0}
{"epoch": 413, "reward_mean": 53.5945945945946, "student_loss": null, "teacher_policy_loss": -24.204572677612305, "teacher_value_loss": 128.54739379882812, "teacher_entropy": 0.563168466091156, "total_time": 1.3218302726745605, "rollout_time": 0.45822858810424805, "train_time": 0.8580322265625, "student_train_time": 0.005151033401489258, "throughput": 1513.0535601618858, "inference_time": 0.05697723804223642, "env_time": 0.4012513500620116, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 414, "reward_mean": 54.973684210526315, "student_loss": null, "teacher_policy_loss": -25.366592407226562, "teacher_value_loss": 221.28440856933594, "teacher_entropy": 0.5517032742500305, "total_time": 1.2714574337005615, "rollout_time": 0.4419889450073242, "train_time": 0.8095767498016357, "student_train_time": 0.01944446563720703, "throughput": 1572.997999767105, "inference_time": 0.05683823151048273, "env_time": 0.3851507134968415, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 415, "reward_mean": 48.46153846153846, "student_loss": null, "teacher_policy_loss": -22.90519905090332, "teacher_value_loss": 127.20624542236328, "teacher_entropy": 0.5482041239738464, "total_time": 1.1871585845947266, "rollout_time": 0.43233656883239746, "train_time": 0.7458541393280029, "student_train_time": 0.008538961410522461, "throughput": 1684.6948890849003, "inference_time": 0.056360885753747425, "env_time": 0.37597568307865004, "samples": 2000, "teacher_eval_reward": 90.0}
{"epoch": 416, "reward_mean": 53.73684210526316, "student_loss": null, "teacher_policy_loss": -23.073759078979492, "teacher_value_loss": 98.30519104003906, "teacher_entropy": 0.555385410785675, "total_time": 1.3510313034057617, "rollout_time": 0.42865586280822754, "train_time": 0.8868968486785889, "student_train_time": 0.03506326675415039, "throughput": 1480.3505995444211, "inference_time": 0.05377256524116092, "env_time": 0.3748832975670666, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 417, "reward_mean": 46.18181818181818, "student_loss": null, "teacher_policy_loss": -19.358341217041016, "teacher_value_loss": 105.6143569946289, "teacher_entropy": 0.5498310923576355, "total_time": 1.162306547164917, "rollout_time": 0.4163508415222168, "train_time": 0.7406325340270996, "student_train_time": 0.004923582077026367, "throughput": 1720.7164537430972, "inference_time": 0.05295701827162702, "env_time": 0.3633938232505898, "samples": 2000, "teacher_eval_reward": 102.0}
{"epoch": 418, "reward_mean": 48.78048780487805, "student_loss": null, "teacher_policy_loss": -22.6938533782959, "teacher_value_loss": 118.83358764648438, "teacher_entropy": 0.5542142987251282, "total_time": 1.2620408535003662, "rollout_time": 0.42220187187194824, "train_time": 0.8329207897186279, "student_train_time": 0.006570339202880859, "throughput": 1584.7347528036419, "inference_time": 0.05295030421075353, "env_time": 0.3692515676611947, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 419, "reward_mean": 50.0, "student_loss": null, "teacher_policy_loss": -24.502655029296875, "teacher_value_loss": 113.63765716552734, "teacher_entropy": 0.5580891966819763, "total_time": 1.2814717292785645, "rollout_time": 0.4767136573791504, "train_time": 0.7960371971130371, "student_train_time": 0.008240461349487305, "throughput": 1560.7055187444114, "inference_time": 0.05920384603268758, "env_time": 0.4175098113464628, "samples": 2000, "teacher_eval_reward": 78.0}
{"epoch": 420, "reward_mean": 54.24390243902439, "student_loss": null, "teacher_policy_loss": -21.600723266601562, "teacher_value_loss": 94.00353240966797, "teacher_entropy": 0.5522695183753967, "total_time": 1.3149135112762451, "rollout_time": 0.4397459030151367, "train_time": 0.8684313297271729, "student_train_time": 0.006331682205200195, "throughput": 1521.0125858839301, "inference_time": 0.05543843420309713, "env_time": 0.3843074688120396, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 421, "reward_mean": 55.0, "student_loss": null, "teacher_policy_loss": -24.431753158569336, "teacher_value_loss": 117.83734130859375, "teacher_entropy": 0.552634596824646, "total_time": 1.2901999950408936, "rollout_time": 0.4401228427886963, "train_time": 0.8417291641235352, "student_train_time": 0.007979631423950195, "throughput": 1550.1472699483377, "inference_time": 0.05730481997670722, "env_time": 0.38281802281198907, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 422, "reward_mean": 51.45945945945946, "student_loss": null, "teacher_policy_loss": -22.41570472717285, "teacher_value_loss": 96.79634857177734, "teacher_entropy": 0.5527765154838562, "total_time": 1.3428285121917725, "rollout_time": 0.43642115592956543, "train_time": 0.9004857540130615, "student_train_time": 0.005402565002441406, "throughput": 1489.3934570510337, "inference_time": 0.05483662196093064, "env_time": 0.3815845339686348, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 423, "reward_mean": 51.05128205128205, "student_loss": null, "teacher_policy_loss": -21.939844131469727, "teacher_value_loss": 104.7962417602539, "teacher_entropy": 0.5469752550125122, "total_time": 1.2563495635986328, "rollout_time": 0.43201255798339844, "train_time": 0.8141820430755615, "student_train_time": 0.009791135787963867, "throughput": 1591.913634507332, "inference_time": 0.05562736497995502, "env_time": 0.3763851930034434, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 424, "reward_mean": 56.333333333333336, "student_loss": null, "teacher_policy_loss": -25.853557586669922, "teacher_value_loss": 175.73443603515625, "teacher_entropy": 0.5578374266624451, "total_time": 1.3030216693878174, "rollout_time": 0.4326136112213135, "train_time": 0.8621268272399902, "student_train_time": 0.007921457290649414, "throughput": 1534.8938908588032, "inference_time": 0.056532388500272646, "env_time": 0.37608122272104083, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 425, "reward_mean": 50.46341463414634, "student_loss": null, "teacher_policy_loss": -21.353389739990234, "teacher_value_loss": 79.32317352294922, "teacher_entropy": 0.5419952869415283, "total_time": 1.3352560997009277, "rollout_time": 0.46132993698120117, "train_time": 0.8607146739959717, "student_train_time": 0.012852191925048828, "throughput": 1497.8400027140578, "inference_time": 0.060570280695174006, "env_time": 0.40075965628602717, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 426, "reward_mean": 50.28947368421053, "student_loss": null, "teacher_policy_loss": -22.106027603149414, "teacher_value_loss": 89.31326293945312, "teacher_entropy": 0.5569776892662048, "total_time": -1.3071999549865723, "rollout_time": -2.1585869789123535, "train_time": 0.8373701572418213, "student_train_time": 0.013647794723510742, "throughput": 200000000000.0, "inference_time": 0.057741019776585745, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 68.0}
{"epoch": 427, "reward_mean": 44.27272727272727, "student_loss": null, "teacher_policy_loss": -20.202985763549805, "teacher_value_loss": 75.10794830322266, "teacher_entropy": 0.5355460047721863, "total_time": 1.3461275100708008, "rollout_time": 0.424835205078125, "train_time": 0.9114739894866943, "student_train_time": 0.009465932846069336, "throughput": 1485.7433527190958, "inference_time": 0.052506401523714885, "env_time": 0.3723288035544101, "samples": 2000, "teacher_eval_reward": 90.0}
{"epoch": 428, "reward_mean": 60.8235294117647, "student_loss": null, "teacher_policy_loss": -24.712413787841797, "teacher_value_loss": 101.3081283569336, "teacher_entropy": 0.5448247790336609, "total_time": 1.430558443069458, "rollout_time": 0.6030421257019043, "train_time": 0.815497875213623, "student_train_time": 0.011670589447021484, "throughput": 1398.0554305133649, "inference_time": 0.18553646177497285, "env_time": 0.41750566392693145, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 429, "reward_mean": 55.142857142857146, "student_loss": null, "teacher_policy_loss": -24.031579971313477, "teacher_value_loss": 98.15908813476562, "teacher_entropy": 0.5449742674827576, "total_time": 1.2724823951721191, "rollout_time": 0.4367985725402832, "train_time": 0.8257694244384766, "student_train_time": 0.009556770324707031, "throughput": 1571.7309784309236, "inference_time": 0.05565257596936135, "env_time": 0.38114599657092185, "samples": 2000, "teacher_eval_reward": 55.0}
{"epoch": 430, "reward_mean": 52.205128205128204, "student_loss": null, "teacher_policy_loss": -23.52780532836914, "teacher_value_loss": 147.7902069091797, "teacher_entropy": 0.5338042378425598, "total_time": 1.3498284816741943, "rollout_time": 0.440166711807251, "train_time": 0.9045443534851074, "student_train_time": 0.004720449447631836, "throughput": 1481.66972852684, "inference_time": 0.056276015218827524, "env_time": 0.38389069658842345, "samples": 2000, "teacher_eval_reward": 53.0}
{"epoch": 431, "reward_mean": 56.02777777777778, "student_loss": null, "teacher_policy_loss": -23.667024612426758, "teacher_value_loss": 129.30677795410156, "teacher_entropy": 0.5442445874214172, "total_time": 1.248777151107788, "rollout_time": 0.44136857986450195, "train_time": 0.8013498783111572, "student_train_time": 0.005699634552001953, "throughput": 1601.5667793295252, "inference_time": 0.057478953518511844, "env_time": 0.3838896263459901, "samples": 2000, "teacher_eval_reward": 91.0}
{"epoch": 432, "reward_mean": 49.8780487804878, "student_loss": null, "teacher_policy_loss": -22.8514461517334, "teacher_value_loss": 151.8623504638672, "teacher_entropy": 0.5358924269676208, "total_time": 1.3154487609863281, "rollout_time": 0.46297693252563477, "train_time": 0.837838888168335, "student_train_time": 0.0142669677734375, "throughput": 1520.3936932521742, "inference_time": 0.05705337172730651, "env_time": 0.40592356079832825, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 433, "reward_mean": 44.71111111111111, "student_loss": null, "teacher_policy_loss": -18.967864990234375, "teacher_value_loss": 93.59344482421875, "teacher_entropy": 0.5339794754981995, "total_time": 1.3227531909942627, "rollout_time": 0.44935178756713867, "train_time": 0.8655509948730469, "student_train_time": 0.007362842559814453, "throughput": 1511.9978644668224, "inference_time": 0.056072619978294824, "env_time": 0.39327916758884385, "samples": 2000, "teacher_eval_reward": 55.0}
{"epoch": 434, "reward_mean": 50.84615384615385, "student_loss": null, "teacher_policy_loss": -21.28795623779297, "teacher_value_loss": 106.07976531982422, "teacher_entropy": 0.5255686044692993, "total_time": 1.3088679313659668, "rollout_time": 0.4385380744934082, "train_time": 0.8585145473480225, "student_train_time": 0.011444807052612305, "throughput": 1528.0380488142534, "inference_time": 0.054144180450748536, "env_time": 0.38439389404265967, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 435, "reward_mean": 53.270270270270274, "student_loss": null, "teacher_policy_loss": -24.590801239013672, "teacher_value_loss": 210.44847106933594, "teacher_entropy": 0.5357086062431335, "total_time": 1.2782008647918701, "rollout_time": 0.46127820014953613, "train_time": 0.8097825050354004, "student_train_time": 0.006774425506591797, "throughput": 1564.699301252359, "inference_time": 0.06055719700816553, "env_time": 0.4007210031413706, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 436, "reward_mean": 54.810810810810814, "student_loss": null, "teacher_policy_loss": -22.74561882019043, "teacher_value_loss": 107.94660949707031, "teacher_entropy": 0.5461043119430542, "total_time": 1.2203030586242676, "rollout_time": 0.44126009941101074, "train_time": 0.7678358554840088, "student_train_time": 0.010758399963378906, "throughput": 1638.9371360379437, "inference_time": 0.056445372005327954, "env_time": 0.3848147274056828, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 437, "reward_mean": 48.48780487804878, "student_loss": null, "teacher_policy_loss": -20.9538516998291, "teacher_value_loss": 101.0213394165039, "teacher_entropy": 0.5354350805282593, "total_time": 1.3152108192443848, "rollout_time": 0.44864511489868164, "train_time": 0.8527584075927734, "student_train_time": 0.013422966003417969, "throughput": 1520.668755712518, "inference_time": 0.05845037996004976, "env_time": 0.3901947349386319, "samples": 2000, "teacher_eval_reward": 68.0}
{"epoch": 438, "reward_mean": 58.38235294117647, "student_loss": null, "teacher_policy_loss": -25.393016815185547, "teacher_value_loss": 197.95343017578125, "teacher_entropy": 0.5249195098876953, "total_time": 1.2020127773284912, "rollout_time": 0.42145729064941406, "train_time": 0.7753298282623291, "student_train_time": 0.004824161529541016, "throughput": 1663.8758237204922, "inference_time": 0.052732993790414184, "env_time": 0.3687242968589999, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 439, "reward_mean": 51.675, "student_loss": null, "teacher_policy_loss": -20.362695693969727, "teacher_value_loss": 107.6565170288086, "teacher_entropy": 0.515484631061554, "total_time": 1.3662714958190918, "rollout_time": 0.45387768745422363, "train_time": 0.8971545696258545, "student_train_time": 0.014858722686767578, "throughput": 1463.8379019983743, "inference_time": 0.055293179331783904, "env_time": 0.39858450812243973, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 440, "reward_mean": 53.888888888888886, "student_loss": null, "teacher_policy_loss": -23.20513916015625, "teacher_value_loss": 141.905029296875, "teacher_entropy": 0.5170928835868835, "total_time": 1.3372411727905273, "rollout_time": 0.5645883083343506, "train_time": 0.7499799728393555, "student_train_time": 0.022257328033447266, "throughput": 1495.6165280391729, "inference_time": 0.07973973379739618, "env_time": 0.4848485745369544, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 441, "reward_mean": 47.714285714285715, "student_loss": null, "teacher_policy_loss": -20.64694595336914, "teacher_value_loss": 81.50550079345703, "teacher_entropy": 0.5368401408195496, "total_time": 1.2694215774536133, "rollout_time": 0.43155860900878906, "train_time": 0.8241677284240723, "student_train_time": 0.013316869735717773, "throughput": 1575.5207218171643, "inference_time": 0.05400389773421921, "env_time": 0.37755471127456985, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 442, "reward_mean": 53.111111111111114, "student_loss": null, "teacher_policy_loss": -21.182546615600586, "teacher_value_loss": 112.14473724365234, "teacher_entropy": 0.510021984577179, "total_time": 1.2091710567474365, "rollout_time": 0.43562746047973633, "train_time": 0.7598958015441895, "student_train_time": 0.013220787048339844, "throughput": 1654.0256970587964, "inference_time": 0.056364866975854966, "env_time": 0.37926259350388136, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 443, "reward_mean": 54.21052631578947, "student_loss": null, "teacher_policy_loss": -20.790550231933594, "teacher_value_loss": 126.50079345703125, "teacher_entropy": 0.4709447920322418, "total_time": 1.2147881984710693, "rollout_time": 0.42253589630126953, "train_time": 0.7871198654174805, "student_train_time": 0.004781246185302734, "throughput": 1646.3775352091807, "inference_time": 0.054357221226382535, "env_time": 0.368178675074887, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 444, "reward_mean": 52.0, "student_loss": null, "teacher_policy_loss": -20.641918182373047, "teacher_value_loss": 97.82398223876953, "teacher_entropy": 0.5014479160308838, "total_time": 1.1975739002227783, "rollout_time": 0.42692065238952637, "train_time": 0.7601916790008545, "student_train_time": 0.010015010833740234, "throughput": 1670.0430759454182, "inference_time": 0.053110281012777705, "env_time": 0.37381037137674866, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 445, "reward_mean": 56.88235294117647, "student_loss": null, "teacher_policy_loss": -25.852758407592773, "teacher_value_loss": 183.50987243652344, "teacher_entropy": 0.5391925573348999, "total_time": 1.2193658351898193, "rollout_time": 0.41964101791381836, "train_time": 0.788062334060669, "student_train_time": 0.01130819320678711, "throughput": 1640.1968484615275, "inference_time": 0.05307151875422278, "env_time": 0.3665694991595956, "samples": 2000, "teacher_eval_reward": 70.0}
{"epoch": 446, "reward_mean": 47.35, "student_loss": null, "teacher_policy_loss": -21.288379669189453, "teacher_value_loss": 100.94269561767578, "teacher_entropy": 0.5110515356063843, "total_time": 1.1929447650909424, "rollout_time": 0.44478464126586914, "train_time": 0.7333307266235352, "student_train_time": 0.014448404312133789, "throughput": 1676.523556266692, "inference_time": 0.05457849499180156, "env_time": 0.3902061462740676, "samples": 2000, "teacher_eval_reward": 45.0}
{"epoch": 447, "reward_mean": 51.68292682926829, "student_loss": null, "teacher_policy_loss": -21.937862396240234, "teacher_value_loss": 138.69451904296875, "teacher_entropy": 0.5049380660057068, "total_time": 1.163785457611084, "rollout_time": 0.4228024482727051, "train_time": 0.7340590953826904, "student_train_time": 0.006576061248779297, "throughput": 1718.5298088407321, "inference_time": 0.05363343777389673, "env_time": 0.36916901049880835, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 448, "reward_mean": 54.85294117647059, "student_loss": null, "teacher_policy_loss": -25.194517135620117, "teacher_value_loss": 140.92909240722656, "teacher_entropy": 0.5070709586143494, "total_time": 1.2842636108398438, "rollout_time": 0.4392881393432617, "train_time": 0.834845781326294, "student_train_time": 0.009769678115844727, "throughput": 1557.3126756212462, "inference_time": 0.0551013999775023, "env_time": 0.3841867393657594, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 449, "reward_mean": 61.583333333333336, "student_loss": null, "teacher_policy_loss": -24.088159561157227, "teacher_value_loss": 104.22140502929688, "teacher_entropy": 0.533574104309082, "total_time": 1.1828222274780273, "rollout_time": 0.42624855041503906, "train_time": 0.7511780261993408, "student_train_time": 0.004990816116333008, "throughput": 1690.8711668906753, "inference_time": 0.054594970040852786, "env_time": 0.3716535803741863, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 450, "reward_mean": 54.25, "student_loss": null, "teacher_policy_loss": -24.654727935791016, "teacher_value_loss": 162.89463806152344, "teacher_entropy": 0.49587786197662354, "total_time": 1.3065643310546875, "rollout_time": 0.4409480094909668, "train_time": 0.8537368774414062, "student_train_time": 0.011438846588134766, "throughput": 1530.7321288845808, "inference_time": 0.05790122801045072, "env_time": 0.3830467814805161, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 451, "reward_mean": 64.11764705882354, "student_loss": null, "teacher_policy_loss": -22.952470779418945, "teacher_value_loss": 135.26097106933594, "teacher_entropy": 0.49797767400741577, "total_time": 1.2784428596496582, "rollout_time": 0.4262397289276123, "train_time": 0.8461012840270996, "student_train_time": 0.00574493408203125, "throughput": 1564.4031212690068, "inference_time": 0.054041963805502746, "env_time": 0.37219776512210956, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 452, "reward_mean": 57.371428571428574, "student_loss": null, "teacher_policy_loss": -22.098770141601562, "teacher_value_loss": 119.62628936767578, "teacher_entropy": 0.4975697696208954, "total_time": 1.3847403526306152, "rollout_time": 0.44116878509521484, "train_time": 0.9331314563751221, "student_train_time": 0.010068655014038086, "throughput": 1444.314088341952, "inference_time": 0.05930949029061594, "env_time": 0.3818592948045989, "samples": 2000, "teacher_eval_reward": 95.0}
{"epoch": 453, "reward_mean": 56.285714285714285, "student_loss": null, "teacher_policy_loss": -25.10092544555664, "teacher_value_loss": 142.6189422607422, "teacher_entropy": 0.5255827903747559, "total_time": 1.3163847923278809, "rollout_time": 0.5183820724487305, "train_time": 0.7923605442047119, "student_train_time": 0.0051686763763427734, "throughput": 1519.3125989120713, "inference_time": 0.06505953377563856, "env_time": 0.4533225386730919, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 454, "reward_mean": 61.46875, "student_loss": null, "teacher_policy_loss": -27.419328689575195, "teacher_value_loss": 191.18948364257812, "teacher_entropy": 0.5214369893074036, "total_time": 1.3662097454071045, "rollout_time": 0.44389986991882324, "train_time": 0.9079532623291016, "student_train_time": 0.01391744613647461, "throughput": 1463.9040650409343, "inference_time": 0.05474842573312344, "env_time": 0.3891514441856998, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 455, "reward_mean": 63.5, "student_loss": null, "teacher_policy_loss": -25.132835388183594, "teacher_value_loss": 165.42507934570312, "teacher_entropy": 0.49594923853874207, "total_time": 1.40681791305542, "rollout_time": 0.5839731693267822, "train_time": 0.8173437118530273, "student_train_time": 0.005120038986206055, "throughput": 1421.648090658917, "inference_time": 0.06825170028059802, "env_time": 0.5157214690461842, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 456, "reward_mean": 50.84615384615385, "student_loss": null, "teacher_policy_loss": -22.081607818603516, "teacher_value_loss": 143.75265502929688, "teacher_entropy": 0.5093015432357788, "total_time": 1.3361446857452393, "rollout_time": 0.4528677463531494, "train_time": 0.877657413482666, "student_train_time": 0.005192279815673828, "throughput": 1496.8438832539257, "inference_time": 0.05751534904993605, "env_time": 0.39535239730321337, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 457, "reward_mean": 57.138888888888886, "student_loss": null, "teacher_policy_loss": -22.891101837158203, "teacher_value_loss": 83.7864761352539, "teacher_entropy": 0.5226770043373108, "total_time": 1.231696367263794, "rollout_time": 0.43369054794311523, "train_time": 0.7906930446624756, "student_train_time": 0.006890058517456055, "throughput": 1623.776811522947, "inference_time": 0.05538989299930108, "env_time": 0.37830065494381415, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 458, "reward_mean": 52.513513513513516, "student_loss": null, "teacher_policy_loss": -22.37291145324707, "teacher_value_loss": 102.83025360107422, "teacher_entropy": 0.5257866382598877, "total_time": 1.3332786560058594, "rollout_time": 0.4454152584075928, "train_time": 0.8792703151702881, "student_train_time": 0.008223772048950195, "throughput": 1500.0615145159952, "inference_time": 0.05546291624523292, "env_time": 0.38995234216235986, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 459, "reward_mean": 51.875, "student_loss": null, "teacher_policy_loss": -20.80381965637207, "teacher_value_loss": 86.97025299072266, "teacher_entropy": 0.5238032937049866, "total_time": -1.243443250656128, "rollout_time": 0.4517025947570801, "train_time": -1.7001547813415527, "student_train_time": 0.00464940071105957, "throughput": 200000000000.0, "inference_time": 0.06017375924602675, "env_time": 0.39152883551105333, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 460, "reward_mean": 51.07692307692308, "student_loss": null, "teacher_policy_loss": -21.47623062133789, "teacher_value_loss": 81.91121673583984, "teacher_entropy": 0.5329049825668335, "total_time": 1.321157455444336, "rollout_time": 0.44469285011291504, "train_time": 0.8680074214935303, "student_train_time": 0.00809621810913086, "throughput": 1513.8241030682852, "inference_time": 0.05548192881360592, "env_time": 0.3892109212993091, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 461, "reward_mean": 53.94444444444444, "student_loss": null, "teacher_policy_loss": -23.30268669128418, "teacher_value_loss": 111.39203643798828, "teacher_entropy": 0.5249478220939636, "total_time": 1.4391024112701416, "rollout_time": 0.4367060661315918, "train_time": 0.9913504123687744, "student_train_time": 0.010639429092407227, "throughput": 1389.7551587275948, "inference_time": 0.056892145239544334, "env_time": 0.37981392089204746, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 462, "reward_mean": 57.44117647058823, "student_loss": null, "teacher_policy_loss": -23.281620025634766, "teacher_value_loss": 102.92166900634766, "teacher_entropy": 0.533227801322937, "total_time": 1.325549602508545, "rollout_time": 0.42424535751342773, "train_time": 0.8908536434173584, "student_train_time": 0.010098457336425781, "throughput": 1508.8081171878343, "inference_time": 0.05504616401049134, "env_time": 0.3691991935029364, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 463, "reward_mean": 60.85294117647059, "student_loss": null, "teacher_policy_loss": -23.647756576538086, "teacher_value_loss": 124.06753540039062, "teacher_entropy": 0.5343016386032104, "total_time": 1.699911117553711, "rollout_time": 0.50966477394104, "train_time": 1.176361322402954, "student_train_time": 0.013430356979370117, "throughput": 1176.5321017949088, "inference_time": 0.06066156995257188, "env_time": 0.44900320398846816, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 464, "reward_mean": 51.87179487179487, "student_loss": null, "teacher_policy_loss": -22.713472366333008, "teacher_value_loss": 113.72077941894531, "teacher_entropy": 0.5221248269081116, "total_time": 1.3579039573669434, "rollout_time": 0.42862558364868164, "train_time": 0.9165687561035156, "student_train_time": 0.012332677841186523, "throughput": 1472.8582158918803, "inference_time": 0.05330558348396153, "env_time": 0.3753200001647201, "samples": 2000, "teacher_eval_reward": 60.0}
{"epoch": 465, "reward_mean": 57.666666666666664, "student_loss": null, "teacher_policy_loss": -23.46706771850586, "teacher_value_loss": 109.79817199707031, "teacher_entropy": 0.5215011239051819, "total_time": 1.413663625717163, "rollout_time": 0.5034847259521484, "train_time": 0.901639461517334, "student_train_time": 0.008177995681762695, "throughput": 1414.7637129627522, "inference_time": 0.0645783267900697, "env_time": 0.43890639916207874, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 466, "reward_mean": 56.945945945945944, "student_loss": null, "teacher_policy_loss": -21.06833839416504, "teacher_value_loss": 90.66664123535156, "teacher_entropy": 0.5158619284629822, "total_time": 1.146761417388916, "rollout_time": 0.42024707794189453, "train_time": 0.7206239700317383, "student_train_time": 0.005491971969604492, "throughput": 1744.041933808551, "inference_time": 0.05411636001736042, "env_time": 0.3661307179245341, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 467, "reward_mean": 56.083333333333336, "student_loss": null, "teacher_policy_loss": -22.791494369506836, "teacher_value_loss": 89.77981567382812, "teacher_entropy": 0.5366247296333313, "total_time": 1.3426196575164795, "rollout_time": 0.4362471103668213, "train_time": 0.895759105682373, "student_train_time": 0.01019597053527832, "throughput": 1489.6251435045385, "inference_time": 0.0553008332663012, "env_time": 0.3809462771005201, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 468, "reward_mean": 55.65714285714286, "student_loss": null, "teacher_policy_loss": -23.122968673706055, "teacher_value_loss": 97.7176742553711, "teacher_entropy": 0.5482603907585144, "total_time": 1.2195322513580322, "rollout_time": 0.44037842750549316, "train_time": 0.7687952518463135, "student_train_time": 0.009981870651245117, "throughput": 1639.9730288172893, "inference_time": 0.056130391247279476, "env_time": 0.3842480362582137, "samples": 2000, "teacher_eval_reward": 60.0}
{"epoch": 469, "reward_mean": 60.90909090909091, "student_loss": null, "teacher_policy_loss": -26.239002227783203, "teacher_value_loss": 242.89572143554688, "teacher_entropy": 0.5346018671989441, "total_time": 1.39202880859375, "rollout_time": 0.4362618923187256, "train_time": 0.9298157691955566, "student_train_time": 0.025524139404296875, "throughput": 1436.7518744245187, "inference_time": 0.05529325803217944, "env_time": 0.38096863428654615, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 470, "reward_mean": 60.54545454545455, "student_loss": null, "teacher_policy_loss": -24.82416343688965, "teacher_value_loss": 116.62065124511719, "teacher_entropy": 0.5171173810958862, "total_time": 1.3344628810882568, "rollout_time": 0.48033857345581055, "train_time": 0.8244574069976807, "student_train_time": 0.029256820678710938, "throughput": 1498.7303343866683, "inference_time": 0.05887314870051341, "env_time": 0.42146542475529714, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 471, "reward_mean": 60.375, "student_loss": null, "teacher_policy_loss": -26.108890533447266, "teacher_value_loss": 185.34536743164062, "teacher_entropy": 0.5262101888656616, "total_time": 1.3755557537078857, "rollout_time": 0.43609166145324707, "train_time": 0.9254341125488281, "student_train_time": 0.013563394546508789, "throughput": 1453.957787322608, "inference_time": 0.05392217548433109, "env_time": 0.382169485968916, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 472, "reward_mean": 66.4375, "student_loss": null, "teacher_policy_loss": -26.417770385742188, "teacher_value_loss": 137.57797241210938, "teacher_entropy": 0.5382154583930969, "total_time": 1.3219883441925049, "rollout_time": 0.5322260856628418, "train_time": 0.7821211814880371, "student_train_time": 0.0071506500244140625, "throughput": 1512.872642777828, "inference_time": 0.06664888049090223, "env_time": 0.46557720517193957, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 473, "reward_mean": 52.351351351351354, "student_loss": null, "teacher_policy_loss": -21.97875213623047, "teacher_value_loss": 133.22341918945312, "teacher_entropy": 0.5197442173957825, "total_time": 1.3231160640716553, "rollout_time": 0.4426429271697998, "train_time": 0.8685026168823242, "student_train_time": 0.011376380920410156, "throughput": 1511.5831893427053, "inference_time": 0.05622819952259306, "env_time": 0.38641472764720675, "samples": 2000, "teacher_eval_reward": 43.0}
{"epoch": 474, "reward_mean": 56.05714285714286, "student_loss": null, "teacher_policy_loss": -21.728776931762695, "teacher_value_loss": 139.9149169921875, "teacher_entropy": 0.49556833505630493, "total_time": 1.2675786018371582, "rollout_time": 0.43311238288879395, "train_time": 0.8021314144134521, "student_train_time": 0.03190302848815918, "throughput": 1577.811424949357, "inference_time": 0.05439868748362642, "env_time": 0.3787136954051675, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 475, "reward_mean": 65.93548387096774, "student_loss": null, "teacher_policy_loss": -25.896482467651367, "teacher_value_loss": 206.83595275878906, "teacher_entropy": 0.49747002124786377, "total_time": 1.3019628524780273, "rollout_time": 0.4392359256744385, "train_time": 0.8511738777160645, "student_train_time": 0.011192560195922852, "throughput": 1536.1421381519433, "inference_time": 0.0561417097269441, "env_time": 0.3830942159474944, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 476, "reward_mean": 59.303030303030305, "student_loss": null, "teacher_policy_loss": -24.097612380981445, "teacher_value_loss": 147.63470458984375, "teacher_entropy": 0.5210450887680054, "total_time": 1.2149646282196045, "rollout_time": 0.4317800998687744, "train_time": 0.7762563228607178, "student_train_time": 0.006556272506713867, "throughput": 1646.1384583111505, "inference_time": 0.0538624506953056, "env_time": 0.3779176491734688, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 477, "reward_mean": 57.05555555555556, "student_loss": null, "teacher_policy_loss": -23.725738525390625, "teacher_value_loss": 133.1990203857422, "teacher_entropy": 0.5308197736740112, "total_time": -1.3399157524108887, "rollout_time": -2.2128043174743652, "train_time": 0.8124544620513916, "student_train_time": 0.060064077377319336, "throughput": 200000000000.0, "inference_time": 0.05842767148351413, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 478, "reward_mean": 54.74285714285714, "student_loss": null, "teacher_policy_loss": -22.500707626342773, "teacher_value_loss": 92.98339080810547, "teacher_entropy": 0.5148064494132996, "total_time": 1.226109504699707, "rollout_time": 0.43974947929382324, "train_time": 0.776080846786499, "student_train_time": 0.009912729263305664, "throughput": 1631.1756758543606, "inference_time": 0.05628240600890422, "env_time": 0.383467073284919, "samples": 2000, "teacher_eval_reward": 57.0}
{"epoch": 479, "reward_mean": 57.22222222222222, "student_loss": null, "teacher_policy_loss": -22.112329483032227, "teacher_value_loss": 96.45353698730469, "teacher_entropy": 0.5295299291610718, "total_time": 1.216722011566162, "rollout_time": 0.4326200485229492, "train_time": 0.7774322032928467, "student_train_time": 0.006297111511230469, "throughput": 1643.760843469581, "inference_time": 0.05498207048185577, "env_time": 0.37763797804109345, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 480, "reward_mean": 55.02777777777778, "student_loss": null, "teacher_policy_loss": -23.91901206970215, "teacher_value_loss": 121.84461975097656, "teacher_entropy": 0.5392932891845703, "total_time": 1.2938005924224854, "rollout_time": 0.42543649673461914, "train_time": 0.8626048564910889, "student_train_time": 0.005356788635253906, "throughput": 1545.833269603967, "inference_time": 0.05350738596462179, "env_time": 0.37192911076999735, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 481, "reward_mean": 63.38709677419355, "student_loss": null, "teacher_policy_loss": -26.341346740722656, "teacher_value_loss": 184.5396728515625, "teacher_entropy": 0.5296743512153625, "total_time": 1.214547872543335, "rollout_time": 0.43067216873168945, "train_time": 0.7742440700531006, "student_train_time": 0.009272336959838867, "throughput": 1646.703308459865, "inference_time": 0.0560531962364621, "env_time": 0.37461897249522735, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 482, "reward_mean": 53.68421052631579, "student_loss": null, "teacher_policy_loss": -21.44902992248535, "teacher_value_loss": 103.38786315917969, "teacher_entropy": 0.5247349143028259, "total_time": 1.3448667526245117, "rollout_time": 0.4367988109588623, "train_time": 0.900665283203125, "student_train_time": 0.0070455074310302734, "throughput": 1487.136176202582, "inference_time": 0.05491227722268377, "env_time": 0.38188653373617854, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 483, "reward_mean": 68.33333333333333, "student_loss": null, "teacher_policy_loss": -26.090843200683594, "teacher_value_loss": 150.5120849609375, "teacher_entropy": 0.513619601726532, "total_time": 1.232966661453247, "rollout_time": 0.46298789978027344, "train_time": 0.7621328830718994, "student_train_time": 0.00748753547668457, "throughput": 1622.1038755765564, "inference_time": 0.05852042348487885, "env_time": 0.4044674762953946, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 484, "reward_mean": 55.916666666666664, "student_loss": null, "teacher_policy_loss": -24.074655532836914, "teacher_value_loss": 134.31683349609375, "teacher_entropy": 0.5327369570732117, "total_time": 1.292646884918213, "rollout_time": 0.43890833854675293, "train_time": 0.8477742671966553, "student_train_time": 0.005601644515991211, "throughput": 1547.2129499051414, "inference_time": 0.05598934494628338, "env_time": 0.38291899360046955, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 485, "reward_mean": 57.294117647058826, "student_loss": null, "teacher_policy_loss": -24.597637176513672, "teacher_value_loss": 133.58265686035156, "teacher_entropy": 0.5184382796287537, "total_time": 1.2155160903930664, "rollout_time": 0.4330027103424072, "train_time": 0.777198076248169, "student_train_time": 0.0049190521240234375, "throughput": 1645.3916289608735, "inference_time": 0.05397754225850804, "env_time": 0.3790251680838992, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 486, "reward_mean": 52.333333333333336, "student_loss": null, "teacher_policy_loss": -21.62898826599121, "teacher_value_loss": 137.54673767089844, "teacher_entropy": 0.502388596534729, "total_time": 1.338202714920044, "rollout_time": 0.4329257011413574, "train_time": 0.885887622833252, "student_train_time": 0.019018888473510742, "throughput": 1494.54187897048, "inference_time": 0.05469795998033078, "env_time": 0.37822774116102664, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 487, "reward_mean": 64.96666666666667, "student_loss": null, "teacher_policy_loss": -26.60977554321289, "teacher_value_loss": 141.62046813964844, "teacher_entropy": 0.515168309211731, "total_time": 1.206554651260376, "rollout_time": 0.42967963218688965, "train_time": 0.7661392688751221, "student_train_time": 0.01036381721496582, "throughput": 1657.6124404400457, "inference_time": 0.05264208727021469, "env_time": 0.37703754491667496, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 488, "reward_mean": 60.26470588235294, "student_loss": null, "teacher_policy_loss": -25.071840286254883, "teacher_value_loss": 115.90503692626953, "teacher_entropy": 0.538951575756073, "total_time": 1.2984955310821533, "rollout_time": 0.4416224956512451, "train_time": 0.8263251781463623, "student_train_time": 0.029894590377807617, "throughput": 1540.2440379084092, "inference_time": 0.05473988700941845, "env_time": 0.38688260864182666, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 489, "reward_mean": 61.3125, "student_loss": null, "teacher_policy_loss": -24.819904327392578, "teacher_value_loss": 133.66140747070312, "teacher_entropy": 0.5222023129463196, "total_time": 1.3322184085845947, "rollout_time": 0.43926239013671875, "train_time": 0.8823206424713135, "student_train_time": 0.010265111923217773, "throughput": 1501.2553400495979, "inference_time": 0.05577355277273455, "env_time": 0.3834888373639842, "samples": 2000, "teacher_eval_reward": 54.0}
{"epoch": 490, "reward_mean": 63.233333333333334, "student_loss": null, "teacher_policy_loss": -25.9484920501709, "teacher_value_loss": 159.3638458251953, "teacher_entropy": 0.5105726718902588, "total_time": 1.1891186237335205, "rollout_time": 0.4256923198699951, "train_time": 0.735116720199585, "student_train_time": 0.027853965759277344, "throughput": 1681.917985373507, "inference_time": 0.055023781258569215, "env_time": 0.3706685386114259, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 491, "reward_mean": 63.515151515151516, "student_loss": null, "teacher_policy_loss": -24.745040893554688, "teacher_value_loss": 132.80311584472656, "teacher_entropy": 0.5138586163520813, "total_time": 1.3153634071350098, "rollout_time": 0.43012261390686035, "train_time": 0.8761608600616455, "student_train_time": 0.008719444274902344, "throughput": 1520.4923515062621, "inference_time": 0.054681242425431265, "env_time": 0.3754413714814291, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 492, "reward_mean": 64.45161290322581, "student_loss": null, "teacher_policy_loss": -27.23541259765625, "teacher_value_loss": 159.28102111816406, "teacher_entropy": 0.5453801155090332, "total_time": 1.173924446105957, "rollout_time": 0.42326951026916504, "train_time": 0.7446227073669434, "student_train_time": 0.005675554275512695, "throughput": 1703.6871551948943, "inference_time": 0.05289505193832156, "env_time": 0.3703744583308435, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 493, "reward_mean": 52.31578947368421, "student_loss": null, "teacher_policy_loss": -20.91889762878418, "teacher_value_loss": 94.9066390991211, "teacher_entropy": 0.5139256715774536, "total_time": 1.319129467010498, "rollout_time": 0.44196295738220215, "train_time": 0.8671770095825195, "student_train_time": 0.009557723999023438, "throughput": 1516.151408953465, "inference_time": 0.057761155778280227, "env_time": 0.3842018016039219, "samples": 2000, "teacher_eval_reward": 55.0}
{"epoch": 494, "reward_mean": 60.18181818181818, "student_loss": null, "teacher_policy_loss": -24.1801700592041, "teacher_value_loss": 158.50035095214844, "teacher_entropy": 0.5178806185722351, "total_time": -1.4593901634216309, "rollout_time": 0.4401125907897949, "train_time": -1.9137780666351318, "student_train_time": 0.01392364501953125, "throughput": 200000000000.0, "inference_time": 0.055027090455041616, "env_time": 0.3850855003347533, "samples": 2000, "teacher_eval_reward": 48.0}
{"epoch": 495, "reward_mean": 69.6896551724138, "student_loss": null, "teacher_policy_loss": -26.854127883911133, "teacher_value_loss": 210.43801879882812, "teacher_entropy": 0.531585693359375, "total_time": 1.3482060432434082, "rollout_time": 0.4384465217590332, "train_time": 0.9012660980224609, "student_train_time": 0.00812530517578125, "throughput": 1483.4527778770055, "inference_time": 0.05611465102083457, "env_time": 0.38233187073819863, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 496, "reward_mean": 51.775, "student_loss": null, "teacher_policy_loss": -21.94695472717285, "teacher_value_loss": 94.16104125976562, "teacher_entropy": 0.5297636389732361, "total_time": 1.2401349544525146, "rollout_time": 0.4319634437561035, "train_time": 0.8030095100402832, "student_train_time": 0.004802227020263672, "throughput": 1612.7277058188758, "inference_time": 0.05343119528515672, "env_time": 0.3785322484709468, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 497, "reward_mean": 54.371428571428574, "student_loss": null, "teacher_policy_loss": -24.149730682373047, "teacher_value_loss": 118.62448120117188, "teacher_entropy": 0.524651288986206, "total_time": 1.4627563953399658, "rollout_time": 0.42197084426879883, "train_time": 1.027529001235962, "student_train_time": 0.012897968292236328, "throughput": 1367.2816651983744, "inference_time": 0.05692268779603182, "env_time": 0.365048156472767, "samples": 2000, "teacher_eval_reward": 72.0}
{"epoch": 498, "reward_mean": 62.39393939393939, "student_loss": null, "teacher_policy_loss": -25.22203826904297, "teacher_value_loss": 151.54959106445312, "teacher_entropy": 0.5263479948043823, "total_time": 1.2392489910125732, "rollout_time": 0.46083807945251465, "train_time": 0.7716999053955078, "student_train_time": 0.0063588619232177734, "throughput": 1613.8806765263755, "inference_time": 0.05565628445765469, "env_time": 0.40518179499485996, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 499, "reward_mean": 52.717948717948715, "student_loss": null, "teacher_policy_loss": -21.239469528198242, "teacher_value_loss": 114.11514282226562, "teacher_entropy": 0.49873536825180054, "total_time": 1.3578357696533203, "rollout_time": 0.4538302421569824, "train_time": 0.8985724449157715, "student_train_time": 0.00502777099609375, "throughput": 1472.9321797956727, "inference_time": 0.053212039752907, "env_time": 0.4006182024040754, "samples": 2000, "teacher_eval_reward": 58.0}
{"epoch": 500, "reward_mean": 53.142857142857146, "student_loss": null, "teacher_policy_loss": -24.323312759399414, "teacher_value_loss": 141.82057189941406, "teacher_entropy": 0.5306837558746338, "total_time": 1.284496545791626, "rollout_time": 0.44108104705810547, "train_time": 0.8347680568695068, "student_train_time": 0.008275747299194336, "throughput": 1557.0302672689668, "inference_time": 0.05732639149209717, "env_time": 0.3837546555660083, "samples": 2000, "teacher_eval_reward": 148.0}
