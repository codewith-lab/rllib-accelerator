{"epoch": 1, "reward_mean": 17.017543859649123, "student_loss": null, "teacher_policy_loss": -9.851456642150879, "teacher_value_loss": 175.47354125976562, "teacher_entropy": 0.5878286361694336, "total_time": 1.498760461807251, "rollout_time": 0.44051527976989746, "train_time": 0.9740588665008545, "student_train_time": 0.08378458023071289, "throughput": 1334.4360563050477, "inference_time": 0.055958908499690097, "env_time": 0.38455637127020736, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 2, "reward_mean": 16.611570247933884, "student_loss": null, "teacher_policy_loss": -8.908836364746094, "teacher_value_loss": 59.98849105834961, "teacher_entropy": 0.6130948662757874, "total_time": 1.244795799255371, "rollout_time": 0.4286155700683594, "train_time": 0.8074436187744141, "student_train_time": 0.008387565612792969, "throughput": 1606.6892266156322, "inference_time": 0.05271380450005836, "env_time": 0.375901765568301, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 3, "reward_mean": 17.14406779661017, "student_loss": null, "teacher_policy_loss": -7.972782135009766, "teacher_value_loss": 72.7489013671875, "teacher_entropy": 0.5904000997543335, "total_time": 1.3651745319366455, "rollout_time": 0.4231863021850586, "train_time": 0.9309749603271484, "student_train_time": 0.01057887077331543, "throughput": 1465.0141452337139, "inference_time": 0.052184514499174384, "env_time": 0.3710017876858842, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 4, "reward_mean": 18.25925925925926, "student_loss": null, "teacher_policy_loss": -9.735157012939453, "teacher_value_loss": 57.76130676269531, "teacher_entropy": 0.5089530348777771, "total_time": 1.253654956817627, "rollout_time": 0.4746267795562744, "train_time": 0.7618057727813721, "student_train_time": 0.016772747039794922, "throughput": 1595.3352947105575, "inference_time": 0.05958528200034152, "env_time": 0.4150414975559329, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 5, "reward_mean": 18.17117117117117, "student_loss": null, "teacher_policy_loss": -9.890074729919434, "teacher_value_loss": 39.38681411743164, "teacher_entropy": 0.6465039849281311, "total_time": 1.3074924945831299, "rollout_time": 0.4399142265319824, "train_time": 0.8548367023468018, "student_train_time": 0.012389421463012695, "throughput": 1529.645491875396, "inference_time": 0.053866644750200976, "env_time": 0.38604758178178145, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 6, "reward_mean": 17.892857142857142, "student_loss": null, "teacher_policy_loss": -10.523683547973633, "teacher_value_loss": 37.97236251831055, "teacher_entropy": 0.6317175626754761, "total_time": 1.2526130676269531, "rollout_time": 0.43880462646484375, "train_time": 0.8069534301757812, "student_train_time": 0.00640106201171875, "throughput": 1596.6622508489029, "inference_time": 0.05415837625008635, "env_time": 0.3846462502147574, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 7, "reward_mean": 19.085714285714285, "student_loss": null, "teacher_policy_loss": -9.986702919006348, "teacher_value_loss": 49.52278518676758, "teacher_entropy": 0.6905304789543152, "total_time": 1.277698040008545, "rollout_time": 0.41973114013671875, "train_time": 0.85164475440979, "student_train_time": 0.0059049129486083984, "throughput": 1565.315072398972, "inference_time": 0.05196809375030398, "env_time": 0.36776304638641477, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 8, "reward_mean": 17.22608695652174, "student_loss": null, "teacher_policy_loss": -9.401561737060547, "teacher_value_loss": 43.88955307006836, "teacher_entropy": 0.6775821447372437, "total_time": 1.1764121055603027, "rollout_time": 0.4417576789855957, "train_time": 0.7246344089508057, "student_train_time": 0.009575605392456055, "throughput": 1700.0845116664607, "inference_time": 0.054657082499034004, "env_time": 0.3871005964865617, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 9, "reward_mean": 19.553398058252426, "student_loss": null, "teacher_policy_loss": -10.700514793395996, "teacher_value_loss": 47.17514419555664, "teacher_entropy": 0.5730054974555969, "total_time": -0.3428962230682373, "rollout_time": 0.4207642078399658, "train_time": -0.7722020149230957, "student_train_time": 0.008172273635864258, "throughput": 200000000000.0, "inference_time": 0.054161755248856025, "env_time": 0.3666024525911098, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 10, "reward_mean": 17.344827586206897, "student_loss": null, "teacher_policy_loss": -9.672083854675293, "teacher_value_loss": 42.800594329833984, "teacher_entropy": 0.5231792330741882, "total_time": 1.420405387878418, "rollout_time": 0.447202205657959, "train_time": 0.9613914489746094, "student_train_time": 0.011468172073364258, "throughput": 1408.0487282488352, "inference_time": 0.05474648624948486, "env_time": 0.3924557194084741, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 11, "reward_mean": 18.895238095238096, "student_loss": null, "teacher_policy_loss": -10.279590606689453, "teacher_value_loss": 35.443241119384766, "teacher_entropy": 0.5992883443832397, "total_time": 1.1679320335388184, "rollout_time": 0.43601298332214355, "train_time": 0.7199854850769043, "student_train_time": 0.011587858200073242, "throughput": 1712.428414126143, "inference_time": 0.055901838250974833, "env_time": 0.3801111450711687, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 12, "reward_mean": 17.20689655172414, "student_loss": null, "teacher_policy_loss": -9.240483283996582, "teacher_value_loss": 24.74892234802246, "teacher_entropy": 0.5805438756942749, "total_time": 1.319645643234253, "rollout_time": 0.4306349754333496, "train_time": 0.8768455982208252, "student_train_time": 0.011811017990112305, "throughput": 1515.5583699714273, "inference_time": 0.05489786574980826, "env_time": 0.37573710968354135, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 13, "reward_mean": 19.095238095238095, "student_loss": null, "teacher_policy_loss": -10.856125831604004, "teacher_value_loss": 46.51404571533203, "teacher_entropy": 0.6541581749916077, "total_time": 1.2442080974578857, "rollout_time": 0.434032678604126, "train_time": 0.7945497035980225, "student_train_time": 0.015280485153198242, "throughput": 1607.448146404381, "inference_time": 0.054454041751284876, "env_time": 0.3795786368528411, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 14, "reward_mean": 19.019417475728154, "student_loss": null, "teacher_policy_loss": -10.081214904785156, "teacher_value_loss": 43.01918029785156, "teacher_entropy": 0.44973406195640564, "total_time": 1.1369409561157227, "rollout_time": 0.4228811264038086, "train_time": 0.7063939571380615, "student_train_time": 0.007228851318359375, "throughput": 1759.1063012039401, "inference_time": 0.05355894575052389, "env_time": 0.3693221806532847, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 15, "reward_mean": 19.1588785046729, "student_loss": null, "teacher_policy_loss": -10.458481788635254, "teacher_value_loss": 52.153079986572266, "teacher_entropy": 0.5108426809310913, "total_time": 1.3062875270843506, "rollout_time": 0.46784329414367676, "train_time": 0.8302857875823975, "student_train_time": 0.00780797004699707, "throughput": 1531.0564929483971, "inference_time": 0.05650935000181789, "env_time": 0.41133394414185886, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 16, "reward_mean": 18.137614678899084, "student_loss": null, "teacher_policy_loss": -9.993778228759766, "teacher_value_loss": 38.93381881713867, "teacher_entropy": 0.6798668503761292, "total_time": 1.2552094459533691, "rollout_time": 0.4184596538543701, "train_time": 0.8234202861785889, "student_train_time": 0.012985467910766602, "throughput": 1593.3595834924108, "inference_time": 0.05594175999920026, "env_time": 0.36251789385516986, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 17, "reward_mean": 19.745098039215687, "student_loss": null, "teacher_policy_loss": -10.41113567352295, "teacher_value_loss": 39.28034591674805, "teacher_entropy": 0.6741050481796265, "total_time": 1.2732295989990234, "rollout_time": 0.418226957321167, "train_time": 0.8481452465057373, "student_train_time": 0.0065135955810546875, "throughput": 1570.8085969508898, "inference_time": 0.054168460250650696, "env_time": 0.3640584970705163, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 18, "reward_mean": 20.11111111111111, "student_loss": null, "teacher_policy_loss": -11.0106782913208, "teacher_value_loss": 51.83263397216797, "teacher_entropy": 0.5723443031311035, "total_time": 1.150458812713623, "rollout_time": 0.4341599941253662, "train_time": 0.7044661045074463, "student_train_time": 0.011490345001220703, "throughput": 1738.4368548427542, "inference_time": 0.05545360500161678, "env_time": 0.37870638912374943, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 19, "reward_mean": 18.07207207207207, "student_loss": null, "teacher_policy_loss": -9.927119255065918, "teacher_value_loss": 47.513023376464844, "teacher_entropy": 0.5408990383148193, "total_time": 1.1906726360321045, "rollout_time": 0.4425373077392578, "train_time": 0.7377119064331055, "student_train_time": 0.010079622268676758, "throughput": 1679.7228217698566, "inference_time": 0.052816379001512814, "env_time": 0.389720928737745, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 20, "reward_mean": 17.473684210526315, "student_loss": null, "teacher_policy_loss": -9.512653350830078, "teacher_value_loss": 24.111406326293945, "teacher_entropy": 0.5987684726715088, "total_time": 1.302027940750122, "rollout_time": 0.4287984371185303, "train_time": 0.8535263538360596, "student_train_time": 0.019346237182617188, "throughput": 1536.0653465299397, "inference_time": 0.054879706500287284, "env_time": 0.373918730618243, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 21, "reward_mean": 18.431192660550458, "student_loss": null, "teacher_policy_loss": -9.197468757629395, "teacher_value_loss": 29.567672729492188, "teacher_entropy": 0.6338285207748413, "total_time": 1.2074453830718994, "rollout_time": 0.4431264400482178, "train_time": 0.7564024925231934, "student_train_time": 0.00751805305480957, "throughput": 1656.3896206317322, "inference_time": 0.05570785099882869, "env_time": 0.3874185890493891, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 22, "reward_mean": 19.33653846153846, "student_loss": null, "teacher_policy_loss": -9.7772855758667, "teacher_value_loss": 32.8676872253418, "teacher_entropy": 0.6332098245620728, "total_time": 1.239217758178711, "rollout_time": 0.4237973690032959, "train_time": 0.804929256439209, "student_train_time": 0.010094404220581055, "throughput": 1613.9213522403174, "inference_time": 0.05342465525046691, "env_time": 0.370372713752829, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 23, "reward_mean": 19.637254901960784, "student_loss": null, "teacher_policy_loss": -11.149113655090332, "teacher_value_loss": 40.25642013549805, "teacher_entropy": 0.6241463422775269, "total_time": 1.2275421619415283, "rollout_time": 0.4245007038116455, "train_time": 0.7933928966522217, "student_train_time": 0.009217500686645508, "throughput": 1629.2719403109727, "inference_time": 0.051628510249486226, "env_time": 0.3728721935621593, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 24, "reward_mean": 18.695238095238096, "student_loss": null, "teacher_policy_loss": -9.338590621948242, "teacher_value_loss": 26.75722885131836, "teacher_entropy": 0.5253593921661377, "total_time": 1.3357560634613037, "rollout_time": 0.4386575222015381, "train_time": 0.8774991035461426, "student_train_time": 0.019253015518188477, "throughput": 1497.2793721163887, "inference_time": 0.05486404924880617, "env_time": 0.3837934729527319, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 25, "reward_mean": 18.327272727272728, "student_loss": null, "teacher_policy_loss": -9.298990249633789, "teacher_value_loss": 30.621837615966797, "teacher_entropy": 0.5482509732246399, "total_time": 1.3019914627075195, "rollout_time": 0.4296834468841553, "train_time": 0.8590757846832275, "student_train_time": 0.012887954711914062, "throughput": 1536.1083826471154, "inference_time": 0.05694447225090471, "env_time": 0.37273897463325056, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 26, "reward_mean": 20.591836734693878, "student_loss": null, "teacher_policy_loss": -12.630769729614258, "teacher_value_loss": 76.11315155029297, "teacher_entropy": 0.6681910753250122, "total_time": 1.156956434249878, "rollout_time": 0.4252128601074219, "train_time": 0.722379207611084, "student_train_time": 0.008916378021240234, "throughput": 1728.673561763556, "inference_time": 0.0554159365005944, "env_time": 0.3697969236068275, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 27, "reward_mean": 21.311827956989248, "student_loss": null, "teacher_policy_loss": -11.43698787689209, "teacher_value_loss": 44.00831985473633, "teacher_entropy": 0.6819961667060852, "total_time": 1.24884033203125, "rollout_time": 0.42507147789001465, "train_time": 0.8147194385528564, "student_train_time": 0.008556127548217773, "throughput": 1601.4857533844875, "inference_time": 0.05524678325048171, "env_time": 0.36982469463953294, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 28, "reward_mean": 20.02, "student_loss": null, "teacher_policy_loss": -11.578685760498047, "teacher_value_loss": 45.20698547363281, "teacher_entropy": 0.6613465547561646, "total_time": 1.240102767944336, "rollout_time": 0.43857550621032715, "train_time": 0.793461799621582, "student_train_time": 0.007720232009887695, "throughput": 1612.769563699396, "inference_time": 0.05706832174871579, "env_time": 0.38150718446161136, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 29, "reward_mean": 20.31, "student_loss": null, "teacher_policy_loss": -11.426158905029297, "teacher_value_loss": 44.37211990356445, "teacher_entropy": 0.6108545660972595, "total_time": 1.1733372211456299, "rollout_time": 0.4494190216064453, "train_time": 0.7176487445831299, "student_train_time": 0.005918741226196289, "throughput": 1704.539806593051, "inference_time": 0.05677868500066552, "env_time": 0.3926403366057798, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 30, "reward_mean": 18.942307692307693, "student_loss": null, "teacher_policy_loss": -10.596573829650879, "teacher_value_loss": 36.3289909362793, "teacher_entropy": 0.6263749003410339, "total_time": 1.2717955112457275, "rollout_time": 0.4382588863372803, "train_time": 0.8226368427276611, "student_train_time": 0.010550975799560547, "throughput": 1572.5798544775441, "inference_time": 0.05522043100057772, "env_time": 0.38303845533670255, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 31, "reward_mean": 20.56122448979592, "student_loss": null, "teacher_policy_loss": -11.649103164672852, "teacher_value_loss": 47.353363037109375, "teacher_entropy": 0.6564781069755554, "total_time": 1.4223289489746094, "rollout_time": 0.44890737533569336, "train_time": 0.9567582607269287, "student_train_time": 0.016293764114379883, "throughput": 1406.1444797575466, "inference_time": 0.0578899729991349, "env_time": 0.39101740233655846, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 32, "reward_mean": 21.118279569892472, "student_loss": null, "teacher_policy_loss": -12.517168998718262, "teacher_value_loss": 58.74949264526367, "teacher_entropy": 0.6715551614761353, "total_time": 1.3091661930084229, "rollout_time": 0.4216759204864502, "train_time": 0.8805019855499268, "student_train_time": 0.0066297054290771484, "throughput": 1527.6899225483837, "inference_time": 0.05461073100275371, "env_time": 0.3670651894836965, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 33, "reward_mean": 21.869565217391305, "student_loss": null, "teacher_policy_loss": -12.235520362854004, "teacher_value_loss": 53.61409378051758, "teacher_entropy": 0.6402879357337952, "total_time": 1.200007438659668, "rollout_time": 0.4364125728607178, "train_time": 0.7559633255004883, "student_train_time": 0.007287263870239258, "throughput": 1666.6563352589487, "inference_time": 0.056012413749556345, "env_time": 0.38040015911116143, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 34, "reward_mean": 20.3, "student_loss": null, "teacher_policy_loss": -11.029261589050293, "teacher_value_loss": 32.41730499267578, "teacher_entropy": 0.6339671611785889, "total_time": 1.14607834815979, "rollout_time": 0.4273068904876709, "train_time": 0.708223819732666, "student_train_time": 0.010162353515625, "throughput": 1745.0813927436254, "inference_time": 0.05475589649768153, "env_time": 0.37255099398998937, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 35, "reward_mean": 20.26530612244898, "student_loss": null, "teacher_policy_loss": -11.273551940917969, "teacher_value_loss": 45.42673110961914, "teacher_entropy": 0.6758902668952942, "total_time": -0.26954030990600586, "rollout_time": -1.0963759422302246, "train_time": 0.8170440196990967, "student_train_time": 0.009449481964111328, "throughput": 200000000000.0, "inference_time": 0.05423110150024968, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 36, "reward_mean": 20.459183673469386, "student_loss": null, "teacher_policy_loss": -12.121305465698242, "teacher_value_loss": 54.949378967285156, "teacher_entropy": 0.6387999057769775, "total_time": 1.1366362571716309, "rollout_time": 0.42275524139404297, "train_time": 0.7016949653625488, "student_train_time": 0.01184225082397461, "throughput": 1759.5778661651493, "inference_time": 0.05096398725117979, "env_time": 0.3717912541428632, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 37, "reward_mean": 22.359550561797754, "student_loss": null, "teacher_policy_loss": -13.476190567016602, "teacher_value_loss": 72.25829315185547, "teacher_entropy": 0.6654752492904663, "total_time": 1.3859422206878662, "rollout_time": 0.4322822093963623, "train_time": 0.9479138851165771, "student_train_time": 0.005325794219970703, "throughput": 1443.061601087069, "inference_time": 0.05262285449924775, "env_time": 0.37965935489711455, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 38, "reward_mean": 23.797619047619047, "student_loss": null, "teacher_policy_loss": -14.321824073791504, "teacher_value_loss": 84.72169494628906, "teacher_entropy": 0.6695089340209961, "total_time": 1.2333714962005615, "rollout_time": 0.4479804039001465, "train_time": 0.7708878517150879, "student_train_time": 0.014167070388793945, "throughput": 1621.5714455547748, "inference_time": 0.05739979424873809, "env_time": 0.3905806096514084, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 39, "reward_mean": 19.95049504950495, "student_loss": null, "teacher_policy_loss": -11.351515769958496, "teacher_value_loss": 65.89611053466797, "teacher_entropy": 0.6205278038978577, "total_time": 1.1622958183288574, "rollout_time": 0.4219033718109131, "train_time": 0.73486328125, "student_train_time": 0.00519561767578125, "throughput": 1720.732337207914, "inference_time": 0.053162966750392116, "env_time": 0.36874040506052097, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 40, "reward_mean": 20.1734693877551, "student_loss": null, "teacher_policy_loss": -10.685059547424316, "teacher_value_loss": 49.13589096069336, "teacher_entropy": 0.5875499248504639, "total_time": 1.2902729511260986, "rollout_time": 0.42734241485595703, "train_time": 0.8491346836090088, "student_train_time": 0.013438224792480469, "throughput": 1550.0596197529212, "inference_time": 0.0531595180021327, "env_time": 0.37418289685382433, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 41, "reward_mean": 20.01010101010101, "student_loss": null, "teacher_policy_loss": -11.486129760742188, "teacher_value_loss": 58.08259582519531, "teacher_entropy": 0.6031263470649719, "total_time": 1.242940902709961, "rollout_time": 0.42035984992980957, "train_time": 0.8150601387023926, "student_train_time": 0.007185935974121094, "throughput": 1609.0869611253738, "inference_time": 0.05521833375132701, "env_time": 0.36514151617848256, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 42, "reward_mean": 21.09278350515464, "student_loss": null, "teacher_policy_loss": -10.92113208770752, "teacher_value_loss": 47.43305206298828, "teacher_entropy": 0.6531933546066284, "total_time": 1.2807261943817139, "rollout_time": 0.42124485969543457, "train_time": 0.8339591026306152, "student_train_time": 0.025077342987060547, "throughput": 1561.6140348917625, "inference_time": 0.0540234380007405, "env_time": 0.3672214216946941, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 43, "reward_mean": 21.795454545454547, "student_loss": null, "teacher_policy_loss": -12.245255470275879, "teacher_value_loss": 67.0454330444336, "teacher_entropy": 0.658040463924408, "total_time": 1.2343480587005615, "rollout_time": 0.4273693561553955, "train_time": 0.7930736541748047, "student_train_time": 0.013470172882080078, "throughput": 1620.2885287521458, "inference_time": 0.05421470874972556, "env_time": 0.37315464740566995, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 44, "reward_mean": 23.528735632183906, "student_loss": null, "teacher_policy_loss": -12.889068603515625, "teacher_value_loss": 59.44504928588867, "teacher_entropy": 0.6689723134040833, "total_time": 1.1403183937072754, "rollout_time": 0.4256880283355713, "train_time": 0.7021987438201904, "student_train_time": 0.012039422988891602, "throughput": 1753.896114485906, "inference_time": 0.05565417575047604, "env_time": 0.37003385258509525, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 45, "reward_mean": 23.04597701149425, "student_loss": null, "teacher_policy_loss": -12.636600494384766, "teacher_value_loss": 54.989566802978516, "teacher_entropy": 0.6018900871276855, "total_time": 1.30692458152771, "rollout_time": 0.4297153949737549, "train_time": 0.8671817779541016, "student_train_time": 0.009601593017578125, "throughput": 1530.3101864241698, "inference_time": 0.05584324275156405, "env_time": 0.37387215222219083, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 46, "reward_mean": 21.752688172043012, "student_loss": null, "teacher_policy_loss": -11.905319213867188, "teacher_value_loss": 46.00277328491211, "teacher_entropy": 0.6345770359039307, "total_time": 1.1446075439453125, "rollout_time": 0.44833946228027344, "train_time": 0.6860146522521973, "student_train_time": 0.009898185729980469, "throughput": 1747.323797208484, "inference_time": 0.056637431998353804, "env_time": 0.39170203028191963, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 47, "reward_mean": 23.046511627906977, "student_loss": null, "teacher_policy_loss": -12.791463851928711, "teacher_value_loss": 62.80084991455078, "teacher_entropy": 0.6748484373092651, "total_time": 1.1447539329528809, "rollout_time": 0.4229123592376709, "train_time": 0.7140762805938721, "student_train_time": 0.0073146820068359375, "throughput": 1747.1003526854201, "inference_time": 0.05392240924823, "env_time": 0.3689899499894409, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 48, "reward_mean": 21.127659574468087, "student_loss": null, "teacher_policy_loss": -11.434178352355957, "teacher_value_loss": 50.479820251464844, "teacher_entropy": 0.6772636771202087, "total_time": 1.2444312572479248, "rollout_time": 0.43680357933044434, "train_time": 0.7997007369995117, "student_train_time": 0.007544040679931641, "throughput": 1607.159887982101, "inference_time": 0.05487259599948402, "env_time": 0.3819309833309603, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 49, "reward_mean": 22.054945054945055, "student_loss": null, "teacher_policy_loss": -11.800535202026367, "teacher_value_loss": 38.55611801147461, "teacher_entropy": 0.6693257093429565, "total_time": 1.1937589645385742, "rollout_time": 0.4442276954650879, "train_time": 0.7389011383056641, "student_train_time": 0.010279655456542969, "throughput": 1675.38008878791, "inference_time": 0.06003057049997551, "env_time": 0.3841971249651124, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 50, "reward_mean": 21.361702127659573, "student_loss": null, "teacher_policy_loss": -11.705696105957031, "teacher_value_loss": 45.81075668334961, "teacher_entropy": 0.6504995822906494, "total_time": 1.3067567348480225, "rollout_time": 0.4339885711669922, "train_time": 0.8595783710479736, "student_train_time": 0.012793779373168945, "throughput": 1530.5067474801288, "inference_time": 0.05355767149899293, "env_time": 0.38043089966799926, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 51, "reward_mean": 21.0625, "student_loss": null, "teacher_policy_loss": -11.94618034362793, "teacher_value_loss": 45.899017333984375, "teacher_entropy": 0.6834890246391296, "total_time": 1.1831767559051514, "rollout_time": 0.43430089950561523, "train_time": 0.7360925674438477, "student_train_time": 0.012439966201782227, "throughput": 1690.3645123335475, "inference_time": 0.052938080251351494, "env_time": 0.38136281925426374, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 52, "reward_mean": 23.69047619047619, "student_loss": null, "teacher_policy_loss": -14.201404571533203, "teacher_value_loss": 106.45491027832031, "teacher_entropy": 0.6823736429214478, "total_time": 1.363771915435791, "rollout_time": 0.4275531768798828, "train_time": 0.9247229099273682, "student_train_time": 0.011157035827636719, "throughput": 1466.5208876668378, "inference_time": 0.05453331449984944, "env_time": 0.3730198623800334, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 53, "reward_mean": 22.71590909090909, "student_loss": null, "teacher_policy_loss": -12.771334648132324, "teacher_value_loss": 62.32978439331055, "teacher_entropy": 0.6767487525939941, "total_time": 1.3601300716400146, "rollout_time": 0.5771114826202393, "train_time": 0.7719354629516602, "student_train_time": 0.010695219039916992, "throughput": 1470.4476003449026, "inference_time": 0.1334194862507161, "env_time": 0.44369199636952317, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 54, "reward_mean": 24.14814814814815, "student_loss": null, "teacher_policy_loss": -14.25329875946045, "teacher_value_loss": 81.32427215576172, "teacher_entropy": 0.6786660552024841, "total_time": 1.2093877792358398, "rollout_time": 0.4420645236968994, "train_time": 0.7596421241760254, "student_train_time": 0.007337808609008789, "throughput": 1653.7292953825895, "inference_time": 0.05637128049909279, "env_time": 0.3856932431978066, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 55, "reward_mean": 23.88235294117647, "student_loss": null, "teacher_policy_loss": -13.845283508300781, "teacher_value_loss": 101.04145812988281, "teacher_entropy": 0.6699112057685852, "total_time": 1.4488255977630615, "rollout_time": 0.5579705238342285, "train_time": 0.8804647922515869, "student_train_time": 0.010024309158325195, "throughput": 1380.428398758231, "inference_time": 0.1279978829998072, "env_time": 0.4299726408344213, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 56, "reward_mean": 23.904761904761905, "student_loss": null, "teacher_policy_loss": -14.379305839538574, "teacher_value_loss": 100.22254180908203, "teacher_entropy": 0.6617521047592163, "total_time": 1.277376413345337, "rollout_time": 0.43682432174682617, "train_time": 0.821751594543457, "student_train_time": 0.01844930648803711, "throughput": 1565.7091982481304, "inference_time": 0.056465596250063754, "env_time": 0.3803587254967624, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 57, "reward_mean": 25.103896103896105, "student_loss": null, "teacher_policy_loss": -15.205153465270996, "teacher_value_loss": 96.49498748779297, "teacher_entropy": 0.6591860055923462, "total_time": 1.2854259014129639, "rollout_time": 0.42145681381225586, "train_time": 0.8534684181213379, "student_train_time": 0.010164499282836914, "throughput": 1555.9045432347077, "inference_time": 0.05255164125145484, "env_time": 0.368905172560801, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 58, "reward_mean": 22.23076923076923, "student_loss": null, "teacher_policy_loss": -12.859890937805176, "teacher_value_loss": 85.19778442382812, "teacher_entropy": 0.6415724754333496, "total_time": 1.3144240379333496, "rollout_time": 0.455996036529541, "train_time": 0.846036434173584, "student_train_time": 0.01204371452331543, "throughput": 1521.57898994648, "inference_time": 0.05793196124864153, "env_time": 0.3980640752808995, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 59, "reward_mean": 24.30952380952381, "student_loss": null, "teacher_policy_loss": -14.243664741516113, "teacher_value_loss": 97.76349639892578, "teacher_entropy": 0.6347065567970276, "total_time": 1.17618727684021, "rollout_time": 0.42174839973449707, "train_time": 0.7438106536865234, "student_train_time": 0.010285139083862305, "throughput": 1700.4094835755552, "inference_time": 0.053724694249979166, "env_time": 0.3680237054845179, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 60, "reward_mean": 23.705882352941178, "student_loss": null, "teacher_policy_loss": -14.237750053405762, "teacher_value_loss": 87.81682586669922, "teacher_entropy": 0.6524931192398071, "total_time": -0.2917947769165039, "rollout_time": 0.4261751174926758, "train_time": -0.7289679050445557, "student_train_time": 0.010645866394042969, "throughput": 200000000000.0, "inference_time": 0.0526056089983058, "env_time": 0.37356950849437, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 61, "reward_mean": 22.862068965517242, "student_loss": null, "teacher_policy_loss": -12.2616548538208, "teacher_value_loss": 47.418006896972656, "teacher_entropy": 0.6597570776939392, "total_time": 1.1797478199005127, "rollout_time": 0.4186573028564453, "train_time": 0.7531819343566895, "student_train_time": 0.007544517517089844, "throughput": 1695.2775553072509, "inference_time": 0.053991185250197304, "env_time": 0.364666117606248, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 62, "reward_mean": 24.468354430379748, "student_loss": null, "teacher_policy_loss": -13.351421356201172, "teacher_value_loss": 61.65780258178711, "teacher_entropy": 0.6214936375617981, "total_time": 1.2218255996704102, "rollout_time": 0.43052172660827637, "train_time": 0.7842926979064941, "student_train_time": 0.0065577030181884766, "throughput": 1636.894824056317, "inference_time": 0.05391164475167898, "env_time": 0.3766100818565974, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 63, "reward_mean": 24.662650602409638, "student_loss": null, "teacher_policy_loss": -13.447911262512207, "teacher_value_loss": 96.35475158691406, "teacher_entropy": 0.594748854637146, "total_time": 1.216857671737671, "rollout_time": 0.4352381229400635, "train_time": 0.7740201950073242, "student_train_time": 0.0070648193359375, "throughput": 1643.5775904210745, "inference_time": 0.054209116499691845, "env_time": 0.38102900644037163, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 64, "reward_mean": 21.967741935483872, "student_loss": null, "teacher_policy_loss": -12.496380805969238, "teacher_value_loss": 63.61260986328125, "teacher_entropy": 0.6280804872512817, "total_time": 1.1848056316375732, "rollout_time": 0.41581082344055176, "train_time": 0.7603919506072998, "student_train_time": 0.008211612701416016, "throughput": 1688.0405921397503, "inference_time": 0.05478403800077558, "env_time": 0.3610267854397762, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 65, "reward_mean": 28.115942028985508, "student_loss": null, "teacher_policy_loss": -15.514389038085938, "teacher_value_loss": 123.55980682373047, "teacher_entropy": 0.6653019785881042, "total_time": 1.285921335220337, "rollout_time": 0.42549753189086914, "train_time": 0.8461325168609619, "student_train_time": 0.01393747329711914, "throughput": 1555.3050915492502, "inference_time": 0.05539869100010719, "env_time": 0.37009884089076195, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 66, "reward_mean": 25.22222222222222, "student_loss": null, "teacher_policy_loss": -12.663138389587402, "teacher_value_loss": 73.1858901977539, "teacher_entropy": 0.6481040120124817, "total_time": 1.1144604682922363, "rollout_time": 0.42228198051452637, "train_time": 0.6802506446838379, "student_train_time": 0.01158452033996582, "throughput": 1794.5903483366585, "inference_time": 0.05299779450024289, "env_time": 0.3692841860142835, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 67, "reward_mean": 23.50588235294118, "student_loss": null, "teacher_policy_loss": -12.830788612365723, "teacher_value_loss": 56.13209533691406, "teacher_entropy": 0.6777499914169312, "total_time": 1.1925725936889648, "rollout_time": 0.42606067657470703, "train_time": 0.7563424110412598, "student_train_time": 0.009761333465576172, "throughput": 1677.0467563852305, "inference_time": 0.05506701799873781, "env_time": 0.3709936585759692, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 68, "reward_mean": 24.294871794871796, "student_loss": null, "teacher_policy_loss": -13.199548721313477, "teacher_value_loss": 55.970760345458984, "teacher_entropy": 0.6312527656555176, "total_time": 1.2979412078857422, "rollout_time": 0.4694221019744873, "train_time": 0.8006987571716309, "student_train_time": 0.027464628219604492, "throughput": 1540.9018435109735, "inference_time": 0.06457703399905768, "env_time": 0.40484506797542963, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 69, "reward_mean": 25.11904761904762, "student_loss": null, "teacher_policy_loss": -11.896455764770508, "teacher_value_loss": 48.81668472290039, "teacher_entropy": 0.5884092450141907, "total_time": 1.1774072647094727, "rollout_time": 0.42414355278015137, "train_time": 0.7480359077453613, "student_train_time": 0.004879474639892578, "throughput": 1698.6475792584001, "inference_time": 0.05465459250052618, "env_time": 0.3694889602796252, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 70, "reward_mean": 25.155844155844157, "student_loss": null, "teacher_policy_loss": -14.065069198608398, "teacher_value_loss": 73.55233001708984, "teacher_entropy": 0.6604583859443665, "total_time": 1.2522578239440918, "rollout_time": 0.42436957359313965, "train_time": 0.8205559253692627, "student_train_time": 0.006982564926147461, "throughput": 1597.1151960550992, "inference_time": 0.053183493251481195, "env_time": 0.37118608034165845, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 71, "reward_mean": 28.166666666666668, "student_loss": null, "teacher_policy_loss": -15.59653091430664, "teacher_value_loss": 105.91815185546875, "teacher_entropy": 0.6765443086624146, "total_time": 1.146505355834961, "rollout_time": 0.42630553245544434, "train_time": 0.7063217163085938, "student_train_time": 0.013448953628540039, "throughput": 1744.431449727915, "inference_time": 0.054488979003338045, "env_time": 0.3718165534521063, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 72, "reward_mean": 26.233766233766232, "student_loss": null, "teacher_policy_loss": -14.905061721801758, "teacher_value_loss": 133.4653778076172, "teacher_entropy": 0.6620061993598938, "total_time": 1.1440303325653076, "rollout_time": 0.42589306831359863, "train_time": 0.7119147777557373, "student_train_time": 0.005870342254638672, "throughput": 1748.2053954944668, "inference_time": 0.051761059250850394, "env_time": 0.37413200906274824, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 73, "reward_mean": 27.833333333333332, "student_loss": null, "teacher_policy_loss": -16.305395126342773, "teacher_value_loss": 126.1976547241211, "teacher_entropy": 0.6689465045928955, "total_time": 1.4219164848327637, "rollout_time": 0.5051653385162354, "train_time": 0.8473680019378662, "student_train_time": 0.06897473335266113, "throughput": 1406.5523688159692, "inference_time": 0.06108759949938758, "env_time": 0.4440777390168478, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 74, "reward_mean": 27.057142857142857, "student_loss": null, "teacher_policy_loss": -15.699958801269531, "teacher_value_loss": 92.17066192626953, "teacher_entropy": 0.6704123020172119, "total_time": 1.1779181957244873, "rollout_time": 0.4216890335083008, "train_time": 0.7357094287872314, "student_train_time": 0.02017378807067871, "throughput": 1697.9107778956459, "inference_time": 0.05669482449940233, "env_time": 0.36499420900889845, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 75, "reward_mean": 27.44, "student_loss": null, "teacher_policy_loss": -14.174524307250977, "teacher_value_loss": 84.4967041015625, "teacher_entropy": 0.6351149082183838, "total_time": 1.2153749465942383, "rollout_time": 0.41883158683776855, "train_time": 0.7850205898284912, "student_train_time": 0.011171102523803711, "throughput": 1645.582711413019, "inference_time": 0.05460029800042321, "env_time": 0.36423128883734535, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 76, "reward_mean": 26.763157894736842, "student_loss": null, "teacher_policy_loss": -15.087180137634277, "teacher_value_loss": 127.549072265625, "teacher_entropy": 0.6369116306304932, "total_time": 1.262544870376587, "rollout_time": 0.45348405838012695, "train_time": 0.7915997505187988, "student_train_time": 0.01698017120361328, "throughput": 1584.102115438834, "inference_time": 0.055867141749331495, "env_time": 0.39761691663079546, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 77, "reward_mean": 25.363636363636363, "student_loss": null, "teacher_policy_loss": -13.598917007446289, "teacher_value_loss": 95.29432678222656, "teacher_entropy": 0.6319021582603455, "total_time": 1.1606366634368896, "rollout_time": 0.41030216217041016, "train_time": 0.744591236114502, "student_train_time": 0.005403757095336914, "throughput": 1723.1921608245416, "inference_time": 0.051538886999935585, "env_time": 0.35876327517047457, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 78, "reward_mean": 28.956521739130434, "student_loss": null, "teacher_policy_loss": -16.11420249938965, "teacher_value_loss": 106.08519744873047, "teacher_entropy": 0.643571138381958, "total_time": 1.2819218635559082, "rollout_time": 0.424879789352417, "train_time": 0.8469192981719971, "student_train_time": 0.009770393371582031, "throughput": 1560.1574923234582, "inference_time": 0.054286915251338996, "env_time": 0.370592874101078, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 79, "reward_mean": 26.20253164556962, "student_loss": null, "teacher_policy_loss": -14.237923622131348, "teacher_value_loss": 85.79324340820312, "teacher_entropy": 0.6290367245674133, "total_time": 1.1727781295776367, "rollout_time": 0.42292022705078125, "train_time": 0.7389614582061768, "student_train_time": 0.010523796081542969, "throughput": 1705.352401754182, "inference_time": 0.05511557274758161, "env_time": 0.36780465430319964, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 80, "reward_mean": 28.36231884057971, "student_loss": null, "teacher_policy_loss": -17.162107467651367, "teacher_value_loss": 135.37998962402344, "teacher_entropy": 0.6298465728759766, "total_time": 1.191439151763916, "rollout_time": 0.4201056957244873, "train_time": 0.7623746395111084, "student_train_time": 0.008564233779907227, "throughput": 1678.6421673645827, "inference_time": 0.05306876950021433, "env_time": 0.367036926224273, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 81, "reward_mean": 26.763157894736842, "student_loss": null, "teacher_policy_loss": -14.507372856140137, "teacher_value_loss": 79.24823760986328, "teacher_entropy": 0.6153267621994019, "total_time": 1.2511649131774902, "rollout_time": 0.43479442596435547, "train_time": 0.8071603775024414, "student_train_time": 0.008792400360107422, "throughput": 1598.5102994302717, "inference_time": 0.053993018498317724, "env_time": 0.38080140746603774, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 82, "reward_mean": 27.356164383561644, "student_loss": null, "teacher_policy_loss": -15.091383934020996, "teacher_value_loss": 81.17845153808594, "teacher_entropy": 0.622215986251831, "total_time": 1.1574759483337402, "rollout_time": 0.4186980724334717, "train_time": 0.7321832180023193, "student_train_time": 0.006252288818359375, "throughput": 1727.8976750049333, "inference_time": 0.05459155349865341, "env_time": 0.36410651893481827, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 83, "reward_mean": 31.046875, "student_loss": null, "teacher_policy_loss": -17.547727584838867, "teacher_value_loss": 122.60598754882812, "teacher_entropy": 0.6368213295936584, "total_time": 1.290008544921875, "rollout_time": 0.41298580169677734, "train_time": 0.8546693325042725, "student_train_time": 0.021969079971313477, "throughput": 1550.3773272456294, "inference_time": 0.05408971124876416, "env_time": 0.3588960904480132, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 84, "reward_mean": 26.81578947368421, "student_loss": null, "teacher_policy_loss": -16.270662307739258, "teacher_value_loss": 131.0292510986328, "teacher_entropy": 0.6381268501281738, "total_time": 1.1909091472625732, "rollout_time": 0.42078280448913574, "train_time": 0.7624051570892334, "student_train_time": 0.0065577030181884766, "throughput": 1679.3892335088742, "inference_time": 0.05559763475145019, "env_time": 0.36518516973768556, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 85, "reward_mean": 24.555555555555557, "student_loss": null, "teacher_policy_loss": -14.10081672668457, "teacher_value_loss": 97.11170959472656, "teacher_entropy": 0.6389142870903015, "total_time": 1.2889430522918701, "rollout_time": 0.4473564624786377, "train_time": 0.823378324508667, "student_train_time": 0.017821073532104492, "throughput": 1551.6589320558417, "inference_time": 0.05894566749753949, "env_time": 0.3884107949810982, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 86, "reward_mean": 25.558441558441558, "student_loss": null, "teacher_policy_loss": -14.458602905273438, "teacher_value_loss": 119.73114776611328, "teacher_entropy": 0.6443117260932922, "total_time": -0.38053345680236816, "rollout_time": 0.43857836723327637, "train_time": -0.8302030563354492, "student_train_time": 0.010693073272705078, "throughput": 200000000000.0, "inference_time": 0.05720156100164786, "env_time": 0.3813768062316285, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 87, "reward_mean": 27.985915492957748, "student_loss": null, "teacher_policy_loss": -15.221936225891113, "teacher_value_loss": 92.0636215209961, "teacher_entropy": 0.6477014422416687, "total_time": 1.1071913242340088, "rollout_time": 0.4057302474975586, "train_time": 0.6929576396942139, "student_train_time": 0.008164167404174805, "throughput": 1806.3725358249762, "inference_time": 0.05268762725052056, "env_time": 0.35304262024703803, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 88, "reward_mean": 31.870967741935484, "student_loss": null, "teacher_policy_loss": -17.317951202392578, "teacher_value_loss": 113.4300765991211, "teacher_entropy": 0.6458920836448669, "total_time": 1.2220184803009033, "rollout_time": 0.4085865020751953, "train_time": 0.806077241897583, "student_train_time": 0.007005453109741211, "throughput": 1636.6364602829335, "inference_time": 0.05347900174785991, "env_time": 0.3551075003273354, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 89, "reward_mean": 30.33823529411765, "student_loss": null, "teacher_policy_loss": -16.304067611694336, "teacher_value_loss": 109.04652404785156, "teacher_entropy": 0.656772255897522, "total_time": 1.176180362701416, "rollout_time": 0.43046021461486816, "train_time": 0.7383882999420166, "student_train_time": 0.0069882869720458984, "throughput": 1700.4194793785364, "inference_time": 0.05518494949842534, "env_time": 0.3752752651164428, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 90, "reward_mean": 29.671641791044777, "student_loss": null, "teacher_policy_loss": -16.521163940429688, "teacher_value_loss": 101.8856430053711, "teacher_entropy": 0.6615129709243774, "total_time": 1.1233634948730469, "rollout_time": 0.39855217933654785, "train_time": 0.7122752666473389, "student_train_time": 0.01217794418334961, "throughput": 1780.3676273333265, "inference_time": 0.05114840124974762, "env_time": 0.34740377808680023, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 91, "reward_mean": 29.11764705882353, "student_loss": null, "teacher_policy_loss": -16.500850677490234, "teacher_value_loss": 115.358154296875, "teacher_entropy": 0.6546436548233032, "total_time": 1.277228832244873, "rollout_time": 0.4145987033843994, "train_time": 0.8512923717498779, "student_train_time": 0.010974884033203125, "throughput": 1565.8901126470623, "inference_time": 0.052640548751128335, "env_time": 0.3619581546332711, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 92, "reward_mean": 32.26229508196721, "student_loss": null, "teacher_policy_loss": -17.21202850341797, "teacher_value_loss": 98.059326171875, "teacher_entropy": 0.6441553235054016, "total_time": 1.17551589012146, "rollout_time": 0.39986658096313477, "train_time": 0.7673602104187012, "student_train_time": 0.00791311264038086, "throughput": 1701.3806591702903, "inference_time": 0.05137922075221013, "env_time": 0.34848736021092463, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 93, "reward_mean": 27.65753424657534, "student_loss": null, "teacher_policy_loss": -15.172607421875, "teacher_value_loss": 95.91869354248047, "teacher_entropy": 0.6504616737365723, "total_time": 1.2169508934020996, "rollout_time": 0.4079766273498535, "train_time": 0.8004662990570068, "student_train_time": 0.008072137832641602, "throughput": 1643.4516880207168, "inference_time": 0.053809060498224426, "env_time": 0.3541675668516291, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 94, "reward_mean": 27.136986301369863, "student_loss": null, "teacher_policy_loss": -15.073966026306152, "teacher_value_loss": 79.2054672241211, "teacher_entropy": 0.6459550857543945, "total_time": 1.2368052005767822, "rollout_time": 0.45907092094421387, "train_time": 0.7697703838348389, "student_train_time": 0.007561922073364258, "throughput": 1617.0695264438596, "inference_time": 0.05893037199973605, "env_time": 0.4001405489444778, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 95, "reward_mean": 29.271428571428572, "student_loss": null, "teacher_policy_loss": -16.116195678710938, "teacher_value_loss": 111.45362091064453, "teacher_entropy": 0.6469162702560425, "total_time": 1.2426507472991943, "rollout_time": 0.5387482643127441, "train_time": 0.6975269317626953, "student_train_time": 0.00603175163269043, "throughput": 1609.4626783485592, "inference_time": 0.06204313525154248, "env_time": 0.47670512906120166, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 96, "reward_mean": 30.276923076923076, "student_loss": null, "teacher_policy_loss": -16.92763900756836, "teacher_value_loss": 95.94575500488281, "teacher_entropy": 0.637722909450531, "total_time": 1.3301360607147217, "rollout_time": 0.43068742752075195, "train_time": 0.892364501953125, "student_train_time": 0.006732940673828125, "throughput": 1503.605577707096, "inference_time": 0.05699823449867836, "env_time": 0.3736891930220736, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 97, "reward_mean": 29.28985507246377, "student_loss": null, "teacher_policy_loss": -16.842798233032227, "teacher_value_loss": 152.2017059326172, "teacher_entropy": 0.6351057887077332, "total_time": 1.1283254623413086, "rollout_time": 0.43684911727905273, "train_time": 0.6816847324371338, "student_train_time": 0.009413003921508789, "throughput": 1772.538214151386, "inference_time": 0.053515107498355974, "env_time": 0.38333400978069676, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 98, "reward_mean": 31.453125, "student_loss": null, "teacher_policy_loss": -18.609405517578125, "teacher_value_loss": 153.23934936523438, "teacher_entropy": 0.6251947283744812, "total_time": 1.2521531581878662, "rollout_time": 0.42250800132751465, "train_time": 0.7895934581756592, "student_train_time": 0.03965497016906738, "throughput": 1597.248696712492, "inference_time": 0.0546840732478131, "env_time": 0.36782392807970155, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 99, "reward_mean": 29.0, "student_loss": null, "teacher_policy_loss": -16.130067825317383, "teacher_value_loss": 84.70633697509766, "teacher_entropy": 0.6355357766151428, "total_time": 1.233389139175415, "rollout_time": 0.43724799156188965, "train_time": 0.7866346836090088, "student_train_time": 0.00914454460144043, "throughput": 1621.5482498387364, "inference_time": 0.055594473000041944, "env_time": 0.3816535185618477, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 100, "reward_mean": 34.94827586206897, "student_loss": null, "teacher_policy_loss": -18.717151641845703, "teacher_value_loss": 126.00984954833984, "teacher_entropy": 0.6324867010116577, "total_time": 1.1539781093597412, "rollout_time": 0.4132206439971924, "train_time": 0.7204997539520264, "student_train_time": 0.019908666610717773, "throughput": 1733.135129495355, "inference_time": 0.05241442350109082, "env_time": 0.36080622049610156, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 101, "reward_mean": 39.21568627450981, "student_loss": null, "teacher_policy_loss": -21.02437973022461, "teacher_value_loss": 184.05702209472656, "teacher_entropy": 0.6287214756011963, "total_time": 1.266336441040039, "rollout_time": 0.41139960289001465, "train_time": 0.8447976112365723, "student_train_time": 0.00979757308959961, "throughput": 1579.3591143577964, "inference_time": 0.05390576225101995, "env_time": 0.3574938406389947, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 102, "reward_mean": 30.545454545454547, "student_loss": null, "teacher_policy_loss": -15.896621704101562, "teacher_value_loss": 103.47814178466797, "teacher_entropy": 0.6238581538200378, "total_time": 1.180739402770996, "rollout_time": 0.40796327590942383, "train_time": 0.7624430656433105, "student_train_time": 0.009989738464355469, "throughput": 1693.8538642026663, "inference_time": 0.051051237002411654, "env_time": 0.3569120389070122, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 103, "reward_mean": 30.848484848484848, "student_loss": null, "teacher_policy_loss": -16.60205841064453, "teacher_value_loss": 129.0020294189453, "teacher_entropy": 0.6186763644218445, "total_time": 1.264690637588501, "rollout_time": 0.4149932861328125, "train_time": 0.8345603942871094, "student_train_time": 0.014792203903198242, "throughput": 1581.4144112061897, "inference_time": 0.05419854774709165, "env_time": 0.36079473838572085, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 104, "reward_mean": 30.734375, "student_loss": null, "teacher_policy_loss": -17.52979278564453, "teacher_value_loss": 135.846435546875, "teacher_entropy": 0.6188861131668091, "total_time": 1.2512977123260498, "rollout_time": 0.4575169086456299, "train_time": 0.7836172580718994, "student_train_time": 0.009705305099487305, "throughput": 1598.3406509088713, "inference_time": 0.054663213497406105, "env_time": 0.4028536951482238, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 105, "reward_mean": 33.758620689655174, "student_loss": null, "teacher_policy_loss": -18.367534637451172, "teacher_value_loss": 112.88870239257812, "teacher_entropy": 0.633398175239563, "total_time": 1.1392858028411865, "rollout_time": 0.4046156406402588, "train_time": 0.7230985164642334, "student_train_time": 0.01119542121887207, "throughput": 1755.4857569648789, "inference_time": 0.05229079099967748, "env_time": 0.3523248496405813, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 106, "reward_mean": 33.38709677419355, "student_loss": null, "teacher_policy_loss": -17.37013053894043, "teacher_value_loss": 114.35665130615234, "teacher_entropy": 0.6264825463294983, "total_time": 1.2998831272125244, "rollout_time": 0.41681766510009766, "train_time": 0.875584602355957, "student_train_time": 0.007142066955566406, "throughput": 1538.5998618882065, "inference_time": 0.05251196499773414, "env_time": 0.3643057001023635, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 107, "reward_mean": 31.21875, "student_loss": null, "teacher_policy_loss": -17.608169555664062, "teacher_value_loss": 131.67845153808594, "teacher_entropy": 0.6264809370040894, "total_time": 1.16363525390625, "rollout_time": 0.4350874423980713, "train_time": 0.7124383449554443, "student_train_time": 0.015766143798828125, "throughput": 1718.7516391292945, "inference_time": 0.056514333752261336, "env_time": 0.37857310864580995, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 108, "reward_mean": 36.851851851851855, "student_loss": null, "teacher_policy_loss": -20.839561462402344, "teacher_value_loss": 180.56362915039062, "teacher_entropy": 0.6311657428741455, "total_time": 1.132368803024292, "rollout_time": 0.4113583564758301, "train_time": 0.7154366970062256, "student_train_time": 0.005229949951171875, "throughput": 1766.2090254151017, "inference_time": 0.051683220244512995, "env_time": 0.3596751362313171, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 109, "reward_mean": 29.955882352941178, "student_loss": null, "teacher_policy_loss": -17.257810592651367, "teacher_value_loss": 119.11580657958984, "teacher_entropy": 0.6156831979751587, "total_time": 1.2971699237823486, "rollout_time": 0.43019890785217285, "train_time": 0.859412431716919, "student_train_time": 0.007217884063720703, "throughput": 1541.818048146157, "inference_time": 0.05641150450060195, "env_time": 0.3737874033515709, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 110, "reward_mean": 29.62121212121212, "student_loss": null, "teacher_policy_loss": -16.482507705688477, "teacher_value_loss": 93.67845153808594, "teacher_entropy": 0.6172462105751038, "total_time": 1.1406550407409668, "rollout_time": 0.42301368713378906, "train_time": 0.7064685821533203, "student_train_time": 0.010825634002685547, "throughput": 1753.378478651008, "inference_time": 0.05536110549769546, "env_time": 0.3676525816360936, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 111, "reward_mean": 33.16393442622951, "student_loss": null, "teacher_policy_loss": -17.619972229003906, "teacher_value_loss": 108.84429931640625, "teacher_entropy": 0.6235619187355042, "total_time": 1.177882432937622, "rollout_time": 0.4215383529663086, "train_time": 0.7463440895080566, "student_train_time": 0.00965118408203125, "throughput": 1697.9623297479939, "inference_time": 0.051951727246319024, "env_time": 0.36958662571998957, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 112, "reward_mean": 30.01492537313433, "student_loss": null, "teacher_policy_loss": -16.305091857910156, "teacher_value_loss": 103.79029846191406, "teacher_entropy": 0.6217055916786194, "total_time": 1.2265334129333496, "rollout_time": 0.4253814220428467, "train_time": 0.7914972305297852, "student_train_time": 0.00931859016418457, "throughput": 1630.6119172219248, "inference_time": 0.056344119250752556, "env_time": 0.3690373027920941, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 113, "reward_mean": 35.125, "student_loss": null, "teacher_policy_loss": -19.613988876342773, "teacher_value_loss": 121.6748046875, "teacher_entropy": 0.6267022490501404, "total_time": -0.38341856002807617, "rollout_time": -1.1744439601898193, "train_time": 0.7793862819671631, "student_train_time": 0.011292219161987305, "throughput": 200000000000.0, "inference_time": 0.05952201024479109, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 114, "reward_mean": 38.15686274509804, "student_loss": null, "teacher_policy_loss": -20.046205520629883, "teacher_value_loss": 136.3837127685547, "teacher_entropy": 0.622333824634552, "total_time": 1.2524609565734863, "rollout_time": 0.40612196922302246, "train_time": 0.8361945152282715, "student_train_time": 0.009793519973754883, "throughput": 1596.8561650589488, "inference_time": 0.05330696175190042, "env_time": 0.35281500747112204, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 115, "reward_mean": 40.04, "student_loss": null, "teacher_policy_loss": -21.08439826965332, "teacher_value_loss": 146.32582092285156, "teacher_entropy": 0.6261563301086426, "total_time": 1.1336631774902344, "rollout_time": 0.4331951141357422, "train_time": 0.6919198036193848, "student_train_time": 0.008204221725463867, "throughput": 1764.1924336183429, "inference_time": 0.0532508435002228, "env_time": 0.3799442706355194, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 116, "reward_mean": 33.9, "student_loss": null, "teacher_policy_loss": -17.719337463378906, "teacher_value_loss": 105.66191864013672, "teacher_entropy": 0.6137499809265137, "total_time": 1.3203890323638916, "rollout_time": 0.4141049385070801, "train_time": 0.9008095264434814, "student_train_time": 0.00507664680480957, "throughput": 1514.7050990111613, "inference_time": 0.052091649002818485, "env_time": 0.3620132895042616, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 117, "reward_mean": 41.166666666666664, "student_loss": null, "teacher_policy_loss": -21.621780395507812, "teacher_value_loss": 191.86032104492188, "teacher_entropy": 0.6244444251060486, "total_time": 1.2560617923736572, "rollout_time": 0.444516658782959, "train_time": 0.8028402328491211, "student_train_time": 0.008358001708984375, "throughput": 1592.2783513862619, "inference_time": 0.0594965000011598, "env_time": 0.3850201587817992, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 118, "reward_mean": 33.11290322580645, "student_loss": null, "teacher_policy_loss": -17.102676391601562, "teacher_value_loss": 116.20429229736328, "teacher_entropy": 0.6175709366798401, "total_time": 1.134521722793579, "rollout_time": 0.40453481674194336, "train_time": 0.7167747020721436, "student_train_time": 0.012877464294433594, "throughput": 1762.8573872303814, "inference_time": 0.05199893724955018, "env_time": 0.3525358794923932, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 119, "reward_mean": 36.38461538461539, "student_loss": null, "teacher_policy_loss": -20.232574462890625, "teacher_value_loss": 179.5172119140625, "teacher_entropy": 0.6062394380569458, "total_time": 1.2566099166870117, "rollout_time": 0.4114687442779541, "train_time": 0.8395628929138184, "student_train_time": 0.00516819953918457, "throughput": 1591.5838108877085, "inference_time": 0.0539308869991828, "env_time": 0.3575378572787713, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 120, "reward_mean": 41.15686274509804, "student_loss": null, "teacher_policy_loss": -21.118715286254883, "teacher_value_loss": 180.87188720703125, "teacher_entropy": 0.6120173335075378, "total_time": 1.1669704914093018, "rollout_time": 0.43343448638916016, "train_time": 0.7248971462249756, "student_train_time": 0.008266687393188477, "throughput": 1713.8393941604154, "inference_time": 0.056234154753042276, "env_time": 0.3772003316361179, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 121, "reward_mean": 36.38181818181818, "student_loss": null, "teacher_policy_loss": -18.884817123413086, "teacher_value_loss": 152.93162536621094, "teacher_entropy": 0.6072129011154175, "total_time": 1.1702585220336914, "rollout_time": 0.44152283668518066, "train_time": 0.7206606864929199, "student_train_time": 0.007724285125732422, "throughput": 1709.024085143488, "inference_time": 0.0560374044987384, "env_time": 0.38548543218644227, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 122, "reward_mean": 38.19230769230769, "student_loss": null, "teacher_policy_loss": -22.14723014831543, "teacher_value_loss": 259.9728698730469, "teacher_entropy": 0.601162850856781, "total_time": 1.265678882598877, "rollout_time": 0.4175295829772949, "train_time": 0.8362040519714355, "student_train_time": 0.011564493179321289, "throughput": 1580.1796391619553, "inference_time": 0.053360582746904583, "env_time": 0.36416900023039034, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 123, "reward_mean": 34.08620689655172, "student_loss": null, "teacher_policy_loss": -19.37504768371582, "teacher_value_loss": 201.14501953125, "teacher_entropy": 0.6071613430976868, "total_time": 1.1706149578094482, "rollout_time": 0.42165327072143555, "train_time": 0.739682674407959, "student_train_time": 0.008934259414672852, "throughput": 1708.503711367712, "inference_time": 0.054019440746742475, "env_time": 0.36763382997469307, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 124, "reward_mean": 38.43396226415094, "student_loss": null, "teacher_policy_loss": -22.703645706176758, "teacher_value_loss": 309.6814880371094, "teacher_entropy": 0.6127495169639587, "total_time": 1.245471477508545, "rollout_time": 0.4281599521636963, "train_time": 0.8087763786315918, "student_train_time": 0.008200645446777344, "throughput": 1605.8175848400979, "inference_time": 0.056406909002021166, "env_time": 0.3717530431616751, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 125, "reward_mean": 34.46551724137931, "student_loss": null, "teacher_policy_loss": -19.077375411987305, "teacher_value_loss": 144.63294982910156, "teacher_entropy": 0.6040863990783691, "total_time": 1.1582224369049072, "rollout_time": 0.4258756637573242, "train_time": 0.7226459980010986, "student_train_time": 0.009355545043945312, "throughput": 1726.7840237532928, "inference_time": 0.05355525049571952, "env_time": 0.3723204132616047, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 126, "reward_mean": 37.07272727272727, "student_loss": null, "teacher_policy_loss": -19.985239028930664, "teacher_value_loss": 142.23397827148438, "teacher_entropy": 0.6149629354476929, "total_time": 1.146838903427124, "rollout_time": 0.40897607803344727, "train_time": 0.7263827323913574, "student_train_time": 0.01112818717956543, "throughput": 1743.92409781649, "inference_time": 0.052872871249292075, "env_time": 0.3561032067841552, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 127, "reward_mean": 33.333333333333336, "student_loss": null, "teacher_policy_loss": -18.705659866333008, "teacher_value_loss": 117.3511734008789, "teacher_entropy": 0.6030526757240295, "total_time": 1.3029680252075195, "rollout_time": 0.4100341796875, "train_time": 0.8801252841949463, "student_train_time": 0.012468576431274414, "throughput": 1534.9570836026205, "inference_time": 0.05346094525236822, "env_time": 0.3565732344351318, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 128, "reward_mean": 46.93333333333333, "student_loss": null, "teacher_policy_loss": -21.763479232788086, "teacher_value_loss": 156.3645477294922, "teacher_entropy": 0.6160234808921814, "total_time": 1.176354169845581, "rollout_time": 0.43518686294555664, "train_time": 0.7283554077148438, "student_train_time": 0.012053251266479492, "throughput": 1700.1682412215516, "inference_time": 0.05520000650130896, "env_time": 0.3799868564442477, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 129, "reward_mean": 38.339622641509436, "student_loss": null, "teacher_policy_loss": -19.909523010253906, "teacher_value_loss": 143.22470092773438, "teacher_entropy": 0.6124976277351379, "total_time": 1.1806533336639404, "rollout_time": 0.40769100189208984, "train_time": 0.765005350112915, "student_train_time": 0.0076160430908203125, "throughput": 1693.9773454019462, "inference_time": 0.052200343753725065, "env_time": 0.3554906581383648, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 130, "reward_mean": 38.57692307692308, "student_loss": null, "teacher_policy_loss": -20.452850341796875, "teacher_value_loss": 156.2676239013672, "teacher_entropy": 0.5911378264427185, "total_time": 1.3081464767456055, "rollout_time": 0.4858875274658203, "train_time": 0.8140103816986084, "student_train_time": 0.007816791534423828, "throughput": 1528.8807756265805, "inference_time": 0.05910608650128779, "env_time": 0.4267814409645325, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 131, "reward_mean": 42.829787234042556, "student_loss": null, "teacher_policy_loss": -21.85157585144043, "teacher_value_loss": 179.16014099121094, "teacher_entropy": 0.6036421656608582, "total_time": 1.1928248405456543, "rollout_time": 0.4128296375274658, "train_time": 0.7673895359039307, "student_train_time": 0.01226353645324707, "throughput": 1676.692111043819, "inference_time": 0.053932730250267014, "env_time": 0.3588969072771988, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 132, "reward_mean": 46.16279069767442, "student_loss": null, "teacher_policy_loss": -23.927444458007812, "teacher_value_loss": 207.2960662841797, "teacher_entropy": 0.6040734648704529, "total_time": 1.2625172138214111, "rollout_time": 0.41193079948425293, "train_time": 0.8390984535217285, "student_train_time": 0.010874032974243164, "throughput": 1584.1368165954443, "inference_time": 0.05416739199802123, "env_time": 0.3577634074862317, "samples": 2000, "teacher_eval_reward": null}
