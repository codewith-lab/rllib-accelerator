{"epoch": 1, "reward_mean": 24.31645569620253, "student_loss": null, "teacher_policy_loss": -14.652139663696289, "teacher_value_loss": 349.3486633300781, "teacher_entropy": 0.6772603392601013, "total_time": 1.8331494331359863, "rollout_time": 0.42877936363220215, "train_time": 1.3208529949188232, "student_train_time": 0.08309555053710938, "throughput": 1091.018530103452, "inference_time": 0.055222110751003584, "env_time": 0.37355725288119856, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 2, "reward_mean": 22.942528735632184, "student_loss": null, "teacher_policy_loss": -12.935397148132324, "teacher_value_loss": 151.32687377929688, "teacher_entropy": 0.6830154061317444, "total_time": 1.4472451210021973, "rollout_time": 0.5956165790557861, "train_time": 0.8199949264526367, "student_train_time": 0.03099536895751953, "throughput": 1381.9359077300103, "inference_time": 0.0759728587487416, "env_time": 0.5196437203070445, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 3, "reward_mean": 23.089887640449437, "student_loss": null, "teacher_policy_loss": -12.423694610595703, "teacher_value_loss": 122.58110809326172, "teacher_entropy": 0.6738150119781494, "total_time": 1.2422759532928467, "rollout_time": 0.4431135654449463, "train_time": 0.7924306392669678, "student_train_time": 0.0062961578369140625, "throughput": 1609.9482523980982, "inference_time": 0.05476034699898946, "env_time": 0.3883532184459568, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 4, "reward_mean": 25.31645569620253, "student_loss": null, "teacher_policy_loss": -14.704482078552246, "teacher_value_loss": 158.19247436523438, "teacher_entropy": 0.6578744649887085, "total_time": -0.23033547401428223, "rollout_time": 0.45117735862731934, "train_time": -0.689406156539917, "student_train_time": 0.007463932037353516, "throughput": 200000000000.0, "inference_time": 0.05678931549982735, "env_time": 0.394388043127492, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 5, "reward_mean": 25.346153846153847, "student_loss": null, "teacher_policy_loss": -13.630928039550781, "teacher_value_loss": 153.40333557128906, "teacher_entropy": 0.5786226391792297, "total_time": 1.1871843338012695, "rollout_time": 0.4237782955169678, "train_time": 0.7472045421600342, "student_train_time": 0.0157928466796875, "throughput": 1684.658349218743, "inference_time": 0.05372849674978397, "env_time": 0.3700497987671838, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 6, "reward_mean": 24.475609756097562, "student_loss": null, "teacher_policy_loss": -13.096919059753418, "teacher_value_loss": 140.73863220214844, "teacher_entropy": 0.573955774307251, "total_time": 1.3184773921966553, "rollout_time": 0.4255232810974121, "train_time": 0.877387523651123, "student_train_time": 0.015130043029785156, "throughput": 1516.9012467236096, "inference_time": 0.054905211498635254, "env_time": 0.37061806959877686, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 7, "reward_mean": 27.027397260273972, "student_loss": null, "teacher_policy_loss": -14.69745922088623, "teacher_value_loss": 105.35867309570312, "teacher_entropy": 0.6421694159507751, "total_time": 1.3180713653564453, "rollout_time": 0.5096054077148438, "train_time": 0.7992105484008789, "student_train_time": 0.008802652359008789, "throughput": 1517.3685223479088, "inference_time": 0.0683576592508075, "env_time": 0.44124774846403625, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 8, "reward_mean": 26.43661971830986, "student_loss": null, "teacher_policy_loss": -12.811288833618164, "teacher_value_loss": 107.55095672607422, "teacher_entropy": 0.5305068492889404, "total_time": 1.1965527534484863, "rollout_time": 0.4201200008392334, "train_time": 0.7568540573120117, "student_train_time": 0.019195079803466797, "throughput": 1671.4683027856183, "inference_time": 0.05576382800029478, "env_time": 0.3643561728389386, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 9, "reward_mean": 23.84269662921348, "student_loss": null, "teacher_policy_loss": -11.458126068115234, "teacher_value_loss": 82.00250244140625, "teacher_entropy": 0.5746045112609863, "total_time": 1.2817368507385254, "rollout_time": 0.44590115547180176, "train_time": 0.8231644630432129, "student_train_time": 0.012256383895874023, "throughput": 1560.3826938794946, "inference_time": 0.05781067525037997, "env_time": 0.3880904802214218, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 10, "reward_mean": 25.896103896103895, "student_loss": null, "teacher_policy_loss": -14.695552825927734, "teacher_value_loss": 93.55169677734375, "teacher_entropy": 0.6280426383018494, "total_time": 1.1823041439056396, "rollout_time": 0.422774076461792, "train_time": 0.7514314651489258, "student_train_time": 0.0077016353607177734, "throughput": 1691.6121036277286, "inference_time": 0.054469156249922435, "env_time": 0.36830492021186956, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 11, "reward_mean": 27.125, "student_loss": null, "teacher_policy_loss": -15.963314056396484, "teacher_value_loss": 136.31851196289062, "teacher_entropy": 0.6346808075904846, "total_time": 1.2058393955230713, "rollout_time": 0.433624267578125, "train_time": 0.7639715671539307, "student_train_time": 0.007893800735473633, "throughput": 1658.595669892205, "inference_time": 0.057512658750340506, "env_time": 0.3761116088277845, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 12, "reward_mean": 28.59722222222222, "student_loss": null, "teacher_policy_loss": -16.08284568786621, "teacher_value_loss": 104.76209259033203, "teacher_entropy": 0.6587992310523987, "total_time": 1.2278003692626953, "rollout_time": 0.4293324947357178, "train_time": 0.7909927368164062, "student_train_time": 0.007083892822265625, "throughput": 1628.9293032229803, "inference_time": 0.053951513000299656, "env_time": 0.3753809817354181, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 13, "reward_mean": 26.03846153846154, "student_loss": null, "teacher_policy_loss": -14.098015785217285, "teacher_value_loss": 78.24517822265625, "teacher_entropy": 0.6677433848381042, "total_time": 1.4203507900238037, "rollout_time": 0.43366312980651855, "train_time": 0.9377455711364746, "student_train_time": 0.04848504066467285, "throughput": 1408.102853215917, "inference_time": 0.057075580999992326, "env_time": 0.37658754880652623, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 14, "reward_mean": 27.26027397260274, "student_loss": null, "teacher_policy_loss": -15.249418258666992, "teacher_value_loss": 99.44589233398438, "teacher_entropy": 0.6764222979545593, "total_time": 1.2959060668945312, "rollout_time": 0.4485900402069092, "train_time": 0.8351137638092041, "student_train_time": 0.011760473251342773, "throughput": 1543.3217353420819, "inference_time": 0.055026605750981616, "env_time": 0.39356343445592756, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 15, "reward_mean": 28.542857142857144, "student_loss": null, "teacher_policy_loss": -16.044111251831055, "teacher_value_loss": 115.2552490234375, "teacher_entropy": 0.6512014269828796, "total_time": 1.1789188385009766, "rollout_time": 0.43329668045043945, "train_time": 0.735034704208374, "student_train_time": 0.009984970092773438, "throughput": 1696.4696251211387, "inference_time": 0.05712074675244594, "env_time": 0.3761759336979935, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 16, "reward_mean": 25.423076923076923, "student_loss": null, "teacher_policy_loss": -14.622593879699707, "teacher_value_loss": 86.0322494506836, "teacher_entropy": 0.6545435190200806, "total_time": 1.2327806949615479, "rollout_time": 0.43990159034729004, "train_time": 0.7849798202514648, "student_train_time": 0.007506370544433594, "throughput": 1622.3485719513014, "inference_time": 0.05562724724950385, "env_time": 0.3842743430977862, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 17, "reward_mean": 25.632911392405063, "student_loss": null, "teacher_policy_loss": -14.964797973632812, "teacher_value_loss": 91.34111022949219, "teacher_entropy": 0.6492730975151062, "total_time": 1.2141764163970947, "rollout_time": 0.4336864948272705, "train_time": 0.7650094032287598, "student_train_time": 0.015124797821044922, "throughput": 1647.207088682163, "inference_time": 0.05553559375050554, "env_time": 0.37815090107676497, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 18, "reward_mean": 24.036585365853657, "student_loss": null, "teacher_policy_loss": -13.332281112670898, "teacher_value_loss": 66.68009948730469, "teacher_entropy": 0.6331775784492493, "total_time": 1.1826567649841309, "rollout_time": 0.4425015449523926, "train_time": 0.7329776287078857, "student_train_time": 0.006830930709838867, "throughput": 1691.107732366319, "inference_time": 0.053395801246722385, "env_time": 0.3891057437056702, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 19, "reward_mean": 26.786666666666665, "student_loss": null, "teacher_policy_loss": -15.101790428161621, "teacher_value_loss": 92.78316497802734, "teacher_entropy": 0.6301843523979187, "total_time": 1.2653286457061768, "rollout_time": 0.43180418014526367, "train_time": 0.8198511600494385, "student_train_time": 0.013193130493164062, "throughput": 1580.617025297649, "inference_time": 0.05547555200092802, "env_time": 0.37632862814433565, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 20, "reward_mean": 25.897435897435898, "student_loss": null, "teacher_policy_loss": -14.58914852142334, "teacher_value_loss": 122.5174331665039, "teacher_entropy": 0.6134100556373596, "total_time": 1.3482534885406494, "rollout_time": 0.42177748680114746, "train_time": 0.9196410179138184, "student_train_time": 0.006299018859863281, "throughput": 1483.4005748910033, "inference_time": 0.055156238749816566, "env_time": 0.3666212480513309, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 21, "reward_mean": 30.70769230769231, "student_loss": null, "teacher_policy_loss": -18.38404655456543, "teacher_value_loss": 164.3223419189453, "teacher_entropy": 0.6471273303031921, "total_time": 1.2153985500335693, "rollout_time": 0.42105746269226074, "train_time": 0.7869997024536133, "student_train_time": 0.006997585296630859, "throughput": 1645.5507536558769, "inference_time": 0.052385186500885084, "env_time": 0.36867227619137566, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 22, "reward_mean": 32.459016393442624, "student_loss": null, "teacher_policy_loss": -17.87668800354004, "teacher_value_loss": 134.77467346191406, "teacher_entropy": 0.6286788582801819, "total_time": 1.2000963687896729, "rollout_time": 0.42411303520202637, "train_time": 0.7438347339630127, "student_train_time": 0.03180336952209473, "throughput": 1666.5328318733687, "inference_time": 0.05540228949962511, "env_time": 0.36871074570240125, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 23, "reward_mean": 27.61111111111111, "student_loss": null, "teacher_policy_loss": -15.81191635131836, "teacher_value_loss": 151.8507080078125, "teacher_entropy": 0.6351547241210938, "total_time": 1.2157533168792725, "rollout_time": 0.4321777820587158, "train_time": 0.7778835296630859, "student_train_time": 0.005353689193725586, "throughput": 1645.0705683730455, "inference_time": 0.05509089400072753, "env_time": 0.3770868880579883, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 24, "reward_mean": 28.338028169014084, "student_loss": null, "teacher_policy_loss": -14.435474395751953, "teacher_value_loss": 120.75288391113281, "teacher_entropy": 0.6163173317909241, "total_time": 1.2818629741668701, "rollout_time": 0.42014622688293457, "train_time": 0.8434913158416748, "student_train_time": 0.01777791976928711, "throughput": 1560.2291666937908, "inference_time": 0.05323341824947647, "env_time": 0.3669128086334581, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 25, "reward_mean": 30.553846153846155, "student_loss": null, "teacher_policy_loss": -16.857807159423828, "teacher_value_loss": 140.021484375, "teacher_entropy": 0.6276506185531616, "total_time": 1.1712687015533447, "rollout_time": 0.42855048179626465, "train_time": 0.733351469039917, "student_train_time": 0.009020090103149414, "throughput": 1707.5501098489067, "inference_time": 0.05531713099986746, "env_time": 0.3732333507963972, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 26, "reward_mean": 26.453333333333333, "student_loss": null, "teacher_policy_loss": -15.036367416381836, "teacher_value_loss": 99.31086730957031, "teacher_entropy": 0.659505307674408, "total_time": 1.2609822750091553, "rollout_time": 0.42441320419311523, "train_time": 0.8231339454650879, "student_train_time": 0.013087749481201172, "throughput": 1586.0651173589883, "inference_time": 0.05681596800019406, "env_time": 0.3675972361929212, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 27, "reward_mean": 25.94736842105263, "student_loss": null, "teacher_policy_loss": -13.947912216186523, "teacher_value_loss": 103.03964233398438, "teacher_entropy": 0.5831417441368103, "total_time": 1.2477970123291016, "rollout_time": 0.44052934646606445, "train_time": 0.7956883907318115, "student_train_time": 0.011233329772949219, "throughput": 1602.824802623031, "inference_time": 0.05753961550061604, "env_time": 0.3829897309654484, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 28, "reward_mean": 29.514285714285716, "student_loss": null, "teacher_policy_loss": -16.557493209838867, "teacher_value_loss": 118.7517318725586, "teacher_entropy": 0.6644841432571411, "total_time": 1.140296220779419, "rollout_time": 0.42859649658203125, "train_time": 0.7019474506378174, "student_train_time": 0.009390830993652344, "throughput": 1753.9302187925814, "inference_time": 0.05210156174752001, "env_time": 0.37649493483451124, "samples": 2000, "teacher_eval_reward": null}
{"epoch": 29, "reward_mean": 23.458823529411763, "student_loss": null, "teacher_policy_loss": -12.725095748901367, "teacher_value_loss": 60.774871826171875, "teacher_entropy": 0.639327347278595, "total_time": 1.2792549133300781, "rollout_time": 0.4189133644104004, "train_time": 0.8458690643310547, "student_train_time": 0.01411128044128418, "throughput": 1563.4100593709836, "inference_time": 0.053302237249795326, "env_time": 0.36561112716060507, "samples": 2000, "teacher_eval_reward": null}
