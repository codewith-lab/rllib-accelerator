{"epoch": 1, "reward_mean": 18.80952380952381, "student_loss": null, "teacher_policy_loss": -10.439835548400879, "teacher_value_loss": 165.4097442626953, "teacher_entropy": 0.6584303379058838, "time": 0.0973212718963623}
{"epoch": 2, "reward_mean": 25.0, "student_loss": null, "teacher_policy_loss": -16.085664749145508, "teacher_value_loss": 397.9732666015625, "teacher_entropy": 0.6825473308563232, "time": 0.03638434410095215}
{"epoch": 3, "reward_mean": 25.3125, "student_loss": null, "teacher_policy_loss": -15.654655456542969, "teacher_value_loss": 345.1600341796875, "teacher_entropy": 0.6891696453094482, "time": 0.02276015281677246}
{"epoch": 4, "reward_mean": 21.833333333333332, "student_loss": null, "teacher_policy_loss": -13.998488426208496, "teacher_value_loss": 276.6778259277344, "teacher_entropy": 0.6919755339622498, "time": 0.021637439727783203}
{"epoch": 5, "reward_mean": 22.11764705882353, "student_loss": null, "teacher_policy_loss": -14.319626808166504, "teacher_value_loss": 247.2930908203125, "teacher_entropy": 0.6914474368095398, "time": 0.015119075775146484}
{"epoch": 6, "reward_mean": 24.705882352941178, "student_loss": null, "teacher_policy_loss": -13.944355010986328, "teacher_value_loss": 238.0799560546875, "teacher_entropy": 0.6879730820655823, "time": 0.01192784309387207}
{"epoch": 7, "reward_mean": 22.61111111111111, "student_loss": null, "teacher_policy_loss": -13.590112686157227, "teacher_value_loss": 185.66131591796875, "teacher_entropy": 0.6781970262527466, "time": 0.022578954696655273}
{"epoch": 8, "reward_mean": 26.666666666666668, "student_loss": null, "teacher_policy_loss": -14.290579795837402, "teacher_value_loss": 166.26797485351562, "teacher_entropy": 0.6733220815658569, "time": 0.014957666397094727}
{"epoch": 9, "reward_mean": 20.105263157894736, "student_loss": null, "teacher_policy_loss": -11.446525573730469, "teacher_value_loss": 98.45191192626953, "teacher_entropy": 0.6637406945228577, "time": 0.0296328067779541}
{"epoch": 10, "reward_mean": 20.3, "student_loss": null, "teacher_policy_loss": -10.587488174438477, "teacher_value_loss": 65.43270874023438, "teacher_entropy": 0.6702861785888672, "time": 0.03729605674743652}
{"epoch": 11, "reward_mean": 19.7, "student_loss": null, "teacher_policy_loss": -11.165114402770996, "teacher_value_loss": 79.52404022216797, "teacher_entropy": 0.6833193898200989, "time": 0.012212753295898438}
{"epoch": 12, "reward_mean": 21.31578947368421, "student_loss": null, "teacher_policy_loss": -11.756023406982422, "teacher_value_loss": 100.36373901367188, "teacher_entropy": 0.6846920847892761, "time": 0.015709638595581055}
{"epoch": 13, "reward_mean": 23.055555555555557, "student_loss": null, "teacher_policy_loss": -13.901520729064941, "teacher_value_loss": 131.19708251953125, "teacher_entropy": 0.6842890977859497, "time": 0.02113199234008789}
{"epoch": 14, "reward_mean": 23.470588235294116, "student_loss": null, "teacher_policy_loss": -13.191113471984863, "teacher_value_loss": 97.6745834350586, "teacher_entropy": 0.6783894896507263, "time": 0.011363029479980469}
{"epoch": 15, "reward_mean": 22.823529411764707, "student_loss": null, "teacher_policy_loss": -12.052241325378418, "teacher_value_loss": 68.5704116821289, "teacher_entropy": 0.6857550144195557, "time": 0.01950693130493164}
{"epoch": 16, "reward_mean": 28.642857142857142, "student_loss": null, "teacher_policy_loss": -15.595725059509277, "teacher_value_loss": 141.86065673828125, "teacher_entropy": 0.6734821796417236, "time": 0.047646522521972656}
{"epoch": 17, "reward_mean": 26.642857142857142, "student_loss": null, "teacher_policy_loss": -15.116911888122559, "teacher_value_loss": 120.03528594970703, "teacher_entropy": 0.6762799024581909, "time": 0.024367332458496094}
{"epoch": 18, "reward_mean": 24.38888888888889, "student_loss": null, "teacher_policy_loss": -14.710426330566406, "teacher_value_loss": 151.77044677734375, "teacher_entropy": 0.6794320940971375, "time": 0.013439655303955078}
{"epoch": 19, "reward_mean": 25.266666666666666, "student_loss": null, "teacher_policy_loss": -12.95553207397461, "teacher_value_loss": 71.49266815185547, "teacher_entropy": 0.6793861389160156, "time": 0.014831781387329102}
{"epoch": 20, "reward_mean": 27.533333333333335, "student_loss": null, "teacher_policy_loss": -15.716569900512695, "teacher_value_loss": 135.67251586914062, "teacher_entropy": 0.6747848987579346, "time": 0.021851062774658203}
{"epoch": 21, "reward_mean": 21.941176470588236, "student_loss": null, "teacher_policy_loss": -14.48965072631836, "teacher_value_loss": 127.98051452636719, "teacher_entropy": 0.677171528339386, "time": 0.022259235382080078}
{"epoch": 22, "reward_mean": 22.166666666666668, "student_loss": null, "teacher_policy_loss": -12.77305793762207, "teacher_value_loss": 112.14492797851562, "teacher_entropy": 0.6673558950424194, "time": 0.023383140563964844}
{"epoch": 23, "reward_mean": 22.470588235294116, "student_loss": null, "teacher_policy_loss": -15.007187843322754, "teacher_value_loss": 174.27450561523438, "teacher_entropy": 0.6590453386306763, "time": 0.030106544494628906}
{"epoch": 24, "reward_mean": 21.285714285714285, "student_loss": null, "teacher_policy_loss": -11.572344779968262, "teacher_value_loss": 101.70884704589844, "teacher_entropy": 0.6622409224510193, "time": 0.015420913696289062}
{"epoch": 25, "reward_mean": 21.77777777777778, "student_loss": null, "teacher_policy_loss": -10.857213973999023, "teacher_value_loss": 50.8795280456543, "teacher_entropy": 0.6653863787651062, "time": 0.014664649963378906}
{"epoch": 26, "reward_mean": 21.0, "student_loss": null, "teacher_policy_loss": -11.897751808166504, "teacher_value_loss": 65.04312133789062, "teacher_entropy": 0.6664632558822632, "time": 0.022671937942504883}
{"epoch": 27, "reward_mean": 28.733333333333334, "student_loss": null, "teacher_policy_loss": -16.928434371948242, "teacher_value_loss": 197.9693145751953, "teacher_entropy": 0.666780948638916, "time": 0.011951684951782227}
{"epoch": 28, "reward_mean": 23.176470588235293, "student_loss": null, "teacher_policy_loss": -12.985553741455078, "teacher_value_loss": 80.26800537109375, "teacher_entropy": 0.6638790369033813, "time": 0.024483680725097656}
{"epoch": 29, "reward_mean": 24.235294117647058, "student_loss": null, "teacher_policy_loss": -12.75307846069336, "teacher_value_loss": 64.57038879394531, "teacher_entropy": 0.6683974266052246, "time": 0.016283512115478516}
{"epoch": 30, "reward_mean": 20.842105263157894, "student_loss": null, "teacher_policy_loss": -10.9832181930542, "teacher_value_loss": 48.69587326049805, "teacher_entropy": 0.6609560251235962, "time": 0.019651174545288086}
{"epoch": 31, "reward_mean": 25.1875, "student_loss": null, "teacher_policy_loss": -14.227060317993164, "teacher_value_loss": 119.020263671875, "teacher_entropy": 0.664120078086853, "time": 0.029813766479492188}
{"epoch": 32, "reward_mean": 21.8125, "student_loss": null, "teacher_policy_loss": -14.605385780334473, "teacher_value_loss": 126.8969497680664, "teacher_entropy": 0.6659697890281677, "time": 0.04279828071594238}
{"epoch": 33, "reward_mean": 25.941176470588236, "student_loss": null, "teacher_policy_loss": -13.024348258972168, "teacher_value_loss": 83.51373291015625, "teacher_entropy": 0.6680516004562378, "time": 0.048480987548828125}
{"epoch": 34, "reward_mean": 21.473684210526315, "student_loss": null, "teacher_policy_loss": -11.705378532409668, "teacher_value_loss": 52.90497970581055, "teacher_entropy": 0.6704199910163879, "time": 0.03735804557800293}
{"epoch": 35, "reward_mean": 20.736842105263158, "student_loss": null, "teacher_policy_loss": -11.629264831542969, "teacher_value_loss": 65.2537612915039, "teacher_entropy": 0.6483129858970642, "time": 0.017666339874267578}
{"epoch": 36, "reward_mean": 29.142857142857142, "student_loss": null, "teacher_policy_loss": -17.387828826904297, "teacher_value_loss": 203.77195739746094, "teacher_entropy": 0.665048360824585, "time": 0.017999887466430664}
{"epoch": 37, "reward_mean": 23.875, "student_loss": null, "teacher_policy_loss": -12.689691543579102, "teacher_value_loss": 63.980995178222656, "teacher_entropy": 0.6668111681938171, "time": 0.01870584487915039}
{"epoch": 38, "reward_mean": 35.083333333333336, "student_loss": null, "teacher_policy_loss": -19.948984146118164, "teacher_value_loss": 244.4047393798828, "teacher_entropy": 0.6743123531341553, "time": 0.018438339233398438}
{"epoch": 39, "reward_mean": 20.0, "student_loss": null, "teacher_policy_loss": -11.948495864868164, "teacher_value_loss": 64.64651489257812, "teacher_entropy": 0.660097599029541, "time": 0.04526090621948242}
{"epoch": 40, "reward_mean": 27.928571428571427, "student_loss": null, "teacher_policy_loss": -16.740720748901367, "teacher_value_loss": 155.3857879638672, "teacher_entropy": 0.6569543480873108, "time": 0.0345454216003418}
{"epoch": 41, "reward_mean": 24.75, "student_loss": null, "teacher_policy_loss": -14.792941093444824, "teacher_value_loss": 117.04924774169922, "teacher_entropy": 0.6558254957199097, "time": 0.01679539680480957}
{"epoch": 42, "reward_mean": 34.63636363636363, "student_loss": null, "teacher_policy_loss": -16.9779109954834, "teacher_value_loss": 109.76793670654297, "teacher_entropy": 0.6746771931648254, "time": 0.015081644058227539}
{"epoch": 43, "reward_mean": 26.375, "student_loss": null, "teacher_policy_loss": -13.305267333984375, "teacher_value_loss": 77.4117202758789, "teacher_entropy": 0.6644902229309082, "time": 0.02610921859741211}
{"epoch": 44, "reward_mean": 22.72222222222222, "student_loss": null, "teacher_policy_loss": -12.089485168457031, "teacher_value_loss": 64.04423522949219, "teacher_entropy": 0.6610516905784607, "time": 0.023775100708007812}
{"epoch": 45, "reward_mean": 42.111111111111114, "student_loss": null, "teacher_policy_loss": -22.734764099121094, "teacher_value_loss": 259.5525817871094, "teacher_entropy": 0.6491816639900208, "time": 0.02123713493347168}
{"epoch": 46, "reward_mean": 22.88888888888889, "student_loss": null, "teacher_policy_loss": -11.583795547485352, "teacher_value_loss": 75.4331283569336, "teacher_entropy": 0.6214408278465271, "time": 0.015219926834106445}
{"epoch": 47, "reward_mean": 26.846153846153847, "student_loss": null, "teacher_policy_loss": -14.975000381469727, "teacher_value_loss": 96.98487091064453, "teacher_entropy": 0.6427163481712341, "time": 0.024343252182006836}
{"epoch": 48, "reward_mean": 32.285714285714285, "student_loss": null, "teacher_policy_loss": -14.069099426269531, "teacher_value_loss": 77.53101348876953, "teacher_entropy": 0.6529951691627502, "time": 0.02059650421142578}
{"epoch": 49, "reward_mean": 30.25, "student_loss": null, "teacher_policy_loss": -18.270973205566406, "teacher_value_loss": 201.7703857421875, "teacher_entropy": 0.6695854663848877, "time": 0.017555713653564453}
{"epoch": 50, "reward_mean": 32.25, "student_loss": null, "teacher_policy_loss": -19.223697662353516, "teacher_value_loss": 179.9785614013672, "teacher_entropy": 0.6647924780845642, "time": 0.017892837524414062}
{"epoch": 51, "reward_mean": 32.42857142857143, "student_loss": null, "teacher_policy_loss": -14.556353569030762, "teacher_value_loss": 80.54505157470703, "teacher_entropy": 0.6477236151695251, "time": 0.023223161697387695}
{"epoch": 52, "reward_mean": 29.76923076923077, "student_loss": null, "teacher_policy_loss": -13.946292877197266, "teacher_value_loss": 76.90740966796875, "teacher_entropy": 0.6383538246154785, "time": 0.015024185180664062}
{"epoch": 53, "reward_mean": 36.81818181818182, "student_loss": null, "teacher_policy_loss": -17.408740997314453, "teacher_value_loss": 122.08036041259766, "teacher_entropy": 0.6630296111106873, "time": 0.023573875427246094}
{"epoch": 54, "reward_mean": 29.0, "student_loss": null, "teacher_policy_loss": -20.839677810668945, "teacher_value_loss": 230.43597412109375, "teacher_entropy": 0.6602707505226135, "time": 0.018346548080444336}
{"epoch": 55, "reward_mean": 38.0, "student_loss": null, "teacher_policy_loss": -16.5266056060791, "teacher_value_loss": 125.27619934082031, "teacher_entropy": 0.6575760841369629, "time": 0.013480663299560547}
{"epoch": 56, "reward_mean": 36.8, "student_loss": null, "teacher_policy_loss": -21.803028106689453, "teacher_value_loss": 374.2674865722656, "teacher_entropy": 0.6399698853492737, "time": 0.017375707626342773}
{"epoch": 57, "reward_mean": 46.333333333333336, "student_loss": null, "teacher_policy_loss": -20.600908279418945, "teacher_value_loss": 176.1636505126953, "teacher_entropy": 0.6385757923126221, "time": 0.01698899269104004}
{"epoch": 58, "reward_mean": 35.36363636363637, "student_loss": null, "teacher_policy_loss": -17.429981231689453, "teacher_value_loss": 117.3246078491211, "teacher_entropy": 0.6432037949562073, "time": 0.03253626823425293}
{"epoch": 59, "reward_mean": 32.76923076923077, "student_loss": null, "teacher_policy_loss": -16.12621307373047, "teacher_value_loss": 130.16685485839844, "teacher_entropy": 0.660247802734375, "time": 0.021046876907348633}
{"epoch": 60, "reward_mean": 37.875, "student_loss": null, "teacher_policy_loss": -23.144960403442383, "teacher_value_loss": 246.7247314453125, "teacher_entropy": 0.6596097350120544, "time": 0.025730133056640625}
{"epoch": 61, "reward_mean": 40.25, "student_loss": null, "teacher_policy_loss": -14.606419563293457, "teacher_value_loss": 104.82893371582031, "teacher_entropy": 0.640668511390686, "time": 0.019243240356445312}
{"epoch": 62, "reward_mean": 36.81818181818182, "student_loss": null, "teacher_policy_loss": -17.825706481933594, "teacher_value_loss": 175.15786743164062, "teacher_entropy": 0.6259786486625671, "time": 0.01858043670654297}
{"epoch": 63, "reward_mean": 40.22222222222222, "student_loss": null, "teacher_policy_loss": -19.188385009765625, "teacher_value_loss": 160.1918487548828, "teacher_entropy": 0.636177659034729, "time": 0.01684284210205078}
{"epoch": 64, "reward_mean": 36.75, "student_loss": null, "teacher_policy_loss": -15.666847229003906, "teacher_value_loss": 99.87200164794922, "teacher_entropy": 0.6432310342788696, "time": 0.012251853942871094}
{"epoch": 65, "reward_mean": 41.22222222222222, "student_loss": null, "teacher_policy_loss": -18.961645126342773, "teacher_value_loss": 137.09124755859375, "teacher_entropy": 0.6434024572372437, "time": 0.15536117553710938}
{"epoch": 66, "reward_mean": 37.63636363636363, "student_loss": null, "teacher_policy_loss": -18.580625534057617, "teacher_value_loss": 160.79005432128906, "teacher_entropy": 0.6250872611999512, "time": 0.01148223876953125}
{"epoch": 67, "reward_mean": 33.333333333333336, "student_loss": null, "teacher_policy_loss": -17.099672317504883, "teacher_value_loss": 156.98480224609375, "teacher_entropy": 0.6331550478935242, "time": 0.011986494064331055}
{"epoch": 68, "reward_mean": 38.5, "student_loss": null, "teacher_policy_loss": -17.74675178527832, "teacher_value_loss": 123.80513763427734, "teacher_entropy": 0.6266188025474548, "time": 0.026083946228027344}
{"epoch": 69, "reward_mean": 49.25, "student_loss": null, "teacher_policy_loss": -21.468830108642578, "teacher_value_loss": 212.05198669433594, "teacher_entropy": 0.6384534239768982, "time": 0.017647504806518555}
{"epoch": 70, "reward_mean": 44.2, "student_loss": null, "teacher_policy_loss": -18.736576080322266, "teacher_value_loss": 133.000732421875, "teacher_entropy": 0.6337656378746033, "time": 0.028040647506713867}
{"epoch": 71, "reward_mean": 28.666666666666668, "student_loss": null, "teacher_policy_loss": -14.558566093444824, "teacher_value_loss": 95.3873062133789, "teacher_entropy": 0.613311767578125, "time": 0.025076866149902344}
{"epoch": 72, "reward_mean": 50.44444444444444, "student_loss": null, "teacher_policy_loss": -27.570388793945312, "teacher_value_loss": 642.4464111328125, "teacher_entropy": 0.6196450591087341, "time": 0.01741480827331543}
{"epoch": 73, "reward_mean": 43.44444444444444, "student_loss": null, "teacher_policy_loss": -21.8305606842041, "teacher_value_loss": 325.1288757324219, "teacher_entropy": 0.6007516980171204, "time": 0.015309333801269531}
{"epoch": 74, "reward_mean": 58.42857142857143, "student_loss": null, "teacher_policy_loss": -32.5980110168457, "teacher_value_loss": 877.18359375, "teacher_entropy": 0.626751184463501, "time": 0.0185089111328125}
{"epoch": 75, "reward_mean": 41.888888888888886, "student_loss": null, "teacher_policy_loss": -17.814504623413086, "teacher_value_loss": 139.08705139160156, "teacher_entropy": 0.6170269250869751, "time": 0.013429403305053711}
{"epoch": 76, "reward_mean": 50.375, "student_loss": null, "teacher_policy_loss": -19.704069137573242, "teacher_value_loss": 151.08554077148438, "teacher_entropy": 0.6315218210220337, "time": 0.05514931678771973}
{"epoch": 77, "reward_mean": 39.4, "student_loss": null, "teacher_policy_loss": -19.476720809936523, "teacher_value_loss": 184.5481414794922, "teacher_entropy": 0.6095519065856934, "time": 0.01986098289489746}
{"epoch": 78, "reward_mean": 40.0, "student_loss": null, "teacher_policy_loss": -16.541500091552734, "teacher_value_loss": 132.46046447753906, "teacher_entropy": 0.6128360629081726, "time": 0.017848968505859375}
{"epoch": 79, "reward_mean": 66.5, "student_loss": null, "teacher_policy_loss": -28.539077758789062, "teacher_value_loss": 406.4206237792969, "teacher_entropy": 0.6305282711982727, "time": 0.050585269927978516}
{"epoch": 80, "reward_mean": 39.5, "student_loss": null, "teacher_policy_loss": -17.081829071044922, "teacher_value_loss": 133.79844665527344, "teacher_entropy": 0.6111947894096375, "time": 0.02077198028564453}
{"epoch": 81, "reward_mean": 40.7, "student_loss": null, "teacher_policy_loss": -19.217079162597656, "teacher_value_loss": 197.64605712890625, "teacher_entropy": 0.6111689209938049, "time": 0.011561155319213867}
{"epoch": 82, "reward_mean": 47.44444444444444, "student_loss": null, "teacher_policy_loss": -21.363889694213867, "teacher_value_loss": 226.96563720703125, "teacher_entropy": 0.6117783188819885, "time": 0.013262033462524414}
{"epoch": 83, "reward_mean": 53.857142857142854, "student_loss": null, "teacher_policy_loss": -21.81583023071289, "teacher_value_loss": 189.36341857910156, "teacher_entropy": 0.6176227331161499, "time": 0.026154756546020508}
{"epoch": 84, "reward_mean": 91.75, "student_loss": null, "teacher_policy_loss": -35.43834686279297, "teacher_value_loss": 690.3228759765625, "teacher_entropy": 0.6256611943244934, "time": 0.02288675308227539}
{"epoch": 85, "reward_mean": 52.75, "student_loss": null, "teacher_policy_loss": -23.042709350585938, "teacher_value_loss": 244.0839080810547, "teacher_entropy": 0.6100301146507263, "time": 0.014078140258789062}
{"epoch": 86, "reward_mean": 53.5, "student_loss": null, "teacher_policy_loss": -22.10265350341797, "teacher_value_loss": 202.07821655273438, "teacher_entropy": 0.6114436984062195, "time": 0.03558087348937988}
{"epoch": 87, "reward_mean": 43.77777777777778, "student_loss": null, "teacher_policy_loss": -16.927156448364258, "teacher_value_loss": 128.24972534179688, "teacher_entropy": 0.5963597297668457, "time": 0.014996528625488281}
{"epoch": 88, "reward_mean": 44.44444444444444, "student_loss": null, "teacher_policy_loss": -18.123332977294922, "teacher_value_loss": 145.385009765625, "teacher_entropy": 0.5917100310325623, "time": 0.01432943344116211}
{"epoch": 89, "reward_mean": 43.625, "student_loss": null, "teacher_policy_loss": -19.150495529174805, "teacher_value_loss": 129.95330810546875, "teacher_entropy": 0.61070317029953, "time": 0.013232707977294922}
{"epoch": 90, "reward_mean": 51.875, "student_loss": null, "teacher_policy_loss": -20.976337432861328, "teacher_value_loss": 186.88897705078125, "teacher_entropy": 0.6024249196052551, "time": 0.012417316436767578}
{"epoch": 91, "reward_mean": 47.666666666666664, "student_loss": null, "teacher_policy_loss": -19.32947540283203, "teacher_value_loss": 142.31134033203125, "teacher_entropy": 0.5963159799575806, "time": 0.022808313369750977}
{"epoch": 92, "reward_mean": 49.125, "student_loss": null, "teacher_policy_loss": -22.351818084716797, "teacher_value_loss": 251.37863159179688, "teacher_entropy": 0.5963280200958252, "time": 0.018301010131835938}
{"epoch": 93, "reward_mean": 82.0, "student_loss": null, "teacher_policy_loss": -27.652219772338867, "teacher_value_loss": 339.2953186035156, "teacher_entropy": 0.6082666516304016, "time": 0.014653921127319336}
{"epoch": 94, "reward_mean": 65.0, "student_loss": null, "teacher_policy_loss": -25.969009399414062, "teacher_value_loss": 371.7506103515625, "teacher_entropy": 0.5808315873146057, "time": 0.018856287002563477}
{"epoch": 95, "reward_mean": 65.16666666666667, "student_loss": null, "teacher_policy_loss": -22.13855743408203, "teacher_value_loss": 175.89048767089844, "teacher_entropy": 0.6080653071403503, "time": 0.015191316604614258}
{"epoch": 96, "reward_mean": 45.75, "student_loss": null, "teacher_policy_loss": -19.771198272705078, "teacher_value_loss": 153.64251708984375, "teacher_entropy": 0.5971248745918274, "time": 0.02095794677734375}
{"epoch": 97, "reward_mean": 75.66666666666667, "student_loss": null, "teacher_policy_loss": -26.801118850708008, "teacher_value_loss": 363.51007080078125, "teacher_entropy": 0.6134333610534668, "time": 0.019422531127929688}
{"epoch": 98, "reward_mean": 77.6, "student_loss": null, "teacher_policy_loss": -30.63461685180664, "teacher_value_loss": 632.3833618164062, "teacher_entropy": 0.5935680866241455, "time": 0.015264272689819336}
{"epoch": 99, "reward_mean": 60.333333333333336, "student_loss": null, "teacher_policy_loss": -21.93686294555664, "teacher_value_loss": 164.94808959960938, "teacher_entropy": 0.5748913288116455, "time": 0.023987770080566406}
{"epoch": 100, "reward_mean": 77.0, "student_loss": null, "teacher_policy_loss": -28.3355655670166, "teacher_value_loss": 316.08123779296875, "teacher_entropy": 0.5898552536964417, "time": 0.015319347381591797}
{"epoch": 101, "reward_mean": 63.0, "student_loss": null, "teacher_policy_loss": -24.671831130981445, "teacher_value_loss": 194.79132080078125, "teacher_entropy": 0.5952813029289246, "time": 0.026189327239990234}
{"epoch": 102, "reward_mean": 59.25, "student_loss": null, "teacher_policy_loss": -24.3548526763916, "teacher_value_loss": 423.1719970703125, "teacher_entropy": 0.5994093418121338, "time": 0.020525217056274414}
{"epoch": 103, "reward_mean": 43.625, "student_loss": null, "teacher_policy_loss": -17.685138702392578, "teacher_value_loss": 203.06324768066406, "teacher_entropy": 0.5843244791030884, "time": 0.01522517204284668}
{"epoch": 104, "reward_mean": 82.0, "student_loss": null, "teacher_policy_loss": -28.940357208251953, "teacher_value_loss": 333.7154235839844, "teacher_entropy": 0.5689334869384766, "time": 0.03208637237548828}
{"epoch": 105, "reward_mean": 67.71428571428571, "student_loss": null, "teacher_policy_loss": -20.291675567626953, "teacher_value_loss": 222.92745971679688, "teacher_entropy": 0.5702787041664124, "time": 0.02816462516784668}
{"epoch": 106, "reward_mean": 72.16666666666667, "student_loss": null, "teacher_policy_loss": -20.992877960205078, "teacher_value_loss": 225.0459442138672, "teacher_entropy": 0.5752190947532654, "time": 0.019124746322631836}
{"epoch": 107, "reward_mean": 113.66666666666667, "student_loss": null, "teacher_policy_loss": -33.363643646240234, "teacher_value_loss": 315.91949462890625, "teacher_entropy": 0.5672321915626526, "time": 0.01714348793029785}
{"epoch": 108, "reward_mean": 73.33333333333333, "student_loss": null, "teacher_policy_loss": -23.875612258911133, "teacher_value_loss": 219.3686981201172, "teacher_entropy": 0.6199585199356079, "time": 0.030461788177490234}
{"epoch": 109, "reward_mean": 53.125, "student_loss": null, "teacher_policy_loss": -19.34990692138672, "teacher_value_loss": 232.77357482910156, "teacher_entropy": 0.6046412587165833, "time": 0.012021541595458984}
{"epoch": 110, "reward_mean": 92.75, "student_loss": null, "teacher_policy_loss": -30.8668270111084, "teacher_value_loss": 392.4293212890625, "teacher_entropy": 0.6050443053245544, "time": 0.027019977569580078}
{"epoch": 111, "reward_mean": 88.0, "student_loss": null, "teacher_policy_loss": -31.92266273498535, "teacher_value_loss": 524.1416625976562, "teacher_entropy": 0.5960691571235657, "time": 0.016457557678222656}
{"epoch": 112, "reward_mean": 65.16666666666667, "student_loss": null, "teacher_policy_loss": -22.35782241821289, "teacher_value_loss": 191.9789276123047, "teacher_entropy": 0.5980834364891052, "time": 0.01056528091430664}
{"epoch": 113, "reward_mean": 84.2, "student_loss": null, "teacher_policy_loss": -35.355743408203125, "teacher_value_loss": 586.8614501953125, "teacher_entropy": 0.6019894480705261, "time": 0.014860868453979492}
{"epoch": 114, "reward_mean": 119.66666666666667, "student_loss": null, "teacher_policy_loss": -36.684696197509766, "teacher_value_loss": 493.0251159667969, "teacher_entropy": 0.6101025938987732, "time": 0.022975921630859375}
{"epoch": 115, "reward_mean": 100.75, "student_loss": null, "teacher_policy_loss": -36.905601501464844, "teacher_value_loss": 580.8775634765625, "teacher_entropy": 0.6129191517829895, "time": 0.013585805892944336}
{"epoch": 116, "reward_mean": 105.25, "student_loss": null, "teacher_policy_loss": -36.46626281738281, "teacher_value_loss": 548.3875732421875, "teacher_entropy": 0.5987030863761902, "time": 0.02462315559387207}
{"epoch": 117, "reward_mean": 79.0, "student_loss": null, "teacher_policy_loss": -27.010278701782227, "teacher_value_loss": 269.222900390625, "teacher_entropy": 0.5978793501853943, "time": 0.014163970947265625}
{"epoch": 118, "reward_mean": 83.75, "student_loss": null, "teacher_policy_loss": -28.953927993774414, "teacher_value_loss": 204.33993530273438, "teacher_entropy": 0.6020591259002686, "time": 0.018680334091186523}
{"epoch": 119, "reward_mean": 113.75, "student_loss": null, "teacher_policy_loss": -32.50174331665039, "teacher_value_loss": 567.88720703125, "teacher_entropy": 0.5992741584777832, "time": 0.01179051399230957}
{"epoch": 120, "reward_mean": 121.33333333333333, "student_loss": null, "teacher_policy_loss": -33.72124481201172, "teacher_value_loss": 560.7323608398438, "teacher_entropy": 0.5905584692955017, "time": 0.01968216896057129}
{"epoch": 121, "reward_mean": 82.6, "student_loss": null, "teacher_policy_loss": -21.8536319732666, "teacher_value_loss": 98.4165267944336, "teacher_entropy": 0.5788238644599915, "time": 0.022845745086669922}
{"epoch": 122, "reward_mean": 119.66666666666667, "student_loss": null, "teacher_policy_loss": -36.277645111083984, "teacher_value_loss": 507.4486083984375, "teacher_entropy": 0.5622917413711548, "time": 0.013295650482177734}
{"epoch": 123, "reward_mean": 123.0, "student_loss": null, "teacher_policy_loss": -35.61652374267578, "teacher_value_loss": 469.7271423339844, "teacher_entropy": 0.5863358974456787, "time": 0.0282442569732666}
{"epoch": 124, "reward_mean": 97.66666666666667, "student_loss": null, "teacher_policy_loss": -33.037879943847656, "teacher_value_loss": 237.36651611328125, "teacher_entropy": 0.5836443901062012, "time": 0.01771855354309082}
{"epoch": 125, "reward_mean": 109.33333333333333, "student_loss": null, "teacher_policy_loss": -37.19520950317383, "teacher_value_loss": 305.52020263671875, "teacher_entropy": 0.5989820957183838, "time": 0.02031993865966797}
{"epoch": 126, "reward_mean": 115.0, "student_loss": null, "teacher_policy_loss": -24.017515182495117, "teacher_value_loss": 254.3608856201172, "teacher_entropy": 0.5872265100479126, "time": 0.01490926742553711}
{"epoch": 127, "reward_mean": 120.0, "student_loss": null, "teacher_policy_loss": -31.9137020111084, "teacher_value_loss": 350.19647216796875, "teacher_entropy": 0.5456582307815552, "time": 0.011681795120239258}
{"epoch": 128, "reward_mean": 159.0, "student_loss": null, "teacher_policy_loss": -38.450531005859375, "teacher_value_loss": 197.88108825683594, "teacher_entropy": 0.5777671337127686, "time": 0.012703418731689453}
{"epoch": 129, "reward_mean": 109.75, "student_loss": null, "teacher_policy_loss": -32.62617874145508, "teacher_value_loss": 277.94842529296875, "teacher_entropy": 0.5905084013938904, "time": 0.02520298957824707}
{"epoch": 130, "reward_mean": 106.5, "student_loss": null, "teacher_policy_loss": -34.25815963745117, "teacher_value_loss": 441.5939025878906, "teacher_entropy": 0.6135880351066589, "time": 0.017609119415283203}
{"epoch": 131, "reward_mean": 117.0, "student_loss": null, "teacher_policy_loss": -32.546730041503906, "teacher_value_loss": 130.9833221435547, "teacher_entropy": 0.5896399021148682, "time": 0.013425111770629883}
{"epoch": 132, "reward_mean": 126.0, "student_loss": null, "teacher_policy_loss": -30.90045738220215, "teacher_value_loss": 297.27862548828125, "teacher_entropy": 0.603117048740387, "time": 0.021795034408569336}
{"epoch": 133, "reward_mean": 148.5, "student_loss": null, "teacher_policy_loss": -39.09039306640625, "teacher_value_loss": 316.4048156738281, "teacher_entropy": 0.5796271562576294, "time": 0.01931929588317871}
{"epoch": 134, "reward_mean": 126.5, "student_loss": null, "teacher_policy_loss": -34.43134689331055, "teacher_value_loss": 356.6754150390625, "teacher_entropy": 0.5882102251052856, "time": 0.013797998428344727}
{"epoch": 135, "reward_mean": 131.66666666666666, "student_loss": null, "teacher_policy_loss": -39.9107551574707, "teacher_value_loss": 369.7779235839844, "teacher_entropy": 0.6010504364967346, "time": 0.021350860595703125}
{"epoch": 136, "reward_mean": 141.5, "student_loss": null, "teacher_policy_loss": -40.91581726074219, "teacher_value_loss": 253.4107208251953, "teacher_entropy": 0.6188406348228455, "time": 0.02217888832092285}
{"epoch": 137, "reward_mean": 132.5, "student_loss": null, "teacher_policy_loss": -46.8864631652832, "teacher_value_loss": 430.5834655761719, "teacher_entropy": 0.5681446194648743, "time": 0.04439187049865723}
{"epoch": 138, "reward_mean": 159.75, "student_loss": null, "teacher_policy_loss": -28.528017044067383, "teacher_value_loss": 369.52069091796875, "teacher_entropy": 0.533400297164917, "time": 0.01503610610961914}
{"epoch": 139, "reward_mean": 190.0, "student_loss": null, "teacher_policy_loss": -39.523502349853516, "teacher_value_loss": 527.8001708984375, "teacher_entropy": 0.5362680554389954, "time": 0.01903986930847168}
{"epoch": 140, "reward_mean": 131.33333333333334, "student_loss": null, "teacher_policy_loss": -38.45576095581055, "teacher_value_loss": 663.1759643554688, "teacher_entropy": 0.5753777027130127, "time": 0.026335716247558594}
{"epoch": 141, "reward_mean": 158.5, "student_loss": null, "teacher_policy_loss": -45.80226135253906, "teacher_value_loss": 276.6991271972656, "teacher_entropy": 0.5933569073677063, "time": 0.017400026321411133}
{"epoch": 142, "reward_mean": 148.0, "student_loss": null, "teacher_policy_loss": -30.463623046875, "teacher_value_loss": 361.2445373535156, "teacher_entropy": 0.579180121421814, "time": 0.04399919509887695}
{"epoch": 143, "reward_mean": 181.5, "student_loss": null, "teacher_policy_loss": -37.828914642333984, "teacher_value_loss": 167.3244171142578, "teacher_entropy": 0.5918707847595215, "time": 0.021974802017211914}
{"epoch": 144, "reward_mean": 130.33333333333334, "student_loss": null, "teacher_policy_loss": -31.332935333251953, "teacher_value_loss": 379.55078125, "teacher_entropy": 0.5089143514633179, "time": 0.028408050537109375}
{"epoch": 145, "reward_mean": 159.0, "student_loss": null, "teacher_policy_loss": -29.89794921875, "teacher_value_loss": 255.5117645263672, "teacher_entropy": 0.5121142864227295, "time": 0.014702320098876953}
{"epoch": 146, "reward_mean": 133.33333333333334, "student_loss": null, "teacher_policy_loss": -29.503681182861328, "teacher_value_loss": 273.52178955078125, "teacher_entropy": 0.5406782627105713, "time": 0.047025203704833984}
{"epoch": 147, "reward_mean": 126.5, "student_loss": null, "teacher_policy_loss": -42.15827941894531, "teacher_value_loss": 292.5856018066406, "teacher_entropy": 0.5677332878112793, "time": 0.020183086395263672}
{"epoch": 148, "reward_mean": 207.5, "student_loss": null, "teacher_policy_loss": -44.06682586669922, "teacher_value_loss": 326.5898742675781, "teacher_entropy": 0.5934943556785583, "time": 0.013379096984863281}
{"epoch": 149, "reward_mean": 172.0, "student_loss": null, "teacher_policy_loss": -34.45893478393555, "teacher_value_loss": 385.2778015136719, "teacher_entropy": 0.5595447421073914, "time": 0.025681257247924805}
{"epoch": 150, "reward_mean": 157.5, "student_loss": null, "teacher_policy_loss": -39.558528900146484, "teacher_value_loss": 438.1717224121094, "teacher_entropy": 0.5486847758293152, "time": 0.011008501052856445}
{"epoch": 151, "reward_mean": 149.0, "student_loss": null, "teacher_policy_loss": -33.96210861206055, "teacher_value_loss": 150.57254028320312, "teacher_entropy": 0.5326053500175476, "time": 0.04034233093261719}
{"epoch": 152, "reward_mean": 163.0, "student_loss": null, "teacher_policy_loss": -41.46030807495117, "teacher_value_loss": 373.4862976074219, "teacher_entropy": 0.5539496541023254, "time": 0.022884368896484375}
{"epoch": 153, "reward_mean": 275.5, "student_loss": null, "teacher_policy_loss": -41.39081954956055, "teacher_value_loss": 379.178955078125, "teacher_entropy": 0.5464891195297241, "time": 0.022367000579833984}
{"epoch": 154, "reward_mean": 151.5, "student_loss": null, "teacher_policy_loss": -37.793251037597656, "teacher_value_loss": 204.017578125, "teacher_entropy": 0.5694738626480103, "time": 0.025258779525756836}
{"epoch": 155, "reward_mean": 146.0, "student_loss": null, "teacher_policy_loss": -36.408145904541016, "teacher_value_loss": 293.0237731933594, "teacher_entropy": 0.588351309299469, "time": 0.01703667640686035}
{"epoch": 156, "reward_mean": 197.5, "student_loss": null, "teacher_policy_loss": -37.72063446044922, "teacher_value_loss": 158.52755737304688, "teacher_entropy": 0.5623387098312378, "time": 0.03881216049194336}
{"epoch": 157, "reward_mean": 153.66666666666666, "student_loss": null, "teacher_policy_loss": -33.370365142822266, "teacher_value_loss": 466.18328857421875, "teacher_entropy": 0.5365766286849976, "time": 0.016752004623413086}
{"epoch": 158, "reward_mean": 175.0, "student_loss": null, "teacher_policy_loss": -40.977108001708984, "teacher_value_loss": 447.9365539550781, "teacher_entropy": 0.5371525287628174, "time": 0.019680500030517578}
{"epoch": 159, "reward_mean": 220.0, "student_loss": null, "teacher_policy_loss": -40.59109878540039, "teacher_value_loss": 324.12518310546875, "teacher_entropy": 0.5860754251480103, "time": 0.027263641357421875}
{"epoch": 160, "reward_mean": 268.0, "student_loss": null, "teacher_policy_loss": -50.98894500732422, "teacher_value_loss": 327.3315734863281, "teacher_entropy": 0.5872326493263245, "time": 0.019975662231445312}
{"epoch": 161, "reward_mean": 253.5, "student_loss": null, "teacher_policy_loss": -44.389522552490234, "teacher_value_loss": 706.668212890625, "teacher_entropy": 0.5870497226715088, "time": 0.02137923240661621}
{"epoch": 162, "reward_mean": 211.5, "student_loss": null, "teacher_policy_loss": -38.66596221923828, "teacher_value_loss": 485.6296081542969, "teacher_entropy": 0.5537981986999512, "time": 0.028718948364257812}
{"epoch": 163, "reward_mean": 177.0, "student_loss": null, "teacher_policy_loss": -36.291072845458984, "teacher_value_loss": 118.7157974243164, "teacher_entropy": 0.578874945640564, "time": 0.017910003662109375}
{"epoch": 164, "reward_mean": 124.5, "student_loss": null, "teacher_policy_loss": -33.69815444946289, "teacher_value_loss": 579.322021484375, "teacher_entropy": 0.5728246569633484, "time": 0.028637409210205078}
{"epoch": 165, "reward_mean": 335.0, "student_loss": null, "teacher_policy_loss": -55.49394607543945, "teacher_value_loss": 797.276123046875, "teacher_entropy": 0.591231107711792, "time": 0.019402503967285156}
{"epoch": 166, "reward_mean": 213.0, "student_loss": null, "teacher_policy_loss": -49.53759765625, "teacher_value_loss": 581.570068359375, "teacher_entropy": 0.5677486658096313, "time": 0.01583409309387207}
{"epoch": 167, "reward_mean": 286.5, "student_loss": null, "teacher_policy_loss": -50.88514709472656, "teacher_value_loss": 616.8912353515625, "teacher_entropy": 0.5724380612373352, "time": 0.016110658645629883}
{"epoch": 168, "reward_mean": 415.0, "student_loss": null, "teacher_policy_loss": -53.78129959106445, "teacher_value_loss": 755.22119140625, "teacher_entropy": 0.5465648770332336, "time": 0.014908552169799805}
{"epoch": 169, "reward_mean": 176.5, "student_loss": null, "teacher_policy_loss": -41.95990753173828, "teacher_value_loss": 269.11968994140625, "teacher_entropy": 0.5898126363754272, "time": 0.0155029296875}
{"epoch": 170, "reward_mean": 196.5, "student_loss": null, "teacher_policy_loss": -42.87297058105469, "teacher_value_loss": 675.3224487304688, "teacher_entropy": 0.5662348866462708, "time": 0.019828319549560547}
{"epoch": 171, "reward_mean": 345.0, "student_loss": null, "teacher_policy_loss": -50.837989807128906, "teacher_value_loss": 297.6212463378906, "teacher_entropy": 0.5760688781738281, "time": 0.023730039596557617}
{"epoch": 172, "reward_mean": 396.0, "student_loss": null, "teacher_policy_loss": -49.810646057128906, "teacher_value_loss": 271.98602294921875, "teacher_entropy": 0.5899288058280945, "time": 0.023149967193603516}
{"epoch": 173, "reward_mean": 185.66666666666666, "student_loss": null, "teacher_policy_loss": -40.5591926574707, "teacher_value_loss": 417.7372741699219, "teacher_entropy": 0.5854789614677429, "time": 0.018134117126464844}
{"epoch": 174, "reward_mean": 198.0, "student_loss": null, "teacher_policy_loss": -49.397884368896484, "teacher_value_loss": 177.5511474609375, "teacher_entropy": 0.5824546813964844, "time": 0.02097177505493164}
{"epoch": 175, "reward_mean": 262.0, "student_loss": null, "teacher_policy_loss": -49.1723747253418, "teacher_value_loss": 802.5977172851562, "teacher_entropy": 0.5724607110023499, "time": 0.03171205520629883}
{"epoch": 176, "reward_mean": 222.0, "student_loss": null, "teacher_policy_loss": -41.811729431152344, "teacher_value_loss": 416.30426025390625, "teacher_entropy": 0.5857270956039429, "time": 0.016275644302368164}
{"epoch": 177, "reward_mean": 142.66666666666666, "student_loss": null, "teacher_policy_loss": -32.74251174926758, "teacher_value_loss": 382.3494567871094, "teacher_entropy": 0.5946933031082153, "time": 0.026224851608276367}
{"epoch": 178, "reward_mean": 164.5, "student_loss": null, "teacher_policy_loss": -37.15517044067383, "teacher_value_loss": 355.7725830078125, "teacher_entropy": 0.5884482860565186, "time": 0.03986668586730957}
{"epoch": 179, "reward_mean": 173.5, "student_loss": null, "teacher_policy_loss": -37.764991760253906, "teacher_value_loss": 88.04072570800781, "teacher_entropy": 0.5742327570915222, "time": 0.011787891387939453}
{"epoch": 180, "reward_mean": 153.66666666666666, "student_loss": null, "teacher_policy_loss": -37.606868743896484, "teacher_value_loss": 285.8117980957031, "teacher_entropy": 0.5915127396583557, "time": 0.025723934173583984}
{"epoch": 181, "reward_mean": 171.0, "student_loss": null, "teacher_policy_loss": -37.205238342285156, "teacher_value_loss": 141.36805725097656, "teacher_entropy": 0.5846250653266907, "time": 0.018423795700073242}
{"epoch": 182, "reward_mean": 180.33333333333334, "student_loss": null, "teacher_policy_loss": -38.184207916259766, "teacher_value_loss": 155.6848602294922, "teacher_entropy": 0.5802301168441772, "time": 0.012398481369018555}
{"epoch": 183, "reward_mean": 176.5, "student_loss": null, "teacher_policy_loss": -40.68819046020508, "teacher_value_loss": 301.48260498046875, "teacher_entropy": 0.5746756196022034, "time": 0.03388500213623047}
{"epoch": 184, "reward_mean": 138.0, "student_loss": null, "teacher_policy_loss": -40.19529342651367, "teacher_value_loss": 310.9382019042969, "teacher_entropy": 0.5906206369400024, "time": 0.017411231994628906}
{"epoch": 185, "reward_mean": 147.0, "student_loss": null, "teacher_policy_loss": -38.16162872314453, "teacher_value_loss": 121.42567443847656, "teacher_entropy": 0.587670087814331, "time": 0.020184040069580078}
{"epoch": 186, "reward_mean": 254.0, "student_loss": null, "teacher_policy_loss": -54.28892517089844, "teacher_value_loss": 842.04541015625, "teacher_entropy": 0.5804417133331299, "time": 0.017527103424072266}
{"epoch": 187, "reward_mean": 229.0, "student_loss": null, "teacher_policy_loss": -48.30558776855469, "teacher_value_loss": 518.7874755859375, "teacher_entropy": 0.562295138835907, "time": 0.011014938354492188}
{"epoch": 188, "reward_mean": 271.5, "student_loss": null, "teacher_policy_loss": -40.181785583496094, "teacher_value_loss": 351.88653564453125, "teacher_entropy": 0.5688225030899048, "time": 0.014409780502319336}
{"epoch": 189, "reward_mean": 465.0, "student_loss": null, "teacher_policy_loss": -67.08484649658203, "teacher_value_loss": 800.2901611328125, "teacher_entropy": 0.5809066295623779, "time": 0.026330947875976562}
{"epoch": 190, "reward_mean": 379.5, "student_loss": null, "teacher_policy_loss": -45.169979095458984, "teacher_value_loss": 343.970703125, "teacher_entropy": 0.5646656155586243, "time": 0.023181438446044922}
{"epoch": 191, "reward_mean": 262.0, "student_loss": null, "teacher_policy_loss": -49.687889099121094, "teacher_value_loss": 1106.873779296875, "teacher_entropy": 0.5828160643577576, "time": 0.019639253616333008}
{"epoch": 192, "reward_mean": 265.5, "student_loss": null, "teacher_policy_loss": -44.33248519897461, "teacher_value_loss": 448.6611022949219, "teacher_entropy": 0.5718232989311218, "time": 0.01717376708984375}
{"epoch": 193, "reward_mean": 187.0, "student_loss": null, "teacher_policy_loss": -38.767066955566406, "teacher_value_loss": 111.96222686767578, "teacher_entropy": 0.5675908923149109, "time": 0.014623165130615234}
{"epoch": 194, "reward_mean": 263.0, "student_loss": null, "teacher_policy_loss": -44.799964904785156, "teacher_value_loss": 944.2322387695312, "teacher_entropy": 0.5827988386154175, "time": 0.01763463020324707}
{"epoch": 195, "reward_mean": 165.0, "student_loss": null, "teacher_policy_loss": -38.260128021240234, "teacher_value_loss": 135.0895538330078, "teacher_entropy": 0.5810446739196777, "time": 0.021970272064208984}
{"epoch": 196, "reward_mean": 149.0, "student_loss": null, "teacher_policy_loss": -34.976654052734375, "teacher_value_loss": 340.4941711425781, "teacher_entropy": 0.584006667137146, "time": 0.02344202995300293}
{"epoch": 197, "reward_mean": 277.0, "student_loss": null, "teacher_policy_loss": -49.62015151977539, "teacher_value_loss": 788.4564208984375, "teacher_entropy": 0.5858711004257202, "time": 0.01818370819091797}
{"epoch": 198, "reward_mean": 447.0, "student_loss": null, "teacher_policy_loss": -51.32366180419922, "teacher_value_loss": 612.3552856445312, "teacher_entropy": 0.5948771238327026, "time": 0.018291473388671875}
{"epoch": 199, "reward_mean": 213.0, "student_loss": null, "teacher_policy_loss": -46.27131652832031, "teacher_value_loss": 1332.91943359375, "teacher_entropy": 0.5707871913909912, "time": 0.010864973068237305}
{"epoch": 200, "reward_mean": 186.0, "student_loss": null, "teacher_policy_loss": -38.07405090332031, "teacher_value_loss": 313.9723815917969, "teacher_entropy": 0.5178946852684021, "time": 0.016794443130493164}
{"epoch": 201, "reward_mean": 230.5, "student_loss": null, "teacher_policy_loss": -48.913063049316406, "teacher_value_loss": 697.2867431640625, "teacher_entropy": 0.5403952598571777, "time": 0.01781606674194336}
{"epoch": 202, "reward_mean": 273.0, "student_loss": null, "teacher_policy_loss": -47.936336517333984, "teacher_value_loss": 578.1621704101562, "teacher_entropy": 0.5838037133216858, "time": 0.01837325096130371}
{"epoch": 203, "reward_mean": 370.0, "student_loss": null, "teacher_policy_loss": -48.639217376708984, "teacher_value_loss": 466.148193359375, "teacher_entropy": 0.5719917416572571, "time": 0.01780557632446289}
{"epoch": 204, "reward_mean": 269.0, "student_loss": null, "teacher_policy_loss": -45.547706604003906, "teacher_value_loss": 586.385009765625, "teacher_entropy": 0.5645912885665894, "time": 0.024778366088867188}
{"epoch": 205, "reward_mean": 472.0, "student_loss": null, "teacher_policy_loss": -63.942840576171875, "teacher_value_loss": 351.0250244140625, "teacher_entropy": 0.5578255653381348, "time": 0.018132925033569336}
{"epoch": 206, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -61.305458068847656, "teacher_value_loss": 590.5213012695312, "teacher_entropy": 0.5499584674835205, "time": 0.0285646915435791}
{"epoch": 207, "reward_mean": 410.0, "student_loss": null, "teacher_policy_loss": -58.920570373535156, "teacher_value_loss": 511.5758972167969, "teacher_entropy": 0.5550065636634827, "time": 0.01233530044555664}
{"epoch": 208, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -51.091064453125, "teacher_value_loss": 408.67816162109375, "teacher_entropy": 0.5540482997894287, "time": 0.01572251319885254}
{"epoch": 209, "reward_mean": 272.0, "student_loss": null, "teacher_policy_loss": -64.4063949584961, "teacher_value_loss": 1079.893798828125, "teacher_entropy": 0.5476972460746765, "time": 0.02074265480041504}
{"epoch": 210, "reward_mean": 343.5, "student_loss": null, "teacher_policy_loss": -37.0456657409668, "teacher_value_loss": 487.6666259765625, "teacher_entropy": 0.5589216351509094, "time": 0.02145838737487793}
{"epoch": 211, "reward_mean": 298.0, "student_loss": null, "teacher_policy_loss": -47.201961517333984, "teacher_value_loss": 380.3962097167969, "teacher_entropy": 0.5546556115150452, "time": 0.017852306365966797}
{"epoch": 212, "reward_mean": 278.0, "student_loss": null, "teacher_policy_loss": -42.64657211303711, "teacher_value_loss": 650.0042724609375, "teacher_entropy": 0.5462769269943237, "time": 0.03393244743347168}
{"epoch": 213, "reward_mean": 173.5, "student_loss": null, "teacher_policy_loss": -37.07933044433594, "teacher_value_loss": 324.44891357421875, "teacher_entropy": 0.5680952668190002, "time": 0.017440319061279297}
{"epoch": 214, "reward_mean": 205.0, "student_loss": null, "teacher_policy_loss": -40.991310119628906, "teacher_value_loss": 271.4916076660156, "teacher_entropy": 0.5565161108970642, "time": 0.01209115982055664}
{"epoch": 215, "reward_mean": 160.0, "student_loss": null, "teacher_policy_loss": -36.6529655456543, "teacher_value_loss": 202.51116943359375, "teacher_entropy": 0.5589995384216309, "time": 0.021332979202270508}
{"epoch": 216, "reward_mean": 246.5, "student_loss": null, "teacher_policy_loss": -39.69990921020508, "teacher_value_loss": 529.4694213867188, "teacher_entropy": 0.5523278117179871, "time": 0.017857074737548828}
{"epoch": 217, "reward_mean": 223.0, "student_loss": null, "teacher_policy_loss": -41.10374450683594, "teacher_value_loss": 368.8333740234375, "teacher_entropy": 0.5557916760444641, "time": 0.010899543762207031}
{"epoch": 218, "reward_mean": 247.0, "student_loss": null, "teacher_policy_loss": -47.132808685302734, "teacher_value_loss": 196.01739501953125, "teacher_entropy": 0.5426527857780457, "time": 0.019829273223876953}
{"epoch": 219, "reward_mean": 273.0, "student_loss": null, "teacher_policy_loss": -42.3012580871582, "teacher_value_loss": 662.3526611328125, "teacher_entropy": 0.5328395366668701, "time": 0.028473615646362305}
{"epoch": 220, "reward_mean": 165.0, "student_loss": null, "teacher_policy_loss": -34.46216583251953, "teacher_value_loss": 455.9868469238281, "teacher_entropy": 0.5406568646430969, "time": 0.015755653381347656}
{"epoch": 221, "reward_mean": 352.0, "student_loss": null, "teacher_policy_loss": -47.624061584472656, "teacher_value_loss": 214.16900634765625, "teacher_entropy": 0.5455160140991211, "time": 0.01741337776184082}
{"epoch": 222, "reward_mean": 262.5, "student_loss": null, "teacher_policy_loss": -43.901973724365234, "teacher_value_loss": 589.5189208984375, "teacher_entropy": 0.5400834679603577, "time": 0.018668651580810547}
{"epoch": 223, "reward_mean": 245.0, "student_loss": null, "teacher_policy_loss": -46.14615249633789, "teacher_value_loss": 228.56910705566406, "teacher_entropy": 0.5335813164710999, "time": 0.012607097625732422}
{"epoch": 224, "reward_mean": 221.0, "student_loss": null, "teacher_policy_loss": -42.25823211669922, "teacher_value_loss": 380.8518371582031, "teacher_entropy": 0.5390943884849548, "time": 0.014404296875}
{"epoch": 225, "reward_mean": 231.0, "student_loss": null, "teacher_policy_loss": -39.349021911621094, "teacher_value_loss": 501.3319396972656, "teacher_entropy": 0.5516874194145203, "time": 0.0179595947265625}
{"epoch": 226, "reward_mean": 278.0, "student_loss": null, "teacher_policy_loss": -46.62018966674805, "teacher_value_loss": 266.762939453125, "teacher_entropy": 0.5361774563789368, "time": 0.01124882698059082}
{"epoch": 227, "reward_mean": 251.0, "student_loss": null, "teacher_policy_loss": -39.521427154541016, "teacher_value_loss": 445.64105224609375, "teacher_entropy": 0.5405719876289368, "time": 0.01654982566833496}
{"epoch": 228, "reward_mean": 243.5, "student_loss": null, "teacher_policy_loss": -43.206886291503906, "teacher_value_loss": 328.4878234863281, "teacher_entropy": 0.5444128513336182, "time": 0.02263617515563965}
{"epoch": 229, "reward_mean": 197.5, "student_loss": null, "teacher_policy_loss": -41.39393615722656, "teacher_value_loss": 247.98507690429688, "teacher_entropy": 0.5466160774230957, "time": 0.026643991470336914}
{"epoch": 230, "reward_mean": 208.5, "student_loss": null, "teacher_policy_loss": -45.609989166259766, "teacher_value_loss": 220.1366729736328, "teacher_entropy": 0.5478242635726929, "time": 0.026136398315429688}
{"epoch": 231, "reward_mean": 195.0, "student_loss": null, "teacher_policy_loss": -43.309818267822266, "teacher_value_loss": 378.3760986328125, "teacher_entropy": 0.5330120921134949, "time": 0.014200687408447266}
{"epoch": 232, "reward_mean": 254.0, "student_loss": null, "teacher_policy_loss": -46.0792236328125, "teacher_value_loss": 184.02455139160156, "teacher_entropy": 0.5185843110084534, "time": 0.016379117965698242}
{"epoch": 233, "reward_mean": 167.66666666666666, "student_loss": null, "teacher_policy_loss": -34.52443313598633, "teacher_value_loss": 291.0471496582031, "teacher_entropy": 0.5385057330131531, "time": 0.044206857681274414}
{"epoch": 234, "reward_mean": 149.0, "student_loss": null, "teacher_policy_loss": -37.2446403503418, "teacher_value_loss": 49.02765655517578, "teacher_entropy": 0.5422542095184326, "time": 0.02274346351623535}
{"epoch": 235, "reward_mean": 215.0, "student_loss": null, "teacher_policy_loss": -39.43702697753906, "teacher_value_loss": 212.1385498046875, "teacher_entropy": 0.5284285545349121, "time": 0.018051862716674805}
{"epoch": 236, "reward_mean": 173.0, "student_loss": null, "teacher_policy_loss": -33.57014465332031, "teacher_value_loss": 172.74855041503906, "teacher_entropy": 0.5349475145339966, "time": 0.015038013458251953}
{"epoch": 237, "reward_mean": 160.5, "student_loss": null, "teacher_policy_loss": -35.9990119934082, "teacher_value_loss": 331.88629150390625, "teacher_entropy": 0.5441473722457886, "time": 0.018100261688232422}
{"epoch": 238, "reward_mean": 183.5, "student_loss": null, "teacher_policy_loss": -37.679012298583984, "teacher_value_loss": 66.12046813964844, "teacher_entropy": 0.5375902652740479, "time": 0.01616835594177246}
{"epoch": 239, "reward_mean": 158.0, "student_loss": null, "teacher_policy_loss": -34.65128707885742, "teacher_value_loss": 299.0384826660156, "teacher_entropy": 0.5319154858589172, "time": 0.02016282081604004}
{"epoch": 240, "reward_mean": 178.0, "student_loss": null, "teacher_policy_loss": -37.75956726074219, "teacher_value_loss": 174.4799041748047, "teacher_entropy": 0.5137405395507812, "time": 0.016016721725463867}
{"epoch": 241, "reward_mean": 179.5, "student_loss": null, "teacher_policy_loss": -40.4113883972168, "teacher_value_loss": 110.49390411376953, "teacher_entropy": 0.5183217525482178, "time": 0.02476358413696289}
{"epoch": 242, "reward_mean": 169.33333333333334, "student_loss": null, "teacher_policy_loss": -34.275978088378906, "teacher_value_loss": 228.6933135986328, "teacher_entropy": 0.5322176218032837, "time": 0.014505386352539062}
{"epoch": 243, "reward_mean": 200.0, "student_loss": null, "teacher_policy_loss": -47.576786041259766, "teacher_value_loss": 105.98986053466797, "teacher_entropy": 0.5215598940849304, "time": 0.01642751693725586}
{"epoch": 244, "reward_mean": 194.66666666666666, "student_loss": null, "teacher_policy_loss": -35.19593811035156, "teacher_value_loss": 276.2759094238281, "teacher_entropy": 0.5229092836380005, "time": 0.016064882278442383}
{"epoch": 245, "reward_mean": 154.0, "student_loss": null, "teacher_policy_loss": -33.63822937011719, "teacher_value_loss": 201.09060668945312, "teacher_entropy": 0.504231333732605, "time": 0.02182745933532715}
{"epoch": 246, "reward_mean": 222.5, "student_loss": null, "teacher_policy_loss": -39.38633728027344, "teacher_value_loss": 202.62408447265625, "teacher_entropy": 0.5268785953521729, "time": 0.05900859832763672}
{"epoch": 247, "reward_mean": 195.0, "student_loss": null, "teacher_policy_loss": -37.08361053466797, "teacher_value_loss": 223.91944885253906, "teacher_entropy": 0.5083949565887451, "time": 0.013564586639404297}
{"epoch": 248, "reward_mean": 176.5, "student_loss": null, "teacher_policy_loss": -36.538368225097656, "teacher_value_loss": 249.03182983398438, "teacher_entropy": 0.49804946780204773, "time": 0.03351020812988281}
{"epoch": 249, "reward_mean": 249.0, "student_loss": null, "teacher_policy_loss": -39.50370788574219, "teacher_value_loss": 391.7735900878906, "teacher_entropy": 0.47830650210380554, "time": 0.02750420570373535}
{"epoch": 250, "reward_mean": 227.0, "student_loss": null, "teacher_policy_loss": -46.07552719116211, "teacher_value_loss": 229.3903350830078, "teacher_entropy": 0.5047190189361572, "time": 0.01887655258178711}
{"epoch": 251, "reward_mean": 259.0, "student_loss": null, "teacher_policy_loss": -40.279747009277344, "teacher_value_loss": 384.5760803222656, "teacher_entropy": 0.5192114114761353, "time": 0.02016425132751465}
{"epoch": 252, "reward_mean": 432.0, "student_loss": null, "teacher_policy_loss": -50.425254821777344, "teacher_value_loss": 722.037353515625, "teacher_entropy": 0.5022149682044983, "time": 0.02515435218811035}
{"epoch": 253, "reward_mean": 329.0, "student_loss": null, "teacher_policy_loss": -45.115447998046875, "teacher_value_loss": 289.9951171875, "teacher_entropy": 0.4814712405204773, "time": 0.02478313446044922}
{"epoch": 254, "reward_mean": 208.0, "student_loss": null, "teacher_policy_loss": -38.2548713684082, "teacher_value_loss": 820.4336547851562, "teacher_entropy": 0.5070204138755798, "time": 0.02022409439086914}
{"epoch": 255, "reward_mean": 478.0, "student_loss": null, "teacher_policy_loss": -54.095848083496094, "teacher_value_loss": 692.2869262695312, "teacher_entropy": 0.4977264404296875, "time": 0.01905989646911621}
{"epoch": 256, "reward_mean": 378.0, "student_loss": null, "teacher_policy_loss": -53.237308502197266, "teacher_value_loss": 805.8277587890625, "teacher_entropy": 0.49763450026512146, "time": 0.02466583251953125}
{"epoch": 257, "reward_mean": 337.0, "student_loss": null, "teacher_policy_loss": -48.229591369628906, "teacher_value_loss": 569.3484497070312, "teacher_entropy": 0.49440842866897583, "time": 0.01999831199645996}
{"epoch": 258, "reward_mean": 433.0, "student_loss": null, "teacher_policy_loss": -48.393310546875, "teacher_value_loss": 678.596435546875, "teacher_entropy": 0.4672020375728607, "time": 0.05583453178405762}
{"epoch": 259, "reward_mean": 475.0, "student_loss": null, "teacher_policy_loss": -57.415950775146484, "teacher_value_loss": 690.052978515625, "teacher_entropy": 0.484211266040802, "time": 0.013964414596557617}
{"epoch": 260, "reward_mean": 417.0, "student_loss": null, "teacher_policy_loss": -61.092369079589844, "teacher_value_loss": 515.81787109375, "teacher_entropy": 0.49235525727272034, "time": 0.015015363693237305}
{"epoch": 261, "reward_mean": 408.0, "student_loss": null, "teacher_policy_loss": -66.9104995727539, "teacher_value_loss": 486.0661315917969, "teacher_entropy": 0.5308602452278137, "time": 0.026064634323120117}
{"epoch": 262, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -49.756534576416016, "teacher_value_loss": 621.261474609375, "teacher_entropy": 0.4865383803844452, "time": 0.011690378189086914}
{"epoch": 263, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -46.842044830322266, "teacher_value_loss": 433.5922546386719, "teacher_entropy": 0.4778406620025635, "time": 0.02138376235961914}
{"epoch": 264, "reward_mean": 365.0, "student_loss": null, "teacher_policy_loss": -44.63091278076172, "teacher_value_loss": 313.2770690917969, "teacher_entropy": 0.4648175835609436, "time": 0.020854711532592773}
{"epoch": 265, "reward_mean": 327.0, "student_loss": null, "teacher_policy_loss": -51.269309997558594, "teacher_value_loss": 840.6806030273438, "teacher_entropy": 0.4815625250339508, "time": 0.013345479965209961}
{"epoch": 266, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -50.92515563964844, "teacher_value_loss": 409.697998046875, "teacher_entropy": 0.5142238140106201, "time": 0.018949270248413086}
{"epoch": 267, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -52.1362419128418, "teacher_value_loss": 634.1406860351562, "teacher_entropy": 0.5184720754623413, "time": 0.02628469467163086}
{"epoch": 268, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -61.41438293457031, "teacher_value_loss": 977.597900390625, "teacher_entropy": 0.5316932201385498, "time": 0.017900943756103516}
{"epoch": 269, "reward_mean": 416.0, "student_loss": null, "teacher_policy_loss": -64.03772735595703, "teacher_value_loss": 682.8987426757812, "teacher_entropy": 0.495123028755188, "time": 0.023053646087646484}
{"epoch": 270, "reward_mean": 486.0, "student_loss": null, "teacher_policy_loss": -52.68324661254883, "teacher_value_loss": 464.3110046386719, "teacher_entropy": 0.49951568245887756, "time": 0.030295372009277344}
{"epoch": 271, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -49.900978088378906, "teacher_value_loss": 555.8021240234375, "teacher_entropy": 0.5171512365341187, "time": 0.022106170654296875}
{"epoch": 272, "reward_mean": 312.0, "student_loss": null, "teacher_policy_loss": -53.59461975097656, "teacher_value_loss": 413.39385986328125, "teacher_entropy": 0.5096814632415771, "time": 0.017874717712402344}
{"epoch": 273, "reward_mean": 404.0, "student_loss": null, "teacher_policy_loss": -52.813724517822266, "teacher_value_loss": 773.2254638671875, "teacher_entropy": 0.506631076335907, "time": 0.020166635513305664}
{"epoch": 274, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -49.503501892089844, "teacher_value_loss": 529.3484497070312, "teacher_entropy": 0.4879986047744751, "time": 0.01683807373046875}
{"epoch": 275, "reward_mean": 403.0, "student_loss": null, "teacher_policy_loss": -47.174110412597656, "teacher_value_loss": 259.287109375, "teacher_entropy": 0.49077895283699036, "time": 0.031659841537475586}
{"epoch": 276, "reward_mean": 248.0, "student_loss": null, "teacher_policy_loss": -59.409969329833984, "teacher_value_loss": 558.1224365234375, "teacher_entropy": 0.49825623631477356, "time": 0.018332242965698242}
{"epoch": 277, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -49.10123062133789, "teacher_value_loss": 502.5280456542969, "teacher_entropy": 0.4823337197303772, "time": 0.017954349517822266}
{"epoch": 278, "reward_mean": 445.0, "student_loss": null, "teacher_policy_loss": -47.4892578125, "teacher_value_loss": 467.9903869628906, "teacher_entropy": 0.5021147727966309, "time": 0.02976226806640625}
{"epoch": 279, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -51.8392333984375, "teacher_value_loss": 571.3599853515625, "teacher_entropy": 0.4710509777069092, "time": 0.014231204986572266}
{"epoch": 280, "reward_mean": 457.0, "student_loss": null, "teacher_policy_loss": -52.60086441040039, "teacher_value_loss": 746.9556274414062, "teacher_entropy": 0.46966812014579773, "time": 0.011527538299560547}
{"epoch": 281, "reward_mean": 377.0, "student_loss": null, "teacher_policy_loss": -51.54270553588867, "teacher_value_loss": 534.6614990234375, "teacher_entropy": 0.4938824474811554, "time": 0.02535533905029297}
{"epoch": 282, "reward_mean": 297.0, "student_loss": null, "teacher_policy_loss": -46.69614791870117, "teacher_value_loss": 305.6623840332031, "teacher_entropy": 0.47760871052742004, "time": 0.019865751266479492}
{"epoch": 283, "reward_mean": 248.0, "student_loss": null, "teacher_policy_loss": -37.20347213745117, "teacher_value_loss": 502.145751953125, "teacher_entropy": 0.4722817540168762, "time": 0.02184271812438965}
{"epoch": 284, "reward_mean": 226.0, "student_loss": null, "teacher_policy_loss": -37.94270324707031, "teacher_value_loss": 480.14385986328125, "teacher_entropy": 0.4723796546459198, "time": 0.0192568302154541}
{"epoch": 285, "reward_mean": 230.0, "student_loss": null, "teacher_policy_loss": -46.388092041015625, "teacher_value_loss": 200.9384002685547, "teacher_entropy": 0.4814731180667877, "time": 0.02250075340270996}
{"epoch": 286, "reward_mean": 181.66666666666666, "student_loss": null, "teacher_policy_loss": -33.270538330078125, "teacher_value_loss": 296.0336608886719, "teacher_entropy": 0.47552695870399475, "time": 0.020186185836791992}
{"epoch": 287, "reward_mean": 184.5, "student_loss": null, "teacher_policy_loss": -35.528358459472656, "teacher_value_loss": 294.7039489746094, "teacher_entropy": 0.47651779651641846, "time": 0.022482633590698242}
{"epoch": 288, "reward_mean": 196.0, "student_loss": null, "teacher_policy_loss": -36.31958770751953, "teacher_value_loss": 202.68186950683594, "teacher_entropy": 0.4883946478366852, "time": 0.022137880325317383}
{"epoch": 289, "reward_mean": 147.33333333333334, "student_loss": null, "teacher_policy_loss": -27.585975646972656, "teacher_value_loss": 208.97048950195312, "teacher_entropy": 0.48699310421943665, "time": 0.024203777313232422}
{"epoch": 290, "reward_mean": 186.5, "student_loss": null, "teacher_policy_loss": -35.794803619384766, "teacher_value_loss": 212.46734619140625, "teacher_entropy": 0.47179505228996277, "time": 0.016069889068603516}
{"epoch": 291, "reward_mean": 154.0, "student_loss": null, "teacher_policy_loss": -36.4908332824707, "teacher_value_loss": 167.0132293701172, "teacher_entropy": 0.47853419184684753, "time": 0.014127969741821289}
{"epoch": 292, "reward_mean": 169.66666666666666, "student_loss": null, "teacher_policy_loss": -32.478763580322266, "teacher_value_loss": 164.5214080810547, "teacher_entropy": 0.4937352240085602, "time": 0.0663919448852539}
{"epoch": 293, "reward_mean": 149.66666666666666, "student_loss": null, "teacher_policy_loss": -32.311466217041016, "teacher_value_loss": 221.60458374023438, "teacher_entropy": 0.47517943382263184, "time": 0.0230865478515625}
{"epoch": 294, "reward_mean": 156.5, "student_loss": null, "teacher_policy_loss": -35.9267463684082, "teacher_value_loss": 174.78662109375, "teacher_entropy": 0.4716871678829193, "time": 0.01518702507019043}
{"epoch": 295, "reward_mean": 165.66666666666666, "student_loss": null, "teacher_policy_loss": -30.60614776611328, "teacher_value_loss": 209.0888214111328, "teacher_entropy": 0.4589909315109253, "time": 0.01404881477355957}
{"epoch": 296, "reward_mean": 149.0, "student_loss": null, "teacher_policy_loss": -34.514122009277344, "teacher_value_loss": 65.67565155029297, "teacher_entropy": 0.47595202922821045, "time": 0.03367757797241211}
{"epoch": 297, "reward_mean": 166.0, "student_loss": null, "teacher_policy_loss": -31.66320037841797, "teacher_value_loss": 140.61785888671875, "teacher_entropy": 0.4677535593509674, "time": 0.022647380828857422}
{"epoch": 298, "reward_mean": 172.5, "student_loss": null, "teacher_policy_loss": -36.21535110473633, "teacher_value_loss": 222.55519104003906, "teacher_entropy": 0.4815610945224762, "time": 0.02430129051208496}
{"epoch": 299, "reward_mean": 152.0, "student_loss": null, "teacher_policy_loss": -30.943031311035156, "teacher_value_loss": 206.5902557373047, "teacher_entropy": 0.46824631094932556, "time": 0.025469303131103516}
{"epoch": 300, "reward_mean": 154.5, "student_loss": null, "teacher_policy_loss": -35.56086349487305, "teacher_value_loss": 118.86809539794922, "teacher_entropy": 0.4824589490890503, "time": 0.025181293487548828}
{"epoch": 301, "reward_mean": 155.0, "student_loss": null, "teacher_policy_loss": -32.05390548706055, "teacher_value_loss": 243.90869140625, "teacher_entropy": 0.47636520862579346, "time": 0.02450275421142578}
{"epoch": 302, "reward_mean": 203.5, "student_loss": null, "teacher_policy_loss": -37.82368469238281, "teacher_value_loss": 357.24688720703125, "teacher_entropy": 0.46048209071159363, "time": 0.015563249588012695}
{"epoch": 303, "reward_mean": 205.5, "student_loss": null, "teacher_policy_loss": -39.95250701904297, "teacher_value_loss": 322.7637939453125, "teacher_entropy": 0.4640040099620819, "time": 0.027286767959594727}
{"epoch": 304, "reward_mean": 190.5, "student_loss": null, "teacher_policy_loss": -38.246524810791016, "teacher_value_loss": 334.4322204589844, "teacher_entropy": 0.44956251978874207, "time": 0.01321101188659668}
{"epoch": 305, "reward_mean": 198.0, "student_loss": null, "teacher_policy_loss": -48.260040283203125, "teacher_value_loss": 203.84254455566406, "teacher_entropy": 0.45294466614723206, "time": 0.0167696475982666}
{"epoch": 306, "reward_mean": 250.0, "student_loss": null, "teacher_policy_loss": -42.27272415161133, "teacher_value_loss": 340.93341064453125, "teacher_entropy": 0.47653937339782715, "time": 0.0323939323425293}
{"epoch": 307, "reward_mean": 316.0, "student_loss": null, "teacher_policy_loss": -49.105377197265625, "teacher_value_loss": 226.6755828857422, "teacher_entropy": 0.46162712574005127, "time": 0.014860153198242188}
{"epoch": 308, "reward_mean": 297.5, "student_loss": null, "teacher_policy_loss": -51.28730010986328, "teacher_value_loss": 496.7926025390625, "teacher_entropy": 0.448894202709198, "time": 0.02339792251586914}
{"epoch": 309, "reward_mean": 122.0, "student_loss": null, "teacher_policy_loss": -50.826316833496094, "teacher_value_loss": 407.0777587890625, "teacher_entropy": 0.4607819616794586, "time": 0.023206472396850586}
{"epoch": 310, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -49.81668472290039, "teacher_value_loss": 559.5014038085938, "teacher_entropy": 0.45500484108924866, "time": 0.011188268661499023}
{"epoch": 311, "reward_mean": 336.0, "student_loss": null, "teacher_policy_loss": -48.795047760009766, "teacher_value_loss": 139.2267608642578, "teacher_entropy": 0.4518301486968994, "time": 0.03152132034301758}
{"epoch": 312, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -50.92353057861328, "teacher_value_loss": 683.018310546875, "teacher_entropy": 0.4486015737056732, "time": 0.014946937561035156}
{"epoch": 313, "reward_mean": 406.0, "student_loss": null, "teacher_policy_loss": -47.2371826171875, "teacher_value_loss": 551.0634155273438, "teacher_entropy": 0.45123445987701416, "time": 0.022608280181884766}
{"epoch": 314, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -56.18741226196289, "teacher_value_loss": 625.0396728515625, "teacher_entropy": 0.46723446249961853, "time": 0.015723466873168945}
{"epoch": 315, "reward_mean": 184.0, "student_loss": null, "teacher_policy_loss": -50.513065338134766, "teacher_value_loss": 447.67840576171875, "teacher_entropy": 0.46205735206604004, "time": 0.016797304153442383}
{"epoch": 316, "reward_mean": 347.0, "student_loss": null, "teacher_policy_loss": -55.2077751159668, "teacher_value_loss": 378.00726318359375, "teacher_entropy": 0.45657309889793396, "time": 0.030702829360961914}
{"epoch": 317, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -51.75422668457031, "teacher_value_loss": 650.5949096679688, "teacher_entropy": 0.4706467390060425, "time": 0.022628307342529297}
{"epoch": 318, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -51.48200607299805, "teacher_value_loss": 726.6575927734375, "teacher_entropy": 0.47364845871925354, "time": 0.0215909481048584}
{"epoch": 319, "reward_mean": 439.0, "student_loss": null, "teacher_policy_loss": -50.8905143737793, "teacher_value_loss": 747.7393798828125, "teacher_entropy": 0.4534813165664673, "time": 0.03355574607849121}
{"epoch": 320, "reward_mean": 354.0, "student_loss": null, "teacher_policy_loss": -48.21156311035156, "teacher_value_loss": 542.2467651367188, "teacher_entropy": 0.4573817551136017, "time": 0.016328096389770508}
{"epoch": 321, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -59.6495361328125, "teacher_value_loss": 621.2999877929688, "teacher_entropy": 0.4673248529434204, "time": 0.011179447174072266}
{"epoch": 322, "reward_mean": 413.0, "student_loss": null, "teacher_policy_loss": -57.51240539550781, "teacher_value_loss": 826.60009765625, "teacher_entropy": 0.4755581021308899, "time": 0.010927200317382812}
{"epoch": 323, "reward_mean": 342.0, "student_loss": null, "teacher_policy_loss": -50.747314453125, "teacher_value_loss": 701.0939331054688, "teacher_entropy": 0.4650804400444031, "time": 0.02307605743408203}
{"epoch": 324, "reward_mean": 207.5, "student_loss": null, "teacher_policy_loss": -40.39860534667969, "teacher_value_loss": 813.4199829101562, "teacher_entropy": 0.4689032733440399, "time": 0.021234750747680664}
{"epoch": 325, "reward_mean": 475.0, "student_loss": null, "teacher_policy_loss": -68.63172912597656, "teacher_value_loss": 803.8807983398438, "teacher_entropy": 0.48803937435150146, "time": 0.020229816436767578}
{"epoch": 326, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -61.447914123535156, "teacher_value_loss": 966.4048461914062, "teacher_entropy": 0.4814876616001129, "time": 0.021955013275146484}
{"epoch": 327, "reward_mean": 373.0, "student_loss": null, "teacher_policy_loss": -38.25019454956055, "teacher_value_loss": 848.094482421875, "teacher_entropy": 0.4501993656158447, "time": 0.015241146087646484}
{"epoch": 328, "reward_mean": 411.0, "student_loss": null, "teacher_policy_loss": -59.161190032958984, "teacher_value_loss": 1052.967529296875, "teacher_entropy": 0.46033748984336853, "time": 0.012395858764648438}
{"epoch": 329, "reward_mean": 159.5, "student_loss": null, "teacher_policy_loss": -35.271629333496094, "teacher_value_loss": 378.7166442871094, "teacher_entropy": 0.4582836925983429, "time": 0.023288488388061523}
{"epoch": 330, "reward_mean": 249.5, "student_loss": null, "teacher_policy_loss": -46.812923431396484, "teacher_value_loss": 541.62841796875, "teacher_entropy": 0.46861088275909424, "time": 0.039689064025878906}
{"epoch": 331, "reward_mean": 155.5, "student_loss": null, "teacher_policy_loss": -37.030399322509766, "teacher_value_loss": 288.43145751953125, "teacher_entropy": 0.47780442237854004, "time": 0.019151687622070312}
{"epoch": 332, "reward_mean": 220.5, "student_loss": null, "teacher_policy_loss": -40.379486083984375, "teacher_value_loss": 607.813232421875, "teacher_entropy": 0.4809460937976837, "time": 0.026452064514160156}
{"epoch": 333, "reward_mean": 132.66666666666666, "student_loss": null, "teacher_policy_loss": -28.9229679107666, "teacher_value_loss": 395.7442321777344, "teacher_entropy": 0.48773494362831116, "time": 0.01236414909362793}
{"epoch": 334, "reward_mean": 160.0, "student_loss": null, "teacher_policy_loss": -35.80066680908203, "teacher_value_loss": 220.751953125, "teacher_entropy": 0.47559016942977905, "time": 0.03287672996520996}
{"epoch": 335, "reward_mean": 176.0, "student_loss": null, "teacher_policy_loss": -36.971126556396484, "teacher_value_loss": 266.99993896484375, "teacher_entropy": 0.4732653796672821, "time": 0.02337336540222168}
{"epoch": 336, "reward_mean": 177.66666666666666, "student_loss": null, "teacher_policy_loss": -39.06461715698242, "teacher_value_loss": 587.136962890625, "teacher_entropy": 0.44643065333366394, "time": 0.04915332794189453}
{"epoch": 337, "reward_mean": 215.0, "student_loss": null, "teacher_policy_loss": -49.24271011352539, "teacher_value_loss": 388.1962585449219, "teacher_entropy": 0.47046950459480286, "time": 0.044816017150878906}
{"epoch": 338, "reward_mean": 204.33333333333334, "student_loss": null, "teacher_policy_loss": -43.016136169433594, "teacher_value_loss": 444.5948486328125, "teacher_entropy": 0.46553507447242737, "time": 0.026862382888793945}
{"epoch": 339, "reward_mean": 201.5, "student_loss": null, "teacher_policy_loss": -46.720314025878906, "teacher_value_loss": 523.233642578125, "teacher_entropy": 0.46426886320114136, "time": 0.022214412689208984}
{"epoch": 340, "reward_mean": 236.0, "student_loss": null, "teacher_policy_loss": -47.528385162353516, "teacher_value_loss": 406.78961181640625, "teacher_entropy": 0.46619194746017456, "time": 0.024268627166748047}
{"epoch": 341, "reward_mean": 236.0, "student_loss": null, "teacher_policy_loss": -40.093021392822266, "teacher_value_loss": 302.302001953125, "teacher_entropy": 0.4504038691520691, "time": 0.013162374496459961}
{"epoch": 342, "reward_mean": 252.5, "student_loss": null, "teacher_policy_loss": -48.839599609375, "teacher_value_loss": 321.80743408203125, "teacher_entropy": 0.4699362814426422, "time": 0.042794227600097656}
{"epoch": 343, "reward_mean": 337.0, "student_loss": null, "teacher_policy_loss": -53.72441101074219, "teacher_value_loss": 855.9508666992188, "teacher_entropy": 0.47227615118026733, "time": 0.017023563385009766}
{"epoch": 344, "reward_mean": 347.0, "student_loss": null, "teacher_policy_loss": -50.14229965209961, "teacher_value_loss": 558.3792724609375, "teacher_entropy": 0.4635144770145416, "time": 0.02575397491455078}
{"epoch": 345, "reward_mean": 445.0, "student_loss": null, "teacher_policy_loss": -52.959651947021484, "teacher_value_loss": 939.5079956054688, "teacher_entropy": 0.4613252580165863, "time": 0.02706122398376465}
{"epoch": 346, "reward_mean": 381.0, "student_loss": null, "teacher_policy_loss": -50.986427307128906, "teacher_value_loss": 764.8172607421875, "teacher_entropy": 0.46041449904441833, "time": 0.022802352905273438}
{"epoch": 347, "reward_mean": 188.0, "student_loss": null, "teacher_policy_loss": -53.547515869140625, "teacher_value_loss": 402.74761962890625, "teacher_entropy": 0.47054967284202576, "time": 0.015648841857910156}
{"epoch": 348, "reward_mean": 471.0, "student_loss": null, "teacher_policy_loss": -47.51637268066406, "teacher_value_loss": 358.2892150878906, "teacher_entropy": 0.44830936193466187, "time": 0.01436471939086914}
{"epoch": 349, "reward_mean": 372.0, "student_loss": null, "teacher_policy_loss": -48.345558166503906, "teacher_value_loss": 529.1484375, "teacher_entropy": 0.4569920301437378, "time": 0.01632094383239746}
{"epoch": 350, "reward_mean": 340.0, "student_loss": null, "teacher_policy_loss": -51.96620178222656, "teacher_value_loss": 595.3605346679688, "teacher_entropy": 0.4521154463291168, "time": 0.023286819458007812}
{"epoch": 351, "reward_mean": 383.0, "student_loss": null, "teacher_policy_loss": -54.79476547241211, "teacher_value_loss": 538.4671630859375, "teacher_entropy": 0.44789788126945496, "time": 0.03153228759765625}
{"epoch": 352, "reward_mean": 353.0, "student_loss": null, "teacher_policy_loss": -61.21967315673828, "teacher_value_loss": 438.4991149902344, "teacher_entropy": 0.44263893365859985, "time": 0.015918731689453125}
{"epoch": 353, "reward_mean": 388.0, "student_loss": null, "teacher_policy_loss": -65.60498809814453, "teacher_value_loss": 510.1393737792969, "teacher_entropy": 0.4429783225059509, "time": 0.023101091384887695}
{"epoch": 354, "reward_mean": 392.0, "student_loss": null, "teacher_policy_loss": -47.163108825683594, "teacher_value_loss": 700.9912719726562, "teacher_entropy": 0.42332667112350464, "time": 0.016550540924072266}
{"epoch": 355, "reward_mean": 412.0, "student_loss": null, "teacher_policy_loss": -63.21322250366211, "teacher_value_loss": 430.4262390136719, "teacher_entropy": 0.4282633662223816, "time": 0.014855623245239258}
{"epoch": 356, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -54.00648880004883, "teacher_value_loss": 706.6188354492188, "teacher_entropy": 0.4456840455532074, "time": 0.02553105354309082}
{"epoch": 357, "reward_mean": 343.5, "student_loss": null, "teacher_policy_loss": -44.3366813659668, "teacher_value_loss": 829.4886474609375, "teacher_entropy": 0.4396879971027374, "time": 0.02488231658935547}
{"epoch": 358, "reward_mean": 425.0, "student_loss": null, "teacher_policy_loss": -66.22833251953125, "teacher_value_loss": 525.057861328125, "teacher_entropy": 0.4439903497695923, "time": 0.030745744705200195}
{"epoch": 359, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -54.990535736083984, "teacher_value_loss": 533.3549194335938, "teacher_entropy": 0.44701087474823, "time": 0.014539003372192383}
{"epoch": 360, "reward_mean": 369.0, "student_loss": null, "teacher_policy_loss": -58.14910125732422, "teacher_value_loss": 726.976318359375, "teacher_entropy": 0.4343978762626648, "time": 0.03697538375854492}
{"epoch": 361, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -49.916629791259766, "teacher_value_loss": 453.5917663574219, "teacher_entropy": 0.4220884442329407, "time": 0.022484540939331055}
{"epoch": 362, "reward_mean": 436.0, "student_loss": null, "teacher_policy_loss": -43.96434020996094, "teacher_value_loss": 494.2298583984375, "teacher_entropy": 0.4239870309829712, "time": 0.05695033073425293}
{"epoch": 363, "reward_mean": 413.0, "student_loss": null, "teacher_policy_loss": -43.2121467590332, "teacher_value_loss": 428.6528015136719, "teacher_entropy": 0.4085526764392853, "time": 0.018066883087158203}
{"epoch": 364, "reward_mean": 360.0, "student_loss": null, "teacher_policy_loss": -46.394737243652344, "teacher_value_loss": 333.5318603515625, "teacher_entropy": 0.4141300618648529, "time": 0.014664411544799805}
{"epoch": 365, "reward_mean": 239.0, "student_loss": null, "teacher_policy_loss": -32.73582077026367, "teacher_value_loss": 225.77120971679688, "teacher_entropy": 0.4192698001861572, "time": 0.046489715576171875}
{"epoch": 366, "reward_mean": 254.5, "student_loss": null, "teacher_policy_loss": -35.93345260620117, "teacher_value_loss": 353.3453369140625, "teacher_entropy": 0.42123520374298096, "time": 0.028948068618774414}
{"epoch": 367, "reward_mean": 270.0, "student_loss": null, "teacher_policy_loss": -44.65619659423828, "teacher_value_loss": 238.1871337890625, "teacher_entropy": 0.4277147650718689, "time": 0.012691497802734375}
{"epoch": 368, "reward_mean": 224.0, "student_loss": null, "teacher_policy_loss": -35.47409439086914, "teacher_value_loss": 300.8974304199219, "teacher_entropy": 0.4305218756198883, "time": 0.011115074157714844}
{"epoch": 369, "reward_mean": 229.0, "student_loss": null, "teacher_policy_loss": -36.80473327636719, "teacher_value_loss": 278.6412048339844, "teacher_entropy": 0.43187329173088074, "time": 0.017781496047973633}
{"epoch": 370, "reward_mean": 172.0, "student_loss": null, "teacher_policy_loss": -32.05292892456055, "teacher_value_loss": 156.41522216796875, "teacher_entropy": 0.43327295780181885, "time": 0.013480901718139648}
{"epoch": 371, "reward_mean": 199.0, "student_loss": null, "teacher_policy_loss": -35.531471252441406, "teacher_value_loss": 196.5779266357422, "teacher_entropy": 0.41179341077804565, "time": 0.023993492126464844}
{"epoch": 372, "reward_mean": 202.0, "student_loss": null, "teacher_policy_loss": -33.965904235839844, "teacher_value_loss": 123.45685577392578, "teacher_entropy": 0.40765583515167236, "time": 0.043157339096069336}
{"epoch": 373, "reward_mean": 208.5, "student_loss": null, "teacher_policy_loss": -34.81782913208008, "teacher_value_loss": 221.8597412109375, "teacher_entropy": 0.4179714620113373, "time": 0.014290571212768555}
{"epoch": 374, "reward_mean": 217.0, "student_loss": null, "teacher_policy_loss": -34.326053619384766, "teacher_value_loss": 285.11004638671875, "teacher_entropy": 0.4307843744754791, "time": 0.01845407485961914}
{"epoch": 375, "reward_mean": 202.0, "student_loss": null, "teacher_policy_loss": -33.721954345703125, "teacher_value_loss": 278.1619567871094, "teacher_entropy": 0.42074573040008545, "time": 0.010847806930541992}
{"epoch": 376, "reward_mean": 228.5, "student_loss": null, "teacher_policy_loss": -35.286781311035156, "teacher_value_loss": 356.48114013671875, "teacher_entropy": 0.3961555063724518, "time": 0.02020549774169922}
{"epoch": 377, "reward_mean": 180.5, "student_loss": null, "teacher_policy_loss": -32.84019470214844, "teacher_value_loss": 353.7402038574219, "teacher_entropy": 0.3962494134902954, "time": 0.16402864456176758}
{"epoch": 378, "reward_mean": 150.0, "student_loss": null, "teacher_policy_loss": -35.36090850830078, "teacher_value_loss": 297.1305236816406, "teacher_entropy": 0.3970964848995209, "time": 0.010897636413574219}
{"epoch": 379, "reward_mean": 242.5, "student_loss": null, "teacher_policy_loss": -37.219566345214844, "teacher_value_loss": 269.1763610839844, "teacher_entropy": 0.423715740442276, "time": 0.03832602500915527}
{"epoch": 380, "reward_mean": 189.0, "student_loss": null, "teacher_policy_loss": -40.123619079589844, "teacher_value_loss": 419.113525390625, "teacher_entropy": 0.40559786558151245, "time": 0.03409409523010254}
{"epoch": 381, "reward_mean": 259.0, "student_loss": null, "teacher_policy_loss": -46.37370681762695, "teacher_value_loss": 323.1205139160156, "teacher_entropy": 0.404424786567688, "time": 0.026476144790649414}
{"epoch": 382, "reward_mean": 290.5, "student_loss": null, "teacher_policy_loss": -34.943077087402344, "teacher_value_loss": 574.433837890625, "teacher_entropy": 0.40540584921836853, "time": 0.0223388671875}
{"epoch": 383, "reward_mean": 227.5, "student_loss": null, "teacher_policy_loss": -39.75861358642578, "teacher_value_loss": 306.23077392578125, "teacher_entropy": 0.39896515011787415, "time": 0.013178825378417969}
{"epoch": 384, "reward_mean": 173.0, "student_loss": null, "teacher_policy_loss": -45.994049072265625, "teacher_value_loss": 260.30010986328125, "teacher_entropy": 0.41084933280944824, "time": 0.01420736312866211}
{"epoch": 385, "reward_mean": 236.5, "student_loss": null, "teacher_policy_loss": -30.727354049682617, "teacher_value_loss": 372.1580810546875, "teacher_entropy": 0.4014870822429657, "time": 0.034713029861450195}
{"epoch": 386, "reward_mean": 240.5, "student_loss": null, "teacher_policy_loss": -34.94781494140625, "teacher_value_loss": 437.1463317871094, "teacher_entropy": 0.4111860990524292, "time": 0.01127314567565918}
{"epoch": 387, "reward_mean": 239.5, "student_loss": null, "teacher_policy_loss": -40.23687744140625, "teacher_value_loss": 207.80633544921875, "teacher_entropy": 0.3973088562488556, "time": 0.01143336296081543}
{"epoch": 388, "reward_mean": 226.0, "student_loss": null, "teacher_policy_loss": -44.045799255371094, "teacher_value_loss": 167.51876831054688, "teacher_entropy": 0.41355904936790466, "time": 0.013698816299438477}
{"epoch": 389, "reward_mean": 195.5, "student_loss": null, "teacher_policy_loss": -36.42551803588867, "teacher_value_loss": 114.0874252319336, "teacher_entropy": 0.4014360010623932, "time": 0.017275333404541016}
{"epoch": 390, "reward_mean": 204.5, "student_loss": null, "teacher_policy_loss": -38.51554870605469, "teacher_value_loss": 43.593589782714844, "teacher_entropy": 0.4037223756313324, "time": 0.03312420845031738}
{"epoch": 391, "reward_mean": 180.33333333333334, "student_loss": null, "teacher_policy_loss": -32.559814453125, "teacher_value_loss": 415.59295654296875, "teacher_entropy": 0.41277608275413513, "time": 0.026362180709838867}
{"epoch": 392, "reward_mean": 120.66666666666667, "student_loss": null, "teacher_policy_loss": -22.196481704711914, "teacher_value_loss": 576.4586791992188, "teacher_entropy": 0.3961073160171509, "time": 0.017827987670898438}
{"epoch": 393, "reward_mean": 149.33333333333334, "student_loss": null, "teacher_policy_loss": -26.16250228881836, "teacher_value_loss": 330.3853759765625, "teacher_entropy": 0.40755695104599, "time": 0.01855611801147461}
{"epoch": 394, "reward_mean": 120.0, "student_loss": null, "teacher_policy_loss": -22.695451736450195, "teacher_value_loss": 427.1569519042969, "teacher_entropy": 0.40915071964263916, "time": 0.012654781341552734}
{"epoch": 395, "reward_mean": 104.0, "student_loss": null, "teacher_policy_loss": -16.1301326751709, "teacher_value_loss": 559.4624633789062, "teacher_entropy": 0.39744117856025696, "time": 0.039040327072143555}
{"epoch": 396, "reward_mean": 93.0, "student_loss": null, "teacher_policy_loss": -18.849788665771484, "teacher_value_loss": 517.050537109375, "teacher_entropy": 0.3870351016521454, "time": 0.025011062622070312}
{"epoch": 397, "reward_mean": 96.75, "student_loss": null, "teacher_policy_loss": -18.912208557128906, "teacher_value_loss": 453.6891784667969, "teacher_entropy": 0.3916287124156952, "time": 0.01380777359008789}
{"epoch": 398, "reward_mean": 111.0, "student_loss": null, "teacher_policy_loss": -18.845834732055664, "teacher_value_loss": 288.2798767089844, "teacher_entropy": 0.37767302989959717, "time": 0.011811494827270508}
{"epoch": 399, "reward_mean": 106.0, "student_loss": null, "teacher_policy_loss": -15.563652038574219, "teacher_value_loss": 233.7293701171875, "teacher_entropy": 0.32353174686431885, "time": 0.011081695556640625}
{"epoch": 400, "reward_mean": 114.0, "student_loss": null, "teacher_policy_loss": -21.157941818237305, "teacher_value_loss": 96.73258972167969, "teacher_entropy": 0.34255051612854004, "time": 0.020818471908569336}
{"epoch": 401, "reward_mean": 94.8, "student_loss": null, "teacher_policy_loss": -11.258414268493652, "teacher_value_loss": 302.3858642578125, "teacher_entropy": 0.32226431369781494, "time": 0.03846144676208496}
{"epoch": 402, "reward_mean": 107.33333333333333, "student_loss": null, "teacher_policy_loss": -19.85870933532715, "teacher_value_loss": 52.854244232177734, "teacher_entropy": 0.32057181000709534, "time": 0.021023273468017578}
{"epoch": 403, "reward_mean": 105.25, "student_loss": null, "teacher_policy_loss": -14.857091903686523, "teacher_value_loss": 79.36190795898438, "teacher_entropy": 0.31897372007369995, "time": 0.012138843536376953}
{"epoch": 404, "reward_mean": 88.5, "student_loss": null, "teacher_policy_loss": -20.131275177001953, "teacher_value_loss": 278.1705017089844, "teacher_entropy": 0.3428581953048706, "time": 0.013911008834838867}
{"epoch": 405, "reward_mean": 99.4, "student_loss": null, "teacher_policy_loss": -18.465835571289062, "teacher_value_loss": 224.30055236816406, "teacher_entropy": 0.3906223773956299, "time": 0.017087221145629883}
{"epoch": 406, "reward_mean": 102.0, "student_loss": null, "teacher_policy_loss": -16.19074249267578, "teacher_value_loss": 61.46363830566406, "teacher_entropy": 0.3748777508735657, "time": 0.01790761947631836}
{"epoch": 407, "reward_mean": 92.0, "student_loss": null, "teacher_policy_loss": -17.738021850585938, "teacher_value_loss": 221.64674377441406, "teacher_entropy": 0.39993518590927124, "time": 0.022589445114135742}
{"epoch": 408, "reward_mean": 113.0, "student_loss": null, "teacher_policy_loss": -21.913618087768555, "teacher_value_loss": 55.317691802978516, "teacher_entropy": 0.40214455127716064, "time": 0.01917099952697754}
{"epoch": 409, "reward_mean": 95.75, "student_loss": null, "teacher_policy_loss": -23.278928756713867, "teacher_value_loss": 225.87303161621094, "teacher_entropy": 0.43094390630722046, "time": 0.019423246383666992}
{"epoch": 410, "reward_mean": 117.75, "student_loss": null, "teacher_policy_loss": -21.474699020385742, "teacher_value_loss": 109.15376281738281, "teacher_entropy": 0.4237413704395294, "time": 0.018669843673706055}
{"epoch": 411, "reward_mean": 133.33333333333334, "student_loss": null, "teacher_policy_loss": -24.455949783325195, "teacher_value_loss": 155.85557556152344, "teacher_entropy": 0.40112531185150146, "time": 0.01828145980834961}
{"epoch": 412, "reward_mean": 120.0, "student_loss": null, "teacher_policy_loss": -24.36516571044922, "teacher_value_loss": 85.34392547607422, "teacher_entropy": 0.4156535267829895, "time": 0.021837234497070312}
{"epoch": 413, "reward_mean": 131.33333333333334, "student_loss": null, "teacher_policy_loss": -25.38207244873047, "teacher_value_loss": 105.63068389892578, "teacher_entropy": 0.4073851704597473, "time": 0.02300548553466797}
{"epoch": 414, "reward_mean": 120.75, "student_loss": null, "teacher_policy_loss": -19.862071990966797, "teacher_value_loss": 115.83624267578125, "teacher_entropy": 0.40431469678878784, "time": 0.01172327995300293}
{"epoch": 415, "reward_mean": 161.0, "student_loss": null, "teacher_policy_loss": -32.13118362426758, "teacher_value_loss": 162.71353149414062, "teacher_entropy": 0.4111383557319641, "time": 0.011615514755249023}
{"epoch": 416, "reward_mean": 160.0, "student_loss": null, "teacher_policy_loss": -32.097877502441406, "teacher_value_loss": 249.2211456298828, "teacher_entropy": 0.39916324615478516, "time": 0.018293142318725586}
{"epoch": 417, "reward_mean": 174.0, "student_loss": null, "teacher_policy_loss": -25.586484909057617, "teacher_value_loss": 372.23480224609375, "teacher_entropy": 0.39923644065856934, "time": 0.014842748641967773}
{"epoch": 418, "reward_mean": 214.0, "student_loss": null, "teacher_policy_loss": -36.806640625, "teacher_value_loss": 330.9457092285156, "teacher_entropy": 0.4002644419670105, "time": 0.02130579948425293}
{"epoch": 419, "reward_mean": 202.0, "student_loss": null, "teacher_policy_loss": -43.00767517089844, "teacher_value_loss": 374.997802734375, "teacher_entropy": 0.4070172905921936, "time": 0.013942241668701172}
{"epoch": 420, "reward_mean": 243.0, "student_loss": null, "teacher_policy_loss": -36.54423904418945, "teacher_value_loss": 307.8653564453125, "teacher_entropy": 0.3948146104812622, "time": 0.01716136932373047}
{"epoch": 421, "reward_mean": 236.5, "student_loss": null, "teacher_policy_loss": -36.24586868286133, "teacher_value_loss": 377.5556640625, "teacher_entropy": 0.41736698150634766, "time": 0.019693374633789062}
{"epoch": 422, "reward_mean": 273.0, "student_loss": null, "teacher_policy_loss": -43.12775421142578, "teacher_value_loss": 184.48638916015625, "teacher_entropy": 0.3947916030883789, "time": 0.03137850761413574}
{"epoch": 423, "reward_mean": 236.5, "student_loss": null, "teacher_policy_loss": -35.072322845458984, "teacher_value_loss": 408.157470703125, "teacher_entropy": 0.4097585678100586, "time": 0.01994609832763672}
{"epoch": 424, "reward_mean": 287.0, "student_loss": null, "teacher_policy_loss": -43.59968566894531, "teacher_value_loss": 304.446533203125, "teacher_entropy": 0.4060215651988983, "time": 0.029561281204223633}
{"epoch": 425, "reward_mean": 352.0, "student_loss": null, "teacher_policy_loss": -44.21513366699219, "teacher_value_loss": 184.4280242919922, "teacher_entropy": 0.3858044743537903, "time": 0.03924250602722168}
{"epoch": 426, "reward_mean": 246.0, "student_loss": null, "teacher_policy_loss": -42.66170883178711, "teacher_value_loss": 438.886474609375, "teacher_entropy": 0.4178429841995239, "time": 0.012264251708984375}
{"epoch": 427, "reward_mean": 422.0, "student_loss": null, "teacher_policy_loss": -41.553897857666016, "teacher_value_loss": 231.73114013671875, "teacher_entropy": 0.39480412006378174, "time": 0.009878873825073242}
{"epoch": 428, "reward_mean": 247.0, "student_loss": null, "teacher_policy_loss": -47.12648391723633, "teacher_value_loss": 333.69793701171875, "teacher_entropy": 0.3841792643070221, "time": 0.0165560245513916}
{"epoch": 429, "reward_mean": 287.0, "student_loss": null, "teacher_policy_loss": -30.61731719970703, "teacher_value_loss": 589.0095825195312, "teacher_entropy": 0.3900502324104309, "time": 0.0815587043762207}
{"epoch": 430, "reward_mean": 291.0, "student_loss": null, "teacher_policy_loss": -45.63819885253906, "teacher_value_loss": 494.940185546875, "teacher_entropy": 0.40653935074806213, "time": 0.015416860580444336}
{"epoch": 431, "reward_mean": 344.0, "student_loss": null, "teacher_policy_loss": -47.16001892089844, "teacher_value_loss": 359.1182861328125, "teacher_entropy": 0.40782588720321655, "time": 0.016529083251953125}
{"epoch": 432, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -46.023963928222656, "teacher_value_loss": 408.342041015625, "teacher_entropy": 0.4121452271938324, "time": 0.009953975677490234}
{"epoch": 433, "reward_mean": 282.0, "student_loss": null, "teacher_policy_loss": -49.313575744628906, "teacher_value_loss": 496.662353515625, "teacher_entropy": 0.39756956696510315, "time": 0.016706466674804688}
{"epoch": 434, "reward_mean": 337.0, "student_loss": null, "teacher_policy_loss": -59.417423248291016, "teacher_value_loss": 402.5332946777344, "teacher_entropy": 0.4142970144748688, "time": 0.02099156379699707}
{"epoch": 435, "reward_mean": 366.0, "student_loss": null, "teacher_policy_loss": -39.864036560058594, "teacher_value_loss": 494.8192138671875, "teacher_entropy": 0.40712273120880127, "time": 0.015245676040649414}
{"epoch": 436, "reward_mean": 303.0, "student_loss": null, "teacher_policy_loss": -44.64894104003906, "teacher_value_loss": 376.0209045410156, "teacher_entropy": 0.4142397344112396, "time": 0.02659440040588379}
{"epoch": 437, "reward_mean": 262.0, "student_loss": null, "teacher_policy_loss": -46.23277282714844, "teacher_value_loss": 315.8332824707031, "teacher_entropy": 0.420481413602829, "time": 0.016717910766601562}
{"epoch": 438, "reward_mean": 305.0, "student_loss": null, "teacher_policy_loss": -58.83855438232422, "teacher_value_loss": 789.4776611328125, "teacher_entropy": 0.42119789123535156, "time": 0.012584209442138672}
{"epoch": 439, "reward_mean": 499.0, "student_loss": null, "teacher_policy_loss": -46.90933609008789, "teacher_value_loss": 345.8863220214844, "teacher_entropy": 0.4090791642665863, "time": 0.017998218536376953}
{"epoch": 440, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -47.12294387817383, "teacher_value_loss": 528.5908813476562, "teacher_entropy": 0.4088748097419739, "time": 0.01927018165588379}
{"epoch": 441, "reward_mean": 245.0, "student_loss": null, "teacher_policy_loss": -49.51579284667969, "teacher_value_loss": 431.40972900390625, "teacher_entropy": 0.4106484353542328, "time": 0.0626835823059082}
{"epoch": 442, "reward_mean": 342.0, "student_loss": null, "teacher_policy_loss": -59.350425720214844, "teacher_value_loss": 463.73162841796875, "teacher_entropy": 0.4025146961212158, "time": 0.0173490047454834}
{"epoch": 443, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -49.35222625732422, "teacher_value_loss": 296.7565612792969, "teacher_entropy": 0.39908942580223083, "time": 0.025913476943969727}
{"epoch": 444, "reward_mean": 362.0, "student_loss": null, "teacher_policy_loss": -51.77412414550781, "teacher_value_loss": 393.16656494140625, "teacher_entropy": 0.41033536195755005, "time": 0.13232207298278809}
{"epoch": 445, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -47.743316650390625, "teacher_value_loss": 592.2797241210938, "teacher_entropy": 0.4029667377471924, "time": 0.011908769607543945}
{"epoch": 446, "reward_mean": 348.0, "student_loss": null, "teacher_policy_loss": -46.9553108215332, "teacher_value_loss": 275.3408508300781, "teacher_entropy": 0.41849052906036377, "time": 0.0316469669342041}
{"epoch": 447, "reward_mean": 465.0, "student_loss": null, "teacher_policy_loss": -43.50205993652344, "teacher_value_loss": 505.4924621582031, "teacher_entropy": 0.4082781672477722, "time": 0.013054847717285156}
{"epoch": 448, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -50.324642181396484, "teacher_value_loss": 496.7314147949219, "teacher_entropy": 0.41508010029792786, "time": 0.019815444946289062}
{"epoch": 449, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -61.1776237487793, "teacher_value_loss": 637.5411987304688, "teacher_entropy": 0.4107706546783447, "time": 0.016839265823364258}
{"epoch": 450, "reward_mean": 356.0, "student_loss": null, "teacher_policy_loss": -49.981590270996094, "teacher_value_loss": 572.079345703125, "teacher_entropy": 0.4139566719532013, "time": 0.018105268478393555}
{"epoch": 451, "reward_mean": 213.0, "student_loss": null, "teacher_policy_loss": -46.44231414794922, "teacher_value_loss": 423.4663391113281, "teacher_entropy": 0.41210660338401794, "time": 0.017940998077392578}
{"epoch": 452, "reward_mean": 249.0, "student_loss": null, "teacher_policy_loss": -63.463985443115234, "teacher_value_loss": 336.7401123046875, "teacher_entropy": 0.42196881771087646, "time": 0.02124190330505371}
{"epoch": 453, "reward_mean": 383.5, "student_loss": null, "teacher_policy_loss": -43.41819381713867, "teacher_value_loss": 771.062255859375, "teacher_entropy": 0.42440304160118103, "time": 0.010970830917358398}
{"epoch": 454, "reward_mean": 351.0, "student_loss": null, "teacher_policy_loss": -48.966705322265625, "teacher_value_loss": 560.0659790039062, "teacher_entropy": 0.4046882390975952, "time": 0.019621849060058594}
{"epoch": 455, "reward_mean": 252.0, "student_loss": null, "teacher_policy_loss": -44.288734436035156, "teacher_value_loss": 731.068115234375, "teacher_entropy": 0.4214394688606262, "time": 0.013092756271362305}
{"epoch": 456, "reward_mean": 460.0, "student_loss": null, "teacher_policy_loss": -45.20195388793945, "teacher_value_loss": 541.846435546875, "teacher_entropy": 0.4095117449760437, "time": 0.01671576499938965}
{"epoch": 457, "reward_mean": 302.0, "student_loss": null, "teacher_policy_loss": -46.03062057495117, "teacher_value_loss": 630.1541137695312, "teacher_entropy": 0.42656758427619934, "time": 0.014461278915405273}
{"epoch": 458, "reward_mean": 381.0, "student_loss": null, "teacher_policy_loss": -48.660797119140625, "teacher_value_loss": 469.96600341796875, "teacher_entropy": 0.4160003662109375, "time": 0.021306276321411133}
{"epoch": 459, "reward_mean": 369.0, "student_loss": null, "teacher_policy_loss": -49.94978332519531, "teacher_value_loss": 274.1724548339844, "teacher_entropy": 0.41021332144737244, "time": -1.4327328205108643}
{"epoch": 460, "reward_mean": 495.0, "student_loss": null, "teacher_policy_loss": -44.520294189453125, "teacher_value_loss": 413.9517822265625, "teacher_entropy": 0.41879644989967346, "time": 0.01399087905883789}
{"epoch": 461, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -51.976463317871094, "teacher_value_loss": 497.12518310546875, "teacher_entropy": 0.42464691400527954, "time": 0.011046171188354492}
{"epoch": 462, "reward_mean": 362.0, "student_loss": null, "teacher_policy_loss": -44.579891204833984, "teacher_value_loss": 448.6493225097656, "teacher_entropy": 0.40723365545272827, "time": 0.02449941635131836}
{"epoch": 463, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -55.18378829956055, "teacher_value_loss": 642.6944580078125, "teacher_entropy": 0.4160032570362091, "time": 0.022701740264892578}
{"epoch": 464, "reward_mean": 365.0, "student_loss": null, "teacher_policy_loss": -47.46353530883789, "teacher_value_loss": 607.5020141601562, "teacher_entropy": 0.40282127261161804, "time": 0.01911783218383789}
{"epoch": 465, "reward_mean": 493.0, "student_loss": null, "teacher_policy_loss": -63.2482795715332, "teacher_value_loss": 822.8297119140625, "teacher_entropy": 0.40829765796661377, "time": 0.04425191879272461}
{"epoch": 466, "reward_mean": 445.5, "student_loss": null, "teacher_policy_loss": -57.544532775878906, "teacher_value_loss": 555.8069458007812, "teacher_entropy": 0.400948703289032, "time": 0.010771989822387695}
{"epoch": 467, "reward_mean": 402.0, "student_loss": null, "teacher_policy_loss": -64.7049560546875, "teacher_value_loss": 541.7025756835938, "teacher_entropy": 0.40483444929122925, "time": 0.12677931785583496}
{"epoch": 468, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -51.6032829284668, "teacher_value_loss": 475.2490539550781, "teacher_entropy": 0.40828049182891846, "time": 0.027466773986816406}
{"epoch": 469, "reward_mean": 407.0, "student_loss": null, "teacher_policy_loss": -48.34526443481445, "teacher_value_loss": 294.379150390625, "teacher_entropy": 0.4048866629600525, "time": 0.01977682113647461}
{"epoch": 470, "reward_mean": 305.0, "student_loss": null, "teacher_policy_loss": -41.350868225097656, "teacher_value_loss": 843.60498046875, "teacher_entropy": 0.39663371443748474, "time": 0.01791214942932129}
{"epoch": 471, "reward_mean": 383.0, "student_loss": null, "teacher_policy_loss": -47.11589431762695, "teacher_value_loss": 396.328369140625, "teacher_entropy": 0.3993319571018219, "time": 0.012636184692382812}
{"epoch": 472, "reward_mean": 269.0, "student_loss": null, "teacher_policy_loss": -44.701480865478516, "teacher_value_loss": 437.28936767578125, "teacher_entropy": 0.38008415699005127, "time": 0.03235173225402832}
{"epoch": 473, "reward_mean": 441.0, "student_loss": null, "teacher_policy_loss": -43.962425231933594, "teacher_value_loss": 442.0260009765625, "teacher_entropy": 0.4050227701663971, "time": 0.01182413101196289}
{"epoch": 474, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -52.86980056762695, "teacher_value_loss": 494.5816345214844, "teacher_entropy": 0.39404717087745667, "time": 0.013025999069213867}
{"epoch": 475, "reward_mean": 350.0, "student_loss": null, "teacher_policy_loss": -43.43345642089844, "teacher_value_loss": 601.6900634765625, "teacher_entropy": 0.3912942409515381, "time": 0.01230931282043457}
{"epoch": 476, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -55.802528381347656, "teacher_value_loss": 644.7741088867188, "teacher_entropy": 0.3800831735134125, "time": 0.02379608154296875}
{"epoch": 477, "reward_mean": 173.0, "student_loss": null, "teacher_policy_loss": -44.638763427734375, "teacher_value_loss": 324.9956359863281, "teacher_entropy": 0.3852529227733612, "time": 0.012700319290161133}
{"epoch": 478, "reward_mean": 260.0, "student_loss": null, "teacher_policy_loss": -43.06112289428711, "teacher_value_loss": 348.88702392578125, "teacher_entropy": 0.3797977864742279, "time": 0.02208089828491211}
{"epoch": 479, "reward_mean": 354.0, "student_loss": null, "teacher_policy_loss": -42.58743667602539, "teacher_value_loss": 256.88623046875, "teacher_entropy": 0.37827441096305847, "time": 0.05401945114135742}
{"epoch": 480, "reward_mean": 257.0, "student_loss": null, "teacher_policy_loss": -53.7230110168457, "teacher_value_loss": 547.6843872070312, "teacher_entropy": 0.38808348774909973, "time": 0.013940811157226562}
{"epoch": 481, "reward_mean": 351.0, "student_loss": null, "teacher_policy_loss": -59.61363220214844, "teacher_value_loss": 452.1937561035156, "teacher_entropy": 0.3782130479812622, "time": 0.01814126968383789}
{"epoch": 482, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -51.046913146972656, "teacher_value_loss": 417.1173400878906, "teacher_entropy": 0.36454978585243225, "time": 0.025548219680786133}
{"epoch": 483, "reward_mean": 438.0, "student_loss": null, "teacher_policy_loss": -42.791656494140625, "teacher_value_loss": 503.9259338378906, "teacher_entropy": 0.38141930103302, "time": 0.01982855796813965}
{"epoch": 484, "reward_mean": 437.0, "student_loss": null, "teacher_policy_loss": -39.945594787597656, "teacher_value_loss": 552.4252319335938, "teacher_entropy": 0.37254342436790466, "time": 0.01513528823852539}
{"epoch": 485, "reward_mean": 300.0, "student_loss": null, "teacher_policy_loss": -39.667171478271484, "teacher_value_loss": 379.8328857421875, "teacher_entropy": 0.37532883882522583, "time": 0.024274349212646484}
{"epoch": 486, "reward_mean": 412.0, "student_loss": null, "teacher_policy_loss": -59.611602783203125, "teacher_value_loss": 786.98291015625, "teacher_entropy": 0.3618605136871338, "time": 0.017654895782470703}
{"epoch": 487, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -49.55079650878906, "teacher_value_loss": 858.0446166992188, "teacher_entropy": 0.37377607822418213, "time": 0.020305395126342773}
{"epoch": 488, "reward_mean": 498.0, "student_loss": null, "teacher_policy_loss": -35.8269157409668, "teacher_value_loss": 962.4166259765625, "teacher_entropy": 0.3865659832954407, "time": 0.020604372024536133}
{"epoch": 489, "reward_mean": 319.0, "student_loss": null, "teacher_policy_loss": -43.62480926513672, "teacher_value_loss": 351.5713195800781, "teacher_entropy": 0.37662073969841003, "time": 0.021121978759765625}
{"epoch": 490, "reward_mean": 331.5, "student_loss": null, "teacher_policy_loss": -34.27424621582031, "teacher_value_loss": 949.7491455078125, "teacher_entropy": 0.37348443269729614, "time": 0.013467550277709961}
{"epoch": 491, "reward_mean": 319.0, "student_loss": null, "teacher_policy_loss": -39.13047790527344, "teacher_value_loss": 449.5417175292969, "teacher_entropy": 0.3741716146469116, "time": 0.020906925201416016}
{"epoch": 492, "reward_mean": 317.0, "student_loss": null, "teacher_policy_loss": -37.48981857299805, "teacher_value_loss": 241.7300567626953, "teacher_entropy": 0.37385958433151245, "time": 0.010864734649658203}
{"epoch": 493, "reward_mean": 351.0, "student_loss": null, "teacher_policy_loss": -38.61188888549805, "teacher_value_loss": 180.1953582763672, "teacher_entropy": 0.36982661485671997, "time": 0.013660192489624023}
{"epoch": 494, "reward_mean": 346.0, "student_loss": null, "teacher_policy_loss": -43.020530700683594, "teacher_value_loss": 494.31781005859375, "teacher_entropy": 0.3854529559612274, "time": 0.029414653778076172}
{"epoch": 495, "reward_mean": 327.0, "student_loss": null, "teacher_policy_loss": -40.42185592651367, "teacher_value_loss": 914.1234130859375, "teacher_entropy": 0.36620503664016724, "time": 0.012772083282470703}
{"epoch": 496, "reward_mean": 445.0, "student_loss": null, "teacher_policy_loss": -57.8213005065918, "teacher_value_loss": 751.1365356445312, "teacher_entropy": 0.3649906814098358, "time": 0.021749496459960938}
{"epoch": 497, "reward_mean": 500.0, "student_loss": null, "teacher_policy_loss": -54.18974685668945, "teacher_value_loss": 865.4071655273438, "teacher_entropy": 0.3738614022731781, "time": 0.01957988739013672}
{"epoch": 498, "reward_mean": 497.0, "student_loss": null, "teacher_policy_loss": -40.625755310058594, "teacher_value_loss": 1238.3336181640625, "teacher_entropy": 0.3675207197666168, "time": 0.013715982437133789}
{"epoch": 499, "reward_mean": 292.0, "student_loss": null, "teacher_policy_loss": -29.357505798339844, "teacher_value_loss": 1380.6048583984375, "teacher_entropy": 0.3758488893508911, "time": 0.02649402618408203}
{"epoch": 500, "reward_mean": 377.0, "student_loss": null, "teacher_policy_loss": -42.34503936767578, "teacher_value_loss": 1204.8631591796875, "teacher_entropy": 0.3676610589027405, "time": 0.021056175231933594}
