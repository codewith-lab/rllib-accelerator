{"epoch": 1, "reward_mean": 21.275862068965516, "student_loss": null, "teacher_policy_loss": -12.078254699707031, "teacher_value_loss": 277.6702880859375, "teacher_entropy": 0.6255688667297363, "total_time": 1.4502320289611816, "rollout_time": 0.4752023220062256, "train_time": 0.9277043342590332, "student_train_time": 0.046952247619628906, "throughput": 1379.089662936643, "inference_time": 0.07035220472607762, "env_time": 0.40485011728014797, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 2, "reward_mean": 28.106666666666666, "student_loss": null, "teacher_policy_loss": -13.560335159301758, "teacher_value_loss": 226.98391723632812, "teacher_entropy": 0.5238751769065857, "total_time": 1.278172492980957, "rollout_time": 0.48004698753356934, "train_time": 0.7814009189605713, "student_train_time": 0.01633453369140625, "throughput": 1564.734033147275, "inference_time": 0.072081589991285, "env_time": 0.40796539754228434, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 3, "reward_mean": 24.9375, "student_loss": null, "teacher_policy_loss": -13.760320663452148, "teacher_value_loss": 145.56040954589844, "teacher_entropy": 0.6339792013168335, "total_time": 1.426520824432373, "rollout_time": 0.47162580490112305, "train_time": 0.9252517223358154, "student_train_time": 0.029277563095092773, "throughput": 1402.01248081732, "inference_time": 0.07041844976629363, "env_time": 0.4012073551348294, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 4, "reward_mean": 25.367088607594937, "student_loss": null, "teacher_policy_loss": -9.30810546875, "teacher_value_loss": 161.39846801757812, "teacher_entropy": 0.14201247692108154, "total_time": 1.481421709060669, "rollout_time": 0.5304751396179199, "train_time": 0.9332242012023926, "student_train_time": 0.01731276512145996, "throughput": 1350.0544698161254, "inference_time": 0.08054884175726329, "env_time": 0.44992629786065663, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 5, "reward_mean": 26.32894736842105, "student_loss": null, "teacher_policy_loss": -9.257258415222168, "teacher_value_loss": 140.9661865234375, "teacher_entropy": 0.035061195492744446, "total_time": 1.3890471458435059, "rollout_time": 0.4717593193054199, "train_time": 0.8993537425994873, "student_train_time": 0.01757359504699707, "throughput": 1439.835937883512, "inference_time": 0.06927600656854338, "env_time": 0.40248331273687654, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 6, "reward_mean": 25.864864864864863, "student_loss": null, "teacher_policy_loss": -8.711421012878418, "teacher_value_loss": 110.46126556396484, "teacher_entropy": 0.019129930064082146, "total_time": 1.4538133144378662, "rollout_time": 0.4765033721923828, "train_time": 0.9542186260223389, "student_train_time": 0.022708892822265625, "throughput": 1375.6924497374846, "inference_time": 0.06796587877215643, "env_time": 0.4085374934202264, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 7, "reward_mean": 35.872727272727275, "student_loss": null, "teacher_policy_loss": -11.994308471679688, "teacher_value_loss": 279.2612609863281, "teacher_entropy": 0.012061393819749355, "total_time": 1.2932369709014893, "rollout_time": 0.44707751274108887, "train_time": 0.8136851787567139, "student_train_time": 0.032114505767822266, "throughput": 1546.5069782267674, "inference_time": 0.06649192726035835, "env_time": 0.3805855854807305, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 8, "reward_mean": 34.672413793103445, "student_loss": null, "teacher_policy_loss": -11.323898315429688, "teacher_value_loss": 204.7298126220703, "teacher_entropy": 0.006247374229133129, "total_time": -1.2503039836883545, "rollout_time": -2.122851848602295, "train_time": 0.8522129058837891, "student_train_time": 0.019941329956054688, "throughput": 200000000000.0, "inference_time": 0.07017142947552202, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 9, "reward_mean": 31.28787878787879, "student_loss": null, "teacher_policy_loss": -9.718315124511719, "teacher_value_loss": 129.96092224121094, "teacher_entropy": 0.0024224123917520046, "total_time": 1.2938506603240967, "rollout_time": 0.45413970947265625, "train_time": 0.8193051815032959, "student_train_time": 0.020047426223754883, "throughput": 1545.7734507775572, "inference_time": 0.06898691175956628, "env_time": 0.38515279771308997, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 10, "reward_mean": 36.2962962962963, "student_loss": null, "teacher_policy_loss": -12.194988250732422, "teacher_value_loss": 213.2258758544922, "teacher_entropy": 0.0008855248452164233, "total_time": 1.4148080348968506, "rollout_time": 0.47448134422302246, "train_time": 0.916684627532959, "student_train_time": 0.0232241153717041, "throughput": 1413.6193396341673, "inference_time": 0.07374464923304913, "env_time": 0.40073669498997333, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 11, "reward_mean": 36.55357142857143, "student_loss": null, "teacher_policy_loss": -11.608163833618164, "teacher_value_loss": 195.0658721923828, "teacher_entropy": 0.0002369547582929954, "total_time": 1.301861047744751, "rollout_time": 0.463822603225708, "train_time": 0.8196690082550049, "student_train_time": 0.017954349517822266, "throughput": 1536.2622635224043, "inference_time": 0.0667229642822349, "env_time": 0.3970996389434731, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 12, "reward_mean": 34.13559322033898, "student_loss": null, "teacher_policy_loss": -10.79757022857666, "teacher_value_loss": 201.16212463378906, "teacher_entropy": 0.00011433742474764585, "total_time": 1.4102630615234375, "rollout_time": 0.4697086811065674, "train_time": 0.9112708568572998, "student_train_time": 0.028849363327026367, "throughput": 1418.1751295673155, "inference_time": 0.0694773782233824, "env_time": 0.400231302883185, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 13, "reward_mean": 38.92, "student_loss": null, "teacher_policy_loss": -12.001230239868164, "teacher_value_loss": 213.03567504882812, "teacher_entropy": 9.321974357590079e-05, "total_time": 1.2887566089630127, "rollout_time": 0.4609959125518799, "train_time": 0.8040890693664551, "student_train_time": 0.023194551467895508, "throughput": 1551.883409241473, "inference_time": 0.07173803596560901, "env_time": 0.38925787658627087, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 14, "reward_mean": 41.833333333333336, "student_loss": null, "teacher_policy_loss": -14.049263954162598, "teacher_value_loss": 311.3955078125, "teacher_entropy": 0.0001343576586805284, "total_time": 1.2627801895141602, "rollout_time": 0.45035219192504883, "train_time": 0.7850158214569092, "student_train_time": 0.026915788650512695, "throughput": 1583.8069179478312, "inference_time": 0.06867683271593705, "env_time": 0.3816753592091118, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 15, "reward_mean": 44.93333333333333, "student_loss": null, "teacher_policy_loss": -13.97581672668457, "teacher_value_loss": 270.49639892578125, "teacher_entropy": 0.0002423224359517917, "total_time": 1.2967257499694824, "rollout_time": 0.4647998809814453, "train_time": 0.8001382350921631, "student_train_time": 0.03136086463928223, "throughput": 1542.346174622559, "inference_time": 0.06875149221559695, "env_time": 0.39604838876584836, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 16, "reward_mean": 37.51020408163265, "student_loss": null, "teacher_policy_loss": -13.39040470123291, "teacher_value_loss": 277.2745056152344, "teacher_entropy": 0.00030544836772605777, "total_time": 1.2449793815612793, "rollout_time": 0.465651273727417, "train_time": 0.7645740509033203, "student_train_time": 0.014386177062988281, "throughput": 1606.452307259803, "inference_time": 0.06924231624907407, "env_time": 0.3964089574783429, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 17, "reward_mean": 43.92, "student_loss": null, "teacher_policy_loss": -13.529224395751953, "teacher_value_loss": 257.3644714355469, "teacher_entropy": 0.0002682704362086952, "total_time": 1.3937098979949951, "rollout_time": 0.4551730155944824, "train_time": 0.8984794616699219, "student_train_time": 0.03922152519226074, "throughput": 1435.0188678987067, "inference_time": 0.06686414015530318, "env_time": 0.38830887543917925, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 18, "reward_mean": 44.13333333333333, "student_loss": null, "teacher_policy_loss": -13.75485610961914, "teacher_value_loss": 247.4910430908203, "teacher_entropy": 0.00015693219029344618, "total_time": 1.2682561874389648, "rollout_time": 0.4502980709075928, "train_time": 0.7894856929779053, "student_train_time": 0.028093576431274414, "throughput": 1576.9684546453282, "inference_time": 0.0686455072118406, "env_time": 0.3816525636957522, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 19, "reward_mean": 44.93181818181818, "student_loss": null, "teacher_policy_loss": -14.775094985961914, "teacher_value_loss": 353.9111328125, "teacher_entropy": 0.00010143378312932327, "total_time": 1.3791892528533936, "rollout_time": 0.47764110565185547, "train_time": 0.8783323764801025, "student_train_time": 0.02284097671508789, "throughput": 1450.1273091145513, "inference_time": 0.07364365203102352, "env_time": 0.40399745362083195, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 20, "reward_mean": 37.76923076923077, "student_loss": null, "teacher_policy_loss": -11.063297271728516, "teacher_value_loss": 169.41024780273438, "teacher_entropy": 0.0001714589016046375, "total_time": 1.2916278839111328, "rollout_time": 0.4720330238342285, "train_time": 0.7991657257080078, "student_train_time": 0.02003765106201172, "throughput": 1548.4335890487828, "inference_time": 0.07110158473005868, "env_time": 0.40093143910416984, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 21, "reward_mean": 44.51111111111111, "student_loss": null, "teacher_policy_loss": -12.943411827087402, "teacher_value_loss": 176.06224060058594, "teacher_entropy": 0.0002816460037138313, "total_time": 1.2818551063537598, "rollout_time": 0.4713258743286133, "train_time": 0.7886102199554443, "student_train_time": 0.021459341049194336, "throughput": 1560.2387431205118, "inference_time": 0.07250564249261515, "env_time": 0.39882023183599813, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 22, "reward_mean": 55.861111111111114, "student_loss": null, "teacher_policy_loss": -15.735062599182129, "teacher_value_loss": 355.7259521484375, "teacher_entropy": 0.0007015263545326889, "total_time": 1.3560597896575928, "rollout_time": 0.4603090286254883, "train_time": 0.8723490238189697, "student_train_time": 0.022896528244018555, "throughput": 1474.8612231212926, "inference_time": 0.06806126447918359, "env_time": 0.3922477641463047, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 23, "reward_mean": 46.904761904761905, "student_loss": null, "teacher_policy_loss": -13.61844539642334, "teacher_value_loss": 248.3646697998047, "teacher_entropy": 0.0008439728408120573, "total_time": 1.2575175762176514, "rollout_time": 0.4634366035461426, "train_time": 0.7697553634643555, "student_train_time": 0.02395939826965332, "throughput": 1590.4350267736056, "inference_time": 0.06738517903067986, "env_time": 0.3960514245154627, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 24, "reward_mean": 46.15909090909091, "student_loss": null, "teacher_policy_loss": -13.211898803710938, "teacher_value_loss": 245.55435180664062, "teacher_entropy": 0.0008040473330765963, "total_time": 1.3168115615844727, "rollout_time": 0.4611985683441162, "train_time": 0.8301212787628174, "student_train_time": 0.024953842163085938, "throughput": 1518.8202005102924, "inference_time": 0.06851144774009299, "env_time": 0.3926871206040232, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 25, "reward_mean": 48.95, "student_loss": null, "teacher_policy_loss": -13.97612476348877, "teacher_value_loss": 216.78416442871094, "teacher_entropy": 0.0006977141019888222, "total_time": 1.2538869380950928, "rollout_time": 0.4529869556427002, "train_time": 0.7731544971466064, "student_train_time": 0.02713608741760254, "throughput": 1595.0401421665686, "inference_time": 0.06762213421825436, "env_time": 0.38536482142444584, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 26, "reward_mean": 58.205882352941174, "student_loss": null, "teacher_policy_loss": -16.72298812866211, "teacher_value_loss": 341.40765380859375, "teacher_entropy": 0.00037062668707221746, "total_time": 1.2876648902893066, "rollout_time": 0.4660313129425049, "train_time": 0.8029277324676514, "student_train_time": 0.018219947814941406, "throughput": 1553.1991398403736, "inference_time": 0.06975944995974714, "env_time": 0.39627186298275774, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 27, "reward_mean": 70.64285714285714, "student_loss": null, "teacher_policy_loss": -18.91278076171875, "teacher_value_loss": 347.565673828125, "teacher_entropy": 0.00017209815268870443, "total_time": 1.3509588241577148, "rollout_time": 0.45611143112182617, "train_time": 0.8635079860687256, "student_train_time": 0.030960559844970703, "throughput": 1480.4300206906337, "inference_time": 0.06912255421411828, "env_time": 0.3869888769077079, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 28, "reward_mean": 54.916666666666664, "student_loss": null, "teacher_policy_loss": -15.574301719665527, "teacher_value_loss": 378.5158386230469, "teacher_entropy": 6.508282240247354e-05, "total_time": 1.3825690746307373, "rollout_time": 0.5313003063201904, "train_time": 0.812406063079834, "student_train_time": 0.03845334053039551, "throughput": 1446.5823347988373, "inference_time": 0.07673768179301987, "env_time": 0.45456262452717056, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 29, "reward_mean": 73.32142857142857, "student_loss": null, "teacher_policy_loss": -18.961872100830078, "teacher_value_loss": 409.19854736328125, "teacher_entropy": 2.3121736376197077e-05, "total_time": 1.6248466968536377, "rollout_time": 0.6457405090332031, "train_time": 0.9587616920471191, "student_train_time": 0.01991868019104004, "throughput": 1230.8853529830299, "inference_time": 0.09753133479171083, "env_time": 0.5482091742414923, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 30, "reward_mean": 81.69565217391305, "student_loss": null, "teacher_policy_loss": -20.963830947875977, "teacher_value_loss": 464.0312805175781, "teacher_entropy": 5.358660018828232e-06, "total_time": 1.248988389968872, "rollout_time": 0.44547438621520996, "train_time": 0.7687325477600098, "student_train_time": 0.0344233512878418, "throughput": 1601.2959096039676, "inference_time": 0.06685284823652182, "env_time": 0.37862153797868814, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 31, "reward_mean": 56.13513513513514, "student_loss": null, "teacher_policy_loss": -14.875990867614746, "teacher_value_loss": 516.8468627929688, "teacher_entropy": 1.2204883205413353e-05, "total_time": -1.2636370658874512, "rollout_time": -2.1549386978149414, "train_time": 0.8751368522644043, "student_train_time": 0.01579117774963379, "throughput": 200000000000.0, "inference_time": 0.07147157180224895, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 32, "reward_mean": 62.96875, "student_loss": null, "teacher_policy_loss": -16.384798049926758, "teacher_value_loss": 455.152587890625, "teacher_entropy": 1.5024897038529161e-05, "total_time": 1.25510573387146, "rollout_time": 0.45879316329956055, "train_time": 0.7738254070281982, "student_train_time": 0.022128820419311523, "throughput": 1593.491246216255, "inference_time": 0.06985016399448796, "env_time": 0.3889429993050726, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 33, "reward_mean": 68.53333333333333, "student_loss": null, "teacher_policy_loss": -16.805362701416016, "teacher_value_loss": 292.00341796875, "teacher_entropy": 4.5958968257764354e-05, "total_time": 1.3312206268310547, "rollout_time": 0.4672234058380127, "train_time": 0.8452069759368896, "student_train_time": 0.018378734588623047, "throughput": 1502.3805668944312, "inference_time": 0.06750656245276332, "env_time": 0.3997168433852494, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 34, "reward_mean": 78.0, "student_loss": null, "teacher_policy_loss": -21.51618003845215, "teacher_value_loss": 474.8238830566406, "teacher_entropy": 0.00010645737347658724, "total_time": 1.3561081886291504, "rollout_time": 0.4635612964630127, "train_time": 0.8308608531951904, "student_train_time": 0.06129145622253418, "throughput": 1474.8085859003188, "inference_time": 0.07049181593902176, "env_time": 0.39306948052399093, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 35, "reward_mean": 65.6, "student_loss": null, "teacher_policy_loss": -16.553234100341797, "teacher_value_loss": 302.73699951171875, "teacher_entropy": 0.00022763341257814318, "total_time": 1.2957956790924072, "rollout_time": 0.45453834533691406, "train_time": 0.8239905834197998, "student_train_time": 0.016880512237548828, "throughput": 1543.4532096918451, "inference_time": 0.06852639323369658, "env_time": 0.3860119521032175, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 36, "reward_mean": 71.11111111111111, "student_loss": null, "teacher_policy_loss": -18.493253707885742, "teacher_value_loss": 364.5389404296875, "teacher_entropy": 0.00036793624167330563, "total_time": 1.4429500102996826, "rollout_time": 0.4777987003326416, "train_time": 0.9464359283447266, "student_train_time": 0.018337011337280273, "throughput": 1386.0494027680315, "inference_time": 0.07230571244872408, "env_time": 0.4054929878839175, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 37, "reward_mean": 87.16, "student_loss": null, "teacher_policy_loss": -20.381549835205078, "teacher_value_loss": 519.230224609375, "teacher_entropy": 0.0003898089344147593, "total_time": 1.2595102787017822, "rollout_time": 0.45868420600891113, "train_time": 0.7870221138000488, "student_train_time": 0.013361215591430664, "throughput": 1587.9187600290682, "inference_time": 0.07232044295597007, "env_time": 0.38636376305294107, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 38, "reward_mean": 93.47368421052632, "student_loss": null, "teacher_policy_loss": -23.818025588989258, "teacher_value_loss": 499.18865966796875, "teacher_entropy": 0.00023986709129530936, "total_time": 1.3296711444854736, "rollout_time": 0.4574606418609619, "train_time": 0.8514771461486816, "student_train_time": 0.020308494567871094, "throughput": 1504.131309681023, "inference_time": 0.07153189493510581, "env_time": 0.3859287469258561, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 39, "reward_mean": 115.52631578947368, "student_loss": null, "teacher_policy_loss": -23.477163314819336, "teacher_value_loss": 477.7626037597656, "teacher_entropy": 0.00011134168016724288, "total_time": 1.2696747779846191, "rollout_time": 0.46105003356933594, "train_time": 0.7779281139373779, "student_train_time": 0.029863834381103516, "throughput": 1575.206529009453, "inference_time": 0.07067341746369493, "env_time": 0.390376616105641, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 40, "reward_mean": 85.41666666666667, "student_loss": null, "teacher_policy_loss": -20.015052795410156, "teacher_value_loss": 350.0378112792969, "teacher_entropy": 2.4115755877573974e-05, "total_time": 1.3158607482910156, "rollout_time": 0.4629364013671875, "train_time": 0.8371200561523438, "student_train_time": 0.015411138534545898, "throughput": 1519.9176680340345, "inference_time": 0.06908794828632381, "env_time": 0.3938484530808637, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 41, "reward_mean": 94.0, "student_loss": null, "teacher_policy_loss": -22.455909729003906, "teacher_value_loss": 359.99224853515625, "teacher_entropy": 2.7382724510971457e-05, "total_time": 1.2965338230133057, "rollout_time": 0.45159029960632324, "train_time": 0.8033645153045654, "student_train_time": 0.041168928146362305, "throughput": 1542.5744893810418, "inference_time": 0.07027680698956829, "env_time": 0.38131349261675496, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 42, "reward_mean": 102.42105263157895, "student_loss": null, "teacher_policy_loss": -22.235734939575195, "teacher_value_loss": 344.6335754394531, "teacher_entropy": 2.3587977921124548e-05, "total_time": 1.2396962642669678, "rollout_time": 0.4455270767211914, "train_time": 0.7759401798248291, "student_train_time": 0.017858266830444336, "throughput": 1613.2984003001734, "inference_time": 0.06602097451104783, "env_time": 0.3795061022101436, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 43, "reward_mean": 99.18181818181819, "student_loss": null, "teacher_policy_loss": -21.22775650024414, "teacher_value_loss": 410.0351867675781, "teacher_entropy": 4.210477709420957e-05, "total_time": 1.4102282524108887, "rollout_time": 0.4712557792663574, "train_time": 0.9117679595947266, "student_train_time": 0.026778697967529297, "throughput": 1418.2101348351612, "inference_time": 0.07422649450563767, "env_time": 0.39702928476071975, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 44, "reward_mean": 79.34615384615384, "student_loss": null, "teacher_policy_loss": -18.70838737487793, "teacher_value_loss": 375.6881103515625, "teacher_entropy": 7.866040687076747e-05, "total_time": 1.3192124366760254, "rollout_time": 0.4719579219818115, "train_time": 0.8186032772064209, "student_train_time": 0.02823019027709961, "throughput": 1516.056053139805, "inference_time": 0.0708972647171322, "env_time": 0.4010606572646793, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 45, "reward_mean": 117.5625, "student_loss": null, "teacher_policy_loss": -23.559947967529297, "teacher_value_loss": 364.5421142578125, "teacher_entropy": 0.00020946923177689314, "total_time": 1.3965997695922852, "rollout_time": 0.46078968048095703, "train_time": 0.9155519008636475, "student_train_time": 0.01977825164794922, "throughput": 1432.049498750718, "inference_time": 0.0693214022758184, "env_time": 0.39146827820513863, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 46, "reward_mean": 121.13333333333334, "student_loss": null, "teacher_policy_loss": -24.014650344848633, "teacher_value_loss": 426.6415710449219, "teacher_entropy": 0.00030800033709965646, "total_time": 1.311983346939087, "rollout_time": 0.47266507148742676, "train_time": 0.8212244510650635, "student_train_time": 0.017725706100463867, "throughput": 1524.4095930532085, "inference_time": 0.07409032100440527, "env_time": 0.3985747504830215, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 47, "reward_mean": 114.61111111111111, "student_loss": null, "teacher_policy_loss": -24.261167526245117, "teacher_value_loss": 660.0292358398438, "teacher_entropy": 0.0004198155365884304, "total_time": 1.3046960830688477, "rollout_time": 0.4629080295562744, "train_time": 0.8238482475280762, "student_train_time": 0.01757025718688965, "throughput": 1532.9240471816927, "inference_time": 0.06924483922557556, "env_time": 0.39366319033069885, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 48, "reward_mean": 127.625, "student_loss": null, "teacher_policy_loss": -23.92784309387207, "teacher_value_loss": 525.7238159179688, "teacher_entropy": 0.0006124486681073904, "total_time": 1.3178820610046387, "rollout_time": 0.4674837589263916, "train_time": 0.8218169212341309, "student_train_time": 0.028194665908813477, "throughput": 1517.586481506072, "inference_time": 0.07263582174164185, "env_time": 0.39484793718474975, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 49, "reward_mean": 93.625, "student_loss": null, "teacher_policy_loss": -19.669889450073242, "teacher_value_loss": 285.5446472167969, "teacher_entropy": 0.00023620644060429186, "total_time": 1.2486326694488525, "rollout_time": 0.45894384384155273, "train_time": 0.7684946060180664, "student_train_time": 0.020824670791625977, "throughput": 1601.7520996649891, "inference_time": 0.06936957250218256, "env_time": 0.38957427133937017, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 50, "reward_mean": 112.6875, "student_loss": null, "teacher_policy_loss": -24.311016082763672, "teacher_value_loss": 419.5963439941406, "teacher_entropy": 0.00017163898155558854, "total_time": 1.7174959182739258, "rollout_time": 0.6152677536010742, "train_time": 1.0809924602508545, "student_train_time": 0.02081012725830078, "throughput": 1164.486028013382, "inference_time": 0.07899005425315409, "env_time": 0.5362776993479201, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 51, "reward_mean": 109.875, "student_loss": null, "teacher_policy_loss": -25.38612174987793, "teacher_value_loss": 544.6542358398438, "teacher_entropy": 6.454433605540544e-05, "total_time": 1.2601840496063232, "rollout_time": 0.447237491607666, "train_time": 0.797032356262207, "student_train_time": 0.015469789505004883, "throughput": 1587.06976225004, "inference_time": 0.06848821999483334, "env_time": 0.37874927161283267, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 52, "reward_mean": 134.76470588235293, "student_loss": null, "teacher_policy_loss": -23.745361328125, "teacher_value_loss": 378.1563415527344, "teacher_entropy": 7.204346911748871e-05, "total_time": 1.3907301425933838, "rollout_time": 0.47397470474243164, "train_time": 0.8892521858215332, "student_train_time": 0.027132749557495117, "throughput": 1438.0935155906461, "inference_time": 0.07121909248962766, "env_time": 0.402755612252804, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 53, "reward_mean": 122.0625, "student_loss": null, "teacher_policy_loss": -24.106189727783203, "teacher_value_loss": 377.14605712890625, "teacher_entropy": 5.485812289407477e-05, "total_time": 1.2590630054473877, "rollout_time": 0.4566946029663086, "train_time": 0.7822434902191162, "student_train_time": 0.01974630355834961, "throughput": 1588.4828569713493, "inference_time": 0.0691030587440764, "env_time": 0.3875915442222322, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 54, "reward_mean": 119.0, "student_loss": null, "teacher_policy_loss": -23.532323837280273, "teacher_value_loss": 316.86505126953125, "teacher_entropy": 0.00010040126653620973, "total_time": -1.3014039993286133, "rollout_time": 0.4342942237854004, "train_time": -1.7617263793945312, "student_train_time": 0.02532219886779785, "throughput": 200000000000.0, "inference_time": 0.06713302405478316, "env_time": 0.3671611997306172, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 55, "reward_mean": 142.63636363636363, "student_loss": null, "teacher_policy_loss": -29.116085052490234, "teacher_value_loss": 438.7015686035156, "teacher_entropy": 6.959435268072411e-05, "total_time": 1.270622968673706, "rollout_time": 0.44486331939697266, "train_time": 0.8069226741790771, "student_train_time": 0.01846909523010254, "throughput": 1574.0310456434042, "inference_time": 0.07032732850166212, "env_time": 0.37453599089531053, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 56, "reward_mean": 172.46666666666667, "student_loss": null, "teacher_policy_loss": -25.30879020690918, "teacher_value_loss": 393.09613037109375, "teacher_entropy": 0.0002709682157728821, "total_time": 1.2017765045166016, "rollout_time": 0.4376988410949707, "train_time": 0.745704174041748, "student_train_time": 0.01801609992980957, "throughput": 1664.202946623984, "inference_time": 0.0681752175114525, "env_time": 0.3695236235835182, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 57, "reward_mean": 130.64285714285714, "student_loss": null, "teacher_policy_loss": -25.431108474731445, "teacher_value_loss": 378.4382019042969, "teacher_entropy": 0.00020613324886653572, "total_time": 1.442505121231079, "rollout_time": 0.438678503036499, "train_time": 0.9739301204681396, "student_train_time": 0.02948164939880371, "throughput": 1386.476880091169, "inference_time": 0.06524559523495554, "env_time": 0.3734329078015435, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 58, "reward_mean": 141.27272727272728, "student_loss": null, "teacher_policy_loss": -28.243515014648438, "teacher_value_loss": 523.6192626953125, "teacher_entropy": 5.438398875412531e-05, "total_time": 1.21425461769104, "rollout_time": 0.4485311508178711, "train_time": 0.739659309387207, "student_train_time": 0.025595426559448242, "throughput": 1647.101004073668, "inference_time": 0.06917144856015511, "env_time": 0.379359702257716, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 59, "reward_mean": 168.93333333333334, "student_loss": null, "teacher_policy_loss": -24.929311752319336, "teacher_value_loss": 350.6180419921875, "teacher_entropy": 4.835228173760697e-05, "total_time": 1.2494442462921143, "rollout_time": 0.43473339080810547, "train_time": 0.7958827018737793, "student_train_time": 0.018389463424682617, "throughput": 1600.7116811616493, "inference_time": 0.06871290700109967, "env_time": 0.3660204838070058, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 60, "reward_mean": 158.92307692307693, "student_loss": null, "teacher_policy_loss": -28.06171226501465, "teacher_value_loss": 521.0569458007812, "teacher_entropy": 4.3183619709452614e-05, "total_time": 1.2967181205749512, "rollout_time": 0.46471548080444336, "train_time": 0.7993204593658447, "student_train_time": 0.03229475021362305, "throughput": 1542.3552491988166, "inference_time": 0.07338227381660545, "env_time": 0.3913332069878379, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 61, "reward_mean": 138.76923076923077, "student_loss": null, "teacher_policy_loss": -26.456180572509766, "teacher_value_loss": 691.5985107421875, "teacher_entropy": 2.754951492534019e-05, "total_time": 1.231081485748291, "rollout_time": 0.44237732887268066, "train_time": 0.7717182636260986, "student_train_time": 0.01662588119506836, "throughput": 1624.587830418338, "inference_time": 0.0694542512519547, "env_time": 0.37292307762072596, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 62, "reward_mean": 210.9, "student_loss": null, "teacher_policy_loss": -30.887327194213867, "teacher_value_loss": 557.1570434570312, "teacher_entropy": 1.313560005655745e-05, "total_time": 1.357154369354248, "rollout_time": 0.45757579803466797, "train_time": 0.8783011436462402, "student_train_time": 0.020847320556640625, "throughput": 1473.6717098377146, "inference_time": 0.07028377144524711, "env_time": 0.38729202658942086, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 63, "reward_mean": 157.0909090909091, "student_loss": null, "teacher_policy_loss": -28.331750869750977, "teacher_value_loss": 518.4114379882812, "teacher_entropy": 3.594597728806548e-05, "total_time": 1.2005681991577148, "rollout_time": 0.44998764991760254, "train_time": 0.7346727848052979, "student_train_time": 0.01550602912902832, "throughput": 1665.8778746623009, "inference_time": 0.0708207464649604, "env_time": 0.37916690345264215, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 64, "reward_mean": 202.0909090909091, "student_loss": null, "teacher_policy_loss": -29.332979202270508, "teacher_value_loss": 412.63348388671875, "teacher_entropy": 5.39610227860976e-05, "total_time": 1.3546395301818848, "rollout_time": 0.44342970848083496, "train_time": 0.892406702041626, "student_train_time": 0.01831364631652832, "throughput": 1476.407527935837, "inference_time": 0.06892833346682892, "env_time": 0.37450137501400604, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 65, "reward_mean": 159.1, "student_loss": null, "teacher_policy_loss": -31.281917572021484, "teacher_value_loss": 436.9132385253906, "teacher_entropy": 4.86602948512882e-05, "total_time": 1.2831947803497314, "rollout_time": 0.4660358428955078, "train_time": 0.7960860729217529, "student_train_time": 0.020689725875854492, "throughput": 1558.6098312018578, "inference_time": 0.0716172119955445, "env_time": 0.3944186308999633, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 66, "reward_mean": 158.41176470588235, "student_loss": null, "teacher_policy_loss": -26.111373901367188, "teacher_value_loss": 442.53466796875, "teacher_entropy": 9.346189472125843e-05, "total_time": 1.2409758567810059, "rollout_time": 0.4449195861816406, "train_time": 0.7702732086181641, "student_train_time": 0.025417566299438477, "throughput": 1611.6348993185438, "inference_time": 0.0681024663062999, "env_time": 0.3768171198753407, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 67, "reward_mean": 187.6, "student_loss": null, "teacher_policy_loss": -30.6700382232666, "teacher_value_loss": 448.5303649902344, "teacher_entropy": 0.00022682707640342414, "total_time": 1.3551297187805176, "rollout_time": 0.46055054664611816, "train_time": 0.8728556632995605, "student_train_time": 0.02134084701538086, "throughput": 1475.8734697367584, "inference_time": 0.06982927650096826, "env_time": 0.3907212701451499, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 68, "reward_mean": 168.0, "student_loss": null, "teacher_policy_loss": -27.63755226135254, "teacher_value_loss": 347.3309326171875, "teacher_entropy": 0.00017510222096461803, "total_time": 1.2882404327392578, "rollout_time": 0.4508035182952881, "train_time": 0.8176217079162598, "student_train_time": 0.019420862197875977, "throughput": 1552.5052227613194, "inference_time": 0.06987425026636629, "env_time": 0.3809292680289218, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 69, "reward_mean": 169.88888888888889, "student_loss": null, "teacher_policy_loss": -32.771568298339844, "teacher_value_loss": 586.2693481445312, "teacher_entropy": 0.00010961602674797177, "total_time": 1.3900916576385498, "rollout_time": 0.4683976173400879, "train_time": 0.8844273090362549, "student_train_time": 0.03668856620788574, "throughput": 1438.7540483463847, "inference_time": 0.069467545252337, "env_time": 0.3989300720877509, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 70, "reward_mean": 194.53846153846155, "student_loss": null, "teacher_policy_loss": -26.681421279907227, "teacher_value_loss": 362.88427734375, "teacher_entropy": 0.00012801302364096045, "total_time": 1.2880511283874512, "rollout_time": 0.46002721786499023, "train_time": 0.8094773292541504, "student_train_time": 0.018126487731933594, "throughput": 1552.7333938240934, "inference_time": 0.0712476622320537, "env_time": 0.38877955563293654, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 71, "reward_mean": 169.41666666666666, "student_loss": null, "teacher_policy_loss": -28.989952087402344, "teacher_value_loss": 387.7347412109375, "teacher_entropy": 0.00017740210751071572, "total_time": 1.292463779449463, "rollout_time": 0.447537899017334, "train_time": 0.815875768661499, "student_train_time": 0.028672218322753906, "throughput": 1547.4321461077377, "inference_time": 0.06774847574888554, "env_time": 0.37978942326844845, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 72, "reward_mean": 162.63636363636363, "student_loss": null, "teacher_policy_loss": -28.33025550842285, "teacher_value_loss": 482.1544494628906, "teacher_entropy": 9.271818271372467e-05, "total_time": 1.3194644451141357, "rollout_time": 0.4525439739227295, "train_time": 0.8436546325683594, "student_train_time": 0.022880077362060547, "throughput": 1515.7664970858664, "inference_time": 0.07206853171919647, "env_time": 0.380475442203533, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 73, "reward_mean": 194.27272727272728, "student_loss": null, "teacher_policy_loss": -28.772647857666016, "teacher_value_loss": 477.46893310546875, "teacher_entropy": 0.00017034172196872532, "total_time": 1.3889539241790771, "rollout_time": 0.45261573791503906, "train_time": 0.9214694499969482, "student_train_time": 0.014501333236694336, "throughput": 1439.9325745683561, "inference_time": 0.06926054476571153, "env_time": 0.38335519314932753, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 74, "reward_mean": 173.91666666666666, "student_loss": null, "teacher_policy_loss": -26.638351440429688, "teacher_value_loss": 296.7474670410156, "teacher_entropy": 0.00010494980233488604, "total_time": 1.3491380214691162, "rollout_time": 0.45232295989990234, "train_time": 0.8766129016876221, "student_train_time": 0.019831418991088867, "throughput": 1482.428015646717, "inference_time": 0.07142838547406427, "env_time": 0.3808945744258381, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 75, "reward_mean": 132.33333333333334, "student_loss": null, "teacher_policy_loss": -25.527212142944336, "teacher_value_loss": 403.7192077636719, "teacher_entropy": 8.60670770634897e-05, "total_time": 1.21431303024292, "rollout_time": 0.4469432830810547, "train_time": 0.748852014541626, "student_train_time": 0.018111705780029297, "throughput": 1647.0217729607214, "inference_time": 0.06852899046134553, "env_time": 0.37841429261970916, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 76, "reward_mean": 219.11111111111111, "student_loss": null, "teacher_policy_loss": -31.225317001342773, "teacher_value_loss": 456.5755920410156, "teacher_entropy": 3.5339020541869104e-05, "total_time": 1.3437609672546387, "rollout_time": 0.4581942558288574, "train_time": 0.869718074798584, "student_train_time": 0.01546478271484375, "throughput": 1488.359945508825, "inference_time": 0.07189627550360456, "env_time": 0.38629798032525287, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 77, "reward_mean": 196.0, "student_loss": null, "teacher_policy_loss": -28.882688522338867, "teacher_value_loss": 337.4281921386719, "teacher_entropy": 0.00017323637439403683, "total_time": 1.252760648727417, "rollout_time": 0.4615616798400879, "train_time": 0.7672154903411865, "student_train_time": 0.023553848266601562, "throughput": 1596.4741565211566, "inference_time": 0.07189973002823535, "env_time": 0.38966194981185254, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 78, "reward_mean": 166.41666666666666, "student_loss": null, "teacher_policy_loss": -26.935531616210938, "teacher_value_loss": 393.21856689453125, "teacher_entropy": 9.09357622731477e-05, "total_time": -1.35807204246521, "rollout_time": -2.1548428535461426, "train_time": 0.7783491611480713, "student_train_time": 0.01804494857788086, "throughput": 200000000000.0, "inference_time": 0.06807684574414452, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 79, "reward_mean": 201.375, "student_loss": null, "teacher_policy_loss": -33.37636184692383, "teacher_value_loss": 540.8966064453125, "teacher_entropy": 0.00013790022057946771, "total_time": 1.4135851860046387, "rollout_time": 0.45262646675109863, "train_time": 0.9249668121337891, "student_train_time": 0.03562593460083008, "throughput": 1414.8422180716295, "inference_time": 0.0721956305369531, "env_time": 0.38043083621414553, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 80, "reward_mean": 252.55555555555554, "student_loss": null, "teacher_policy_loss": -30.06062889099121, "teacher_value_loss": 448.54180908203125, "teacher_entropy": 0.00019832879479508847, "total_time": 1.193202257156372, "rollout_time": 0.44169116020202637, "train_time": 0.7302088737487793, "student_train_time": 0.020942211151123047, "throughput": 1676.1617638625496, "inference_time": 0.07071123302011983, "env_time": 0.37097992718190653, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 81, "reward_mean": 180.54545454545453, "student_loss": null, "teacher_policy_loss": -28.162967681884766, "teacher_value_loss": 581.2986450195312, "teacher_entropy": 0.00013393693370744586, "total_time": 1.384383201599121, "rollout_time": 0.4519646167755127, "train_time": 0.9146895408630371, "student_train_time": 0.017368316650390625, "throughput": 1444.686700683576, "inference_time": 0.06931027322207228, "env_time": 0.3826543435534404, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 82, "reward_mean": 196.7, "student_loss": null, "teacher_policy_loss": -31.601097106933594, "teacher_value_loss": 325.2646484375, "teacher_entropy": 0.00010944734094664454, "total_time": 1.2297632694244385, "rollout_time": 0.44614720344543457, "train_time": 0.7593557834625244, "student_train_time": 0.023889541625976562, "throughput": 1626.3292698082066, "inference_time": 0.07005386798846303, "env_time": 0.37609333545697154, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 83, "reward_mean": 235.22222222222223, "student_loss": null, "teacher_policy_loss": -32.33173751831055, "teacher_value_loss": 588.57568359375, "teacher_entropy": 0.00028390332590788603, "total_time": 1.2791223526000977, "rollout_time": 0.4389052391052246, "train_time": 0.8207228183746338, "student_train_time": 0.019133567810058594, "throughput": 1563.5720820096371, "inference_time": 0.06773494747903896, "env_time": 0.37117029162618564, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 84, "reward_mean": 196.33333333333334, "student_loss": null, "teacher_policy_loss": -29.973573684692383, "teacher_value_loss": 313.56396484375, "teacher_entropy": 0.00022507226094603539, "total_time": 1.2694621086120605, "rollout_time": 0.4554176330566406, "train_time": 0.768669605255127, "student_train_time": 0.04500102996826172, "throughput": 1575.470418874225, "inference_time": 0.07190693328448106, "env_time": 0.38351069977215957, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 85, "reward_mean": 226.66666666666666, "student_loss": null, "teacher_policy_loss": -30.59556007385254, "teacher_value_loss": 406.59075927734375, "teacher_entropy": 0.00022521191567648202, "total_time": 1.221860408782959, "rollout_time": 0.43720459938049316, "train_time": 0.7642052173614502, "student_train_time": 0.020090341567993164, "throughput": 1636.8481911874953, "inference_time": 0.06645272196146834, "env_time": 0.3707518774190248, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 86, "reward_mean": 290.42857142857144, "student_loss": null, "teacher_policy_loss": -33.6619873046875, "teacher_value_loss": 444.89080810546875, "teacher_entropy": 6.336146907415241e-05, "total_time": 1.396644115447998, "rollout_time": 0.475053071975708, "train_time": 0.9005193710327148, "student_train_time": 0.020699501037597656, "throughput": 1432.0040287131164, "inference_time": 0.07173136946767045, "env_time": 0.40332170250803756, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 87, "reward_mean": 171.25, "student_loss": null, "teacher_policy_loss": -27.812210083007812, "teacher_value_loss": 372.1860656738281, "teacher_entropy": 0.00015922132297419012, "total_time": 1.2335989475250244, "rollout_time": 0.4466409683227539, "train_time": 0.7670888900756836, "student_train_time": 0.019442081451416016, "throughput": 1621.2724597508857, "inference_time": 0.0694135190005909, "env_time": 0.377227449322163, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 88, "reward_mean": 161.7, "student_loss": null, "teacher_policy_loss": -33.20552444458008, "teacher_value_loss": 456.7510070800781, "teacher_entropy": 7.18787923688069e-05, "total_time": 1.3563923835754395, "rollout_time": 0.45157766342163086, "train_time": 0.8813638687133789, "student_train_time": 0.023084402084350586, "throughput": 1474.4995800758008, "inference_time": 0.06863024096310255, "env_time": 0.3829474224585283, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 89, "reward_mean": 305.85714285714283, "student_loss": null, "teacher_policy_loss": -33.83701705932617, "teacher_value_loss": 511.0909729003906, "teacher_entropy": 3.641722651082091e-05, "total_time": 1.2659306526184082, "rollout_time": 0.4679872989654541, "train_time": 0.7785124778747559, "student_train_time": 0.019048213958740234, "throughput": 1579.8653708742004, "inference_time": 0.07161224973424396, "env_time": 0.39637504923121014, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 90, "reward_mean": 268.625, "student_loss": null, "teacher_policy_loss": -32.09086990356445, "teacher_value_loss": 533.5971069335938, "teacher_entropy": 0.00014341302448883653, "total_time": 1.255293369293213, "rollout_time": 0.45320773124694824, "train_time": 0.7844464778900146, "student_train_time": 0.017222881317138672, "throughput": 1593.2530585468564, "inference_time": 0.06996141925810662, "env_time": 0.3832463119888416, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 91, "reward_mean": 274.7142857142857, "student_loss": null, "teacher_policy_loss": -33.092777252197266, "teacher_value_loss": 474.3873291015625, "teacher_entropy": 8.477884694002569e-05, "total_time": 1.3203558921813965, "rollout_time": 0.4603569507598877, "train_time": 0.8361613750457764, "student_train_time": 0.023454666137695312, "throughput": 1514.7431172482934, "inference_time": 0.07254091525464901, "env_time": 0.3878160355052387, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 92, "reward_mean": 244.55555555555554, "student_loss": null, "teacher_policy_loss": -30.843063354492188, "teacher_value_loss": 472.9896240234375, "teacher_entropy": 2.2489650291390717e-05, "total_time": 1.4027016162872314, "rollout_time": 0.45200681686401367, "train_time": 0.9366128444671631, "student_train_time": 0.013670682907104492, "throughput": 1425.8199867864555, "inference_time": 0.07004077398960362, "env_time": 0.38196604287441005, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 93, "reward_mean": 180.72727272727272, "student_loss": null, "teacher_policy_loss": -27.878591537475586, "teacher_value_loss": 462.26324462890625, "teacher_entropy": 0.00021514248510356992, "total_time": 1.3808941841125488, "rollout_time": 0.44837355613708496, "train_time": 0.904778242111206, "student_train_time": 0.027374267578125, "throughput": 1448.336898663476, "inference_time": 0.07029313026032469, "env_time": 0.3780804258767603, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 94, "reward_mean": 209.3, "student_loss": null, "teacher_policy_loss": -27.312562942504883, "teacher_value_loss": 429.02880859375, "teacher_entropy": 0.00033650334808044136, "total_time": 1.2640182971954346, "rollout_time": 0.48737430572509766, "train_time": 0.7579355239868164, "student_train_time": 0.018339157104492188, "throughput": 1582.2555768674704, "inference_time": 0.07480873874374083, "env_time": 0.4125655669813568, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 95, "reward_mean": 344.6, "student_loss": null, "teacher_policy_loss": -36.1951904296875, "teacher_value_loss": 757.3561401367188, "teacher_entropy": 0.00044209446059539914, "total_time": 1.3278892040252686, "rollout_time": 0.4584488868713379, "train_time": 0.8537812232971191, "student_train_time": 0.01505136489868164, "throughput": 1506.1497555197698, "inference_time": 0.07297281702994951, "env_time": 0.3854760698413884, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 96, "reward_mean": 324.1666666666667, "student_loss": null, "teacher_policy_loss": -36.013092041015625, "teacher_value_loss": 647.294189453125, "teacher_entropy": 0.00022678307141177356, "total_time": 1.2666914463043213, "rollout_time": 0.45264720916748047, "train_time": 0.7922649383544922, "student_train_time": 0.02141404151916504, "throughput": 1578.9164802803145, "inference_time": 0.06946501204765809, "env_time": 0.3831821971198224, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 97, "reward_mean": 220.66666666666666, "student_loss": null, "teacher_policy_loss": -32.501220703125, "teacher_value_loss": 649.3200073242188, "teacher_entropy": 1.828806307457853e-05, "total_time": 1.223273754119873, "rollout_time": 0.4519164562225342, "train_time": 0.7568223476409912, "student_train_time": 0.014101505279541016, "throughput": 1634.9570104518182, "inference_time": 0.0709109002200421, "env_time": 0.3810055560024921, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 98, "reward_mean": 273.75, "student_loss": null, "teacher_policy_loss": -30.851640701293945, "teacher_value_loss": 536.4348754882812, "teacher_entropy": 3.171277285218821e-06, "total_time": 1.395354986190796, "rollout_time": 0.4673008918762207, "train_time": 0.901602029800415, "student_train_time": 0.02604365348815918, "throughput": 1433.3270169907337, "inference_time": 0.07091402898913657, "env_time": 0.39638686288708413, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 99, "reward_mean": 229.28571428571428, "student_loss": null, "teacher_policy_loss": -32.36005401611328, "teacher_value_loss": 341.37774658203125, "teacher_entropy": 3.243455648771487e-05, "total_time": 1.2006185054779053, "rollout_time": 0.4390988349914551, "train_time": 0.7395708560943604, "student_train_time": 0.021558284759521484, "throughput": 1665.8080738176707, "inference_time": 0.06943015229990124, "env_time": 0.36966868269155384, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 100, "reward_mean": 241.66666666666666, "student_loss": null, "teacher_policy_loss": -31.3861026763916, "teacher_value_loss": 482.16986083984375, "teacher_entropy": 2.6708248697104864e-05, "total_time": 1.3092677593231201, "rollout_time": 0.45699524879455566, "train_time": 0.8380725383758545, "student_train_time": 0.013823509216308594, "throughput": 1527.571412156351, "inference_time": 0.06956525599161978, "env_time": 0.3874299928029359, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 101, "reward_mean": 271.375, "student_loss": null, "teacher_policy_loss": -29.613014221191406, "teacher_value_loss": 324.9122009277344, "teacher_entropy": 5.106725075165741e-05, "total_time": -1.365063190460205, "rollout_time": 0.4635634422302246, "train_time": -1.8478357791900635, "student_train_time": 0.018758296966552734, "throughput": 200000000000.0, "inference_time": 0.0725199364733271, "env_time": 0.3910435057568975, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 102, "reward_mean": 316.3333333333333, "student_loss": null, "teacher_policy_loss": -34.81590270996094, "teacher_value_loss": 587.9290161132812, "teacher_entropy": 4.991137029719539e-05, "total_time": 1.229513168334961, "rollout_time": 0.4322226047515869, "train_time": 0.7648317813873291, "student_train_time": 0.03206276893615723, "throughput": 1626.6600891379248, "inference_time": 0.06648225150638609, "env_time": 0.3657403532452008, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 103, "reward_mean": 234.55555555555554, "student_loss": null, "teacher_policy_loss": -31.762985229492188, "teacher_value_loss": 702.80517578125, "teacher_entropy": 2.6258459911332466e-05, "total_time": 1.3473787307739258, "rollout_time": 0.45509839057922363, "train_time": 0.8633100986480713, "student_train_time": 0.028606176376342773, "throughput": 1484.3636420260343, "inference_time": 0.06971506401532679, "env_time": 0.38538332656389684, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 104, "reward_mean": 248.125, "student_loss": null, "teacher_policy_loss": -30.935550689697266, "teacher_value_loss": 610.529296875, "teacher_entropy": 0.000468034646473825, "total_time": 1.1932361125946045, "rollout_time": 0.4404444694519043, "train_time": 0.7264289855957031, "student_train_time": 0.026009321212768555, "throughput": 1676.1142064759895, "inference_time": 0.06719807455010596, "env_time": 0.37324639490179834, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 105, "reward_mean": 312.6666666666667, "student_loss": null, "teacher_policy_loss": -33.60175704956055, "teacher_value_loss": 518.3148803710938, "teacher_entropy": 0.00034074910217896104, "total_time": 1.3999073505401611, "rollout_time": 0.43648505210876465, "train_time": 0.9450931549072266, "student_train_time": 0.017961502075195312, "throughput": 1428.6659750934875, "inference_time": 0.06887796373121091, "env_time": 0.36760708837755374, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 106, "reward_mean": 288.42857142857144, "student_loss": null, "teacher_policy_loss": -35.385154724121094, "teacher_value_loss": 912.8773193359375, "teacher_entropy": 0.0005239049205556512, "total_time": 1.2308716773986816, "rollout_time": 0.4462897777557373, "train_time": 0.7679591178894043, "student_train_time": 0.016256332397460938, "throughput": 1624.864749692503, "inference_time": 0.06830086378795386, "env_time": 0.37798891396778345, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 107, "reward_mean": 224.77777777777777, "student_loss": null, "teacher_policy_loss": -30.66132354736328, "teacher_value_loss": 568.613525390625, "teacher_entropy": 5.478380262502469e-05, "total_time": 1.2420439720153809, "rollout_time": 0.4496757984161377, "train_time": 0.7733526229858398, "student_train_time": 0.018583059310913086, "throughput": 1610.2489485575418, "inference_time": 0.06796789252439339, "env_time": 0.3817079058917443, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 108, "reward_mean": 233.25, "student_loss": null, "teacher_policy_loss": -30.46082305908203, "teacher_value_loss": 403.40667724609375, "teacher_entropy": 0.0002830277953762561, "total_time": 1.3208205699920654, "rollout_time": 0.45598483085632324, "train_time": 0.8195981979370117, "student_train_time": 0.0448002815246582, "throughput": 1514.2102155571476, "inference_time": 0.06798484275168448, "env_time": 0.38799998810463876, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 109, "reward_mean": 261.57142857142856, "student_loss": null, "teacher_policy_loss": -34.645538330078125, "teacher_value_loss": 562.2620239257812, "teacher_entropy": 8.422937389696017e-05, "total_time": 1.6543424129486084, "rollout_time": 0.446120023727417, "train_time": 1.1189899444580078, "student_train_time": 0.08881831169128418, "throughput": 1208.9395667704068, "inference_time": 0.06677682299050502, "env_time": 0.37934320073691197, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 110, "reward_mean": 307.25, "student_loss": null, "teacher_policy_loss": -33.06989669799805, "teacher_value_loss": 635.75244140625, "teacher_entropy": 5.80314065246057e-07, "total_time": 1.4623725414276123, "rollout_time": 0.561187744140625, "train_time": 0.8636138439178467, "student_train_time": 0.0372006893157959, "throughput": 1367.6405589833762, "inference_time": 0.08831541958534217, "env_time": 0.47287232455528283, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 111, "reward_mean": 246.33333333333334, "student_loss": null, "teacher_policy_loss": -34.749847412109375, "teacher_value_loss": 399.2059020996094, "teacher_entropy": 2.09285608434584e-05, "total_time": 1.3796842098236084, "rollout_time": 0.44826698303222656, "train_time": 0.9086332321166992, "student_train_time": 0.02242112159729004, "throughput": 1449.607080924481, "inference_time": 0.06980601202485559, "env_time": 0.37846097100737097, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 112, "reward_mean": 254.0, "student_loss": null, "teacher_policy_loss": -34.499759674072266, "teacher_value_loss": 763.8949584960938, "teacher_entropy": 3.272713365731761e-05, "total_time": 1.4718852043151855, "rollout_time": 0.541959285736084, "train_time": 0.90395188331604, "student_train_time": 0.025487184524536133, "throughput": 1358.801619947343, "inference_time": 0.0829596070379921, "env_time": 0.4589996786980919, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 113, "reward_mean": 245.3, "student_loss": null, "teacher_policy_loss": -29.35105323791504, "teacher_value_loss": 510.3799743652344, "teacher_entropy": 0.0001762453030096367, "total_time": 1.2503929138183594, "rollout_time": 0.4448099136352539, "train_time": 0.7841200828552246, "student_train_time": 0.02109503746032715, "throughput": 1599.4972283492432, "inference_time": 0.0699007787516166, "env_time": 0.3749091348836373, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 114, "reward_mean": 347.2, "student_loss": null, "teacher_policy_loss": -37.15039825439453, "teacher_value_loss": 715.4871215820312, "teacher_entropy": 1.5017033547337633e-05, "total_time": 1.5522785186767578, "rollout_time": 0.44753146171569824, "train_time": 1.0686602592468262, "student_train_time": 0.03571271896362305, "throughput": 1288.4285751147952, "inference_time": 0.06910601200979727, "env_time": 0.378425449705901, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 115, "reward_mean": 231.66666666666666, "student_loss": null, "teacher_policy_loss": -29.687313079833984, "teacher_value_loss": 379.2955627441406, "teacher_entropy": 0.0004076987970620394, "total_time": 1.2453629970550537, "rollout_time": 0.46492695808410645, "train_time": 0.7594771385192871, "student_train_time": 0.020572900772094727, "throughput": 1605.9574635905021, "inference_time": 0.07103910146543058, "env_time": 0.39388785661867587, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 116, "reward_mean": 267.0, "student_loss": null, "teacher_policy_loss": -30.78430938720703, "teacher_value_loss": 677.437744140625, "teacher_entropy": 0.000511201738845557, "total_time": 1.4120433330535889, "rollout_time": 0.44303011894226074, "train_time": 0.9090642929077148, "student_train_time": 0.059389591217041016, "throughput": 1416.3871272101374, "inference_time": 0.06695865578330995, "env_time": 0.3760714631589508, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 117, "reward_mean": 195.3, "student_loss": null, "teacher_policy_loss": -30.021909713745117, "teacher_value_loss": 331.338134765625, "teacher_entropy": 0.00025714485673233867, "total_time": 1.3640947341918945, "rollout_time": 0.4976363182067871, "train_time": 0.8442814350128174, "student_train_time": 0.021801233291625977, "throughput": 1466.1738293307196, "inference_time": 0.07694973552133888, "env_time": 0.42068658268544823, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 118, "reward_mean": 214.58333333333334, "student_loss": null, "teacher_policy_loss": -28.057241439819336, "teacher_value_loss": 347.81719970703125, "teacher_entropy": 0.0001652140635997057, "total_time": 1.395592451095581, "rollout_time": 0.47516918182373047, "train_time": 0.9030554294586182, "student_train_time": 0.0169985294342041, "throughput": 1433.083131418446, "inference_time": 0.07257540944920038, "env_time": 0.4025937723745301, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 119, "reward_mean": 184.55555555555554, "student_loss": null, "teacher_policy_loss": -29.524646759033203, "teacher_value_loss": 446.0923156738281, "teacher_entropy": 8.356606122106314e-05, "total_time": 1.3914623260498047, "rollout_time": 0.4734354019165039, "train_time": 0.8942441940307617, "student_train_time": 0.023351430892944336, "throughput": 1437.3367949369933, "inference_time": 0.0741224772791611, "env_time": 0.3993129246373428, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 120, "reward_mean": 223.66666666666666, "student_loss": null, "teacher_policy_loss": -28.510883331298828, "teacher_value_loss": 362.8035583496094, "teacher_entropy": 7.022616046015173e-05, "total_time": 1.2047076225280762, "rollout_time": 0.44861721992492676, "train_time": 0.7338628768920898, "student_train_time": 0.021818876266479492, "throughput": 1660.1538519387839, "inference_time": 0.06882922201111796, "env_time": 0.3797879979138088, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 121, "reward_mean": 225.5, "student_loss": null, "teacher_policy_loss": -33.17473220825195, "teacher_value_loss": 495.8141174316406, "teacher_entropy": 0.00011098721734015271, "total_time": 1.3303117752075195, "rollout_time": 0.44248247146606445, "train_time": 0.8735775947570801, "student_train_time": 0.013874292373657227, "throughput": 1503.4069736682693, "inference_time": 0.06815073347024736, "env_time": 0.3743317379958171, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 122, "reward_mean": 274.75, "student_loss": null, "teacher_policy_loss": -32.91180419921875, "teacher_value_loss": 1096.8077392578125, "teacher_entropy": 0.0005451743490993977, "total_time": 1.2847046852111816, "rollout_time": 0.4652371406555176, "train_time": 0.7966933250427246, "student_train_time": 0.022256851196289062, "throughput": 1556.7780074463083, "inference_time": 0.07326032902346924, "env_time": 0.39197681163204834, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 123, "reward_mean": 300.42857142857144, "student_loss": null, "teacher_policy_loss": -34.37529373168945, "teacher_value_loss": 843.1880493164062, "teacher_entropy": 0.0011646451894193888, "total_time": 1.2120578289031982, "rollout_time": 0.45752382278442383, "train_time": 0.7394797801971436, "student_train_time": 0.014628410339355469, "throughput": 1650.0862849174594, "inference_time": 0.06922445102645725, "env_time": 0.3882993717579666, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 124, "reward_mean": 220.36363636363637, "student_loss": null, "teacher_policy_loss": -27.96998405456543, "teacher_value_loss": 415.79852294921875, "teacher_entropy": 0.0032216841354966164, "total_time": -1.285292148590088, "rollout_time": 0.4479670524597168, "train_time": -1.7580223083496094, "student_train_time": 0.02437734603881836, "throughput": 200000000000.0, "inference_time": 0.06860888776827778, "env_time": 0.379358164691439, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 125, "reward_mean": 215.77777777777777, "student_loss": null, "teacher_policy_loss": -30.905736923217773, "teacher_value_loss": 703.0799560546875, "teacher_entropy": 0.0017421796219423413, "total_time": 1.2221007347106934, "rollout_time": 0.4377610683441162, "train_time": 0.7675952911376953, "student_train_time": 0.016255855560302734, "throughput": 1636.5263052341245, "inference_time": 0.0681550620302005, "env_time": 0.3696060063139157, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 126, "reward_mean": 183.27272727272728, "student_loss": null, "teacher_policy_loss": -28.80103874206543, "teacher_value_loss": 312.4142761230469, "teacher_entropy": 0.000571030133869499, "total_time": 1.383842945098877, "rollout_time": 0.4344923496246338, "train_time": 0.9100923538208008, "student_train_time": 0.03882598876953125, "throughput": 1445.2507107712993, "inference_time": 0.06613002902849985, "env_time": 0.36836232059613394, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 127, "reward_mean": 172.91666666666666, "student_loss": null, "teacher_policy_loss": -27.91033363342285, "teacher_value_loss": 256.9788513183594, "teacher_entropy": 0.0001736345875542611, "total_time": 1.2484462261199951, "rollout_time": 0.45545172691345215, "train_time": 0.7712728977203369, "student_train_time": 0.021336078643798828, "throughput": 1601.9913057975546, "inference_time": 0.06671914073194785, "env_time": 0.3887325861815043, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 128, "reward_mean": 146.07142857142858, "student_loss": null, "teacher_policy_loss": -27.33842658996582, "teacher_value_loss": 475.7971496582031, "teacher_entropy": 8.359996718354523e-05, "total_time": 1.3159935474395752, "rollout_time": 0.4701235294342041, "train_time": 0.8222503662109375, "student_train_time": 0.023159265518188477, "throughput": 1519.7642905554076, "inference_time": 0.0741987256824359, "env_time": 0.3959248037517682, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 129, "reward_mean": 161.41666666666666, "student_loss": null, "teacher_policy_loss": -27.665239334106445, "teacher_value_loss": 843.24755859375, "teacher_entropy": 3.004494465130847e-05, "total_time": 1.2576878070831299, "rollout_time": 0.4574711322784424, "train_time": 0.7763442993164062, "student_train_time": 0.023416519165039062, "throughput": 1590.219757825644, "inference_time": 0.07210549426599755, "env_time": 0.38536563801244483, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 130, "reward_mean": 138.5, "student_loss": null, "teacher_policy_loss": -23.964357376098633, "teacher_value_loss": 588.0792846679688, "teacher_entropy": 2.6575882657198235e-05, "total_time": 1.2133474349975586, "rollout_time": 0.4360027313232422, "train_time": 0.7592618465423584, "student_train_time": 0.017678022384643555, "throughput": 1648.332491018143, "inference_time": 0.06715725303911313, "env_time": 0.36884547828412906, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 131, "reward_mean": 179.91666666666666, "student_loss": null, "teacher_policy_loss": -28.672346115112305, "teacher_value_loss": 537.2893676757812, "teacher_entropy": 2.4065297111519612e-05, "total_time": 1.3993737697601318, "rollout_time": 0.4527449607849121, "train_time": 0.9008285999298096, "student_train_time": 0.045426130294799805, "throughput": 1429.210724982234, "inference_time": 0.06931812352922861, "env_time": 0.3834268372556835, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 132, "reward_mean": 169.9090909090909, "student_loss": null, "teacher_policy_loss": -30.09723472595215, "teacher_value_loss": 489.9570617675781, "teacher_entropy": 3.061418465222232e-05, "total_time": 1.365321159362793, "rollout_time": 0.4609246253967285, "train_time": 0.8798079490661621, "student_train_time": 0.02390289306640625, "throughput": 1464.8568113698736, "inference_time": 0.06860274824975932, "env_time": 0.3923218771469692, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 133, "reward_mean": 171.58333333333334, "student_loss": null, "teacher_policy_loss": -26.80915069580078, "teacher_value_loss": 272.10186767578125, "teacher_entropy": 4.1291019442724064e-05, "total_time": 1.402322769165039, "rollout_time": 0.4490795135498047, "train_time": 0.9360051155090332, "student_train_time": 0.01677417755126953, "throughput": 1426.2051818432824, "inference_time": 0.06773302801411774, "env_time": 0.38134648553568695, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 134, "reward_mean": 158.5, "student_loss": null, "teacher_policy_loss": -30.89702796936035, "teacher_value_loss": 658.099365234375, "teacher_entropy": 7.536920747952536e-05, "total_time": 1.244351863861084, "rollout_time": 0.45973682403564453, "train_time": 0.7496931552886963, "student_train_time": 0.034548044204711914, "throughput": 1607.2624296107251, "inference_time": 0.07037212334034848, "env_time": 0.38936470069529605, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 135, "reward_mean": 209.1818181818182, "student_loss": null, "teacher_policy_loss": -28.699670791625977, "teacher_value_loss": 426.7038269042969, "teacher_entropy": 7.600065873702988e-05, "total_time": 1.2165298461914062, "rollout_time": 0.46160387992858887, "train_time": 0.7340285778045654, "student_train_time": 0.020517826080322266, "throughput": 1644.020495067512, "inference_time": 0.06866010693738644, "env_time": 0.3929437729912024, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 136, "reward_mean": 144.21428571428572, "student_loss": null, "teacher_policy_loss": -25.303546905517578, "teacher_value_loss": 252.55845642089844, "teacher_entropy": 0.0001130835444200784, "total_time": 1.4100289344787598, "rollout_time": 0.47221899032592773, "train_time": 0.9127194881439209, "student_train_time": 0.02471137046813965, "throughput": 1418.4106092399677, "inference_time": 0.07228694422883564, "env_time": 0.3999320460970921, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 137, "reward_mean": 190.9, "student_loss": null, "teacher_policy_loss": -30.284305572509766, "teacher_value_loss": 490.21868896484375, "teacher_entropy": 0.00015715243353042752, "total_time": 1.5857360363006592, "rollout_time": 0.47867369651794434, "train_time": 1.0703978538513184, "student_train_time": 0.03628206253051758, "throughput": 1261.2439612999974, "inference_time": 0.06814790022326633, "env_time": 0.410525796294678, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 138, "reward_mean": 190.0, "student_loss": null, "teacher_policy_loss": -28.46177101135254, "teacher_value_loss": 364.35858154296875, "teacher_entropy": 0.0002012548502534628, "total_time": 1.3250970840454102, "rollout_time": 0.46561217308044434, "train_time": 0.8307449817657471, "student_train_time": 0.028265953063964844, "throughput": 1509.3233726650185, "inference_time": 0.07162903954485955, "env_time": 0.3939831335355848, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 139, "reward_mean": 253.33333333333334, "student_loss": null, "teacher_policy_loss": -33.971012115478516, "teacher_value_loss": 473.0455627441406, "teacher_entropy": 6.539666355820373e-05, "total_time": 1.2959887981414795, "rollout_time": 0.46345043182373047, "train_time": 0.8133859634399414, "student_train_time": 0.018698453903198242, "throughput": 1543.2232152531813, "inference_time": 0.0743514919631707, "env_time": 0.38909893986055977, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 140, "reward_mean": 214.88888888888889, "student_loss": null, "teacher_policy_loss": -33.19889450073242, "teacher_value_loss": 667.6705322265625, "teacher_entropy": 7.431361154885963e-05, "total_time": 1.4242560863494873, "rollout_time": 0.4609830379486084, "train_time": 0.929563045501709, "student_train_time": 0.0333247184753418, "throughput": 1404.2418488982573, "inference_time": 0.07124587072030408, "env_time": 0.3897371672283043, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 141, "reward_mean": 283.25, "student_loss": null, "teacher_policy_loss": -31.67548370361328, "teacher_value_loss": 491.0009460449219, "teacher_entropy": 8.939180588640738e-06, "total_time": 1.2813847064971924, "rollout_time": 0.4719808101654053, "train_time": 0.7839982509613037, "student_train_time": 0.025036334991455078, "throughput": 1560.8115110622964, "inference_time": 0.07238577524003631, "env_time": 0.39959503492536896, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 142, "reward_mean": 204.88888888888889, "student_loss": null, "teacher_policy_loss": -30.2569637298584, "teacher_value_loss": 630.8404541015625, "teacher_entropy": 2.7104635591967963e-05, "total_time": 1.3798863887786865, "rollout_time": 0.4510467052459717, "train_time": 0.9019560813903809, "student_train_time": 0.026494979858398438, "throughput": 1449.394686594572, "inference_time": 0.0687111437709973, "env_time": 0.3823355614749744, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 143, "reward_mean": 300.85714285714283, "student_loss": null, "teacher_policy_loss": -32.96613311767578, "teacher_value_loss": 426.31536865234375, "teacher_entropy": 3.50217851519119e-05, "total_time": 1.3498344421386719, "rollout_time": 0.4535501003265381, "train_time": 0.8749678134918213, "student_train_time": 0.02094411849975586, "throughput": 1481.6631859172364, "inference_time": 0.06886398245842429, "env_time": 0.3846861178681138, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 144, "reward_mean": 243.55555555555554, "student_loss": null, "teacher_policy_loss": -31.279945373535156, "teacher_value_loss": 614.95166015625, "teacher_entropy": 5.622675234917551e-05, "total_time": 1.2835872173309326, "rollout_time": 0.462662935256958, "train_time": 0.8021211624145508, "student_train_time": 0.018373966217041016, "throughput": 1558.1333103010818, "inference_time": 0.06676708878876525, "env_time": 0.39589584646819276, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 145, "reward_mean": 252.28571428571428, "student_loss": null, "teacher_policy_loss": -32.72981643676758, "teacher_value_loss": 383.1642150878906, "teacher_entropy": 0.00010568137804511935, "total_time": 1.3172402381896973, "rollout_time": 0.44936370849609375, "train_time": 0.8430352210998535, "student_train_time": 0.024410724639892578, "throughput": 1518.3259226491816, "inference_time": 0.06815452501359687, "env_time": 0.3812091834824969, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 146, "reward_mean": 352.6666666666667, "student_loss": null, "teacher_policy_loss": -34.659793853759766, "teacher_value_loss": 538.083740234375, "teacher_entropy": 7.537786586908624e-05, "total_time": 1.272228717803955, "rollout_time": 0.4531090259552002, "train_time": 0.7989742755889893, "student_train_time": 0.01976633071899414, "throughput": 1572.0443753637946, "inference_time": 0.07031283652941056, "env_time": 0.38279618942578963, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 147, "reward_mean": 249.625, "student_loss": null, "teacher_policy_loss": -30.336545944213867, "teacher_value_loss": 644.787353515625, "teacher_entropy": 8.17347172414884e-05, "total_time": 1.348602533340454, "rollout_time": 0.44481801986694336, "train_time": 0.8660242557525635, "student_train_time": 0.03739500045776367, "throughput": 1483.0166417128485, "inference_time": 0.0686209044943098, "env_time": 0.37619711537263356, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 148, "reward_mean": 332.3333333333333, "student_loss": null, "teacher_policy_loss": -36.631568908691406, "teacher_value_loss": 563.8508911132812, "teacher_entropy": 0.00013646026491187513, "total_time": -1.3751106262207031, "rollout_time": -2.17920184135437, "train_time": 0.7762384414672852, "student_train_time": 0.02749490737915039, "throughput": 200000000000.0, "inference_time": 0.07215713970799698, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 149, "reward_mean": 267.2857142857143, "student_loss": null, "teacher_policy_loss": -33.77467346191406, "teacher_value_loss": 551.4051513671875, "teacher_entropy": 0.00018881475261878222, "total_time": 1.2167003154754639, "rollout_time": 0.44156336784362793, "train_time": 0.7578842639923096, "student_train_time": 0.01688671112060547, "throughput": 1643.7901548652408, "inference_time": 0.06814093797402165, "env_time": 0.3734224298696063, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 150, "reward_mean": 340.2, "student_loss": null, "teacher_policy_loss": -35.71756362915039, "teacher_value_loss": 623.4850463867188, "teacher_entropy": 0.0003423148882575333, "total_time": 1.316563367843628, "rollout_time": 0.4598226547241211, "train_time": 0.83156418800354, "student_train_time": 0.024812698364257812, "throughput": 1519.1065229740964, "inference_time": 0.06910412047000136, "env_time": 0.39071853425411973, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 151, "reward_mean": 285.2857142857143, "student_loss": null, "teacher_policy_loss": -33.27287673950195, "teacher_value_loss": 448.0850830078125, "teacher_entropy": 0.00018199431360699236, "total_time": 1.2667555809020996, "rollout_time": 0.4395885467529297, "train_time": 0.8072094917297363, "student_train_time": 0.019598960876464844, "throughput": 1578.8365412810988, "inference_time": 0.06631798843955039, "env_time": 0.3732705583133793, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 152, "reward_mean": 291.7142857142857, "student_loss": null, "teacher_policy_loss": -32.57380294799805, "teacher_value_loss": 557.6944580078125, "teacher_entropy": 4.1495128243695945e-05, "total_time": 1.3831231594085693, "rollout_time": 0.43639230728149414, "train_time": 0.9200506210327148, "student_train_time": 0.026259660720825195, "throughput": 1446.0028280165668, "inference_time": 0.06649938099326391, "env_time": 0.36989292628823023, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 153, "reward_mean": 361.75, "student_loss": null, "teacher_policy_loss": -40.556522369384766, "teacher_value_loss": 583.3328857421875, "teacher_entropy": 2.0971465346519835e-05, "total_time": 1.2418913841247559, "rollout_time": 0.46250391006469727, "train_time": 0.7564201354980469, "student_train_time": 0.02259683609008789, "throughput": 1610.4467955621853, "inference_time": 0.07399771878772299, "env_time": 0.3885061912769743, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 154, "reward_mean": 349.42857142857144, "student_loss": null, "teacher_policy_loss": -33.587703704833984, "teacher_value_loss": 932.89306640625, "teacher_entropy": 1.335857632511761e-06, "total_time": 1.259488582611084, "rollout_time": 0.4425489902496338, "train_time": 0.7934975624084473, "student_train_time": 0.02299785614013672, "throughput": 1587.9461136946072, "inference_time": 0.07079105145567155, "env_time": 0.37175793879396224, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 155, "reward_mean": 334.2857142857143, "student_loss": null, "teacher_policy_loss": -34.92946243286133, "teacher_value_loss": 948.081787109375, "teacher_entropy": 7.63168486628274e-07, "total_time": 1.2264070510864258, "rollout_time": 0.4422130584716797, "train_time": 0.7681999206542969, "student_train_time": 0.015625953674316406, "throughput": 1630.7799259864648, "inference_time": 0.06769395297669689, "env_time": 0.3745191054949828, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 156, "reward_mean": 293.0, "student_loss": null, "teacher_policy_loss": -36.101898193359375, "teacher_value_loss": 773.5951538085938, "teacher_entropy": 1.535719547973713e-06, "total_time": 1.227543830871582, "rollout_time": 0.44054603576660156, "train_time": 0.7667362689971924, "student_train_time": 0.01981353759765625, "throughput": 1629.2697252039936, "inference_time": 0.06652741601828893, "env_time": 0.37401861974831263, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 157, "reward_mean": 377.0, "student_loss": null, "teacher_policy_loss": -36.55358123779297, "teacher_value_loss": 517.5564575195312, "teacher_entropy": 0.00014972046483308077, "total_time": 1.380596399307251, "rollout_time": 0.457700252532959, "train_time": 0.8771171569824219, "student_train_time": 0.04540228843688965, "throughput": 1448.649294611771, "inference_time": 0.07227504331422097, "env_time": 0.385425209218738, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 158, "reward_mean": 358.2, "student_loss": null, "teacher_policy_loss": -39.25263214111328, "teacher_value_loss": 401.7186279296875, "teacher_entropy": 0.00022660207469016314, "total_time": 1.2840707302093506, "rollout_time": 0.4534926414489746, "train_time": 0.8114466667175293, "student_train_time": 0.018764257431030273, "throughput": 1557.5466000022652, "inference_time": 0.07184013725418481, "env_time": 0.3816525041947898, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 159, "reward_mean": 343.2857142857143, "student_loss": null, "teacher_policy_loss": -33.8099479675293, "teacher_value_loss": 698.5887451171875, "teacher_entropy": 0.00026722485199570656, "total_time": 1.658998727798462, "rollout_time": 0.45752525329589844, "train_time": 1.1805446147918701, "student_train_time": 0.02056121826171875, "throughput": 1205.5464338143624, "inference_time": 0.06928122542376514, "env_time": 0.3882440278721333, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 160, "reward_mean": 360.1666666666667, "student_loss": null, "teacher_policy_loss": -33.9807243347168, "teacher_value_loss": 608.4921264648438, "teacher_entropy": 0.00016786711057648063, "total_time": 1.315335750579834, "rollout_time": 0.4627690315246582, "train_time": 0.8331456184387207, "student_train_time": 0.01904296875, "throughput": 1520.5243217318075, "inference_time": 0.07144668005457788, "env_time": 0.3913223514700803, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 161, "reward_mean": 282.6666666666667, "student_loss": null, "teacher_policy_loss": -32.41158676147461, "teacher_value_loss": 381.9018859863281, "teacher_entropy": 0.0009645042009651661, "total_time": 1.3559746742248535, "rollout_time": 0.45429372787475586, "train_time": 0.8773934841156006, "student_train_time": 0.02390885353088379, "throughput": 1474.9538011418283, "inference_time": 0.0694831175278523, "env_time": 0.38481061034690356, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 162, "reward_mean": 367.3333333333333, "student_loss": null, "teacher_policy_loss": -34.671356201171875, "teacher_value_loss": 708.0421142578125, "teacher_entropy": 0.0016383311012759805, "total_time": 1.307257890701294, "rollout_time": 0.48286890983581543, "train_time": 0.7931106090545654, "student_train_time": 0.030895471572875977, "throughput": 1529.920006011267, "inference_time": 0.07172248677306925, "env_time": 0.4111464230627462, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 163, "reward_mean": 405.8333333333333, "student_loss": null, "teacher_policy_loss": -38.73371887207031, "teacher_value_loss": 1092.878662109375, "teacher_entropy": 0.0002823240065481514, "total_time": 1.2170915603637695, "rollout_time": 0.4403204917907715, "train_time": 0.7562394142150879, "student_train_time": 0.02016735076904297, "throughput": 1643.2617439251912, "inference_time": 0.0691630559758778, "env_time": 0.3711574358148937, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 164, "reward_mean": 308.8, "student_loss": null, "teacher_policy_loss": -34.39049530029297, "teacher_value_loss": 762.4400024414062, "teacher_entropy": 0.00018384282884653658, "total_time": 1.4191851615905762, "rollout_time": 0.46628737449645996, "train_time": 0.9308891296386719, "student_train_time": 0.0216372013092041, "throughput": 1409.2593793458675, "inference_time": 0.07320989478648698, "env_time": 0.393077479709973, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 165, "reward_mean": 315.0, "student_loss": null, "teacher_policy_loss": -34.87941360473633, "teacher_value_loss": 883.96728515625, "teacher_entropy": 0.0005997937987558544, "total_time": 1.2457313537597656, "rollout_time": 0.4540383815765381, "train_time": 0.775306224822998, "student_train_time": 0.016021728515625, "throughput": 1605.482589776489, "inference_time": 0.07040958217839943, "env_time": 0.38362879939813865, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 166, "reward_mean": 351.0, "student_loss": null, "teacher_policy_loss": -34.56733322143555, "teacher_value_loss": 848.4060668945312, "teacher_entropy": 0.0003279547963757068, "total_time": 1.380946159362793, "rollout_time": 0.4513719081878662, "train_time": 0.9147899150848389, "student_train_time": 0.014423847198486328, "throughput": 1448.2823869996898, "inference_time": 0.07113970069622155, "env_time": 0.38023220749164466, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 167, "reward_mean": 353.6666666666667, "student_loss": null, "teacher_policy_loss": -32.97792053222656, "teacher_value_loss": 672.82861328125, "teacher_entropy": 0.0001459386694477871, "total_time": 1.2669720649719238, "rollout_time": 0.4634385108947754, "train_time": 0.7788693904876709, "student_train_time": 0.02425551414489746, "throughput": 1578.5667697766644, "inference_time": 0.07025961129329517, "env_time": 0.3931788996014802, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 168, "reward_mean": 456.0, "student_loss": null, "teacher_policy_loss": -36.02043533325195, "teacher_value_loss": 587.9584350585938, "teacher_entropy": 8.471665205433965e-05, "total_time": 1.3256590366363525, "rollout_time": 0.4605405330657959, "train_time": 0.8469865322113037, "student_train_time": 0.0177304744720459, "throughput": 1508.6835639688163, "inference_time": 0.07510341828856326, "env_time": 0.38543711477723264, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 169, "reward_mean": 431.4, "student_loss": null, "teacher_policy_loss": -36.52810287475586, "teacher_value_loss": 638.6592407226562, "teacher_entropy": 2.654051422723569e-05, "total_time": 1.6346697807312012, "rollout_time": 0.670964241027832, "train_time": 0.7698590755462646, "student_train_time": 0.19347906112670898, "throughput": 1223.4886969681324, "inference_time": 0.11253030676743947, "env_time": 0.5584339342603926, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 170, "reward_mean": 361.75, "student_loss": null, "teacher_policy_loss": -38.235897064208984, "teacher_value_loss": 548.209228515625, "teacher_entropy": 6.364009550452465e-06, "total_time": 1.2078325748443604, "rollout_time": 0.43912220001220703, "train_time": 0.7485044002532959, "student_train_time": 0.019826650619506836, "throughput": 1655.8586360843242, "inference_time": 0.06510319197332137, "env_time": 0.37401900803888566, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 171, "reward_mean": 407.3333333333333, "student_loss": null, "teacher_policy_loss": -35.72404479980469, "teacher_value_loss": 611.9382934570312, "teacher_entropy": 7.8812727224431e-06, "total_time": -1.266890048980713, "rollout_time": 0.4575657844543457, "train_time": -1.7517335414886475, "student_train_time": 0.026759862899780273, "throughput": 200000000000.0, "inference_time": 0.07007027001054666, "env_time": 0.38749551444379904, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 172, "reward_mean": 373.3333333333333, "student_loss": null, "teacher_policy_loss": -35.00800323486328, "teacher_value_loss": 813.7108764648438, "teacher_entropy": 1.8945178453577682e-05, "total_time": 1.2260313034057617, "rollout_time": 0.44559645652770996, "train_time": 0.7588176727294922, "student_train_time": 0.02125239372253418, "throughput": 1631.2797189143948, "inference_time": 0.06726448199697188, "env_time": 0.3783319745307381, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 173, "reward_mean": 435.25, "student_loss": null, "teacher_policy_loss": -37.3317756652832, "teacher_value_loss": 676.92724609375, "teacher_entropy": 4.942173291055951e-06, "total_time": 1.3254470825195312, "rollout_time": 0.4413299560546875, "train_time": 0.8602240085601807, "student_train_time": 0.023487329483032227, "throughput": 1508.9248196904375, "inference_time": 0.06802974798483774, "env_time": 0.37330020806984976, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 174, "reward_mean": 367.25, "student_loss": null, "teacher_policy_loss": -36.85014343261719, "teacher_value_loss": 569.4144897460938, "teacher_entropy": 1.4259598174248822e-05, "total_time": 1.237088680267334, "rollout_time": 0.45793652534484863, "train_time": 0.7601175308227539, "student_train_time": 0.018334388732910156, "throughput": 1616.6989738907007, "inference_time": 0.07049812546574685, "env_time": 0.3874383998791018, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 175, "reward_mean": 322.6666666666667, "student_loss": null, "teacher_policy_loss": -36.007110595703125, "teacher_value_loss": 623.234619140625, "teacher_entropy": 3.9780094084562734e-05, "total_time": 1.2365238666534424, "rollout_time": 0.43961381912231445, "train_time": 0.7609555721282959, "student_train_time": 0.035596609115600586, "throughput": 1617.437442119777, "inference_time": 0.06787184671156865, "env_time": 0.3717419724107458, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 176, "reward_mean": 406.4, "student_loss": null, "teacher_policy_loss": -38.05412673950195, "teacher_value_loss": 461.74517822265625, "teacher_entropy": 2.241312358819414e-05, "total_time": 1.4034695625305176, "rollout_time": 0.4614429473876953, "train_time": 0.9166858196258545, "student_train_time": 0.024976253509521484, "throughput": 1425.039810905419, "inference_time": 0.0689659089603083, "env_time": 0.392477038427387, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 177, "reward_mean": 366.57142857142856, "student_loss": null, "teacher_policy_loss": -33.01616287231445, "teacher_value_loss": 530.8568115234375, "teacher_entropy": 9.206727554555982e-05, "total_time": 1.2524139881134033, "rollout_time": 0.4435913562774658, "train_time": 0.7876241207122803, "student_train_time": 0.020834922790527344, "throughput": 1596.916050908004, "inference_time": 0.07084447353008727, "env_time": 0.37274688274737855, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 178, "reward_mean": 419.8, "student_loss": null, "teacher_policy_loss": -35.78364562988281, "teacher_value_loss": 422.19140625, "teacher_entropy": 0.0004606659058481455, "total_time": 1.3517816066741943, "rollout_time": 0.43740415573120117, "train_time": 0.8888170719146729, "student_train_time": 0.02519965171813965, "throughput": 1479.528934352514, "inference_time": 0.06876089873730962, "env_time": 0.36864325699389155, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 179, "reward_mean": 335.6666666666667, "student_loss": null, "teacher_policy_loss": -34.096736907958984, "teacher_value_loss": 564.8342895507812, "teacher_entropy": 0.0005168905481696129, "total_time": 1.1636269092559814, "rollout_time": 0.4475119113922119, "train_time": 0.6959097385406494, "student_train_time": 0.019840240478515625, "throughput": 1718.763964713391, "inference_time": 0.06932893749399227, "env_time": 0.37818297389821964, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 180, "reward_mean": 294.0, "student_loss": null, "teacher_policy_loss": -31.088409423828125, "teacher_value_loss": 557.9837036132812, "teacher_entropy": 0.0009206906543113291, "total_time": 1.3143959045410156, "rollout_time": 0.4408528804779053, "train_time": 0.8553586006164551, "student_train_time": 0.017756223678588867, "throughput": 1521.6115578954089, "inference_time": 0.06654506597442378, "env_time": 0.3743078145034815, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 181, "reward_mean": 332.2, "student_loss": null, "teacher_policy_loss": -34.49018859863281, "teacher_value_loss": 521.7572631835938, "teacher_entropy": 0.0005036801449023187, "total_time": 1.2900545597076416, "rollout_time": 0.4804196357727051, "train_time": 0.7859556674957275, "student_train_time": 0.023313283920288086, "throughput": 1550.3220270414374, "inference_time": 0.07165208347760199, "env_time": 0.4087675522951031, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 182, "reward_mean": 415.4, "student_loss": null, "teacher_policy_loss": -37.1069450378418, "teacher_value_loss": 685.1571655273438, "teacher_entropy": 0.0004795220447704196, "total_time": 1.2177634239196777, "rollout_time": 0.4388546943664551, "train_time": 0.7425210475921631, "student_train_time": 0.03588104248046875, "throughput": 1642.3551247437676, "inference_time": 0.06734553421119926, "env_time": 0.3715091601552558, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 183, "reward_mean": 269.875, "student_loss": null, "teacher_policy_loss": -32.046871185302734, "teacher_value_loss": 347.25244140625, "teacher_entropy": 0.0005485746078193188, "total_time": 1.365034818649292, "rollout_time": 0.45975446701049805, "train_time": 0.8803491592407227, "student_train_time": 0.024475812911987305, "throughput": 1465.1640915497005, "inference_time": 0.07279614999970363, "env_time": 0.3869583170107944, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 184, "reward_mean": 329.0, "student_loss": null, "teacher_policy_loss": -34.85173034667969, "teacher_value_loss": 452.07550048828125, "teacher_entropy": 0.0004331071104388684, "total_time": 1.2259652614593506, "rollout_time": 0.45817112922668457, "train_time": 0.7537779808044434, "student_train_time": 0.013610363006591797, "throughput": 1631.367594885407, "inference_time": 0.07103459102290799, "env_time": 0.3871365382037766, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 185, "reward_mean": 284.0, "student_loss": null, "teacher_policy_loss": -32.30866622924805, "teacher_value_loss": 416.2339782714844, "teacher_entropy": 0.0003215129254385829, "total_time": 1.5346853733062744, "rollout_time": 0.5764532089233398, "train_time": 0.9373576641082764, "student_train_time": 0.020500659942626953, "throughput": 1303.198710815408, "inference_time": 0.08625983571073448, "env_time": 0.49019337321260537, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 186, "reward_mean": 282.2857142857143, "student_loss": null, "teacher_policy_loss": -32.48493576049805, "teacher_value_loss": 450.9200439453125, "teacher_entropy": 0.0002482034033164382, "total_time": 1.2630436420440674, "rollout_time": 0.46373796463012695, "train_time": 0.7811620235443115, "student_train_time": 0.017732858657836914, "throughput": 1583.4765588647967, "inference_time": 0.06923949049996736, "env_time": 0.3944984741301596, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 187, "reward_mean": 308.5, "student_loss": null, "teacher_policy_loss": -34.292015075683594, "teacher_value_loss": 411.5453186035156, "teacher_entropy": 0.00014429885777644813, "total_time": 1.2394874095916748, "rollout_time": 0.43485569953918457, "train_time": 0.7854375839233398, "student_train_time": 0.018815994262695312, "throughput": 1613.5702424430929, "inference_time": 0.06835909601431922, "env_time": 0.36649660352486535, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 188, "reward_mean": 284.5, "student_loss": null, "teacher_policy_loss": -31.875606536865234, "teacher_value_loss": 431.9623107910156, "teacher_entropy": 0.00019264484581071883, "total_time": 1.3482351303100586, "rollout_time": 0.46610188484191895, "train_time": 0.8539605140686035, "student_train_time": 0.027707815170288086, "throughput": 1483.4207736005608, "inference_time": 0.07254091217873793, "env_time": 0.393560972663181, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 189, "reward_mean": 269.0, "student_loss": null, "teacher_policy_loss": -32.778324127197266, "teacher_value_loss": 448.3203430175781, "teacher_entropy": 0.00022919148614164442, "total_time": 1.2315223217010498, "rollout_time": 0.44724297523498535, "train_time": 0.7656419277191162, "student_train_time": 0.018262624740600586, "throughput": 1624.0062926650687, "inference_time": 0.07152395549201174, "env_time": 0.3757190197429736, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 190, "reward_mean": 291.8333333333333, "student_loss": null, "teacher_policy_loss": -36.8392219543457, "teacher_value_loss": 426.6513366699219, "teacher_entropy": 0.000188894453458488, "total_time": 1.3631689548492432, "rollout_time": 0.4395148754119873, "train_time": 0.8965058326721191, "student_train_time": 0.026773691177368164, "throughput": 1467.1695631604123, "inference_time": 0.06671349700263818, "env_time": 0.3728013784093491, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 191, "reward_mean": 297.57142857142856, "student_loss": null, "teacher_policy_loss": -33.60263442993164, "teacher_value_loss": 537.0044555664062, "teacher_entropy": 0.00023563804279547185, "total_time": 1.2947726249694824, "rollout_time": 0.45484447479248047, "train_time": 0.8160929679870605, "student_train_time": 0.023402929306030273, "throughput": 1544.6727567685018, "inference_time": 0.07001562904224556, "env_time": 0.3848288457502349, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 192, "reward_mean": 336.8333333333333, "student_loss": null, "teacher_policy_loss": -33.52512741088867, "teacher_value_loss": 585.173095703125, "teacher_entropy": 0.00010440725600346923, "total_time": 1.308424949645996, "rollout_time": 0.4444732666015625, "train_time": 0.8475687503814697, "student_train_time": 0.01581859588623047, "throughput": 1528.555382974862, "inference_time": 0.0679098254749988, "env_time": 0.3765634411265637, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 193, "reward_mean": 267.85714285714283, "student_loss": null, "teacher_policy_loss": -33.551719665527344, "teacher_value_loss": 443.76275634765625, "teacher_entropy": 5.0487415137467906e-05, "total_time": 1.3117125034332275, "rollout_time": 0.46131300926208496, "train_time": 0.8214192390441895, "student_train_time": 0.028603553771972656, "throughput": 1524.7243544338216, "inference_time": 0.07102299344660423, "env_time": 0.39029001581548073, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 194, "reward_mean": 363.3333333333333, "student_loss": null, "teacher_policy_loss": -33.78791809082031, "teacher_value_loss": 654.2567138671875, "teacher_entropy": 0.00016720719577278942, "total_time": 1.268796443939209, "rollout_time": 0.47196054458618164, "train_time": 0.7752504348754883, "student_train_time": 0.021214723587036133, "throughput": 1576.2969777804838, "inference_time": 0.07166078170848778, "env_time": 0.40029976287769387, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 195, "reward_mean": 379.42857142857144, "student_loss": null, "teacher_policy_loss": -34.5943489074707, "teacher_value_loss": 676.0619506835938, "teacher_entropy": 9.045046681421809e-06, "total_time": -1.2680141925811768, "rollout_time": -2.183732748031616, "train_time": 0.8626322746276855, "student_train_time": 0.05266237258911133, "throughput": 200000000000.0, "inference_time": 0.0687406822671619, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 196, "reward_mean": 262.8, "student_loss": null, "teacher_policy_loss": -36.3336296081543, "teacher_value_loss": 739.263916015625, "teacher_entropy": 1.1283682397333905e-06, "total_time": 1.1929771900177002, "rollout_time": 0.43763184547424316, "train_time": 0.7287452220916748, "student_train_time": 0.026233434677124023, "throughput": 1676.4779886280357, "inference_time": 0.06693878123769537, "env_time": 0.3706930642365478, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 197, "reward_mean": 277.0, "student_loss": null, "teacher_policy_loss": -34.440040588378906, "teacher_value_loss": 716.26708984375, "teacher_entropy": 5.240618179414014e-07, "total_time": 1.3023576736450195, "rollout_time": 0.44045209884643555, "train_time": 0.8410272598266602, "student_train_time": 0.02052450180053711, "throughput": 1535.6764431712752, "inference_time": 0.06743525898855296, "env_time": 0.3730168398578826, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 198, "reward_mean": 400.4, "student_loss": null, "teacher_policy_loss": -37.49803924560547, "teacher_value_loss": 609.457763671875, "teacher_entropy": 5.709679317078553e-05, "total_time": 1.548166036605835, "rollout_time": 0.5031187534332275, "train_time": 0.7432973384857178, "student_train_time": 0.30132341384887695, "throughput": 1291.8511016975647, "inference_time": 0.0781568494712701, "env_time": 0.42496190396195743, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 199, "reward_mean": 427.75, "student_loss": null, "teacher_policy_loss": -36.94917297363281, "teacher_value_loss": 600.7028198242188, "teacher_entropy": 1.2187847460154444e-06, "total_time": 1.2013423442840576, "rollout_time": 0.42910289764404297, "train_time": 0.7471761703491211, "student_train_time": 0.024626970291137695, "throughput": 1664.804382793902, "inference_time": 0.0668161137655261, "env_time": 0.36228678387851687, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 200, "reward_mean": 377.7142857142857, "student_loss": null, "teacher_policy_loss": -34.53977584838867, "teacher_value_loss": 618.4130859375, "teacher_entropy": 2.3045715352054685e-05, "total_time": 1.307380199432373, "rollout_time": 0.47796154022216797, "train_time": 0.8036818504333496, "student_train_time": 0.02532792091369629, "throughput": 1529.776878117278, "inference_time": 0.07297907272550219, "env_time": 0.4049824674966658, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 201, "reward_mean": 308.4, "student_loss": null, "teacher_policy_loss": -34.792301177978516, "teacher_value_loss": 574.1456298828125, "teacher_entropy": 5.236751530901529e-05, "total_time": 1.267643928527832, "rollout_time": 0.4325733184814453, "train_time": 0.8001861572265625, "student_train_time": 0.034462928771972656, "throughput": 1577.7301141044265, "inference_time": 0.06694353023522126, "env_time": 0.36562978824622405, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 202, "reward_mean": 364.6666666666667, "student_loss": null, "teacher_policy_loss": -34.542179107666016, "teacher_value_loss": 701.55322265625, "teacher_entropy": 1.7618120182305574e-05, "total_time": 1.4071176052093506, "rollout_time": 0.4476602077484131, "train_time": 0.9276604652404785, "student_train_time": 0.03142809867858887, "throughput": 1421.3453037583454, "inference_time": 0.06761419677241065, "env_time": 0.38004601097600244, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 203, "reward_mean": 457.75, "student_loss": null, "teacher_policy_loss": -37.99797058105469, "teacher_value_loss": 687.8010864257812, "teacher_entropy": 3.7526231722040393e-07, "total_time": 1.2051401138305664, "rollout_time": 0.4345827102661133, "train_time": 0.7547509670257568, "student_train_time": 0.01538228988647461, "throughput": 1659.5580688480716, "inference_time": 0.0699135610320809, "env_time": 0.3646691492340324, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 204, "reward_mean": 469.0, "student_loss": null, "teacher_policy_loss": -37.734230041503906, "teacher_value_loss": 742.0607299804688, "teacher_entropy": 8.036879080464132e-06, "total_time": 1.2888586521148682, "rollout_time": 0.4471292495727539, "train_time": 0.8214952945709229, "student_train_time": 0.019807815551757812, "throughput": 1551.760541559954, "inference_time": 0.06855136999911338, "env_time": 0.37857787957364053, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 205, "reward_mean": 445.8, "student_loss": null, "teacher_policy_loss": -38.40532302856445, "teacher_value_loss": 755.8416137695312, "teacher_entropy": 2.327102265553549e-05, "total_time": 1.2582645416259766, "rollout_time": 0.4637327194213867, "train_time": 0.7677485942840576, "student_train_time": 0.026332616806030273, "throughput": 1589.4908692376605, "inference_time": 0.0703127862943802, "env_time": 0.3934199331270065, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 206, "reward_mean": 392.8, "student_loss": null, "teacher_policy_loss": -34.1281852722168, "teacher_value_loss": 406.8665771484375, "teacher_entropy": 3.257084244978614e-05, "total_time": 1.2426128387451172, "rollout_time": 0.44478917121887207, "train_time": 0.7707889080047607, "student_train_time": 0.026655197143554688, "throughput": 1609.5117784391707, "inference_time": 0.06819460303995584, "env_time": 0.37659456817891623, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 207, "reward_mean": 359.8, "student_loss": null, "teacher_policy_loss": -37.68138122558594, "teacher_value_loss": 551.9713745117188, "teacher_entropy": 5.979105844744481e-05, "total_time": 1.3367013931274414, "rollout_time": 0.45380091667175293, "train_time": 0.8529412746429443, "student_train_time": 0.02955770492553711, "throughput": 1496.2204799687222, "inference_time": 0.0696380590161425, "env_time": 0.3841628576556104, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 208, "reward_mean": 342.2, "student_loss": null, "teacher_policy_loss": -37.6584358215332, "teacher_value_loss": 653.50048828125, "teacher_entropy": 7.97700704424642e-05, "total_time": 1.2334010601043701, "rollout_time": 0.4508357048034668, "train_time": 0.7554314136505127, "student_train_time": 0.02675318717956543, "throughput": 1621.5325774332969, "inference_time": 0.0690223952242377, "env_time": 0.3818133095792291, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 209, "reward_mean": 425.1666666666667, "student_loss": null, "teacher_policy_loss": -36.88056945800781, "teacher_value_loss": 701.3953857421875, "teacher_entropy": 5.472432167152874e-05, "total_time": 1.8914551734924316, "rollout_time": 0.6461923122406006, "train_time": 0.9478304386138916, "student_train_time": 0.296994686126709, "throughput": 1057.3869410328919, "inference_time": 0.08046861573893693, "env_time": 0.5657236965016637, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 210, "reward_mean": 436.75, "student_loss": null, "teacher_policy_loss": -36.56444549560547, "teacher_value_loss": 600.9940185546875, "teacher_entropy": 2.2945563614484854e-05, "total_time": 1.2605137825012207, "rollout_time": 0.47002720832824707, "train_time": 0.765967845916748, "student_train_time": 0.024137496948242188, "throughput": 1586.6546068472387, "inference_time": 0.07112597697596357, "env_time": 0.3989012313522835, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 211, "reward_mean": 425.6, "student_loss": null, "teacher_policy_loss": -37.42534637451172, "teacher_value_loss": 563.3178100585938, "teacher_entropy": 2.3402206352329813e-05, "total_time": 1.4035379886627197, "rollout_time": 0.44223904609680176, "train_time": 0.9400601387023926, "student_train_time": 0.02087092399597168, "throughput": 1424.9703365033852, "inference_time": 0.06811404569452861, "env_time": 0.37412500040227314, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 212, "reward_mean": 388.3333333333333, "student_loss": null, "teacher_policy_loss": -33.95457458496094, "teacher_value_loss": 616.7953491210938, "teacher_entropy": 2.9811521017109044e-05, "total_time": 1.4402523040771484, "rollout_time": 0.5918653011322021, "train_time": 0.8201148509979248, "student_train_time": 0.02779984474182129, "throughput": 1388.645582679011, "inference_time": 0.09393975000966748, "env_time": 0.49792555112253467, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 213, "reward_mean": 305.8333333333333, "student_loss": null, "teacher_policy_loss": -33.27172088623047, "teacher_value_loss": 496.2096252441406, "teacher_entropy": 7.812684634700418e-05, "total_time": 1.8686304092407227, "rollout_time": 0.43915843963623047, "train_time": 1.3906068801879883, "student_train_time": 0.038496971130371094, "throughput": 1070.3026077867676, "inference_time": 0.0685301157500362, "env_time": 0.37062832388619427, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 214, "reward_mean": 294.25, "student_loss": null, "teacher_policy_loss": -30.732994079589844, "teacher_value_loss": 369.13238525390625, "teacher_entropy": 0.00012928570504300296, "total_time": 1.2444021701812744, "rollout_time": 0.45355677604675293, "train_time": 0.7735464572906494, "student_train_time": 0.016929149627685547, "throughput": 1607.1974542672617, "inference_time": 0.07296621299974504, "env_time": 0.3805905630470079, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 215, "reward_mean": 237.875, "student_loss": null, "teacher_policy_loss": -31.839048385620117, "teacher_value_loss": 447.1134338378906, "teacher_entropy": 0.00025521713541820645, "total_time": 1.2685737609863281, "rollout_time": 0.4387972354888916, "train_time": 0.814565896987915, "student_train_time": 0.014765739440917969, "throughput": 1576.573677864014, "inference_time": 0.06777696803146682, "env_time": 0.3710202674574248, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 216, "reward_mean": 224.3, "student_loss": null, "teacher_policy_loss": -28.378440856933594, "teacher_value_loss": 215.29013061523438, "teacher_entropy": 0.0009286599233746529, "total_time": 1.3599412441253662, "rollout_time": 0.48916149139404297, "train_time": 0.8411767482757568, "student_train_time": 0.02922368049621582, "throughput": 1470.6517716405326, "inference_time": 0.07357968274845916, "env_time": 0.4155818086455838, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 217, "reward_mean": 175.45454545454547, "student_loss": null, "teacher_policy_loss": -26.803821563720703, "teacher_value_loss": 178.47116088867188, "teacher_entropy": 0.0036811295431107283, "total_time": -1.1872336864471436, "rollout_time": 0.4844036102294922, "train_time": -1.695443868637085, "student_train_time": 0.02343273162841797, "throughput": 200000000000.0, "inference_time": 0.0777283839724987, "env_time": 0.4066752262569935, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 218, "reward_mean": 180.0909090909091, "student_loss": null, "teacher_policy_loss": -26.84902572631836, "teacher_value_loss": 232.1664276123047, "teacher_entropy": 0.005746933631598949, "total_time": 1.3477671146392822, "rollout_time": 0.45728445053100586, "train_time": 0.8585200309753418, "student_train_time": 0.031594038009643555, "throughput": 1483.9358953607368, "inference_time": 0.06953147470449039, "env_time": 0.38775297582651547, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 219, "reward_mean": 166.0, "student_loss": null, "teacher_policy_loss": -24.227827072143555, "teacher_value_loss": 170.663818359375, "teacher_entropy": 0.007421643007546663, "total_time": 1.2780077457427979, "rollout_time": 0.44484901428222656, "train_time": 0.8021550178527832, "student_train_time": 0.030631542205810547, "throughput": 1564.9357421050443, "inference_time": 0.0679402177738666, "env_time": 0.37690879650835996, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 220, "reward_mean": 144.15384615384616, "student_loss": null, "teacher_policy_loss": -24.427536010742188, "teacher_value_loss": 276.9862976074219, "teacher_entropy": 0.004704756662249565, "total_time": 1.341519832611084, "rollout_time": 0.45015549659729004, "train_time": 0.8635735511779785, "student_train_time": 0.027359962463378906, "throughput": 1490.8463903267645, "inference_time": 0.06794639218060183, "env_time": 0.3822091044166882, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 221, "reward_mean": 138.5, "student_loss": null, "teacher_policy_loss": -22.33507537841797, "teacher_value_loss": 192.55224609375, "teacher_entropy": 0.004565227311104536, "total_time": 1.2451746463775635, "rollout_time": 0.45235157012939453, "train_time": 0.7678430080413818, "student_train_time": 0.024565935134887695, "throughput": 1606.2003878880437, "inference_time": 0.06917759976386151, "env_time": 0.383173970365533, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 222, "reward_mean": 122.66666666666667, "student_loss": null, "teacher_policy_loss": -22.258380889892578, "teacher_value_loss": 219.76353454589844, "teacher_entropy": 0.003010648535564542, "total_time": 1.2338347434997559, "rollout_time": 0.44254159927368164, "train_time": 0.7692022323608398, "student_train_time": 0.021730661392211914, "throughput": 1620.9626212397186, "inference_time": 0.06862560979061527, "env_time": 0.37391598948306637, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 223, "reward_mean": 131.2, "student_loss": null, "teacher_policy_loss": -22.258987426757812, "teacher_value_loss": 180.634033203125, "teacher_entropy": 0.0025638265069574118, "total_time": 1.402402400970459, "rollout_time": 0.49805355072021484, "train_time": 0.8704664707183838, "student_train_time": 0.03350043296813965, "throughput": 1426.1241984583062, "inference_time": 0.06977151067803788, "env_time": 0.42828204004217696, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 224, "reward_mean": 112.66666666666667, "student_loss": null, "teacher_policy_loss": -21.462411880493164, "teacher_value_loss": 219.5264129638672, "teacher_entropy": 0.0016723877051845193, "total_time": 1.2121729850769043, "rollout_time": 0.4532461166381836, "train_time": 0.7415981292724609, "student_train_time": 0.01691436767578125, "throughput": 1649.9295270741522, "inference_time": 0.0710674972669949, "env_time": 0.3821786193711887, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 225, "reward_mean": 120.66666666666667, "student_loss": null, "teacher_policy_loss": -21.204023361206055, "teacher_value_loss": 204.1123504638672, "teacher_entropy": 0.0013392278924584389, "total_time": 1.3398756980895996, "rollout_time": 0.4548218250274658, "train_time": 0.8622159957885742, "student_train_time": 0.022403717041015625, "throughput": 1492.6757779483637, "inference_time": 0.0710009497088322, "env_time": 0.3838208753186336, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 226, "reward_mean": 118.33333333333333, "student_loss": null, "teacher_policy_loss": -21.76995277404785, "teacher_value_loss": 157.21096801757812, "teacher_entropy": 0.0014009098522365093, "total_time": 1.3423559665679932, "rollout_time": 0.4818861484527588, "train_time": 0.8419454097747803, "student_train_time": 0.018158435821533203, "throughput": 1489.917763850231, "inference_time": 0.07216634471478756, "env_time": 0.40971980373797123, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 227, "reward_mean": 125.82352941176471, "student_loss": null, "teacher_policy_loss": -20.275924682617188, "teacher_value_loss": 155.50543212890625, "teacher_entropy": 0.002434732858091593, "total_time": 1.3712623119354248, "rollout_time": 0.4550604820251465, "train_time": 0.8902971744537354, "student_train_time": 0.025479793548583984, "throughput": 1458.5101498028946, "inference_time": 0.06849406549736159, "env_time": 0.3865664165277849, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 228, "reward_mean": 119.82352941176471, "student_loss": null, "teacher_policy_loss": -21.101573944091797, "teacher_value_loss": 153.58815002441406, "teacher_entropy": 0.003473654156550765, "total_time": 1.2564537525177002, "rollout_time": 0.45522165298461914, "train_time": 0.7638797760009766, "student_train_time": 0.03691983222961426, "throughput": 1591.7816282472563, "inference_time": 0.07171271249899291, "env_time": 0.3835089404856262, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 229, "reward_mean": 130.2, "student_loss": null, "teacher_policy_loss": -22.869802474975586, "teacher_value_loss": 122.99880981445312, "teacher_entropy": 0.0037788590416312218, "total_time": 1.250678300857544, "rollout_time": 0.4513359069824219, "train_time": 0.7769362926483154, "student_train_time": 0.022003650665283203, "throughput": 1599.1322457810884, "inference_time": 0.07187229827286501, "env_time": 0.37946360870955687, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 230, "reward_mean": 137.0, "student_loss": null, "teacher_policy_loss": -22.938194274902344, "teacher_value_loss": 78.60131072998047, "teacher_entropy": 0.004821687005460262, "total_time": 1.4071481227874756, "rollout_time": 0.45407962799072266, "train_time": 0.9031858444213867, "student_train_time": 0.049420833587646484, "throughput": 1421.3144782783213, "inference_time": 0.07140662476376747, "env_time": 0.3826730032269552, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 231, "reward_mean": 124.33333333333333, "student_loss": null, "teacher_policy_loss": -22.187639236450195, "teacher_value_loss": 206.48934936523438, "teacher_entropy": 0.0035625940654426813, "total_time": 1.2436370849609375, "rollout_time": 0.4679839611053467, "train_time": 0.7457020282745361, "student_train_time": 0.029577016830444336, "throughput": 1608.1862017349054, "inference_time": 0.07109334695633152, "env_time": 0.39689061414901516, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 232, "reward_mean": 151.3846153846154, "student_loss": null, "teacher_policy_loss": -23.728668212890625, "teacher_value_loss": 132.05230712890625, "teacher_entropy": 0.003669875441119075, "total_time": 1.3532238006591797, "rollout_time": 0.4591987133026123, "train_time": 0.8733386993408203, "student_train_time": 0.02023768424987793, "throughput": 1477.952131070828, "inference_time": 0.07023400746766129, "env_time": 0.388964705834951, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 233, "reward_mean": 148.85714285714286, "student_loss": null, "teacher_policy_loss": -25.00686264038086, "teacher_value_loss": 210.8888397216797, "teacher_entropy": 0.004013141617178917, "total_time": 1.4661448001861572, "rollout_time": 0.6159121990203857, "train_time": 0.7913260459899902, "student_train_time": 0.05843973159790039, "throughput": 1364.1217427815172, "inference_time": 0.0835648139964178, "env_time": 0.532347385023968, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 234, "reward_mean": 165.83333333333334, "student_loss": null, "teacher_policy_loss": -24.766611099243164, "teacher_value_loss": 257.40362548828125, "teacher_entropy": 0.004170907661318779, "total_time": 1.4034311771392822, "rollout_time": 0.45984697341918945, "train_time": 0.9263782501220703, "student_train_time": 0.016829252243041992, "throughput": 1425.0787873166307, "inference_time": 0.07144408171188843, "env_time": 0.388402891707301, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 235, "reward_mean": 173.6, "student_loss": null, "teacher_policy_loss": -27.35796356201172, "teacher_value_loss": 237.0384063720703, "teacher_entropy": 0.0050356630235910416, "total_time": 1.2743947505950928, "rollout_time": 0.47048115730285645, "train_time": 0.7669425010681152, "student_train_time": 0.03660178184509277, "throughput": 1569.3724405770486, "inference_time": 0.07393603573473229, "env_time": 0.39654512156812416, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 236, "reward_mean": 233.0, "student_loss": null, "teacher_policy_loss": -29.648754119873047, "teacher_value_loss": 303.2860412597656, "teacher_entropy": 0.004962272942066193, "total_time": 1.808068037033081, "rollout_time": 0.4618692398071289, "train_time": 1.286236047744751, "student_train_time": 0.05949664115905762, "throughput": 1106.1530645062817, "inference_time": 0.07161682849437057, "env_time": 0.39025241131275834, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 237, "reward_mean": 248.14285714285714, "student_loss": null, "teacher_policy_loss": -31.690032958984375, "teacher_value_loss": 308.7108459472656, "teacher_entropy": 0.0023522598203271627, "total_time": 1.337254285812378, "rollout_time": 0.45165371894836426, "train_time": 0.8492062091827393, "student_train_time": 0.03601241111755371, "throughput": 1495.6018621282683, "inference_time": 0.06835001347099023, "env_time": 0.383303705477374, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 238, "reward_mean": 290.57142857142856, "student_loss": null, "teacher_policy_loss": -30.27787971496582, "teacher_value_loss": 572.129150390625, "teacher_entropy": 0.0008159659337252378, "total_time": 1.2426438331604004, "rollout_time": 0.44307374954223633, "train_time": 0.782008171081543, "student_train_time": 0.017209529876708984, "throughput": 1609.4716334876302, "inference_time": 0.06987633324570197, "env_time": 0.37319741629653436, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 239, "reward_mean": 405.8, "student_loss": null, "teacher_policy_loss": -34.99217224121094, "teacher_value_loss": 653.4498291015625, "teacher_entropy": 0.00010516004113014787, "total_time": 1.3393168449401855, "rollout_time": 0.4488370418548584, "train_time": 0.8746488094329834, "student_train_time": 0.015404224395751953, "throughput": 1493.2986227686256, "inference_time": 0.06939730444355519, "env_time": 0.3794397374113032, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 240, "reward_mean": 455.5, "student_loss": null, "teacher_policy_loss": -36.15079116821289, "teacher_value_loss": 742.6365356445312, "teacher_entropy": 2.4406463126069866e-05, "total_time": 1.2257304191589355, "rollout_time": 0.44763708114624023, "train_time": 0.7577705383300781, "student_train_time": 0.01989150047302246, "throughput": 1631.6801547377345, "inference_time": 0.07065592150865996, "env_time": 0.3769811596375803, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 241, "reward_mean": 336.6, "student_loss": null, "teacher_policy_loss": -34.73847579956055, "teacher_value_loss": 681.7275390625, "teacher_entropy": 3.393592851352878e-05, "total_time": 1.936772108078003, "rollout_time": 0.4418370723724365, "train_time": 1.4729056358337402, "student_train_time": 0.021188974380493164, "throughput": 1032.6460153253356, "inference_time": 0.06887740145430143, "env_time": 0.3729596709181351, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 242, "reward_mean": 347.8333333333333, "student_loss": null, "teacher_policy_loss": -34.156490325927734, "teacher_value_loss": 579.9944458007812, "teacher_entropy": 0.00011596754484344274, "total_time": 1.2049612998962402, "rollout_time": 0.4362325668334961, "train_time": 0.7510156631469727, "student_train_time": 0.01730656623840332, "throughput": 1659.804344066669, "inference_time": 0.06752423298894428, "env_time": 0.3687083338445518, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 243, "reward_mean": 328.2, "student_loss": null, "teacher_policy_loss": -32.92495346069336, "teacher_value_loss": 377.10870361328125, "teacher_entropy": 0.0004566145362332463, "total_time": 1.3042519092559814, "rollout_time": 0.4409651756286621, "train_time": 0.8433356285095215, "student_train_time": 0.01958632469177246, "throughput": 1533.446097189087, "inference_time": 0.06907023447638494, "env_time": 0.37189494115227717, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 244, "reward_mean": 393.6, "student_loss": null, "teacher_policy_loss": -35.6246337890625, "teacher_value_loss": 434.5381774902344, "teacher_entropy": 0.0001968603755813092, "total_time": 1.2337675094604492, "rollout_time": 0.451160192489624, "train_time": 0.7396585941314697, "student_train_time": 0.04256939888000488, "throughput": 1621.05095543863, "inference_time": 0.07113538196244917, "env_time": 0.38002481052717485, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 245, "reward_mean": 322.375, "student_loss": null, "teacher_policy_loss": -30.20943832397461, "teacher_value_loss": 311.21783447265625, "teacher_entropy": 0.0008551476639695466, "total_time": 1.1917169094085693, "rollout_time": 0.45183539390563965, "train_time": 0.7238163948059082, "student_train_time": 0.015639305114746094, "throughput": 1678.2509203402753, "inference_time": 0.06962406753518735, "env_time": 0.3822113263704523, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 246, "reward_mean": 242.33333333333334, "student_loss": null, "teacher_policy_loss": -28.55240249633789, "teacher_value_loss": 436.2430725097656, "teacher_entropy": 0.0008299577748402953, "total_time": 1.3515868186950684, "rollout_time": 0.43924975395202637, "train_time": 0.8710217475891113, "student_train_time": 0.04095196723937988, "throughput": 1479.7421610925167, "inference_time": 0.06850842827952874, "env_time": 0.3707413256724976, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 247, "reward_mean": 303.7142857142857, "student_loss": null, "teacher_policy_loss": -31.79287338256836, "teacher_value_loss": 371.4615478515625, "teacher_entropy": 0.0005188266513869166, "total_time": 1.1787614822387695, "rollout_time": 0.437345027923584, "train_time": 0.7249972820281982, "student_train_time": 0.01599287986755371, "throughput": 1696.6960917330694, "inference_time": 0.06765622119382897, "env_time": 0.369688806729755, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 248, "reward_mean": 235.0, "student_loss": null, "teacher_policy_loss": -31.180274963378906, "teacher_value_loss": 217.65432739257812, "teacher_entropy": 0.0005853914190083742, "total_time": 1.3354411125183105, "rollout_time": 0.4346435070037842, "train_time": 0.8801863193511963, "student_train_time": 0.020203351974487305, "throughput": 1497.6324910564542, "inference_time": 0.06727458372188266, "env_time": 0.3673689232819015, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 249, "reward_mean": 290.42857142857144, "student_loss": null, "teacher_policy_loss": -33.54196548461914, "teacher_value_loss": 317.5880126953125, "teacher_entropy": 0.0005560004501603544, "total_time": 1.305070400238037, "rollout_time": 0.4933304786682129, "train_time": 0.7793962955474854, "student_train_time": 0.03191637992858887, "throughput": 1532.484377574736, "inference_time": 0.07490845698703197, "env_time": 0.4184220216811809, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 250, "reward_mean": 274.375, "student_loss": null, "teacher_policy_loss": -30.014848709106445, "teacher_value_loss": 251.57366943359375, "teacher_entropy": 0.0008445627172477543, "total_time": 1.3114864826202393, "rollout_time": 0.468644380569458, "train_time": 0.8264596462249756, "student_train_time": 0.0160219669342041, "throughput": 1524.9871245368606, "inference_time": 0.06943466204938886, "env_time": 0.39920971852006915, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 251, "reward_mean": 278.5, "student_loss": null, "teacher_policy_loss": -29.623313903808594, "teacher_value_loss": 413.7204284667969, "teacher_entropy": 0.0008278301684185863, "total_time": 1.3160696029663086, "rollout_time": 0.46410465240478516, "train_time": 0.833698034286499, "student_train_time": 0.017841577529907227, "throughput": 1519.6764635336692, "inference_time": 0.07426303571446624, "env_time": 0.3898416166903189, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 252, "reward_mean": 257.14285714285717, "student_loss": null, "teacher_policy_loss": -30.714744567871094, "teacher_value_loss": 399.7337951660156, "teacher_entropy": 0.0009370261104777455, "total_time": 1.30983304977417, "rollout_time": 0.45214176177978516, "train_time": 0.8321044445037842, "student_train_time": 0.025209903717041016, "throughput": 1526.9121513958003, "inference_time": 0.07043839148172992, "env_time": 0.38170337029805523, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 253, "reward_mean": 308.625, "student_loss": null, "teacher_policy_loss": -30.045555114746094, "teacher_value_loss": 472.8366394042969, "teacher_entropy": 0.0015579452738165855, "total_time": 1.3622591495513916, "rollout_time": 0.4534585475921631, "train_time": 0.8877620697021484, "student_train_time": 0.020661592483520508, "throughput": 1468.1494344586522, "inference_time": 0.07058834343297349, "env_time": 0.3828702041591896, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 254, "reward_mean": 326.8, "student_loss": null, "teacher_policy_loss": -33.255271911621094, "teacher_value_loss": 650.9293212890625, "teacher_entropy": 0.0007576417410746217, "total_time": 1.2180960178375244, "rollout_time": 0.4472339153289795, "train_time": 0.7505960464477539, "student_train_time": 0.019774675369262695, "throughput": 1641.9066893844567, "inference_time": 0.06920216199432616, "env_time": 0.37803175333465333, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 255, "reward_mean": 280.5, "student_loss": null, "teacher_policy_loss": -32.50909423828125, "teacher_value_loss": 495.8797607421875, "teacher_entropy": 0.00028225700953043997, "total_time": 1.266528606414795, "rollout_time": 0.4451889991760254, "train_time": 0.7928030490875244, "student_train_time": 0.028107643127441406, "throughput": 1579.119484447704, "inference_time": 0.06855673467180168, "env_time": 0.3766322645042237, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 256, "reward_mean": 353.6666666666667, "student_loss": null, "teacher_policy_loss": -34.55680465698242, "teacher_value_loss": 415.15191650390625, "teacher_entropy": 3.860730430460535e-05, "total_time": 1.3050222396850586, "rollout_time": 0.4693107604980469, "train_time": 0.8158981800079346, "student_train_time": 0.019450664520263672, "throughput": 1532.5409323925855, "inference_time": 0.07297369852130942, "env_time": 0.39633706197673746, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 257, "reward_mean": 323.0, "student_loss": null, "teacher_policy_loss": -32.567073822021484, "teacher_value_loss": 633.2442016601562, "teacher_entropy": 2.355489050387405e-05, "total_time": 1.3088047504425049, "rollout_time": 0.4554286003112793, "train_time": 0.8354690074920654, "student_train_time": 0.017452716827392578, "throughput": 1528.111812952851, "inference_time": 0.07146024226130976, "env_time": 0.38396835804996954, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 258, "reward_mean": 355.0, "student_loss": null, "teacher_policy_loss": -35.818687438964844, "teacher_value_loss": 636.9686889648438, "teacher_entropy": 5.792552656203043e-06, "total_time": 1.4258217811584473, "rollout_time": 0.4566154479980469, "train_time": 0.9306936264038086, "student_train_time": 0.03793478012084961, "throughput": 1402.6998510115664, "inference_time": 0.06981538183936209, "env_time": 0.3868000661586848, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 259, "reward_mean": 385.4, "student_loss": null, "teacher_policy_loss": -35.325069427490234, "teacher_value_loss": 645.4279174804688, "teacher_entropy": 2.1901269064983353e-06, "total_time": 1.4460139274597168, "rollout_time": 0.4477667808532715, "train_time": 0.9649744033813477, "student_train_time": 0.03288531303405762, "throughput": 1383.1125427080067, "inference_time": 0.06733946699023363, "env_time": 0.38042731386303785, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 260, "reward_mean": 268.375, "student_loss": null, "teacher_policy_loss": -29.688465118408203, "teacher_value_loss": 564.9232177734375, "teacher_entropy": 1.7083301599996048e-06, "total_time": 1.409029483795166, "rollout_time": 0.4601247310638428, "train_time": 0.9306995868682861, "student_train_time": 0.01783919334411621, "throughput": 1419.4167141294147, "inference_time": 0.0711743637730251, "env_time": 0.38895036729081767, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 261, "reward_mean": 252.0, "student_loss": null, "teacher_policy_loss": -31.395763397216797, "teacher_value_loss": 482.844482421875, "teacher_entropy": 2.182895741498214e-06, "total_time": 1.2676725387573242, "rollout_time": 0.4573538303375244, "train_time": 0.7922861576080322, "student_train_time": 0.017596006393432617, "throughput": 1577.6945061542176, "inference_time": 0.07353790698653029, "env_time": 0.3838159233509941, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 262, "reward_mean": 268.5, "student_loss": null, "teacher_policy_loss": -31.7061824798584, "teacher_value_loss": 619.1302490234375, "teacher_entropy": 5.967837751086336e-06, "total_time": 1.3688066005706787, "rollout_time": 0.4360954761505127, "train_time": 0.8855533599853516, "student_train_time": 0.04665017127990723, "throughput": 1461.1267940746093, "inference_time": 0.06646134000220627, "env_time": 0.3696341361483064, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 263, "reward_mean": 435.75, "student_loss": null, "teacher_policy_loss": -37.72477340698242, "teacher_value_loss": 957.6976928710938, "teacher_entropy": 1.4368962183652911e-05, "total_time": 1.3020544052124023, "rollout_time": 0.46789050102233887, "train_time": 0.7904422283172607, "student_train_time": 0.0433499813079834, "throughput": 1536.0341257581651, "inference_time": 0.07479094897280447, "env_time": 0.3930995520495344, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 264, "reward_mean": 359.42857142857144, "student_loss": null, "teacher_policy_loss": -33.900203704833984, "teacher_value_loss": 800.63916015625, "teacher_entropy": 2.747159123828169e-05, "total_time": -1.3944499492645264, "rollout_time": -2.214291572570801, "train_time": 0.8021833896636963, "student_train_time": 0.017294883728027344, "throughput": 200000000000.0, "inference_time": 0.06744261827407172, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 265, "reward_mean": 291.0, "student_loss": null, "teacher_policy_loss": -32.52939987182617, "teacher_value_loss": 558.5286865234375, "teacher_entropy": 1.618800888536498e-05, "total_time": 1.3380892276763916, "rollout_time": 0.4621295928955078, "train_time": 0.856194019317627, "student_train_time": 0.01940441131591797, "throughput": 1494.6686354190479, "inference_time": 0.06926290879346197, "env_time": 0.39286668410204584, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 266, "reward_mean": 350.8333333333333, "student_loss": null, "teacher_policy_loss": -31.64691162109375, "teacher_value_loss": 576.0709838867188, "teacher_entropy": 1.9190005332347937e-05, "total_time": 1.2873194217681885, "rollout_time": 0.45192575454711914, "train_time": 0.8055663108825684, "student_train_time": 0.02940082550048828, "throughput": 1553.6159605616097, "inference_time": 0.06778159276109363, "env_time": 0.3841441617860255, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 267, "reward_mean": 248.875, "student_loss": null, "teacher_policy_loss": -30.02446746826172, "teacher_value_loss": 420.5268859863281, "teacher_entropy": 2.2550899302586913e-05, "total_time": 1.35601806640625, "rollout_time": 0.46788454055786133, "train_time": 0.8681728839874268, "student_train_time": 0.019576072692871094, "throughput": 1474.9066030517172, "inference_time": 0.07432328320828674, "env_time": 0.3935612573495746, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 268, "reward_mean": 242.5, "student_loss": null, "teacher_policy_loss": -29.614267349243164, "teacher_value_loss": 381.87921142578125, "teacher_entropy": 2.5235814973711967e-05, "total_time": 1.3120219707489014, "rollout_time": 0.48536229133605957, "train_time": 0.8033828735351562, "student_train_time": 0.02283763885498047, "throughput": 1524.3647168944901, "inference_time": 0.08286716476322908, "env_time": 0.4024951265728305, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 269, "reward_mean": 237.625, "student_loss": null, "teacher_policy_loss": -30.908349990844727, "teacher_value_loss": 437.2528991699219, "teacher_entropy": 4.077371704624966e-05, "total_time": 1.2558341026306152, "rollout_time": 0.45784497261047363, "train_time": 0.7832794189453125, "student_train_time": 0.014262914657592773, "throughput": 1592.5670403523593, "inference_time": 0.07118353872465377, "env_time": 0.38666143388581986, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 270, "reward_mean": 253.875, "student_loss": null, "teacher_policy_loss": -29.16449546813965, "teacher_value_loss": 388.08880615234375, "teacher_entropy": 0.00014461319369729608, "total_time": 1.335448980331421, "rollout_time": 0.4535074234008789, "train_time": 0.85611891746521, "student_train_time": 0.025464773178100586, "throughput": 1497.623667737315, "inference_time": 0.07130922172655119, "env_time": 0.3821982016743277, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 271, "reward_mean": 271.5, "student_loss": null, "teacher_policy_loss": -29.643468856811523, "teacher_value_loss": 595.12646484375, "teacher_entropy": 0.0006225328543223441, "total_time": 1.226700782775879, "rollout_time": 0.4385662078857422, "train_time": 0.7682435512542725, "student_train_time": 0.019422054290771484, "throughput": 1630.3894381433722, "inference_time": 0.06791226475252188, "env_time": 0.3706539431332203, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 272, "reward_mean": 272.0, "student_loss": null, "teacher_policy_loss": -31.177400588989258, "teacher_value_loss": 578.9979248046875, "teacher_entropy": 0.0007315498660318553, "total_time": 1.34855318069458, "rollout_time": 0.4793875217437744, "train_time": 0.8397760391235352, "student_train_time": 0.029017210006713867, "throughput": 1483.0709152826205, "inference_time": 0.07466353973541118, "env_time": 0.40472398200836324, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 273, "reward_mean": 228.5, "student_loss": null, "teacher_policy_loss": -28.560243606567383, "teacher_value_loss": 392.3541564941406, "teacher_entropy": 0.0004663549188990146, "total_time": 1.2257683277130127, "rollout_time": 0.44044995307922363, "train_time": 0.7657575607299805, "student_train_time": 0.019182443618774414, "throughput": 1631.6296928078705, "inference_time": 0.06653422348790627, "env_time": 0.37391572959131736, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 274, "reward_mean": 303.57142857142856, "student_loss": null, "teacher_policy_loss": -30.495155334472656, "teacher_value_loss": 457.1038818359375, "teacher_entropy": 0.00024625041987746954, "total_time": 1.3928673267364502, "rollout_time": 0.4426240921020508, "train_time": 0.930450439453125, "student_train_time": 0.0194399356842041, "throughput": 1435.8869374056526, "inference_time": 0.07017503275528725, "env_time": 0.37244905934676353, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 275, "reward_mean": 336.1666666666667, "student_loss": null, "teacher_policy_loss": -33.941219329833984, "teacher_value_loss": 479.33001708984375, "teacher_entropy": 0.00013347055937629193, "total_time": 1.2224836349487305, "rollout_time": 0.4346306324005127, "train_time": 0.7661986351013184, "student_train_time": 0.021233320236206055, "throughput": 1636.0137206122008, "inference_time": 0.06876070825092029, "env_time": 0.3658699241495924, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 276, "reward_mean": 280.8333333333333, "student_loss": null, "teacher_policy_loss": -32.67367172241211, "teacher_value_loss": 471.42144775390625, "teacher_entropy": 2.6629921194398776e-05, "total_time": 1.2158234119415283, "rollout_time": 0.44798994064331055, "train_time": 0.7484128475189209, "student_train_time": 0.019050121307373047, "throughput": 1644.9757262086548, "inference_time": 0.07010437198914587, "env_time": 0.37788556865416467, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 277, "reward_mean": 290.8333333333333, "student_loss": null, "teacher_policy_loss": -33.425296783447266, "teacher_value_loss": 677.7510986328125, "teacher_entropy": 8.398360478167888e-06, "total_time": 1.3441596031188965, "rollout_time": 0.45504093170166016, "train_time": 0.8601117134094238, "student_train_time": 0.028630733489990234, "throughput": 1487.9185443152257, "inference_time": 0.06785994725578348, "env_time": 0.3871809844458767, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 278, "reward_mean": 305.8888888888889, "student_loss": null, "teacher_policy_loss": -31.745492935180664, "teacher_value_loss": 747.9345092773438, "teacher_entropy": 1.3184786439524032e-05, "total_time": 1.2280704975128174, "rollout_time": 0.44807934761047363, "train_time": 0.7636697292327881, "student_train_time": 0.01590132713317871, "throughput": 1628.571001461686, "inference_time": 0.06868876423322945, "env_time": 0.3793905833772442, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 279, "reward_mean": 267.85714285714283, "student_loss": null, "teacher_policy_loss": -31.445476531982422, "teacher_value_loss": 629.7508544921875, "teacher_entropy": 1.4839136383670848e-05, "total_time": 1.370987892150879, "rollout_time": 0.443131685256958, "train_time": 0.8924808502197266, "student_train_time": 0.03500556945800781, "throughput": 1458.8020882243484, "inference_time": 0.06688394847878953, "env_time": 0.3762477367781685, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 280, "reward_mean": 425.5, "student_loss": null, "teacher_policy_loss": -34.63930892944336, "teacher_value_loss": 559.7041015625, "teacher_entropy": 4.1382798372069374e-05, "total_time": 1.2569663524627686, "rollout_time": 0.4528343677520752, "train_time": 0.7710227966308594, "student_train_time": 0.03274106979370117, "throughput": 1591.132488217691, "inference_time": 0.06993816148860788, "env_time": 0.3828962062634673, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 281, "reward_mean": 280.7142857142857, "student_loss": null, "teacher_policy_loss": -30.95614242553711, "teacher_value_loss": 593.3482666015625, "teacher_entropy": 6.66238265694119e-05, "total_time": 1.2495059967041016, "rollout_time": 0.4434468746185303, "train_time": 0.7806930541992188, "student_train_time": 0.02500128746032715, "throughput": 1600.6325742137471, "inference_time": 0.071267933533818, "env_time": 0.3721789410847123, "samples": 2000, "teacher_eval_reward": 9.0}
