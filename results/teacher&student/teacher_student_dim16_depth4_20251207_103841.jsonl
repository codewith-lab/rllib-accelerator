{"epoch": 1, "reward_mean": 20.648936170212767, "student_loss": null, "teacher_policy_loss": -12.558114051818848, "teacher_value_loss": 218.2071533203125, "teacher_entropy": 0.6857222318649292, "total_time": 1.6566367149353027, "rollout_time": 0.4490323066711426, "train_time": 1.1283965110778809, "student_train_time": 0.07882928848266602, "throughput": 1207.2652875365657, "inference_time": 0.05361203326538089, "env_time": 0.3954202734057617, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 2, "reward_mean": 21.1875, "student_loss": null, "teacher_policy_loss": -11.728219985961914, "teacher_value_loss": 120.5438003540039, "teacher_entropy": 0.5803236365318298, "total_time": 1.2920677661895752, "rollout_time": 0.45972275733947754, "train_time": 0.8247148990631104, "student_train_time": 0.0072743892669677734, "throughput": 1547.9064274609846, "inference_time": 0.058907430327963084, "env_time": 0.40081532701151446, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 3, "reward_mean": 20.344086021505376, "student_loss": null, "teacher_policy_loss": -8.344989776611328, "teacher_value_loss": 126.32207489013672, "teacher_entropy": 0.22640082240104675, "total_time": 1.2494454383850098, "rollout_time": 0.4446892738342285, "train_time": 0.7834184169769287, "student_train_time": 0.02095627784729004, "throughput": 1600.7101539264743, "inference_time": 0.05475524328358006, "env_time": 0.38993403055064846, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 4, "reward_mean": 23.303370786516854, "student_loss": null, "teacher_policy_loss": -7.51139497756958, "teacher_value_loss": 81.85345458984375, "teacher_entropy": 0.09541485458612442, "total_time": 1.417677640914917, "rollout_time": 0.45185208320617676, "train_time": 0.9573934078216553, "student_train_time": 0.008065462112426758, "throughput": 1410.7579482662036, "inference_time": 0.055454108471167274, "env_time": 0.3963979747350095, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 5, "reward_mean": 20.842105263157894, "student_loss": null, "teacher_policy_loss": -7.109241008758545, "teacher_value_loss": 71.6651382446289, "teacher_entropy": 0.06352733820676804, "total_time": 1.368685245513916, "rollout_time": 0.573871374130249, "train_time": 0.7841479778289795, "student_train_time": 0.010223388671875, "throughput": 1461.2563455004126, "inference_time": 0.07034680928882153, "env_time": 0.5035245648414275, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 6, "reward_mean": 21.1340206185567, "student_loss": null, "teacher_policy_loss": -7.3287153244018555, "teacher_value_loss": 76.56026458740234, "teacher_entropy": 0.07427423447370529, "total_time": 1.3716461658477783, "rollout_time": 0.4616403579711914, "train_time": 0.899472713470459, "student_train_time": 0.010062217712402344, "throughput": 1458.1019870848781, "inference_time": 0.05641275604284601, "env_time": 0.4052276019283454, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 7, "reward_mean": 20.63157894736842, "student_loss": null, "teacher_policy_loss": -7.483301162719727, "teacher_value_loss": 84.46195983886719, "teacher_entropy": 0.1053411066532135, "total_time": 1.2203819751739502, "rollout_time": 0.4423708915710449, "train_time": 0.7580432891845703, "student_train_time": 0.01955556869506836, "throughput": 1638.8311534304044, "inference_time": 0.05583574151387438, "env_time": 0.38653515005717054, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 8, "reward_mean": 22.797752808988765, "student_loss": null, "teacher_policy_loss": -8.36980152130127, "teacher_value_loss": 65.42997741699219, "teacher_entropy": 0.2049863040447235, "total_time": 1.376389980316162, "rollout_time": 0.43208861351013184, "train_time": 0.9371585845947266, "student_train_time": 0.006733894348144531, "throughput": 1453.0765470557933, "inference_time": 0.054546195973671274, "env_time": 0.37754241753646056, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 9, "reward_mean": 22.988505747126435, "student_loss": null, "teacher_policy_loss": -12.058690071105957, "teacher_value_loss": 92.71546936035156, "teacher_entropy": 0.5246708989143372, "total_time": 1.305936336517334, "rollout_time": 0.5614171028137207, "train_time": 0.7362895011901855, "student_train_time": 0.007843017578125, "throughput": 1531.4682225119736, "inference_time": 0.06118411472380103, "env_time": 0.5002329880899197, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 10, "reward_mean": 23.047619047619047, "student_loss": null, "teacher_policy_loss": -10.229146957397461, "teacher_value_loss": 87.63914489746094, "teacher_entropy": 0.3326035141944885, "total_time": 1.2264375686645508, "rollout_time": 0.4322543144226074, "train_time": 0.7868008613586426, "student_train_time": 0.00702357292175293, "throughput": 1630.7393471139094, "inference_time": 0.05265131175656279, "env_time": 0.37960300266604463, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 11, "reward_mean": 21.595744680851062, "student_loss": null, "teacher_policy_loss": -8.515711784362793, "teacher_value_loss": 44.57232666015625, "teacher_entropy": 0.2430495023727417, "total_time": -1.283691167831421, "rollout_time": 0.4936823844909668, "train_time": -1.7864618301391602, "student_train_time": 0.008732080459594727, "throughput": 200000000000.0, "inference_time": 0.06402645078014757, "env_time": 0.4296559337108192, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 12, "reward_mean": 24.023809523809526, "student_loss": null, "teacher_policy_loss": -9.952611923217773, "teacher_value_loss": 109.7364730834961, "teacher_entropy": 0.25741857290267944, "total_time": 1.188880443572998, "rollout_time": 0.4243960380554199, "train_time": 0.757117509841919, "student_train_time": 0.006902933120727539, "throughput": 1682.2549406139665, "inference_time": 0.052436585176110384, "env_time": 0.37195945287930954, "samples": 2000, "teacher_eval_reward": 13.0}
{"epoch": 13, "reward_mean": 21.516129032258064, "student_loss": null, "teacher_policy_loss": -9.125261306762695, "teacher_value_loss": 92.84837341308594, "teacher_entropy": 0.2994858920574188, "total_time": 1.4595658779144287, "rollout_time": 0.43652987480163574, "train_time": 1.0122051239013672, "student_train_time": 0.010427713394165039, "throughput": 1370.2704552519388, "inference_time": 0.05506747172694304, "env_time": 0.3814624030746927, "samples": 2000, "teacher_eval_reward": 13.0}
{"epoch": 14, "reward_mean": 21.763440860215052, "student_loss": null, "teacher_policy_loss": -9.512748718261719, "teacher_value_loss": 55.949703216552734, "teacher_entropy": 0.33421146869659424, "total_time": 1.1653122901916504, "rollout_time": 0.4234189987182617, "train_time": 0.730186939239502, "student_train_time": 0.011353731155395508, "throughput": 1716.278131479309, "inference_time": 0.0529261430256156, "env_time": 0.3704928556926461, "samples": 2000, "teacher_eval_reward": 17.0}
{"epoch": 15, "reward_mean": 19.649484536082475, "student_loss": null, "teacher_policy_loss": -9.137765884399414, "teacher_value_loss": 51.41368103027344, "teacher_entropy": 0.38037002086639404, "total_time": 1.2904775142669678, "rollout_time": 0.4425642490386963, "train_time": 0.836674690246582, "student_train_time": 0.010833263397216797, "throughput": 1549.8139083314936, "inference_time": 0.0510776017436001, "env_time": 0.3914866472950962, "samples": 2000, "teacher_eval_reward": 26.0}
{"epoch": 16, "reward_mean": 22.311827956989248, "student_loss": null, "teacher_policy_loss": -11.800675392150879, "teacher_value_loss": 76.16439819335938, "teacher_entropy": 0.5168038606643677, "total_time": 1.26613187789917, "rollout_time": 0.458176851272583, "train_time": 0.772240400314331, "student_train_time": 0.03533744812011719, "throughput": 1579.6142841917078, "inference_time": 0.056156645536248107, "env_time": 0.4020202057363349, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 17, "reward_mean": 21.565217391304348, "student_loss": null, "teacher_policy_loss": -10.404662132263184, "teacher_value_loss": 91.88442993164062, "teacher_entropy": 0.40448734164237976, "total_time": 1.1898443698883057, "rollout_time": 0.4530768394470215, "train_time": 0.7298963069915771, "student_train_time": 0.0064504146575927734, "throughput": 1680.8920986765236, "inference_time": 0.05471814625161642, "env_time": 0.39835869319540507, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 18, "reward_mean": 20.8659793814433, "student_loss": null, "teacher_policy_loss": -8.411710739135742, "teacher_value_loss": 50.090843200683594, "teacher_entropy": 0.30093806982040405, "total_time": 1.3189620971679688, "rollout_time": 0.44856882095336914, "train_time": 0.8646829128265381, "student_train_time": 0.0053102970123291016, "throughput": 1516.3438011557216, "inference_time": 0.055146068225440104, "env_time": 0.39342275272792904, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 19, "reward_mean": 21.706521739130434, "student_loss": null, "teacher_policy_loss": -8.794356346130371, "teacher_value_loss": 51.128326416015625, "teacher_entropy": 0.32602792978286743, "total_time": 1.1556694507598877, "rollout_time": 0.43333864212036133, "train_time": 0.7156128883361816, "student_train_time": 0.006310224533081055, "throughput": 1730.5986575010177, "inference_time": 0.05631483178876806, "env_time": 0.37702381033159327, "samples": 2000, "teacher_eval_reward": 19.0}
{"epoch": 20, "reward_mean": 22.454545454545453, "student_loss": null, "teacher_policy_loss": -11.401087760925293, "teacher_value_loss": 52.940914154052734, "teacher_entropy": 0.5195209383964539, "total_time": 1.271348237991333, "rollout_time": 0.438645601272583, "train_time": 0.823707103729248, "student_train_time": 0.008636713027954102, "throughput": 1573.133104081617, "inference_time": 0.053147454440477304, "env_time": 0.3854981468321057, "samples": 2000, "teacher_eval_reward": 25.0}
{"epoch": 21, "reward_mean": 23.94047619047619, "student_loss": null, "teacher_policy_loss": -11.995229721069336, "teacher_value_loss": 55.88380813598633, "teacher_entropy": 0.5150191187858582, "total_time": 1.2156918048858643, "rollout_time": 0.44753026962280273, "train_time": 0.760084867477417, "student_train_time": 0.007683277130126953, "throughput": 1645.1538062212821, "inference_time": 0.05504652271338273, "env_time": 0.39248374690942, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 22, "reward_mean": 22.929411764705883, "student_loss": null, "teacher_policy_loss": -10.80118465423584, "teacher_value_loss": 60.02104187011719, "teacher_entropy": 0.4084761142730713, "total_time": 1.2242276668548584, "rollout_time": 0.43801450729370117, "train_time": 0.770270586013794, "student_train_time": 0.015566110610961914, "throughput": 1633.6830592451522, "inference_time": 0.054310383973643184, "env_time": 0.383704123320058, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 23, "reward_mean": 25.444444444444443, "student_loss": null, "teacher_policy_loss": -11.612129211425781, "teacher_value_loss": 75.78290557861328, "teacher_entropy": 0.3883265256881714, "total_time": 1.3682911396026611, "rollout_time": 0.4497203826904297, "train_time": 0.9088780879974365, "student_train_time": 0.009270191192626953, "throughput": 1461.677227977067, "inference_time": 0.0543969390073471, "env_time": 0.3953234436830826, "samples": 2000, "teacher_eval_reward": 20.0}
{"epoch": 24, "reward_mean": 24.19753086419753, "student_loss": null, "teacher_policy_loss": -12.499600410461426, "teacher_value_loss": 66.458984375, "teacher_entropy": 0.48271018266677856, "total_time": 1.2429299354553223, "rollout_time": 0.44173550605773926, "train_time": 0.792227029800415, "student_train_time": 0.008561849594116211, "throughput": 1609.1011592438156, "inference_time": 0.055094408522563754, "env_time": 0.3866410975351755, "samples": 2000, "teacher_eval_reward": 102.0}
{"epoch": 25, "reward_mean": 22.744444444444444, "student_loss": null, "teacher_policy_loss": -13.283628463745117, "teacher_value_loss": 101.1196060180664, "teacher_entropy": 0.5456559658050537, "total_time": 1.3345203399658203, "rollout_time": 0.4499337673187256, "train_time": 0.87673020362854, "student_train_time": 0.007463216781616211, "throughput": 1498.66580531191, "inference_time": 0.05807922299572965, "env_time": 0.39185454432299593, "samples": 2000, "teacher_eval_reward": 17.0}
{"epoch": 26, "reward_mean": 23.435294117647057, "student_loss": null, "teacher_policy_loss": -12.04052448272705, "teacher_value_loss": 90.0210189819336, "teacher_entropy": 0.45552051067352295, "total_time": 1.1760368347167969, "rollout_time": 0.43802428245544434, "train_time": 0.7295024394989014, "student_train_time": 0.008045196533203125, "throughput": 1700.6270050050116, "inference_time": 0.05552007879123266, "env_time": 0.3825042036642117, "samples": 2000, "teacher_eval_reward": 18.0}
{"epoch": 27, "reward_mean": 21.247311827956988, "student_loss": null, "teacher_policy_loss": -10.102944374084473, "teacher_value_loss": 43.73102951049805, "teacher_entropy": 0.4742513597011566, "total_time": 1.3135910034179688, "rollout_time": 0.427201509475708, "train_time": 0.8806629180908203, "student_train_time": 0.005372285842895508, "throughput": 1522.5439233338172, "inference_time": 0.052269646503191325, "env_time": 0.3749318629725167, "samples": 2000, "teacher_eval_reward": 33.0}
{"epoch": 28, "reward_mean": 23.170454545454547, "student_loss": null, "teacher_policy_loss": -11.953106880187988, "teacher_value_loss": 69.33373260498047, "teacher_entropy": 0.5239288210868835, "total_time": 1.194155216217041, "rollout_time": 0.437070369720459, "train_time": 0.7461028099060059, "student_train_time": 0.01061868667602539, "throughput": 1674.8241542132112, "inference_time": 0.05428127851700992, "env_time": 0.38278909120344906, "samples": 2000, "teacher_eval_reward": 45.0}
{"epoch": 29, "reward_mean": 21.934065934065934, "student_loss": null, "teacher_policy_loss": -13.132686614990234, "teacher_value_loss": 96.37750244140625, "teacher_entropy": 0.5645381808280945, "total_time": 1.2159526348114014, "rollout_time": 0.43511390686035156, "train_time": 0.7745907306671143, "student_train_time": 0.005533695220947266, "throughput": 1644.8009097905424, "inference_time": 0.054810183004519786, "env_time": 0.3803037238558318, "samples": 2000, "teacher_eval_reward": 21.0}
{"epoch": 30, "reward_mean": 23.080459770114942, "student_loss": null, "teacher_policy_loss": -12.955666542053223, "teacher_value_loss": 98.28272247314453, "teacher_entropy": 0.5507425665855408, "total_time": 1.2781476974487305, "rollout_time": 0.46082592010498047, "train_time": 0.8115532398223877, "student_train_time": 0.005368471145629883, "throughput": 1564.7643883348815, "inference_time": 0.05761850773706101, "env_time": 0.40320741236791946, "samples": 2000, "teacher_eval_reward": 17.0}
{"epoch": 31, "reward_mean": 21.813186813186814, "student_loss": null, "teacher_policy_loss": -10.817708969116211, "teacher_value_loss": 45.876686096191406, "teacher_entropy": 0.5030989646911621, "total_time": 1.3420586585998535, "rollout_time": 0.561265230178833, "train_time": 0.7671074867248535, "student_train_time": 0.013318538665771484, "throughput": 1490.247827234739, "inference_time": 0.0692263888213347, "env_time": 0.4920388413574983, "samples": 2000, "teacher_eval_reward": 22.0}
{"epoch": 32, "reward_mean": 21.554347826086957, "student_loss": null, "teacher_policy_loss": -12.239556312561035, "teacher_value_loss": 60.00199508666992, "teacher_entropy": 0.5748238563537598, "total_time": 1.3960003852844238, "rollout_time": 0.45242977142333984, "train_time": 0.9323186874389648, "student_train_time": 0.010823488235473633, "throughput": 1432.664361043508, "inference_time": 0.05708660181153391, "env_time": 0.39534316961180593, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 33, "reward_mean": 20.22680412371134, "student_loss": null, "teacher_policy_loss": -11.525017738342285, "teacher_value_loss": 60.747894287109375, "teacher_entropy": 0.6071861386299133, "total_time": 1.2055633068084717, "rollout_time": 0.43809938430786133, "train_time": 0.7615933418273926, "student_train_time": 0.005522489547729492, "throughput": 1658.9755085485035, "inference_time": 0.05441208479714987, "env_time": 0.38368729951071145, "samples": 2000, "teacher_eval_reward": 14.0}
{"epoch": 34, "reward_mean": 21.28421052631579, "student_loss": null, "teacher_policy_loss": -9.820554733276367, "teacher_value_loss": 37.63678741455078, "teacher_entropy": 0.5400118231773376, "total_time": -1.2891132831573486, "rollout_time": 0.4363901615142822, "train_time": -1.7344400882720947, "student_train_time": 0.008586406707763672, "throughput": 200000000000.0, "inference_time": 0.053533576985500986, "env_time": 0.38285658452878124, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 35, "reward_mean": 23.185185185185187, "student_loss": null, "teacher_policy_loss": -11.883210182189941, "teacher_value_loss": 95.764892578125, "teacher_entropy": 0.5218675136566162, "total_time": 1.1625497341156006, "rollout_time": 0.4330480098724365, "train_time": 0.719764232635498, "student_train_time": 0.009330987930297852, "throughput": 1720.356507174708, "inference_time": 0.05512764577179041, "env_time": 0.3779203641006461, "samples": 2000, "teacher_eval_reward": 16.0}
{"epoch": 36, "reward_mean": 23.544444444444444, "student_loss": null, "teacher_policy_loss": -11.708150863647461, "teacher_value_loss": 52.476661682128906, "teacher_entropy": 0.6217602491378784, "total_time": 1.2054061889648438, "rollout_time": 0.4462423324584961, "train_time": 0.7491042613983154, "student_train_time": 0.009694576263427734, "throughput": 1659.1917465742588, "inference_time": 0.054191601018828806, "env_time": 0.3920507314396673, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 37, "reward_mean": 23.079545454545453, "student_loss": null, "teacher_policy_loss": -12.694581985473633, "teacher_value_loss": 46.3917121887207, "teacher_entropy": 0.6432040929794312, "total_time": 1.3420586585998535, "rollout_time": 0.44197964668273926, "train_time": 0.8911280632019043, "student_train_time": 0.008599996566772461, "throughput": 1490.247827234739, "inference_time": 0.058611011490938836, "env_time": 0.3833686351918004, "samples": 2000, "teacher_eval_reward": 8.0}
{"epoch": 38, "reward_mean": 24.426829268292682, "student_loss": null, "teacher_policy_loss": -13.375072479248047, "teacher_value_loss": 65.05027770996094, "teacher_entropy": 0.6049992442131042, "total_time": 1.1621136665344238, "rollout_time": 0.4284329414367676, "train_time": 0.7252402305603027, "student_train_time": 0.00809478759765625, "throughput": 1721.0020479014447, "inference_time": 0.0522821404520073, "env_time": 0.3761508009847603, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 39, "reward_mean": 20.255102040816325, "student_loss": null, "teacher_policy_loss": -11.550603866577148, "teacher_value_loss": 36.65114974975586, "teacher_entropy": 0.6415122151374817, "total_time": 1.3095142841339111, "rollout_time": 0.44055819511413574, "train_time": 0.8600363731384277, "student_train_time": 0.008557796478271484, "throughput": 1527.2838366347135, "inference_time": 0.05477275790508429, "env_time": 0.38578543720905145, "samples": 2000, "teacher_eval_reward": 46.0}
{"epoch": 40, "reward_mean": 25.615384615384617, "student_loss": null, "teacher_policy_loss": -15.70893669128418, "teacher_value_loss": 97.22937774658203, "teacher_entropy": 0.6747073531150818, "total_time": 1.1964905261993408, "rollout_time": 0.4382452964782715, "train_time": 0.7488508224487305, "student_train_time": 0.008999824523925781, "throughput": 1671.5552327463986, "inference_time": 0.05508708403795026, "env_time": 0.3831582124403212, "samples": 2000, "teacher_eval_reward": 24.0}
{"epoch": 41, "reward_mean": 21.72043010752688, "student_loss": null, "teacher_policy_loss": -12.006582260131836, "teacher_value_loss": 46.1442985534668, "teacher_entropy": 0.6723625659942627, "total_time": 1.2451629638671875, "rollout_time": 0.4225647449493408, "train_time": 0.8100848197937012, "student_train_time": 0.01216268539428711, "throughput": 1606.215457765033, "inference_time": 0.052979806174334954, "env_time": 0.36958493877500587, "samples": 2000, "teacher_eval_reward": 216.0}
{"epoch": 42, "reward_mean": 22.977011494252874, "student_loss": null, "teacher_policy_loss": -13.460738182067871, "teacher_value_loss": 56.22800064086914, "teacher_entropy": 0.6784595251083374, "total_time": 1.2098698616027832, "rollout_time": 0.4392883777618408, "train_time": 0.753699779510498, "student_train_time": 0.01649332046508789, "throughput": 1653.0703536581088, "inference_time": 0.05416206649533706, "env_time": 0.38512631126650376, "samples": 2000, "teacher_eval_reward": 345.0}
{"epoch": 43, "reward_mean": 21.844444444444445, "student_loss": null, "teacher_policy_loss": -13.307952880859375, "teacher_value_loss": 57.05632019042969, "teacher_entropy": 0.6828303337097168, "total_time": 1.2582223415374756, "rollout_time": 0.46790146827697754, "train_time": 0.7830820083618164, "student_train_time": 0.006896018981933594, "throughput": 1589.5441798912223, "inference_time": 0.05553126872837311, "env_time": 0.41237019954860443, "samples": 2000, "teacher_eval_reward": 465.0}
{"epoch": 44, "reward_mean": 27.364864864864863, "student_loss": null, "teacher_policy_loss": -16.45290184020996, "teacher_value_loss": 97.85755920410156, "teacher_entropy": 0.6706926226615906, "total_time": 1.2129361629486084, "rollout_time": 0.43758392333984375, "train_time": 0.765761137008667, "student_train_time": 0.009161710739135742, "throughput": 1648.8913935405017, "inference_time": 0.05683393449362484, "env_time": 0.3807499888462189, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 45, "reward_mean": 23.36470588235294, "student_loss": null, "teacher_policy_loss": -13.739751815795898, "teacher_value_loss": 58.726783752441406, "teacher_entropy": 0.6515918970108032, "total_time": 1.4740800857543945, "rollout_time": 0.4889230728149414, "train_time": 0.9669594764709473, "student_train_time": 0.017668724060058594, "throughput": 1356.7783862818103, "inference_time": 0.06004612398282916, "env_time": 0.42887694883211225, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 46, "reward_mean": 22.382022471910112, "student_loss": null, "teacher_policy_loss": -12.991002082824707, "teacher_value_loss": 57.73324203491211, "teacher_entropy": 0.6429625153541565, "total_time": 1.4826748371124268, "rollout_time": 0.4541149139404297, "train_time": 1.0236012935638428, "student_train_time": 0.004590034484863281, "throughput": 1348.9134299298464, "inference_time": 0.06078631732088979, "env_time": 0.3933285966195399, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 47, "reward_mean": 23.773809523809526, "student_loss": null, "teacher_policy_loss": -13.731620788574219, "teacher_value_loss": 60.36067199707031, "teacher_entropy": 0.6620283722877502, "total_time": 1.2225086688995361, "rollout_time": 0.4428999423980713, "train_time": 0.7719700336456299, "student_train_time": 0.0072863101959228516, "throughput": 1635.9802191017075, "inference_time": 0.05272060597962991, "env_time": 0.3901793364184414, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 48, "reward_mean": 24.297619047619047, "student_loss": null, "teacher_policy_loss": -14.988044738769531, "teacher_value_loss": 96.17635345458984, "teacher_entropy": 0.666641354560852, "total_time": 1.397813320159912, "rollout_time": 0.46210432052612305, "train_time": 0.9089903831481934, "student_train_time": 0.02634119987487793, "throughput": 1430.8062250910564, "inference_time": 0.05505433327743958, "env_time": 0.40704998724868346, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 49, "reward_mean": 25.40506329113924, "student_loss": null, "teacher_policy_loss": -15.257476806640625, "teacher_value_loss": 70.18025207519531, "teacher_entropy": 0.6775668859481812, "total_time": 1.211766242980957, "rollout_time": 0.4344210624694824, "train_time": 0.7664945125579834, "student_train_time": 0.010435104370117188, "throughput": 1650.4833432890325, "inference_time": 0.054375508465454914, "env_time": 0.3800455540040275, "samples": 2000, "teacher_eval_reward": 28.0}
{"epoch": 50, "reward_mean": 23.13953488372093, "student_loss": null, "teacher_policy_loss": -13.656997680664062, "teacher_value_loss": 65.54338073730469, "teacher_entropy": 0.6848195195198059, "total_time": 1.3659756183624268, "rollout_time": 0.44445133209228516, "train_time": 0.9168004989624023, "student_train_time": 0.0043697357177734375, "throughput": 1464.1549769370415, "inference_time": 0.05520835728930251, "env_time": 0.38924297480298264, "samples": 2000, "teacher_eval_reward": 32.0}
{"epoch": 51, "reward_mean": 22.897727272727273, "student_loss": null, "teacher_policy_loss": -13.85197925567627, "teacher_value_loss": 96.66332244873047, "teacher_entropy": 0.6811603307723999, "total_time": 1.2361435890197754, "rollout_time": 0.4541645050048828, "train_time": 0.7772140502929688, "student_train_time": 0.004409074783325195, "throughput": 1617.9350180394008, "inference_time": 0.05744807355404191, "env_time": 0.3967164314508409, "samples": 2000, "teacher_eval_reward": 30.0}
{"epoch": 52, "reward_mean": 24.21951219512195, "student_loss": null, "teacher_policy_loss": -14.90082836151123, "teacher_value_loss": 78.49585723876953, "teacher_entropy": 0.6829656362533569, "total_time": -1.2569012641906738, "rollout_time": 0.4288179874420166, "train_time": -1.6906638145446777, "student_train_time": 0.004583597183227539, "throughput": 200000000000.0, "inference_time": 0.05283634203078691, "env_time": 0.3759816454112297, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 53, "reward_mean": 25.367088607594937, "student_loss": null, "teacher_policy_loss": -14.471187591552734, "teacher_value_loss": 63.28357696533203, "teacher_entropy": 0.6809425950050354, "total_time": 1.2444193363189697, "rollout_time": 0.4422900676727295, "train_time": 0.7926034927368164, "student_train_time": 0.009105205535888672, "throughput": 1607.1752837882293, "inference_time": 0.05806104653493094, "env_time": 0.38422902113779855, "samples": 2000, "teacher_eval_reward": 406.0}
{"epoch": 54, "reward_mean": 24.08641975308642, "student_loss": null, "teacher_policy_loss": -14.694162368774414, "teacher_value_loss": 83.16664123535156, "teacher_entropy": 0.6797013878822327, "total_time": 1.1975195407867432, "rollout_time": 0.45615696907043457, "train_time": 0.736487865447998, "student_train_time": 0.004487276077270508, "throughput": 1670.1188848125562, "inference_time": 0.06102833873410418, "env_time": 0.3951286303363304, "samples": 2000, "teacher_eval_reward": 367.0}
{"epoch": 55, "reward_mean": 24.129411764705882, "student_loss": null, "teacher_policy_loss": -14.345325469970703, "teacher_value_loss": 75.68992614746094, "teacher_entropy": 0.6639513373374939, "total_time": 1.2735130786895752, "rollout_time": 0.4479966163635254, "train_time": 0.815662145614624, "student_train_time": 0.009430646896362305, "throughput": 1570.4589402866347, "inference_time": 0.05442358453910856, "env_time": 0.39357303182441683, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 56, "reward_mean": 22.651162790697676, "student_loss": null, "teacher_policy_loss": -14.04496955871582, "teacher_value_loss": 101.27228546142578, "teacher_entropy": 0.6484490036964417, "total_time": 1.353090763092041, "rollout_time": 0.6044185161590576, "train_time": 0.7405002117156982, "student_train_time": 0.0077936649322509766, "throughput": 1478.097445163, "inference_time": 0.10112837900305749, "env_time": 0.5032901371560001, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 57, "reward_mean": 23.611764705882354, "student_loss": null, "teacher_policy_loss": -13.988950729370117, "teacher_value_loss": 69.05192565917969, "teacher_entropy": 0.6305713057518005, "total_time": 1.4569480419158936, "rollout_time": 0.5682048797607422, "train_time": 0.8836643695831299, "student_train_time": 0.004715919494628906, "throughput": 1372.7325494531642, "inference_time": 0.08970193422464945, "env_time": 0.47850294553609274, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 58, "reward_mean": 24.227848101265824, "student_loss": null, "teacher_policy_loss": -15.524924278259277, "teacher_value_loss": 91.04422760009766, "teacher_entropy": 0.6394666433334351, "total_time": 1.5882573127746582, "rollout_time": 0.601168155670166, "train_time": 0.9790158271789551, "student_train_time": 0.007666349411010742, "throughput": 1259.241801636055, "inference_time": 0.09922708448721096, "env_time": 0.5019410711829551, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 59, "reward_mean": 24.08235294117647, "student_loss": null, "teacher_policy_loss": -13.438863754272461, "teacher_value_loss": 75.39718627929688, "teacher_entropy": 0.628525972366333, "total_time": 1.3773071765899658, "rollout_time": 0.45018720626831055, "train_time": 0.9115350246429443, "student_train_time": 0.015204668045043945, "throughput": 1452.1088933492244, "inference_time": 0.056300691239812295, "env_time": 0.39388651502849825, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 60, "reward_mean": 23.848837209302324, "student_loss": null, "teacher_policy_loss": -13.415474891662598, "teacher_value_loss": 66.42296600341797, "teacher_entropy": 0.6475552916526794, "total_time": 1.2163903713226318, "rollout_time": 0.4305706024169922, "train_time": 0.7783012390136719, "student_train_time": 0.007158756256103516, "throughput": 1644.2090032538788, "inference_time": 0.05268575726040581, "env_time": 0.3778848451565864, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 61, "reward_mean": 23.987951807228917, "student_loss": null, "teacher_policy_loss": -14.440414428710938, "teacher_value_loss": 59.98940658569336, "teacher_entropy": 0.6655946969985962, "total_time": 1.1626098155975342, "rollout_time": 0.4321916103363037, "train_time": 0.725170373916626, "student_train_time": 0.0048923492431640625, "throughput": 1720.2676023959777, "inference_time": 0.05320616094832076, "env_time": 0.37898544938798295, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 62, "reward_mean": 23.58823529411765, "student_loss": null, "teacher_policy_loss": -13.255478858947754, "teacher_value_loss": 56.9859619140625, "teacher_entropy": 0.6521567702293396, "total_time": 1.3849003314971924, "rollout_time": 0.44163942337036133, "train_time": 0.9338414669036865, "student_train_time": 0.009061813354492188, "throughput": 1444.1472462049553, "inference_time": 0.05671133297983033, "env_time": 0.384928090390531, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 63, "reward_mean": 22.685393258426966, "student_loss": null, "teacher_policy_loss": -13.305773735046387, "teacher_value_loss": 53.5847282409668, "teacher_entropy": 0.6716194748878479, "total_time": 1.1956570148468018, "rollout_time": 0.44330477714538574, "train_time": 0.7418527603149414, "student_train_time": 0.010145902633666992, "throughput": 1672.7205002483574, "inference_time": 0.056506838745917776, "env_time": 0.38679793839946797, "samples": 2000, "teacher_eval_reward": 39.0}
{"epoch": 64, "reward_mean": 27.54794520547945, "student_loss": null, "teacher_policy_loss": -15.923163414001465, "teacher_value_loss": 99.11531066894531, "teacher_entropy": 0.6798978447914124, "total_time": 1.2785520553588867, "rollout_time": 0.43372201919555664, "train_time": 0.8378458023071289, "student_train_time": 0.006627559661865234, "throughput": 1564.2695122324171, "inference_time": 0.053488838428165764, "env_time": 0.3802331807673909, "samples": 2000, "teacher_eval_reward": 17.0}
{"epoch": 65, "reward_mean": 23.48235294117647, "student_loss": null, "teacher_policy_loss": -12.805715560913086, "teacher_value_loss": 48.64100646972656, "teacher_entropy": 0.6670244932174683, "total_time": 1.186708688735962, "rollout_time": 0.4361104965209961, "train_time": 0.7451510429382324, "student_train_time": 0.0050432682037353516, "throughput": 1685.3335776367542, "inference_time": 0.05524064649762295, "env_time": 0.38086985002337315, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 66, "reward_mean": 23.294117647058822, "student_loss": null, "teacher_policy_loss": -13.317312240600586, "teacher_value_loss": 49.0980110168457, "teacher_entropy": 0.6871978044509888, "total_time": 1.1550407409667969, "rollout_time": 0.4229154586791992, "train_time": 0.7270729541778564, "student_train_time": 0.004697084426879883, "throughput": 1731.5406539910894, "inference_time": 0.051026418588662636, "env_time": 0.3718890400905366, "samples": 2000, "teacher_eval_reward": 169.0}
{"epoch": 67, "reward_mean": 23.344827586206897, "student_loss": null, "teacher_policy_loss": -13.227441787719727, "teacher_value_loss": 44.931644439697266, "teacher_entropy": 0.6864687204360962, "total_time": 1.2048990726470947, "rollout_time": 0.42862701416015625, "train_time": 0.77140212059021, "student_train_time": 0.0045146942138671875, "throughput": 1659.8900649878615, "inference_time": 0.05608302602922777, "env_time": 0.3725439881309285, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 68, "reward_mean": 23.290697674418606, "student_loss": null, "teacher_policy_loss": -13.8750638961792, "teacher_value_loss": 55.29567337036133, "teacher_entropy": 0.6803022027015686, "total_time": 1.1779699325561523, "rollout_time": 0.4170200824737549, "train_time": 0.7474963665008545, "student_train_time": 0.013090133666992188, "throughput": 1697.8362050889295, "inference_time": 0.05120066477866203, "env_time": 0.36581941769509285, "samples": 2000, "teacher_eval_reward": 96.0}
{"epoch": 69, "reward_mean": 20.49484536082474, "student_loss": null, "teacher_policy_loss": -11.68457317352295, "teacher_value_loss": 27.577186584472656, "teacher_entropy": 0.6700889468193054, "total_time": 1.2706890106201172, "rollout_time": 0.4290163516998291, "train_time": 0.8300666809082031, "student_train_time": 0.011250734329223633, "throughput": 1573.9492379996007, "inference_time": 0.05270573852430971, "env_time": 0.3763106131755194, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 70, "reward_mean": 28.357142857142858, "student_loss": null, "teacher_policy_loss": -16.424903869628906, "teacher_value_loss": 110.2650375366211, "teacher_entropy": 0.6595402956008911, "total_time": 1.245905876159668, "rollout_time": 0.4689514636993408, "train_time": 0.7693955898284912, "student_train_time": 0.007200956344604492, "throughput": 1605.2576990524537, "inference_time": 0.062322631929419, "env_time": 0.4066288317699218, "samples": 2000, "teacher_eval_reward": 51.0}
{"epoch": 71, "reward_mean": 24.154761904761905, "student_loss": null, "teacher_policy_loss": -14.501062393188477, "teacher_value_loss": 101.89776611328125, "teacher_entropy": 0.6360457539558411, "total_time": 1.3002116680145264, "rollout_time": 0.45147252082824707, "train_time": 0.840949296951294, "student_train_time": 0.007305622100830078, "throughput": 1538.2110845490854, "inference_time": 0.05580228399776388, "env_time": 0.3956702368304832, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 72, "reward_mean": 24.325, "student_loss": null, "teacher_policy_loss": -14.707327842712402, "teacher_value_loss": 93.91699981689453, "teacher_entropy": 0.6324645280838013, "total_time": 1.1734426021575928, "rollout_time": 0.428786039352417, "train_time": 0.7361364364624023, "student_train_time": 0.008124828338623047, "throughput": 1704.3867303970621, "inference_time": 0.05764634022852988, "env_time": 0.3711396991238871, "samples": 2000, "teacher_eval_reward": 70.0}
{"epoch": 73, "reward_mean": 23.905882352941177, "student_loss": null, "teacher_policy_loss": -13.127564430236816, "teacher_value_loss": 63.05609893798828, "teacher_entropy": 0.6264782547950745, "total_time": 1.4555113315582275, "rollout_time": 0.42610740661621094, "train_time": 1.023082971572876, "student_train_time": 0.0059697628021240234, "throughput": 1374.0875502898757, "inference_time": 0.054448576742288424, "env_time": 0.3716588298739225, "samples": 2000, "teacher_eval_reward": 139.0}
{"epoch": 74, "reward_mean": 24.036585365853657, "student_loss": null, "teacher_policy_loss": -14.129681587219238, "teacher_value_loss": 71.8935775756836, "teacher_entropy": 0.6284927725791931, "total_time": 1.1461029052734375, "rollout_time": 0.4313831329345703, "train_time": 0.7062499523162842, "student_train_time": 0.008027076721191406, "throughput": 1745.044001544381, "inference_time": 0.05336967900620948, "env_time": 0.37801345392836083, "samples": 2000, "teacher_eval_reward": 157.0}
{"epoch": 75, "reward_mean": 24.7375, "student_loss": null, "teacher_policy_loss": -15.164690017700195, "teacher_value_loss": 84.31139373779297, "teacher_entropy": 0.6315370798110962, "total_time": 1.3857920169830322, "rollout_time": 0.4497966766357422, "train_time": 0.9261527061462402, "student_train_time": 0.009464502334594727, "throughput": 1443.218012147409, "inference_time": 0.05580574475425237, "env_time": 0.3939909318814898, "samples": 2000, "teacher_eval_reward": 450.0}
{"epoch": 76, "reward_mean": 23.714285714285715, "student_loss": null, "teacher_policy_loss": -13.68486213684082, "teacher_value_loss": 57.234657287597656, "teacher_entropy": 0.6399931907653809, "total_time": 1.3798375129699707, "rollout_time": 0.45499539375305176, "train_time": 0.9166910648345947, "student_train_time": 0.007764577865600586, "throughput": 1449.4460262173825, "inference_time": 0.0570209909510595, "env_time": 0.39797440280199226, "samples": 2000, "teacher_eval_reward": 45.0}
{"epoch": 77, "reward_mean": 23.764705882352942, "student_loss": null, "teacher_policy_loss": -13.698540687561035, "teacher_value_loss": 72.43013000488281, "teacher_entropy": 0.6333060264587402, "total_time": 1.1730608940124512, "rollout_time": 0.43007397651672363, "train_time": 0.7251138687133789, "student_train_time": 0.01745772361755371, "throughput": 1704.9413293107114, "inference_time": 0.0559678937697754, "env_time": 0.37410608274694823, "samples": 2000, "teacher_eval_reward": 273.0}
{"epoch": 78, "reward_mean": 25.948051948051948, "student_loss": null, "teacher_policy_loss": -16.009389877319336, "teacher_value_loss": 112.88191223144531, "teacher_entropy": 0.6611397862434387, "total_time": 1.2058000564575195, "rollout_time": 0.46969127655029297, "train_time": 0.7276642322540283, "student_train_time": 0.00808572769165039, "throughput": 1658.6497813540782, "inference_time": 0.05932828252844047, "env_time": 0.4103629940218525, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 79, "reward_mean": 23.976744186046513, "student_loss": null, "teacher_policy_loss": -13.977659225463867, "teacher_value_loss": 77.70804595947266, "teacher_entropy": 0.6645330786705017, "total_time": 1.1971988677978516, "rollout_time": 0.4341084957122803, "train_time": 0.754601240158081, "student_train_time": 0.008077144622802734, "throughput": 1670.5662307205776, "inference_time": 0.05371576592915517, "env_time": 0.3803927297831251, "samples": 2000, "teacher_eval_reward": 105.0}
{"epoch": 80, "reward_mean": 23.938271604938272, "student_loss": null, "teacher_policy_loss": -14.765564918518066, "teacher_value_loss": 81.17180633544922, "teacher_entropy": 0.6769626140594482, "total_time": 1.207735538482666, "rollout_time": 0.45661330223083496, "train_time": 0.7434291839599609, "student_train_time": 0.007287740707397461, "throughput": 1655.991677211629, "inference_time": 0.05791365798904735, "env_time": 0.3986996442417876, "samples": 2000, "teacher_eval_reward": 51.0}
{"epoch": 81, "reward_mean": 24.30952380952381, "student_loss": null, "teacher_policy_loss": -14.449185371398926, "teacher_value_loss": 78.2900161743164, "teacher_entropy": 0.6737310290336609, "total_time": 1.171029806137085, "rollout_time": 0.4357419013977051, "train_time": 0.7182338237762451, "student_train_time": 0.016634702682495117, "throughput": 1707.8984578517832, "inference_time": 0.05505869653461559, "env_time": 0.3806832048630895, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 82, "reward_mean": 24.884615384615383, "student_loss": null, "teacher_policy_loss": -14.385740280151367, "teacher_value_loss": 57.890586853027344, "teacher_entropy": 0.6542356610298157, "total_time": 1.3989150524139404, "rollout_time": 0.4547591209411621, "train_time": 0.9332993030548096, "student_train_time": 0.010492801666259766, "throughput": 1429.6793765631724, "inference_time": 0.05586781948477437, "env_time": 0.39889130145638774, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 83, "reward_mean": 27.135135135135137, "student_loss": null, "teacher_policy_loss": -16.544885635375977, "teacher_value_loss": 112.5572509765625, "teacher_entropy": 0.6796702742576599, "total_time": 1.2353975772857666, "rollout_time": 0.4310023784637451, "train_time": 0.7996087074279785, "student_train_time": 0.0044345855712890625, "throughput": 1618.9120302422036, "inference_time": 0.05363132547427085, "env_time": 0.37737105298947426, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 84, "reward_mean": 25.085365853658537, "student_loss": null, "teacher_policy_loss": -14.019853591918945, "teacher_value_loss": 60.35829162597656, "teacher_entropy": 0.6831856369972229, "total_time": 1.3133456707000732, "rollout_time": 0.4569997787475586, "train_time": 0.8476262092590332, "student_train_time": 0.008311986923217773, "throughput": 1522.828334244943, "inference_time": 0.05627719470248849, "env_time": 0.4007225840450701, "samples": 2000, "teacher_eval_reward": 20.0}
{"epoch": 85, "reward_mean": 25.512820512820515, "student_loss": null, "teacher_policy_loss": -15.025994300842285, "teacher_value_loss": 84.60417938232422, "teacher_entropy": 0.6749392747879028, "total_time": 1.2340307235717773, "rollout_time": 0.43831706047058105, "train_time": 0.7869503498077393, "student_train_time": 0.008340120315551758, "throughput": 1620.7051913676848, "inference_time": 0.05504265351919457, "env_time": 0.3832744069513865, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 86, "reward_mean": 25.27848101265823, "student_loss": null, "teacher_policy_loss": -15.656842231750488, "teacher_value_loss": 115.86723327636719, "teacher_entropy": 0.686759352684021, "total_time": 1.3097593784332275, "rollout_time": 0.44016575813293457, "train_time": 0.8613288402557373, "student_train_time": 0.007891654968261719, "throughput": 1526.9980371451575, "inference_time": 0.054940782063567895, "env_time": 0.3852249760693667, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 87, "reward_mean": 23.74390243902439, "student_loss": null, "teacher_policy_loss": -13.931408882141113, "teacher_value_loss": 57.76374053955078, "teacher_entropy": 0.6683404445648193, "total_time": 1.2429168224334717, "rollout_time": 0.4332425594329834, "train_time": 0.8046779632568359, "student_train_time": 0.0046460628509521484, "throughput": 1609.1181355838894, "inference_time": 0.05494678081231541, "env_time": 0.378295778620668, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 88, "reward_mean": 24.987654320987655, "student_loss": null, "teacher_policy_loss": -13.833470344543457, "teacher_value_loss": 70.4488296508789, "teacher_entropy": 0.6505905389785767, "total_time": 1.2489466667175293, "rollout_time": 0.4436030387878418, "train_time": 0.7962024211883545, "student_train_time": 0.008729219436645508, "throughput": 1601.3494036990246, "inference_time": 0.05464380671401159, "env_time": 0.3889592320738302, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 89, "reward_mean": 25.82051282051282, "student_loss": null, "teacher_policy_loss": -15.73086929321289, "teacher_value_loss": 95.86468505859375, "teacher_entropy": 0.6749457120895386, "total_time": 1.2278823852539062, "rollout_time": 0.454667329788208, "train_time": 0.766770601272583, "student_train_time": 0.005860805511474609, "throughput": 1628.8204994376822, "inference_time": 0.05655426038902078, "env_time": 0.3981130693991872, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 90, "reward_mean": 23.511627906976745, "student_loss": null, "teacher_policy_loss": -13.601227760314941, "teacher_value_loss": 58.039119720458984, "teacher_entropy": 0.6762629151344299, "total_time": 1.269418478012085, "rollout_time": 0.4481344223022461, "train_time": 0.8165585994720459, "student_train_time": 0.004368305206298828, "throughput": 1575.5245686450137, "inference_time": 0.05867772475721722, "env_time": 0.3894566975450289, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 91, "reward_mean": 22.0, "student_loss": null, "teacher_policy_loss": -13.62585163116455, "teacher_value_loss": 78.87286376953125, "teacher_entropy": 0.67071133852005, "total_time": 1.1851081848144531, "rollout_time": 0.43413662910461426, "train_time": 0.7427291870117188, "student_train_time": 0.007878541946411133, "throughput": 1687.6096424168488, "inference_time": 0.053069610195962014, "env_time": 0.38106701890865224, "samples": 2000, "teacher_eval_reward": 420.0}
{"epoch": 92, "reward_mean": 24.216867469879517, "student_loss": null, "teacher_policy_loss": -14.535512924194336, "teacher_value_loss": 76.20272827148438, "teacher_entropy": 0.6678866147994995, "total_time": 1.1840717792510986, "rollout_time": 0.43741893768310547, "train_time": 0.7335822582244873, "student_train_time": 0.01262044906616211, "throughput": 1689.0867893709615, "inference_time": 0.05780366449653229, "env_time": 0.3796152731865732, "samples": 2000, "teacher_eval_reward": 39.0}
{"epoch": 93, "reward_mean": 22.88372093023256, "student_loss": null, "teacher_policy_loss": -12.812260627746582, "teacher_value_loss": 51.307987213134766, "teacher_entropy": 0.6538429856300354, "total_time": 1.2484405040740967, "rollout_time": 0.42890453338623047, "train_time": 0.8136098384857178, "student_train_time": 0.005576133728027344, "throughput": 1601.9986482922516, "inference_time": 0.05385058499632578, "env_time": 0.3750539483899047, "samples": 2000, "teacher_eval_reward": 29.0}
{"epoch": 94, "reward_mean": 23.078651685393258, "student_loss": null, "teacher_policy_loss": -12.547653198242188, "teacher_value_loss": 47.36409378051758, "teacher_entropy": 0.6403764486312866, "total_time": 1.3089625835418701, "rollout_time": 0.45437145233154297, "train_time": 0.8439798355102539, "student_train_time": 0.01012873649597168, "throughput": 1527.9275551087787, "inference_time": 0.05573845149956469, "env_time": 0.3986330008319783, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 95, "reward_mean": 23.72289156626506, "student_loss": null, "teacher_policy_loss": -13.761505126953125, "teacher_value_loss": 66.4935531616211, "teacher_entropy": 0.6475189328193665, "total_time": 1.4631373882293701, "rollout_time": 0.44347357749938965, "train_time": 1.0102801322937012, "student_train_time": 0.008957386016845703, "throughput": 1366.9256326094703, "inference_time": 0.0550849502269557, "env_time": 0.38838862727243395, "samples": 2000, "teacher_eval_reward": 120.0}
{"epoch": 96, "reward_mean": 26.05263157894737, "student_loss": null, "teacher_policy_loss": -15.664351463317871, "teacher_value_loss": 86.05337524414062, "teacher_entropy": 0.6630330681800842, "total_time": 1.329202651977539, "rollout_time": 0.44509196281433105, "train_time": 0.8785991668701172, "student_train_time": 0.005141019821166992, "throughput": 1504.6614577728033, "inference_time": 0.05413707269144652, "env_time": 0.39095489012288454, "samples": 2000, "teacher_eval_reward": 33.0}
{"epoch": 97, "reward_mean": 21.891304347826086, "student_loss": null, "teacher_policy_loss": -11.932024002075195, "teacher_value_loss": 48.10658264160156, "teacher_entropy": 0.6473195552825928, "total_time": 1.2417523860931396, "rollout_time": 0.44408750534057617, "train_time": 0.7900171279907227, "student_train_time": 0.007230281829833984, "throughput": 1610.6270641383626, "inference_time": 0.055780836984922644, "env_time": 0.38830666835565353, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 98, "reward_mean": 24.27710843373494, "student_loss": null, "teacher_policy_loss": -14.066441535949707, "teacher_value_loss": 73.77404022216797, "teacher_entropy": 0.6607669591903687, "total_time": 1.2725725173950195, "rollout_time": 0.48442983627319336, "train_time": 0.7786247730255127, "student_train_time": 0.009119987487792969, "throughput": 1571.6196701261777, "inference_time": 0.059007902034863946, "env_time": 0.4254219342383294, "samples": 2000, "teacher_eval_reward": 265.0}
{"epoch": 99, "reward_mean": 27.25, "student_loss": null, "teacher_policy_loss": -15.837118148803711, "teacher_value_loss": 84.97671508789062, "teacher_entropy": 0.6679335236549377, "total_time": 1.3799586296081543, "rollout_time": 0.4439370632171631, "train_time": 0.9241070747375488, "student_train_time": 0.01149749755859375, "throughput": 1449.318810787762, "inference_time": 0.0575488401864277, "env_time": 0.3863882230307354, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 100, "reward_mean": 23.666666666666668, "student_loss": null, "teacher_policy_loss": -13.863059043884277, "teacher_value_loss": 63.91123580932617, "teacher_entropy": 0.643181562423706, "total_time": 1.2013306617736816, "rollout_time": 0.44840431213378906, "train_time": 0.7435197830200195, "student_train_time": 0.008985519409179688, "throughput": 1664.8205724202014, "inference_time": 0.0569232294910762, "env_time": 0.39148108264271286, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 101, "reward_mean": 27.291666666666668, "student_loss": null, "teacher_policy_loss": -15.112678527832031, "teacher_value_loss": 62.93434524536133, "teacher_entropy": 0.660256028175354, "total_time": 1.2708423137664795, "rollout_time": 0.44321560859680176, "train_time": 0.8178389072418213, "student_train_time": 0.009439229965209961, "throughput": 1573.75937072198, "inference_time": 0.05639285249344539, "env_time": 0.38682275610335637, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 102, "reward_mean": 22.86046511627907, "student_loss": null, "teacher_policy_loss": -13.177567481994629, "teacher_value_loss": 56.554115295410156, "teacher_entropy": 0.6703166365623474, "total_time": 1.2573332786560059, "rollout_time": 0.4569993019104004, "train_time": 0.7901427745819092, "student_train_time": 0.009833097457885742, "throughput": 1590.6681497668212, "inference_time": 0.06083944823512866, "env_time": 0.39615985367527173, "samples": 2000, "teacher_eval_reward": 24.0}
{"epoch": 103, "reward_mean": 27.81081081081081, "student_loss": null, "teacher_policy_loss": -15.437590599060059, "teacher_value_loss": 88.23770141601562, "teacher_entropy": 0.6585693955421448, "total_time": 1.2577450275421143, "rollout_time": 0.43238210678100586, "train_time": 0.8196742534637451, "student_train_time": 0.005334377288818359, "throughput": 1590.1474116009035, "inference_time": 0.05493117747755605, "env_time": 0.3774509293034498, "samples": 2000, "teacher_eval_reward": 84.0}
{"epoch": 104, "reward_mean": 25.4025974025974, "student_loss": null, "teacher_policy_loss": -14.92375373840332, "teacher_value_loss": 60.284828186035156, "teacher_entropy": 0.6776673793792725, "total_time": 1.2495512962341309, "rollout_time": 0.4786970615386963, "train_time": 0.7619204521179199, "student_train_time": 0.008579730987548828, "throughput": 1600.5745470614565, "inference_time": 0.058988471268094145, "env_time": 0.41970859027060214, "samples": 2000, "teacher_eval_reward": 27.0}
{"epoch": 105, "reward_mean": 24.62962962962963, "student_loss": null, "teacher_policy_loss": -13.695449829101562, "teacher_value_loss": 54.084197998046875, "teacher_entropy": 0.6621372103691101, "total_time": -1.387561321258545, "rollout_time": -2.153599739074707, "train_time": 0.7568943500518799, "student_train_time": 0.008733272552490234, "throughput": 200000000000.0, "inference_time": 0.056474284749128856, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 11.0}
{"epoch": 106, "reward_mean": 28.085714285714285, "student_loss": null, "teacher_policy_loss": -17.010173797607422, "teacher_value_loss": 142.55621337890625, "teacher_entropy": 0.6577646136283875, "total_time": 1.3125855922698975, "rollout_time": 0.4311237335205078, "train_time": 0.8766262531280518, "student_train_time": 0.00448155403137207, "throughput": 1523.7101578582271, "inference_time": 0.05391256298207736, "env_time": 0.37721117053843045, "samples": 2000, "teacher_eval_reward": 27.0}
{"epoch": 107, "reward_mean": 22.619565217391305, "student_loss": null, "teacher_policy_loss": -12.170443534851074, "teacher_value_loss": 33.60664367675781, "teacher_entropy": 0.6643034815788269, "total_time": 1.175255537033081, "rollout_time": 0.4266510009765625, "train_time": 0.739051342010498, "student_train_time": 0.00920557975769043, "throughput": 1701.7575641881056, "inference_time": 0.05312700841204787, "env_time": 0.37352399256451463, "samples": 2000, "teacher_eval_reward": 48.0}
{"epoch": 108, "reward_mean": 21.72222222222222, "student_loss": null, "teacher_policy_loss": -12.258270263671875, "teacher_value_loss": 37.71012496948242, "teacher_entropy": 0.6721851825714111, "total_time": 1.2918803691864014, "rollout_time": 0.4211571216583252, "train_time": 0.8646445274353027, "student_train_time": 0.005728721618652344, "throughput": 1548.1309629772895, "inference_time": 0.05173562174422841, "env_time": 0.3694214999140968, "samples": 2000, "teacher_eval_reward": 31.0}
{"epoch": 109, "reward_mean": 25.50632911392405, "student_loss": null, "teacher_policy_loss": -14.114903450012207, "teacher_value_loss": 55.85005569458008, "teacher_entropy": 0.665112316608429, "total_time": 1.1947815418243408, "rollout_time": 0.4247593879699707, "train_time": 0.7622599601745605, "student_train_time": 0.007350921630859375, "throughput": 1673.9461817816098, "inference_time": 0.05494344077305868, "env_time": 0.369815947196912, "samples": 2000, "teacher_eval_reward": 46.0}
{"epoch": 110, "reward_mean": 24.679012345679013, "student_loss": null, "teacher_policy_loss": -15.128239631652832, "teacher_value_loss": 89.22342681884766, "teacher_entropy": 0.6741426587104797, "total_time": 1.2488279342651367, "rollout_time": 0.4256613254547119, "train_time": 0.8156533241271973, "student_train_time": 0.0070841312408447266, "throughput": 1601.501652168667, "inference_time": 0.05262078299529094, "env_time": 0.373040542459421, "samples": 2000, "teacher_eval_reward": 223.0}
{"epoch": 111, "reward_mean": 21.881720430107528, "student_loss": null, "teacher_policy_loss": -12.898778915405273, "teacher_value_loss": 50.89877700805664, "teacher_entropy": 0.6786015629768372, "total_time": 1.3903603553771973, "rollout_time": 0.43915843963623047, "train_time": 0.9441092014312744, "student_train_time": 0.0066874027252197266, "throughput": 1438.4759981576221, "inference_time": 0.05543125920303282, "env_time": 0.38372718043319765, "samples": 2000, "teacher_eval_reward": 34.0}
{"epoch": 112, "reward_mean": 27.971830985915492, "student_loss": null, "teacher_policy_loss": -15.511528015136719, "teacher_value_loss": 69.99321746826172, "teacher_entropy": 0.6732490658760071, "total_time": 1.355454921722412, "rollout_time": 0.43918728828430176, "train_time": 0.9069674015045166, "student_train_time": 0.00894927978515625, "throughput": 1475.5193757816362, "inference_time": 0.058321431277363445, "env_time": 0.3808658570069383, "samples": 2000, "teacher_eval_reward": 19.0}
{"epoch": 113, "reward_mean": 24.25925925925926, "student_loss": null, "teacher_policy_loss": -13.471028327941895, "teacher_value_loss": 57.190155029296875, "teacher_entropy": 0.6565977334976196, "total_time": 1.2134556770324707, "rollout_time": 0.4329030513763428, "train_time": 0.7747631072998047, "student_train_time": 0.005423545837402344, "throughput": 1648.1854573304554, "inference_time": 0.05509703426832857, "env_time": 0.3778060171080142, "samples": 2000, "teacher_eval_reward": 34.0}
{"epoch": 114, "reward_mean": 25.60810810810811, "student_loss": null, "teacher_policy_loss": -16.365680694580078, "teacher_value_loss": 127.29454803466797, "teacher_entropy": 0.6641708612442017, "total_time": 1.268310546875, "rollout_time": 0.4344022274017334, "train_time": 0.8289005756378174, "student_train_time": 0.004648685455322266, "throughput": 1576.9008662175168, "inference_time": 0.05550072881305823, "env_time": 0.37890149858867517, "samples": 2000, "teacher_eval_reward": 104.0}
{"epoch": 115, "reward_mean": 24.97590361445783, "student_loss": null, "teacher_policy_loss": -13.758956909179688, "teacher_value_loss": 53.329532623291016, "teacher_entropy": 0.6785061359405518, "total_time": 1.2638108730316162, "rollout_time": 0.4271113872528076, "train_time": 0.8221170902252197, "student_train_time": 0.014221429824829102, "throughput": 1582.515266071751, "inference_time": 0.052675556971735205, "env_time": 0.3744358302810724, "samples": 2000, "teacher_eval_reward": 21.0}
{"epoch": 116, "reward_mean": 27.07894736842105, "student_loss": null, "teacher_policy_loss": -14.840044021606445, "teacher_value_loss": 74.43131256103516, "teacher_entropy": 0.6678329110145569, "total_time": 1.2696449756622314, "rollout_time": 0.43395543098449707, "train_time": 0.8305399417877197, "student_train_time": 0.004724740982055664, "throughput": 1575.2435037651562, "inference_time": 0.05435775999831094, "env_time": 0.37959767098618613, "samples": 2000, "teacher_eval_reward": 32.0}
{"epoch": 117, "reward_mean": 26.460526315789473, "student_loss": null, "teacher_policy_loss": -14.46958065032959, "teacher_value_loss": 54.189002990722656, "teacher_entropy": 0.673952043056488, "total_time": 1.217151403427124, "rollout_time": 0.4598848819732666, "train_time": 0.7508544921875, "student_train_time": 0.0060155391693115234, "throughput": 1643.1809505116744, "inference_time": 0.0588065937608917, "env_time": 0.4010782882123749, "samples": 2000, "teacher_eval_reward": 93.0}
{"epoch": 118, "reward_mean": 25.025316455696203, "student_loss": null, "teacher_policy_loss": -15.668249130249023, "teacher_value_loss": 89.16690826416016, "teacher_entropy": 0.6752826571464539, "total_time": 1.331087589263916, "rollout_time": 0.438129186630249, "train_time": 0.8861448764801025, "student_train_time": 0.0064542293548583984, "throughput": 1502.5307245979122, "inference_time": 0.0551587697755167, "env_time": 0.3829704168547323, "samples": 2000, "teacher_eval_reward": 27.0}
{"epoch": 119, "reward_mean": 26.586666666666666, "student_loss": null, "teacher_policy_loss": -15.232980728149414, "teacher_value_loss": 74.92193603515625, "teacher_entropy": 0.6476688385009766, "total_time": 1.2821083068847656, "rollout_time": 0.4593067169189453, "train_time": 0.8055694103240967, "student_train_time": 0.01685309410095215, "throughput": 1559.9306152688064, "inference_time": 0.055724218300383654, "env_time": 0.40358249861856166, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 120, "reward_mean": 25.756410256410255, "student_loss": null, "teacher_policy_loss": -15.952122688293457, "teacher_value_loss": 97.50962829589844, "teacher_entropy": 0.6682582497596741, "total_time": 1.2025947570800781, "rollout_time": 0.4432387351989746, "train_time": 0.7532939910888672, "student_train_time": 0.005708932876586914, "throughput": 1663.0706131266, "inference_time": 0.05588114993588533, "env_time": 0.3873575852630893, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 121, "reward_mean": 25.884615384615383, "student_loss": null, "teacher_policy_loss": -13.976709365844727, "teacher_value_loss": 51.981502532958984, "teacher_entropy": 0.6610906720161438, "total_time": 1.2593128681182861, "rollout_time": 0.4573333263397217, "train_time": 0.795396089553833, "student_train_time": 0.006117343902587891, "throughput": 1588.1676830543922, "inference_time": 0.05633960754130385, "env_time": 0.40099371879841783, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 122, "reward_mean": 23.341176470588234, "student_loss": null, "teacher_policy_loss": -12.953535079956055, "teacher_value_loss": 53.603851318359375, "teacher_entropy": 0.6464595198631287, "total_time": 1.1448230743408203, "rollout_time": 0.4271814823150635, "train_time": 0.7116706371307373, "student_train_time": 0.00562596321105957, "throughput": 1746.9948368673329, "inference_time": 0.053436834288731916, "env_time": 0.37374464802633156, "samples": 2000, "teacher_eval_reward": 83.0}
{"epoch": 123, "reward_mean": 23.710843373493976, "student_loss": null, "teacher_policy_loss": -13.56584644317627, "teacher_value_loss": 48.01787185668945, "teacher_entropy": 0.6593244075775146, "total_time": 1.2859668731689453, "rollout_time": 0.4489285945892334, "train_time": 0.818955659866333, "student_train_time": 0.017682313919067383, "throughput": 1555.2500159444214, "inference_time": 0.055834701490312, "env_time": 0.3930938930989214, "samples": 2000, "teacher_eval_reward": 34.0}
{"epoch": 124, "reward_mean": 27.356164383561644, "student_loss": null, "teacher_policy_loss": -16.603492736816406, "teacher_value_loss": 150.9743194580078, "teacher_entropy": 0.6463236808776855, "total_time": 1.1487882137298584, "rollout_time": 0.4207930564880371, "train_time": 0.7160089015960693, "student_train_time": 0.01155853271484375, "throughput": 1740.9649368759167, "inference_time": 0.05167850524230744, "env_time": 0.36911455124572967, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 125, "reward_mean": 26.55263157894737, "student_loss": null, "teacher_policy_loss": -13.567996978759766, "teacher_value_loss": 73.321533203125, "teacher_entropy": 0.6123558282852173, "total_time": 1.3768434524536133, "rollout_time": 0.43439650535583496, "train_time": 0.9315271377563477, "student_train_time": 0.010293960571289062, "throughput": 1452.5979670643646, "inference_time": 0.05440977852413198, "env_time": 0.379986726831703, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 126, "reward_mean": 24.59259259259259, "student_loss": null, "teacher_policy_loss": -13.8704252243042, "teacher_value_loss": 142.68728637695312, "teacher_entropy": 0.5941375494003296, "total_time": -1.324371337890625, "rollout_time": 0.44712328910827637, "train_time": -1.7797958850860596, "student_train_time": 0.007942676544189453, "throughput": 200000000000.0, "inference_time": 0.05607392525780597, "env_time": 0.3910493638504704, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 127, "reward_mean": 26.75, "student_loss": null, "teacher_policy_loss": -15.741482734680176, "teacher_value_loss": 177.75186157226562, "teacher_entropy": 0.5917177796363831, "total_time": 1.3513767719268799, "rollout_time": 0.4316244125366211, "train_time": 0.9042103290557861, "student_train_time": 0.015182018280029297, "throughput": 1479.9721599093873, "inference_time": 0.054511742973772925, "env_time": 0.37711266956284817, "samples": 2000, "teacher_eval_reward": 17.0}
{"epoch": 128, "reward_mean": 25.28205128205128, "student_loss": null, "teacher_policy_loss": -13.561575889587402, "teacher_value_loss": 50.81724548339844, "teacher_entropy": 0.6290835738182068, "total_time": 1.199556589126587, "rollout_time": 0.4440574645996094, "train_time": 0.7448890209197998, "student_train_time": 0.010164976119995117, "throughput": 1667.2827427476568, "inference_time": 0.05752448732710036, "env_time": 0.386532977272509, "samples": 2000, "teacher_eval_reward": 187.0}
{"epoch": 129, "reward_mean": 28.014084507042252, "student_loss": null, "teacher_policy_loss": -17.013296127319336, "teacher_value_loss": 94.45954132080078, "teacher_entropy": 0.6657416820526123, "total_time": 1.2518424987792969, "rollout_time": 0.4177873134613037, "train_time": 0.8234131336212158, "student_train_time": 0.010046005249023438, "throughput": 1597.6450727230065, "inference_time": 0.05069028502475703, "env_time": 0.3670970284365467, "samples": 2000, "teacher_eval_reward": 19.0}
{"epoch": 130, "reward_mean": 26.105263157894736, "student_loss": null, "teacher_policy_loss": -13.720516204833984, "teacher_value_loss": 75.04319763183594, "teacher_entropy": 0.6091195344924927, "total_time": 1.227860689163208, "rollout_time": 0.4431915283203125, "train_time": 0.7782597541809082, "student_train_time": 0.006051301956176758, "throughput": 1628.84928042041, "inference_time": 0.057033661021705484, "env_time": 0.386157867298607, "samples": 2000, "teacher_eval_reward": 20.0}
{"epoch": 131, "reward_mean": 26.644736842105264, "student_loss": null, "teacher_policy_loss": -13.145127296447754, "teacher_value_loss": 64.96632385253906, "teacher_entropy": 0.5731990337371826, "total_time": 1.2131364345550537, "rollout_time": 0.424976110458374, "train_time": 0.7832376956939697, "student_train_time": 0.0045621395111083984, "throughput": 1648.619184975305, "inference_time": 0.055038396749296226, "env_time": 0.3699377137090778, "samples": 2000, "teacher_eval_reward": 17.0}
{"epoch": 132, "reward_mean": 23.576470588235296, "student_loss": null, "teacher_policy_loss": -12.069336891174316, "teacher_value_loss": 48.90501022338867, "teacher_entropy": 0.5930852293968201, "total_time": 1.4260082244873047, "rollout_time": 0.4455878734588623, "train_time": 0.9708390235900879, "student_train_time": 0.00916743278503418, "throughput": 1402.5164551340954, "inference_time": 0.0549367924741091, "env_time": 0.3906510809847532, "samples": 2000, "teacher_eval_reward": 36.0}
{"epoch": 133, "reward_mean": 23.04705882352941, "student_loss": null, "teacher_policy_loss": -13.447954177856445, "teacher_value_loss": 61.61243438720703, "teacher_entropy": 0.6323664784431458, "total_time": 1.1950840950012207, "rollout_time": 0.43198323249816895, "train_time": 0.7457168102264404, "student_train_time": 0.016943931579589844, "throughput": 1673.5223975999422, "inference_time": 0.055208398543982184, "env_time": 0.37677483395418676, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 134, "reward_mean": 28.535211267605632, "student_loss": null, "teacher_policy_loss": -16.54739761352539, "teacher_value_loss": 105.31169891357422, "teacher_entropy": 0.6506831645965576, "total_time": 1.2581284046173096, "rollout_time": 0.43329453468322754, "train_time": 0.820016622543335, "student_train_time": 0.004408121109008789, "throughput": 1589.6628616443556, "inference_time": 0.05243313881874201, "env_time": 0.38086139586448553, "samples": 2000, "teacher_eval_reward": 27.0}
{"epoch": 135, "reward_mean": 26.662337662337663, "student_loss": null, "teacher_policy_loss": -13.967779159545898, "teacher_value_loss": 78.29348754882812, "teacher_entropy": 0.6073682904243469, "total_time": 1.2127909660339355, "rollout_time": 0.4425923824310303, "train_time": 0.7640328407287598, "student_train_time": 0.005762815475463867, "throughput": 1649.0888009665775, "inference_time": 0.05341811872312974, "env_time": 0.38917426370790054, "samples": 2000, "teacher_eval_reward": 14.0}
{"epoch": 136, "reward_mean": 26.82191780821918, "student_loss": null, "teacher_policy_loss": -13.323119163513184, "teacher_value_loss": 76.02989196777344, "teacher_entropy": 0.5600157380104065, "total_time": 1.337552785873413, "rollout_time": 0.44081568717956543, "train_time": 0.8855130672454834, "student_train_time": 0.010792970657348633, "throughput": 1495.2680904432593, "inference_time": 0.05583195325198176, "env_time": 0.38498373392758367, "samples": 2000, "teacher_eval_reward": 19.0}
{"epoch": 137, "reward_mean": 26.86842105263158, "student_loss": null, "teacher_policy_loss": -13.549744606018066, "teacher_value_loss": 74.48360443115234, "teacher_entropy": 0.5767601132392883, "total_time": 1.311866044998169, "rollout_time": 0.4645984172821045, "train_time": 0.8421485424041748, "student_train_time": 0.004751920700073242, "throughput": 1524.545899808537, "inference_time": 0.05710549297509715, "env_time": 0.40749292430700734, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 138, "reward_mean": 24.443037974683545, "student_loss": null, "teacher_policy_loss": -13.177140235900879, "teacher_value_loss": 51.16659164428711, "teacher_entropy": 0.6183872222900391, "total_time": 1.2971994876861572, "rollout_time": 0.4385237693786621, "train_time": 0.8517031669616699, "student_train_time": 0.006560802459716797, "throughput": 1541.7829092481707, "inference_time": 0.05825538698809396, "env_time": 0.38026838239056815, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 139, "reward_mean": 29.318840579710145, "student_loss": null, "teacher_policy_loss": -16.494457244873047, "teacher_value_loss": 98.05998229980469, "teacher_entropy": 0.6388497948646545, "total_time": 1.2320780754089355, "rollout_time": 0.4362068176269531, "train_time": 0.7872202396392822, "student_train_time": 0.008116483688354492, "throughput": 1623.2737518165686, "inference_time": 0.0551050897956884, "env_time": 0.3811017278312647, "samples": 2000, "teacher_eval_reward": 36.0}
{"epoch": 140, "reward_mean": 27.17808219178082, "student_loss": null, "teacher_policy_loss": -15.566886901855469, "teacher_value_loss": 86.1731185913086, "teacher_entropy": 0.6181856393814087, "total_time": 1.3248467445373535, "rollout_time": 0.46445703506469727, "train_time": 0.8511528968811035, "student_train_time": 0.008688688278198242, "throughput": 1509.608570384807, "inference_time": 0.05806508303976443, "env_time": 0.40639195202493283, "samples": 2000, "teacher_eval_reward": 44.0}
{"epoch": 141, "reward_mean": 27.5, "student_loss": null, "teacher_policy_loss": -15.13367748260498, "teacher_value_loss": 84.06751251220703, "teacher_entropy": 0.6302812099456787, "total_time": 1.2546157836914062, "rollout_time": 0.4553501605987549, "train_time": 0.7911043167114258, "student_train_time": 0.007802486419677734, "throughput": 1594.113533400225, "inference_time": 0.056395099018118344, "env_time": 0.39895506158063654, "samples": 2000, "teacher_eval_reward": 212.0}
{"epoch": 142, "reward_mean": 26.064935064935064, "student_loss": null, "teacher_policy_loss": -15.031285285949707, "teacher_value_loss": 73.66719818115234, "teacher_entropy": 0.6456143260002136, "total_time": 1.3915295600891113, "rollout_time": 0.4501018524169922, "train_time": 0.9300158023834229, "student_train_time": 0.011052131652832031, "throughput": 1437.2673476457971, "inference_time": 0.0577732243182254, "env_time": 0.3923286280987668, "samples": 2000, "teacher_eval_reward": 93.0}
{"epoch": 143, "reward_mean": 26.266666666666666, "student_loss": null, "teacher_policy_loss": -15.59846305847168, "teacher_value_loss": 79.82379150390625, "teacher_entropy": 0.648565411567688, "total_time": 1.1770775318145752, "rollout_time": 0.4316065311431885, "train_time": 0.7383177280426025, "student_train_time": 0.006752967834472656, "throughput": 1699.1234187579919, "inference_time": 0.0533855724879686, "env_time": 0.3782209586552199, "samples": 2000, "teacher_eval_reward": 200.0}
{"epoch": 144, "reward_mean": 25.225, "student_loss": null, "teacher_policy_loss": -13.745026588439941, "teacher_value_loss": 51.727603912353516, "teacher_entropy": 0.6555549502372742, "total_time": 1.245023488998413, "rollout_time": 0.4538259506225586, "train_time": 0.7761390209197998, "student_train_time": 0.014681339263916016, "throughput": 1606.395395486831, "inference_time": 0.05553163593685895, "env_time": 0.39829431468569965, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 145, "reward_mean": 24.333333333333332, "student_loss": null, "teacher_policy_loss": -13.436126708984375, "teacher_value_loss": 41.2266960144043, "teacher_entropy": 0.6650439500808716, "total_time": 1.273238182067871, "rollout_time": 0.4462001323699951, "train_time": 0.819838285446167, "student_train_time": 0.006799936294555664, "throughput": 1570.7980079200831, "inference_time": 0.057854532797136926, "env_time": 0.3883455995728582, "samples": 2000, "teacher_eval_reward": 38.0}
{"epoch": 146, "reward_mean": 25.329113924050635, "student_loss": null, "teacher_policy_loss": -14.411419868469238, "teacher_value_loss": 69.66119384765625, "teacher_entropy": 0.6642195582389832, "total_time": -1.3488895893096924, "rollout_time": 0.4473385810852051, "train_time": -1.8025126457214355, "student_train_time": 0.005916118621826172, "throughput": 200000000000.0, "inference_time": 0.05811085974710295, "env_time": 0.38922772133810213, "samples": 2000, "teacher_eval_reward": 26.0}
{"epoch": 147, "reward_mean": 29.16176470588235, "student_loss": null, "teacher_policy_loss": -17.753950119018555, "teacher_value_loss": 205.10089111328125, "teacher_entropy": 0.6643350124359131, "total_time": 1.2258517742156982, "rollout_time": 0.42140746116638184, "train_time": 0.7929215431213379, "student_train_time": 0.011161327362060547, "throughput": 1631.5186240845496, "inference_time": 0.052512891530568595, "env_time": 0.36889456963581324, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 148, "reward_mean": 24.270588235294117, "student_loss": null, "teacher_policy_loss": -13.356071472167969, "teacher_value_loss": 49.925872802734375, "teacher_entropy": 0.675198495388031, "total_time": 1.339491844177246, "rollout_time": 0.4479029178619385, "train_time": 0.8791611194610596, "student_train_time": 0.012031793594360352, "throughput": 1493.1035292928243, "inference_time": 0.05651012046109827, "env_time": 0.3913927974008402, "samples": 2000, "teacher_eval_reward": 133.0}
{"epoch": 149, "reward_mean": 23.28235294117647, "student_loss": null, "teacher_policy_loss": -13.257169723510742, "teacher_value_loss": 49.640682220458984, "teacher_entropy": 0.6814976930618286, "total_time": 1.1798620223999023, "rollout_time": 0.43993067741394043, "train_time": 0.7322268486022949, "student_train_time": 0.007345676422119141, "throughput": 1695.1134641420979, "inference_time": 0.05440360849024728, "env_time": 0.38552706892369315, "samples": 2000, "teacher_eval_reward": 228.0}
{"epoch": 150, "reward_mean": 30.625, "student_loss": null, "teacher_policy_loss": -18.634397506713867, "teacher_value_loss": 138.3206024169922, "teacher_entropy": 0.6790496706962585, "total_time": 1.193694829940796, "rollout_time": 0.44217538833618164, "train_time": 0.7422850131988525, "student_train_time": 0.008864879608154297, "throughput": 1675.4701032752187, "inference_time": 0.056609756784382625, "env_time": 0.385565631551799, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 151, "reward_mean": 25.55128205128205, "student_loss": null, "teacher_policy_loss": -14.740945816040039, "teacher_value_loss": 67.14155578613281, "teacher_entropy": 0.6595296263694763, "total_time": 1.4024348258972168, "rollout_time": 0.42887353897094727, "train_time": 0.9673631191253662, "student_train_time": 0.0058405399322509766, "throughput": 1426.0912258225526, "inference_time": 0.052945013074349845, "env_time": 0.3759285258965974, "samples": 2000, "teacher_eval_reward": 10.0}
{"epoch": 152, "reward_mean": 27.223684210526315, "student_loss": null, "teacher_policy_loss": -15.055790901184082, "teacher_value_loss": 74.12181091308594, "teacher_entropy": 0.6676686406135559, "total_time": 1.263113260269165, "rollout_time": 0.4495394229888916, "train_time": 0.8055028915405273, "student_train_time": 0.007533550262451172, "throughput": 1583.3892833757498, "inference_time": 0.057155982531185145, "env_time": 0.39238344045770646, "samples": 2000, "teacher_eval_reward": 9.0}
{"epoch": 153, "reward_mean": 26.051948051948052, "student_loss": null, "teacher_policy_loss": -14.762804985046387, "teacher_value_loss": 68.88764953613281, "teacher_entropy": 0.6722620725631714, "total_time": 1.1661288738250732, "rollout_time": 0.42838191986083984, "train_time": 0.7282798290252686, "student_train_time": 0.009104728698730469, "throughput": 1715.0763049367843, "inference_time": 0.0519034092376387, "env_time": 0.37647851062320115, "samples": 2000, "teacher_eval_reward": 217.0}
{"epoch": 154, "reward_mean": 30.166666666666668, "student_loss": null, "teacher_policy_loss": -18.4685115814209, "teacher_value_loss": 153.3256072998047, "teacher_entropy": 0.6778435111045837, "total_time": 1.1952402591705322, "rollout_time": 0.45638155937194824, "train_time": 0.7313299179077148, "student_train_time": 0.007170915603637695, "throughput": 1673.303743456526, "inference_time": 0.0583744647756248, "env_time": 0.39800709459632344, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 155, "reward_mean": 27.47222222222222, "student_loss": null, "teacher_policy_loss": -16.610450744628906, "teacher_value_loss": 100.4023208618164, "teacher_entropy": 0.6763081550598145, "total_time": 1.2540490627288818, "rollout_time": 0.426605224609375, "train_time": 0.8222751617431641, "student_train_time": 0.004815816879272461, "throughput": 1594.8339338876317, "inference_time": 0.05379008350610093, "env_time": 0.3728151411032741, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 156, "reward_mean": 25.78205128205128, "student_loss": null, "teacher_policy_loss": -14.472930908203125, "teacher_value_loss": 62.04405212402344, "teacher_entropy": 0.6692225337028503, "total_time": 1.3211188316345215, "rollout_time": 0.45192551612854004, "train_time": 0.8598580360412598, "student_train_time": 0.008903264999389648, "throughput": 1513.8683607481014, "inference_time": 0.05888314173898834, "env_time": 0.3930423743895517, "samples": 2000, "teacher_eval_reward": 86.0}
{"epoch": 157, "reward_mean": 29.560606060606062, "student_loss": null, "teacher_policy_loss": -18.19341468811035, "teacher_value_loss": 123.4338150024414, "teacher_entropy": 0.6658493876457214, "total_time": 1.3112013339996338, "rollout_time": 0.43184447288513184, "train_time": 0.8729698657989502, "student_train_time": 0.005988121032714844, "throughput": 1525.31876542505, "inference_time": 0.054027388576287194, "env_time": 0.37781708430884464, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 158, "reward_mean": 27.30263157894737, "student_loss": null, "teacher_policy_loss": -14.520509719848633, "teacher_value_loss": 61.97304153442383, "teacher_entropy": 0.6594996452331543, "total_time": 1.2044637203216553, "rollout_time": 0.43651628494262695, "train_time": 0.7624053955078125, "student_train_time": 0.005170583724975586, "throughput": 1660.4900307548446, "inference_time": 0.056715946724580135, "env_time": 0.3798003382180468, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 159, "reward_mean": 25.064102564102566, "student_loss": null, "teacher_policy_loss": -14.309951782226562, "teacher_value_loss": 63.44890594482422, "teacher_entropy": 0.6528445482254028, "total_time": 1.3276817798614502, "rollout_time": 0.4460287094116211, "train_time": 0.8741061687469482, "student_train_time": 0.007191658020019531, "throughput": 1506.3850617944831, "inference_time": 0.05553349998081103, "env_time": 0.39049520943081006, "samples": 2000, "teacher_eval_reward": 157.0}
{"epoch": 160, "reward_mean": 29.057142857142857, "student_loss": null, "teacher_policy_loss": -16.654109954833984, "teacher_value_loss": 89.56002807617188, "teacher_entropy": 0.6513208150863647, "total_time": 1.19167160987854, "rollout_time": 0.43283772468566895, "train_time": 0.752988338470459, "student_train_time": 0.00543212890625, "throughput": 1678.314716420783, "inference_time": 0.053293981991373585, "env_time": 0.37954374269429536, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 161, "reward_mean": 27.15277777777778, "student_loss": null, "teacher_policy_loss": -15.819506645202637, "teacher_value_loss": 87.80229949951172, "teacher_entropy": 0.6482144594192505, "total_time": 1.3043909072875977, "rollout_time": 0.4463319778442383, "train_time": 0.8523969650268555, "student_train_time": 0.005235195159912109, "throughput": 1533.2826906612524, "inference_time": 0.05836970301243127, "env_time": 0.387962274831807, "samples": 2000, "teacher_eval_reward": 118.0}
{"epoch": 162, "reward_mean": 28.02777777777778, "student_loss": null, "teacher_policy_loss": -16.254396438598633, "teacher_value_loss": 84.77091979980469, "teacher_entropy": 0.6451837420463562, "total_time": 1.2018277645111084, "rollout_time": 0.4515831470489502, "train_time": 0.7425477504730225, "student_train_time": 0.0073299407958984375, "throughput": 1664.131965542983, "inference_time": 0.05489086724992376, "env_time": 0.39669227979902644, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 163, "reward_mean": 29.3768115942029, "student_loss": null, "teacher_policy_loss": -17.73029327392578, "teacher_value_loss": 140.60845947265625, "teacher_entropy": 0.636962890625, "total_time": 1.1694896221160889, "rollout_time": 0.4399096965789795, "train_time": 0.7209322452545166, "student_train_time": 0.00829315185546875, "throughput": 1710.1477107434057, "inference_time": 0.054062166296716896, "env_time": 0.3858475302822626, "samples": 2000, "teacher_eval_reward": 207.0}
{"epoch": 164, "reward_mean": 28.582089552238806, "student_loss": null, "teacher_policy_loss": -17.33987808227539, "teacher_value_loss": 98.66947174072266, "teacher_entropy": 0.6388941407203674, "total_time": 1.1803767681121826, "rollout_time": 0.42223119735717773, "train_time": 0.7502970695495605, "student_train_time": 0.007487297058105469, "throughput": 1694.3742489939625, "inference_time": 0.054681782550687785, "env_time": 0.36754941480648995, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 165, "reward_mean": 25.653846153846153, "student_loss": null, "teacher_policy_loss": -14.492371559143066, "teacher_value_loss": 80.47105407714844, "teacher_entropy": 0.6342281103134155, "total_time": 1.3356318473815918, "rollout_time": 0.4355645179748535, "train_time": 0.8899219036102295, "student_train_time": 0.009692668914794922, "throughput": 1497.4186216964301, "inference_time": 0.05398074321055901, "env_time": 0.3815837747642945, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 166, "reward_mean": 31.208955223880597, "student_loss": null, "teacher_policy_loss": -17.181621551513672, "teacher_value_loss": 119.12854766845703, "teacher_entropy": 0.6375377178192139, "total_time": 1.1636149883270264, "rollout_time": 0.43204188346862793, "train_time": 0.7229738235473633, "student_train_time": 0.008205890655517578, "throughput": 1718.7815729973333, "inference_time": 0.05387583054834977, "env_time": 0.37816605292027816, "samples": 2000, "teacher_eval_reward": 98.0}
{"epoch": 167, "reward_mean": 32.20338983050848, "student_loss": null, "teacher_policy_loss": -19.296829223632812, "teacher_value_loss": 152.8357391357422, "teacher_entropy": 0.640727698802948, "total_time": 1.5472848415374756, "rollout_time": 0.4464278221130371, "train_time": 1.0907478332519531, "student_train_time": 0.009735584259033203, "throughput": 1292.5868245517609, "inference_time": 0.05669999976635154, "env_time": 0.38972782234668557, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 168, "reward_mean": 30.352941176470587, "student_loss": null, "teacher_policy_loss": -18.13277816772461, "teacher_value_loss": 167.9759521484375, "teacher_entropy": 0.6422027349472046, "total_time": 1.2883892059326172, "rollout_time": 0.44640445709228516, "train_time": 0.8335862159729004, "student_train_time": 0.008035898208618164, "throughput": 1552.3259514986964, "inference_time": 0.057359328186066705, "env_time": 0.38904512890621845, "samples": 2000, "teacher_eval_reward": 186.0}
{"epoch": 169, "reward_mean": 30.560606060606062, "student_loss": null, "teacher_policy_loss": -19.21179962158203, "teacher_value_loss": 191.43890380859375, "teacher_entropy": 0.6494361758232117, "total_time": 1.3310413360595703, "rollout_time": 0.4370615482330322, "train_time": 0.8865153789520264, "student_train_time": 0.007036924362182617, "throughput": 1502.582936996399, "inference_time": 0.05454596952040447, "env_time": 0.38251557871262776, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 170, "reward_mean": 29.582089552238806, "student_loss": null, "teacher_policy_loss": -16.960084915161133, "teacher_value_loss": 92.2093505859375, "teacher_entropy": 0.6528602242469788, "total_time": 1.3137397766113281, "rollout_time": 0.4405937194824219, "train_time": 0.8601062297821045, "student_train_time": 0.012659549713134766, "throughput": 1522.37150431634, "inference_time": 0.055733819002853124, "env_time": 0.38485990047956875, "samples": 2000, "teacher_eval_reward": 148.0}
{"epoch": 171, "reward_mean": 24.80246913580247, "student_loss": null, "teacher_policy_loss": -13.65463638305664, "teacher_value_loss": 71.06187438964844, "teacher_entropy": 0.650464653968811, "total_time": 1.394040822982788, "rollout_time": 0.4461350440979004, "train_time": 0.9382705688476562, "student_train_time": 0.009269475936889648, "throughput": 1434.6782153198778, "inference_time": 0.05578933474680525, "env_time": 0.39034570935109514, "samples": 2000, "teacher_eval_reward": 107.0}
{"epoch": 172, "reward_mean": 29.147058823529413, "student_loss": null, "teacher_policy_loss": -16.43073844909668, "teacher_value_loss": 79.00926971435547, "teacher_entropy": 0.6575537323951721, "total_time": 1.191394567489624, "rollout_time": 0.43743085861206055, "train_time": 0.7485883235931396, "student_train_time": 0.00501561164855957, "throughput": 1678.7049853804358, "inference_time": 0.05461292872314516, "env_time": 0.3828179298889154, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 173, "reward_mean": 29.441176470588236, "student_loss": null, "teacher_policy_loss": -16.088638305664062, "teacher_value_loss": 71.02644348144531, "teacher_entropy": 0.6623034477233887, "total_time": 1.2479438781738281, "rollout_time": 0.44684314727783203, "train_time": 0.7911539077758789, "student_train_time": 0.009581565856933594, "throughput": 1602.6361721704097, "inference_time": 0.05743937598890625, "env_time": 0.3894037712889258, "samples": 2000, "teacher_eval_reward": 171.0}
{"epoch": 174, "reward_mean": 24.658536585365855, "student_loss": null, "teacher_policy_loss": -15.155652046203613, "teacher_value_loss": 89.8839111328125, "teacher_entropy": 0.6609363555908203, "total_time": 1.2520580291748047, "rollout_time": 0.44187331199645996, "train_time": 0.803584098815918, "student_train_time": 0.006175518035888672, "throughput": 1597.3700526629284, "inference_time": 0.056385386513284175, "env_time": 0.3854879254831758, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 175, "reward_mean": 29.303030303030305, "student_loss": null, "teacher_policy_loss": -18.38237190246582, "teacher_value_loss": 147.123779296875, "teacher_entropy": 0.6600445508956909, "total_time": 1.2453885078430176, "rollout_time": 0.4184224605560303, "train_time": 0.8153712749481201, "student_train_time": 0.011206865310668945, "throughput": 1605.9245668357346, "inference_time": 0.05506909754149092, "env_time": 0.36335336301453935, "samples": 2000, "teacher_eval_reward": 357.0}
{"epoch": 176, "reward_mean": 28.916666666666668, "student_loss": null, "teacher_policy_loss": -15.370336532592773, "teacher_value_loss": 68.66873168945312, "teacher_entropy": 0.6606386303901672, "total_time": 1.2070682048797607, "rollout_time": 0.4290337562561035, "train_time": 0.7716493606567383, "student_train_time": 0.0060346126556396484, "throughput": 1656.9072003675428, "inference_time": 0.05214036549295997, "env_time": 0.37689339076314354, "samples": 2000, "teacher_eval_reward": 357.0}
{"epoch": 177, "reward_mean": 27.283783783783782, "student_loss": null, "teacher_policy_loss": -16.028745651245117, "teacher_value_loss": 101.91539764404297, "teacher_entropy": 0.6520687937736511, "total_time": 1.227881908416748, "rollout_time": 0.43000030517578125, "train_time": 0.7858603000640869, "student_train_time": 0.01165318489074707, "throughput": 1628.8211319758218, "inference_time": 0.05353405853566073, "env_time": 0.3764662466401205, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 178, "reward_mean": 25.358974358974358, "student_loss": null, "teacher_policy_loss": -14.219890594482422, "teacher_value_loss": 51.52649688720703, "teacher_entropy": 0.6495026350021362, "total_time": 1.2270514965057373, "rollout_time": 0.4373311996459961, "train_time": 0.7761282920837402, "student_train_time": 0.013189554214477539, "throughput": 1629.923443062806, "inference_time": 0.054002608987502754, "env_time": 0.38332859065849334, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 179, "reward_mean": 26.506666666666668, "student_loss": null, "teacher_policy_loss": -14.87341022491455, "teacher_value_loss": 72.96121215820312, "teacher_entropy": 0.6435304880142212, "total_time": 1.3077774047851562, "rollout_time": 0.4238123893737793, "train_time": 0.8768627643585205, "student_train_time": 0.006751298904418945, "throughput": 1529.3122458623325, "inference_time": 0.05324006701994222, "env_time": 0.3705723223538371, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 180, "reward_mean": 27.676056338028168, "student_loss": null, "teacher_policy_loss": -15.67387866973877, "teacher_value_loss": 62.249820709228516, "teacher_entropy": 0.6450631022453308, "total_time": 1.3834490776062012, "rollout_time": 0.42731642723083496, "train_time": 0.9479577541351318, "student_train_time": 0.007827281951904297, "throughput": 1445.6621731684006, "inference_time": 0.054423533019871684, "env_time": 0.3728928942109633, "samples": 2000, "teacher_eval_reward": 91.0}
{"epoch": 181, "reward_mean": 30.615384615384617, "student_loss": null, "teacher_policy_loss": -18.241455078125, "teacher_value_loss": 148.6579132080078, "teacher_entropy": 0.6441493034362793, "total_time": 1.36753511428833, "rollout_time": 0.4441988468170166, "train_time": 0.9175863265991211, "student_train_time": 0.0053327083587646484, "throughput": 1462.4852986248961, "inference_time": 0.05480017402078374, "env_time": 0.38939867279623286, "samples": 2000, "teacher_eval_reward": 61.0}
{"epoch": 182, "reward_mean": 26.294871794871796, "student_loss": null, "teacher_policy_loss": -15.548480033874512, "teacher_value_loss": 99.40660858154297, "teacher_entropy": 0.6402099132537842, "total_time": 1.1568603515625, "rollout_time": 0.4203307628631592, "train_time": 0.729219913482666, "student_train_time": 0.006963491439819336, "throughput": 1728.8171362245437, "inference_time": 0.05218142551893834, "env_time": 0.36814933734422084, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 183, "reward_mean": 26.31168831168831, "student_loss": null, "teacher_policy_loss": -14.52003002166748, "teacher_value_loss": 53.9005241394043, "teacher_entropy": 0.6403051614761353, "total_time": 1.3244600296020508, "rollout_time": 0.443178653717041, "train_time": 0.8711984157562256, "student_train_time": 0.009611129760742188, "throughput": 1510.0493448646562, "inference_time": 0.05337739643800887, "env_time": 0.38980125727903214, "samples": 2000, "teacher_eval_reward": 128.0}
{"epoch": 184, "reward_mean": 26.791666666666668, "student_loss": null, "teacher_policy_loss": -15.553255081176758, "teacher_value_loss": 71.23881530761719, "teacher_entropy": 0.6457955241203308, "total_time": 1.1734421253204346, "rollout_time": 0.42873454093933105, "train_time": 0.7388713359832764, "student_train_time": 0.005395174026489258, "throughput": 1704.3874229876103, "inference_time": 0.054450148203613935, "env_time": 0.3742843927357171, "samples": 2000, "teacher_eval_reward": 148.0}
{"epoch": 185, "reward_mean": 31.846153846153847, "student_loss": null, "teacher_policy_loss": -18.296018600463867, "teacher_value_loss": 150.4715118408203, "teacher_entropy": 0.6552090048789978, "total_time": 1.3012752532958984, "rollout_time": 0.45140528678894043, "train_time": 0.8397643566131592, "student_train_time": 0.00973963737487793, "throughput": 1536.9538419595365, "inference_time": 0.05929075273343187, "env_time": 0.39211453405550856, "samples": 2000, "teacher_eval_reward": 484.0}
{"epoch": 186, "reward_mean": 26.9, "student_loss": null, "teacher_policy_loss": -16.703405380249023, "teacher_value_loss": 98.27981567382812, "teacher_entropy": 0.6577476263046265, "total_time": 1.271599531173706, "rollout_time": 0.46872615814208984, "train_time": 0.7903017997741699, "student_train_time": 0.012117862701416016, "throughput": 1572.8222219097306, "inference_time": 0.05759652495908085, "env_time": 0.411129633183009, "samples": 2000, "teacher_eval_reward": 317.0}
{"epoch": 187, "reward_mean": 28.24, "student_loss": null, "teacher_policy_loss": -15.27731990814209, "teacher_value_loss": 72.22917938232422, "teacher_entropy": 0.6523937582969666, "total_time": 1.4073150157928467, "rollout_time": 0.4531424045562744, "train_time": 0.9405856132507324, "student_train_time": 0.013135194778442383, "throughput": 1421.1459250814924, "inference_time": 0.05892786525146221, "env_time": 0.3942145393048122, "samples": 2000, "teacher_eval_reward": 212.0}
{"epoch": 188, "reward_mean": 28.142857142857142, "student_loss": null, "teacher_policy_loss": -16.324668884277344, "teacher_value_loss": 91.92939758300781, "teacher_entropy": 0.6533050537109375, "total_time": 1.283595323562622, "rollout_time": 0.43239760398864746, "train_time": 0.8331897258758545, "student_train_time": 0.017632722854614258, "throughput": 1558.1234702920192, "inference_time": 0.054774540514699765, "env_time": 0.3776230634739477, "samples": 2000, "teacher_eval_reward": 157.0}
{"epoch": 189, "reward_mean": 25.558441558441558, "student_loss": null, "teacher_policy_loss": -14.28435230255127, "teacher_value_loss": 56.50535202026367, "teacher_entropy": 0.6536446809768677, "total_time": 1.252467393875122, "rollout_time": 0.44392943382263184, "train_time": 0.8005907535552979, "student_train_time": 0.00755620002746582, "throughput": 1596.8479577037285, "inference_time": 0.05767575603022124, "env_time": 0.3862536777924106, "samples": 2000, "teacher_eval_reward": 144.0}
{"epoch": 190, "reward_mean": 30.43076923076923, "student_loss": null, "teacher_policy_loss": -17.485000610351562, "teacher_value_loss": 124.50784301757812, "teacher_entropy": 0.6491848230361938, "total_time": 1.3451945781707764, "rollout_time": 0.46848487854003906, "train_time": 0.8697021007537842, "student_train_time": 0.006395578384399414, "throughput": 1486.7737593171403, "inference_time": 0.05835218272841303, "env_time": 0.41013269581162604, "samples": 2000, "teacher_eval_reward": 184.0}
{"epoch": 191, "reward_mean": 30.485294117647058, "student_loss": null, "teacher_policy_loss": -16.592018127441406, "teacher_value_loss": 75.95155334472656, "teacher_entropy": 0.6550825834274292, "total_time": 1.2160043716430664, "rollout_time": 0.4500603675842285, "train_time": 0.7513082027435303, "student_train_time": 0.014140129089355469, "throughput": 1644.7309291311165, "inference_time": 0.05538040354622353, "env_time": 0.394679964038005, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 192, "reward_mean": 26.506849315068493, "student_loss": null, "teacher_policy_loss": -16.883625030517578, "teacher_value_loss": 127.46910095214844, "teacher_entropy": 0.6509737968444824, "total_time": -1.3999574184417725, "rollout_time": 0.42800140380859375, "train_time": -1.8343136310577393, "student_train_time": 0.005921125411987305, "throughput": 200000000000.0, "inference_time": 0.05386051093955757, "env_time": 0.3741408928690362, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 193, "reward_mean": 27.95945945945946, "student_loss": null, "teacher_policy_loss": -16.99349021911621, "teacher_value_loss": 112.82908630371094, "teacher_entropy": 0.646872341632843, "total_time": 1.3466970920562744, "rollout_time": 0.42496633529663086, "train_time": 0.912390947341919, "student_train_time": 0.008929967880249023, "throughput": 1485.1149614841718, "inference_time": 0.05321839371572423, "env_time": 0.3717479415809066, "samples": 2000, "teacher_eval_reward": 144.0}
{"epoch": 194, "reward_mean": 28.984848484848484, "student_loss": null, "teacher_policy_loss": -17.231117248535156, "teacher_value_loss": 96.1993408203125, "teacher_entropy": 0.650198757648468, "total_time": 1.1820275783538818, "rollout_time": 0.4371349811553955, "train_time": 0.7348532676696777, "student_train_time": 0.009616851806640625, "throughput": 1692.0078994986268, "inference_time": 0.055193856183905154, "env_time": 0.38194112497149035, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 195, "reward_mean": 26.705128205128204, "student_loss": null, "teacher_policy_loss": -13.823698043823242, "teacher_value_loss": 62.21488952636719, "teacher_entropy": 0.6408770680427551, "total_time": 1.4183387756347656, "rollout_time": 0.43799376487731934, "train_time": 0.962841272354126, "student_train_time": 0.01712942123413086, "throughput": 1410.1003472212883, "inference_time": 0.0556900592691818, "env_time": 0.38230370560813753, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 196, "reward_mean": 25.649350649350648, "student_loss": null, "teacher_policy_loss": -14.599040031433105, "teacher_value_loss": 87.27802276611328, "teacher_entropy": 0.636478841304779, "total_time": 1.2025749683380127, "rollout_time": 0.44467759132385254, "train_time": 0.7479252815246582, "student_train_time": 0.009603023529052734, "throughput": 1663.0979794665507, "inference_time": 0.05904717449993768, "env_time": 0.38563041682391486, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 197, "reward_mean": 26.95945945945946, "student_loss": null, "teacher_policy_loss": -15.159457206726074, "teacher_value_loss": 69.78385925292969, "teacher_entropy": 0.639151394367218, "total_time": 1.2997691631317139, "rollout_time": 0.4433739185333252, "train_time": 0.8489506244659424, "student_train_time": 0.007081508636474609, "throughput": 1538.7347667035915, "inference_time": 0.05469446300776326, "env_time": 0.38867945552556193, "samples": 2000, "teacher_eval_reward": 387.0}
{"epoch": 198, "reward_mean": 26.407894736842106, "student_loss": null, "teacher_policy_loss": -16.23991584777832, "teacher_value_loss": 139.27267456054688, "teacher_entropy": 0.6484813690185547, "total_time": 1.3110053539276123, "rollout_time": 0.43402719497680664, "train_time": 0.866070032119751, "student_train_time": 0.010548114776611328, "throughput": 1525.546782862666, "inference_time": 0.05255507701986062, "env_time": 0.381472117956946, "samples": 2000, "teacher_eval_reward": 216.0}
{"epoch": 199, "reward_mean": 28.32857142857143, "student_loss": null, "teacher_policy_loss": -16.357881546020508, "teacher_value_loss": 98.44695281982422, "teacher_entropy": 0.6500496864318848, "total_time": 1.2734565734863281, "rollout_time": 0.43207669258117676, "train_time": 0.8347628116607666, "student_train_time": 0.0062558650970458984, "throughput": 1570.528623936207, "inference_time": 0.05569212376030919, "env_time": 0.37638456882086757, "samples": 2000, "teacher_eval_reward": 126.0}
{"epoch": 200, "reward_mean": 29.5, "student_loss": null, "teacher_policy_loss": -16.447410583496094, "teacher_value_loss": 94.94441223144531, "teacher_entropy": 0.6420178413391113, "total_time": 1.3145561218261719, "rollout_time": 0.4629063606262207, "train_time": 0.840033769607544, "student_train_time": 0.011248350143432617, "throughput": 1521.4261048220706, "inference_time": 0.05674523297966516, "env_time": 0.40616112764655554, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 201, "reward_mean": 30.151515151515152, "student_loss": null, "teacher_policy_loss": -17.354145050048828, "teacher_value_loss": 95.46710968017578, "teacher_entropy": 0.6401616930961609, "total_time": 1.2237474918365479, "rollout_time": 0.4431476593017578, "train_time": 0.7723844051361084, "student_train_time": 0.007843732833862305, "throughput": 1634.324085108837, "inference_time": 0.056058388983728946, "env_time": 0.38708927031802887, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 202, "reward_mean": 32.85245901639344, "student_loss": null, "teacher_policy_loss": -18.640316009521484, "teacher_value_loss": 135.1109161376953, "teacher_entropy": 0.6415877938270569, "total_time": 1.5209531784057617, "rollout_time": 0.437075138092041, "train_time": 1.0785799026489258, "student_train_time": 0.004931926727294922, "throughput": 1314.9648709741134, "inference_time": 0.05376617406909645, "env_time": 0.38330896402294456, "samples": 2000, "teacher_eval_reward": 68.0}
{"epoch": 203, "reward_mean": 28.794117647058822, "student_loss": null, "teacher_policy_loss": -16.66081428527832, "teacher_value_loss": 86.16522979736328, "teacher_entropy": 0.6347963213920593, "total_time": 1.1880512237548828, "rollout_time": 0.435896635055542, "train_time": 0.7430675029754639, "student_train_time": 0.00872945785522461, "throughput": 1683.4290980139062, "inference_time": 0.056073815718264086, "env_time": 0.3798228193372779, "samples": 2000, "teacher_eval_reward": 91.0}
{"epoch": 204, "reward_mean": 30.176470588235293, "student_loss": null, "teacher_policy_loss": -17.607234954833984, "teacher_value_loss": 122.71236419677734, "teacher_entropy": 0.6409049034118652, "total_time": 1.3658499717712402, "rollout_time": 0.45702052116394043, "train_time": 0.899371862411499, "student_train_time": 0.009093761444091797, "throughput": 1464.2896667533632, "inference_time": 0.054986058095892076, "env_time": 0.40203446306804835, "samples": 2000, "teacher_eval_reward": 322.0}
{"epoch": 205, "reward_mean": 27.54794520547945, "student_loss": null, "teacher_policy_loss": -16.196449279785156, "teacher_value_loss": 107.64073181152344, "teacher_entropy": 0.6386479139328003, "total_time": 1.3234057426452637, "rollout_time": 0.44343090057373047, "train_time": 0.8715953826904297, "student_train_time": 0.008015871047973633, "throughput": 1511.252320850852, "inference_time": 0.053295403995434754, "env_time": 0.3901354965782957, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 206, "reward_mean": 25.95945945945946, "student_loss": null, "teacher_policy_loss": -15.106266021728516, "teacher_value_loss": 79.96745300292969, "teacher_entropy": 0.6303998827934265, "total_time": 1.1802494525909424, "rollout_time": 0.44203686714172363, "train_time": 0.729881763458252, "student_train_time": 0.007983207702636719, "throughput": 1694.5570240337756, "inference_time": 0.05333908696411527, "env_time": 0.38869778017760837, "samples": 2000, "teacher_eval_reward": 70.0}
{"epoch": 207, "reward_mean": 27.28, "student_loss": null, "teacher_policy_loss": -13.927858352661133, "teacher_value_loss": 64.00633239746094, "teacher_entropy": 0.6321833729743958, "total_time": -1.446678638458252, "rollout_time": -2.2603824138641357, "train_time": 0.8051121234893799, "student_train_time": 0.00823664665222168, "throughput": 200000000000.0, "inference_time": 0.053128200972423656, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 133.0}
{"epoch": 208, "reward_mean": 30.44776119402985, "student_loss": null, "teacher_policy_loss": -17.484750747680664, "teacher_value_loss": 115.0643081665039, "teacher_entropy": 0.6513910889625549, "total_time": 1.137963056564331, "rollout_time": 0.419008731842041, "train_time": 0.7046360969543457, "student_train_time": 0.013955831527709961, "throughput": 1757.5262997010452, "inference_time": 0.051594998223663424, "env_time": 0.3674137336183776, "samples": 2000, "teacher_eval_reward": 263.0}
{"epoch": 209, "reward_mean": 26.534246575342465, "student_loss": null, "teacher_policy_loss": -15.250405311584473, "teacher_value_loss": 65.9212646484375, "teacher_entropy": 0.6500455141067505, "total_time": 1.3616206645965576, "rollout_time": 0.45006752014160156, "train_time": 0.8988311290740967, "student_train_time": 0.012191057205200195, "throughput": 1468.837872398618, "inference_time": 0.05571318127294944, "env_time": 0.3943543388686521, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 210, "reward_mean": 30.58823529411765, "student_loss": null, "teacher_policy_loss": -17.69902801513672, "teacher_value_loss": 123.75618743896484, "teacher_entropy": 0.6515903472900391, "total_time": 1.1437487602233887, "rollout_time": 0.42330121994018555, "train_time": 0.7108151912689209, "student_train_time": 0.009283304214477539, "throughput": 1748.6357752286215, "inference_time": 0.053198623756543384, "env_time": 0.37010259618364216, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 211, "reward_mean": 31.19047619047619, "student_loss": null, "teacher_policy_loss": -17.92560386657715, "teacher_value_loss": 123.8100357055664, "teacher_entropy": 0.6453843712806702, "total_time": 1.3329968452453613, "rollout_time": 0.4385831356048584, "train_time": 0.8871362209320068, "student_train_time": 0.00687098503112793, "throughput": 1500.3786446560307, "inference_time": 0.05370212169327715, "env_time": 0.38488101391158125, "samples": 2000, "teacher_eval_reward": 70.0}
{"epoch": 212, "reward_mean": 29.313432835820894, "student_loss": null, "teacher_policy_loss": -16.770858764648438, "teacher_value_loss": 98.84761047363281, "teacher_entropy": 0.6452873945236206, "total_time": 1.1693143844604492, "rollout_time": 0.43164515495300293, "train_time": 0.7280054092407227, "student_train_time": 0.009214162826538086, "throughput": 1710.4039996248314, "inference_time": 0.053291890460968716, "env_time": 0.3783532644920342, "samples": 2000, "teacher_eval_reward": 323.0}
{"epoch": 213, "reward_mean": 31.03030303030303, "student_loss": null, "teacher_policy_loss": -17.573707580566406, "teacher_value_loss": 116.04356384277344, "teacher_entropy": 0.648600161075592, "total_time": 1.2151634693145752, "rollout_time": 0.4439077377319336, "train_time": 0.7641677856445312, "student_train_time": 0.006730318069458008, "throughput": 1645.869095396786, "inference_time": 0.05758709349174751, "env_time": 0.3863206442401861, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 214, "reward_mean": 31.62295081967213, "student_loss": null, "teacher_policy_loss": -18.15678596496582, "teacher_value_loss": 100.46099853515625, "teacher_entropy": 0.6421191692352295, "total_time": 1.2859489917755127, "rollout_time": 0.4342505931854248, "train_time": 0.8409700393676758, "student_train_time": 0.010294675827026367, "throughput": 1555.2716420257038, "inference_time": 0.053891000568910385, "env_time": 0.3803595926165144, "samples": 2000, "teacher_eval_reward": 149.0}
{"epoch": 215, "reward_mean": 30.71641791044776, "student_loss": null, "teacher_policy_loss": -16.982946395874023, "teacher_value_loss": 99.80298614501953, "teacher_entropy": 0.6378756761550903, "total_time": 1.1923048496246338, "rollout_time": 0.45604705810546875, "train_time": 0.7288897037506104, "student_train_time": 0.00696110725402832, "throughput": 1677.423354127636, "inference_time": 0.05555587199705769, "env_time": 0.40049118610841106, "samples": 2000, "teacher_eval_reward": 91.0}
{"epoch": 216, "reward_mean": 28.893939393939394, "student_loss": null, "teacher_policy_loss": -16.646728515625, "teacher_value_loss": 81.28594970703125, "teacher_entropy": 0.6332709789276123, "total_time": 1.512617826461792, "rollout_time": 0.5774950981140137, "train_time": 0.9190065860748291, "student_train_time": 0.015738248825073242, "throughput": 1322.2110469755985, "inference_time": 0.07434052196003904, "env_time": 0.5031545761539746, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 217, "reward_mean": 27.662337662337663, "student_loss": null, "teacher_policy_loss": -14.939035415649414, "teacher_value_loss": 68.60397338867188, "teacher_entropy": 0.6262004375457764, "total_time": 1.4673514366149902, "rollout_time": 0.504570484161377, "train_time": 0.9507474899291992, "student_train_time": 0.011578798294067383, "throughput": 1362.9999944756032, "inference_time": 0.06252826554555213, "env_time": 0.4420422186158248, "samples": 2000, "teacher_eval_reward": 77.0}
{"epoch": 218, "reward_mean": 30.41269841269841, "student_loss": null, "teacher_policy_loss": -18.167858123779297, "teacher_value_loss": 145.9311981201172, "teacher_entropy": 0.629002034664154, "total_time": 1.4032974243164062, "rollout_time": 0.5118241310119629, "train_time": 0.8801772594451904, "student_train_time": 0.010898113250732422, "throughput": 1425.2146161917656, "inference_time": 0.06266059953304648, "env_time": 0.4491635314789164, "samples": 2000, "teacher_eval_reward": 447.0}
{"epoch": 219, "reward_mean": 27.89041095890411, "student_loss": null, "teacher_policy_loss": -14.785428047180176, "teacher_value_loss": 46.67344665527344, "teacher_entropy": 0.6291887164115906, "total_time": 1.2724852561950684, "rollout_time": 0.42330408096313477, "train_time": 0.8436136245727539, "student_train_time": 0.005222797393798828, "throughput": 1571.7274445916296, "inference_time": 0.05502549997254391, "env_time": 0.36827858099059085, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 220, "reward_mean": 31.9375, "student_loss": null, "teacher_policy_loss": -18.793001174926758, "teacher_value_loss": 146.71633911132812, "teacher_entropy": 0.6375158429145813, "total_time": 1.2243549823760986, "rollout_time": 0.43627071380615234, "train_time": 0.7773323059082031, "student_train_time": 0.01038360595703125, "throughput": 1633.5131794200825, "inference_time": 0.05283517344469146, "env_time": 0.3834355403614609, "samples": 2000, "teacher_eval_reward": 298.0}
{"epoch": 221, "reward_mean": 30.873015873015873, "student_loss": null, "teacher_policy_loss": -18.124095916748047, "teacher_value_loss": 114.17024230957031, "teacher_entropy": 0.6327041387557983, "total_time": 1.2829563617706299, "rollout_time": 0.47042083740234375, "train_time": 0.8067328929901123, "student_train_time": 0.005437135696411133, "throughput": 1558.8994759258733, "inference_time": 0.059085005492306664, "env_time": 0.4113358319100371, "samples": 2000, "teacher_eval_reward": 255.0}
{"epoch": 222, "reward_mean": 31.96875, "student_loss": null, "teacher_policy_loss": -18.35154151916504, "teacher_value_loss": 139.89434814453125, "teacher_entropy": 0.640396773815155, "total_time": 1.2451198101043701, "rollout_time": 0.41246867179870605, "train_time": 0.8248205184936523, "student_train_time": 0.0074307918548583984, "throughput": 1606.271126496938, "inference_time": 0.05216859351276071, "env_time": 0.36030007828594535, "samples": 2000, "teacher_eval_reward": 209.0}
{"epoch": 223, "reward_mean": 28.08450704225352, "student_loss": null, "teacher_policy_loss": -15.769109725952148, "teacher_value_loss": 81.4665756225586, "teacher_entropy": 0.6387085914611816, "total_time": 1.202033519744873, "rollout_time": 0.42575550079345703, "train_time": 0.7703909873962402, "student_train_time": 0.005523204803466797, "throughput": 1663.847111704915, "inference_time": 0.05249667028328986, "env_time": 0.37325883051016717, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 224, "reward_mean": 28.463768115942027, "student_loss": null, "teacher_policy_loss": -16.97501564025879, "teacher_value_loss": 110.21569061279297, "teacher_entropy": 0.6446676254272461, "total_time": 1.315722942352295, "rollout_time": 0.44873690605163574, "train_time": 0.8570883274078369, "student_train_time": 0.009546041488647461, "throughput": 1520.076860881008, "inference_time": 0.05707647153030848, "env_time": 0.39166043452132726, "samples": 2000, "teacher_eval_reward": 146.0}
{"epoch": 225, "reward_mean": 33.16393442622951, "student_loss": null, "teacher_policy_loss": -18.047801971435547, "teacher_value_loss": 99.7204360961914, "teacher_entropy": 0.6434165239334106, "total_time": 1.1955649852752686, "rollout_time": 0.4294297695159912, "train_time": 0.7565972805023193, "student_train_time": 0.009175539016723633, "throughput": 1672.8492592475156, "inference_time": 0.05269120222692436, "env_time": 0.37673856728906685, "samples": 2000, "teacher_eval_reward": 205.0}
{"epoch": 226, "reward_mean": 29.014705882352942, "student_loss": null, "teacher_policy_loss": -18.201101303100586, "teacher_value_loss": 190.47235107421875, "teacher_entropy": 0.6406724452972412, "total_time": 1.1812777519226074, "rollout_time": 0.4257211685180664, "train_time": 0.7485454082489014, "student_train_time": 0.006659030914306641, "throughput": 1693.0819163781491, "inference_time": 0.053583491762765334, "env_time": 0.3721376767553011, "samples": 2000, "teacher_eval_reward": 396.0}
{"epoch": 227, "reward_mean": 30.92063492063492, "student_loss": null, "teacher_policy_loss": -18.809152603149414, "teacher_value_loss": 135.89181518554688, "teacher_entropy": 0.647406816482544, "total_time": 1.38812255859375, "rollout_time": 0.4380810260772705, "train_time": 0.9426841735839844, "student_train_time": 0.0069980621337890625, "throughput": 1440.7949698808425, "inference_time": 0.056991738976648776, "env_time": 0.38108928710062173, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 228, "reward_mean": 31.59090909090909, "student_loss": null, "teacher_policy_loss": -17.9555606842041, "teacher_value_loss": 122.66631317138672, "teacher_entropy": 0.6423609852790833, "total_time": 1.1597511768341064, "rollout_time": 0.43880701065063477, "train_time": 0.7139091491699219, "student_train_time": 0.006652116775512695, "throughput": 1724.507842673295, "inference_time": 0.053538279977146885, "env_time": 0.3852687306734879, "samples": 2000, "teacher_eval_reward": 242.0}
{"epoch": 229, "reward_mean": 35.339285714285715, "student_loss": null, "teacher_policy_loss": -18.836267471313477, "teacher_value_loss": 91.05274200439453, "teacher_entropy": 0.6474387049674988, "total_time": 1.2835278511047363, "rollout_time": 0.4319138526916504, "train_time": 0.8457849025726318, "student_train_time": 0.005477190017700195, "throughput": 1558.2053776850996, "inference_time": 0.05222692726601963, "env_time": 0.37968692542563076, "samples": 2000, "teacher_eval_reward": 240.0}
{"epoch": 230, "reward_mean": 31.515625, "student_loss": null, "teacher_policy_loss": -17.715166091918945, "teacher_value_loss": 87.74759674072266, "teacher_entropy": 0.6377533078193665, "total_time": 1.3070487976074219, "rollout_time": 0.4302201271057129, "train_time": 0.8681952953338623, "student_train_time": 0.008234977722167969, "throughput": 1530.1647525792753, "inference_time": 0.0551163632353564, "env_time": 0.3751037638703565, "samples": 2000, "teacher_eval_reward": 197.0}
{"epoch": 231, "reward_mean": 28.852941176470587, "student_loss": null, "teacher_policy_loss": -16.349401473999023, "teacher_value_loss": 81.01873779296875, "teacher_entropy": 0.6332170367240906, "total_time": 1.3510525226593018, "rollout_time": 0.4632997512817383, "train_time": 0.8765990734100342, "student_train_time": 0.010720968246459961, "throughput": 1480.3273495714016, "inference_time": 0.05742741319227207, "env_time": 0.4058723380894662, "samples": 2000, "teacher_eval_reward": 121.0}
{"epoch": 232, "reward_mean": 28.676056338028168, "student_loss": null, "teacher_policy_loss": -16.2709903717041, "teacher_value_loss": 111.596435546875, "teacher_entropy": 0.6300713419914246, "total_time": 1.2811615467071533, "rollout_time": 0.4388887882232666, "train_time": 0.8356702327728271, "student_train_time": 0.006235361099243164, "throughput": 1561.0833818267558, "inference_time": 0.0548116325007868, "env_time": 0.3840771557224798, "samples": 2000, "teacher_eval_reward": 143.0}
{"epoch": 233, "reward_mean": 33.11864406779661, "student_loss": null, "teacher_policy_loss": -19.26925277709961, "teacher_value_loss": 158.64324951171875, "teacher_entropy": 0.6402851343154907, "total_time": 1.2639882564544678, "rollout_time": 0.4298076629638672, "train_time": 0.8256955146789551, "student_train_time": 0.008063316345214844, "throughput": 1582.29318175002, "inference_time": 0.05250727847487724, "env_time": 0.37730038448898995, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 234, "reward_mean": 28.73913043478261, "student_loss": null, "teacher_policy_loss": -16.525850296020508, "teacher_value_loss": 90.48834991455078, "teacher_entropy": 0.6274871230125427, "total_time": 1.2953269481658936, "rollout_time": 0.46683216094970703, "train_time": 0.8189370632171631, "student_train_time": 0.009191751480102539, "throughput": 1544.0117283376849, "inference_time": 0.05610965601954376, "env_time": 0.41072250493016327, "samples": 2000, "teacher_eval_reward": 363.0}
{"epoch": 235, "reward_mean": 32.578125, "student_loss": null, "teacher_policy_loss": -17.104007720947266, "teacher_value_loss": 105.61158752441406, "teacher_entropy": 0.6292242407798767, "total_time": 1.2384412288665771, "rollout_time": 0.44143176078796387, "train_time": 0.7841169834136963, "student_train_time": 0.012476921081542969, "throughput": 1614.9333156732857, "inference_time": 0.05660106169307255, "env_time": 0.3848306990948913, "samples": 2000, "teacher_eval_reward": 171.0}
{"epoch": 236, "reward_mean": 35.98148148148148, "student_loss": null, "teacher_policy_loss": -21.718856811523438, "teacher_value_loss": 206.44674682617188, "teacher_entropy": 0.6382625699043274, "total_time": 1.3491225242614746, "rollout_time": 0.4525477886199951, "train_time": 0.8820221424102783, "student_train_time": 0.014186382293701172, "throughput": 1482.4450441184526, "inference_time": 0.057450966467513354, "env_time": 0.39509682215248176, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 237, "reward_mean": 31.158730158730158, "student_loss": null, "teacher_policy_loss": -16.386474609375, "teacher_value_loss": 78.451171875, "teacher_entropy": 0.623195230960846, "total_time": 1.2142729759216309, "rollout_time": 0.4319956302642822, "train_time": 0.7718665599822998, "student_train_time": 0.010057449340820312, "throughput": 1647.0761020453442, "inference_time": 0.05573433818426565, "env_time": 0.3762612920800166, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 238, "reward_mean": 29.957142857142856, "student_loss": null, "teacher_policy_loss": -17.19031524658203, "teacher_value_loss": 98.75713348388672, "teacher_entropy": 0.621269166469574, "total_time": 1.2626557350158691, "rollout_time": 0.4405837059020996, "train_time": 0.8157434463500977, "student_train_time": 0.00594019889831543, "throughput": 1583.9630269250422, "inference_time": 0.057011137179870275, "env_time": 0.38357256872222933, "samples": 2000, "teacher_eval_reward": 164.0}
{"epoch": 239, "reward_mean": 33.98275862068966, "student_loss": null, "teacher_policy_loss": -18.938220977783203, "teacher_value_loss": 115.37313842773438, "teacher_entropy": 0.6312801837921143, "total_time": 1.1744821071624756, "rollout_time": 0.43420910835266113, "train_time": 0.732703447341919, "student_train_time": 0.007220268249511719, "throughput": 1702.8782199432212, "inference_time": 0.05598280228150543, "env_time": 0.3782263060711557, "samples": 2000, "teacher_eval_reward": 319.0}
{"epoch": 240, "reward_mean": 31.609375, "student_loss": null, "teacher_policy_loss": -17.741531372070312, "teacher_value_loss": 105.17131042480469, "teacher_entropy": 0.6274293065071106, "total_time": 1.3941230773925781, "rollout_time": 0.6011888980865479, "train_time": 0.784907341003418, "student_train_time": 0.007669925689697266, "throughput": 1434.593568123548, "inference_time": 0.06817254823909025, "env_time": 0.5330163498474576, "samples": 2000, "teacher_eval_reward": 374.0}
{"epoch": 241, "reward_mean": 31.476190476190474, "student_loss": null, "teacher_policy_loss": -18.059335708618164, "teacher_value_loss": 106.951171875, "teacher_entropy": 0.6292868256568909, "total_time": 1.286191463470459, "rollout_time": 0.44928812980651855, "train_time": 0.8275911808013916, "student_train_time": 0.008959770202636719, "throughput": 1554.9784435697552, "inference_time": 0.05508668253423821, "env_time": 0.39420144727228035, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 242, "reward_mean": 28.485714285714284, "student_loss": null, "teacher_policy_loss": -16.89914321899414, "teacher_value_loss": 134.648193359375, "teacher_entropy": 0.6325008869171143, "total_time": 1.3095717430114746, "rollout_time": 0.4334547519683838, "train_time": 0.8677563667297363, "student_train_time": 0.007909297943115234, "throughput": 1527.216825403414, "inference_time": 0.055587165465112776, "env_time": 0.377867586503271, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 243, "reward_mean": 27.246575342465754, "student_loss": null, "teacher_policy_loss": -15.240816116333008, "teacher_value_loss": 79.0501708984375, "teacher_entropy": 0.6342843174934387, "total_time": 1.2969732284545898, "rollout_time": 0.4693775177001953, "train_time": 0.8213398456573486, "student_train_time": 0.005896806716918945, "throughput": 1542.0518759536021, "inference_time": 0.05596923971643264, "env_time": 0.4134082779837627, "samples": 2000, "teacher_eval_reward": 214.0}
{"epoch": 244, "reward_mean": 30.184615384615384, "student_loss": null, "teacher_policy_loss": -17.3907413482666, "teacher_value_loss": 93.24056243896484, "teacher_entropy": 0.6448975205421448, "total_time": 1.3546786308288574, "rollout_time": 0.4577157497406006, "train_time": 0.88773512840271, "student_train_time": 0.008821725845336914, "throughput": 1476.3649137775976, "inference_time": 0.05668381952273194, "env_time": 0.40103193021786865, "samples": 2000, "teacher_eval_reward": 105.0}
{"epoch": 245, "reward_mean": 34.92982456140351, "student_loss": null, "teacher_policy_loss": -19.521175384521484, "teacher_value_loss": 138.12429809570312, "teacher_entropy": 0.6483291983604431, "total_time": 1.2655291557312012, "rollout_time": 0.43886804580688477, "train_time": 0.806342363357544, "student_train_time": 0.019965648651123047, "throughput": 1580.3665928537491, "inference_time": 0.05495357123436406, "env_time": 0.3839144745725207, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 246, "reward_mean": 31.21212121212121, "student_loss": null, "teacher_policy_loss": -16.485231399536133, "teacher_value_loss": 92.58518981933594, "teacher_entropy": 0.6377229690551758, "total_time": 1.2936913967132568, "rollout_time": 0.442363977432251, "train_time": 0.8435277938842773, "student_train_time": 0.007432699203491211, "throughput": 1545.9637476767534, "inference_time": 0.05495503127895063, "env_time": 0.38740894615330035, "samples": 2000, "teacher_eval_reward": 169.0}
{"epoch": 247, "reward_mean": 29.439393939393938, "student_loss": null, "teacher_policy_loss": -16.483688354492188, "teacher_value_loss": 85.72944641113281, "teacher_entropy": 0.6467037796974182, "total_time": 1.409710168838501, "rollout_time": 0.4822113513946533, "train_time": 0.9224069118499756, "student_train_time": 0.004721403121948242, "throughput": 1418.731342236011, "inference_time": 0.061147142474510474, "env_time": 0.42106420892014285, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 248, "reward_mean": 33.29032258064516, "student_loss": null, "teacher_policy_loss": -17.96099281311035, "teacher_value_loss": 106.81465911865234, "teacher_entropy": 0.6381165385246277, "total_time": 1.3015565872192383, "rollout_time": 0.451566219329834, "train_time": 0.843496561050415, "student_train_time": 0.005991458892822266, "throughput": 1536.6216264734048, "inference_time": 0.05791837025208224, "env_time": 0.39364784907775174, "samples": 2000, "teacher_eval_reward": 96.0}
{"epoch": 249, "reward_mean": 31.317460317460316, "student_loss": null, "teacher_policy_loss": -17.16000747680664, "teacher_value_loss": 96.63369750976562, "teacher_entropy": 0.645243763923645, "total_time": 1.292496919631958, "rollout_time": 0.4357759952545166, "train_time": 0.8486402034759521, "student_train_time": 0.007508277893066406, "throughput": 1547.3924692752887, "inference_time": 0.05323342829615285, "env_time": 0.38254256695836375, "samples": 2000, "teacher_eval_reward": 186.0}
{"epoch": 250, "reward_mean": 34.08620689655172, "student_loss": null, "teacher_policy_loss": -19.138322830200195, "teacher_value_loss": 127.1120834350586, "teacher_entropy": 0.6469837427139282, "total_time": 1.250535249710083, "rollout_time": 0.4448714256286621, "train_time": 0.7986021041870117, "student_train_time": 0.006629228591918945, "throughput": 1599.3151736135935, "inference_time": 0.054572915278185974, "env_time": 0.39029851035047614, "samples": 2000, "teacher_eval_reward": 244.0}
{"epoch": 251, "reward_mean": 32.714285714285715, "student_loss": null, "teacher_policy_loss": -17.388654708862305, "teacher_value_loss": 97.8818588256836, "teacher_entropy": 0.6403515338897705, "total_time": -1.345146894454956, "rollout_time": 0.4418449401855469, "train_time": -1.7953460216522217, "student_train_time": 0.007927417755126953, "throughput": 200000000000.0, "inference_time": 0.0566415839966794, "env_time": 0.3852033561888675, "samples": 2000, "teacher_eval_reward": 264.0}
{"epoch": 252, "reward_mean": 28.7, "student_loss": null, "teacher_policy_loss": -15.8308687210083, "teacher_value_loss": 79.65155029296875, "teacher_entropy": 0.6376198530197144, "total_time": 1.3283343315124512, "rollout_time": 0.4475822448730469, "train_time": 0.8659157752990723, "student_train_time": 0.01373744010925293, "throughput": 1505.6450417289038, "inference_time": 0.05606158246882842, "env_time": 0.39152066240421846, "samples": 2000, "teacher_eval_reward": 385.0}
{"epoch": 253, "reward_mean": 31.639344262295083, "student_loss": null, "teacher_policy_loss": -18.91535758972168, "teacher_value_loss": 146.39413452148438, "teacher_entropy": 0.6436763405799866, "total_time": 1.3041605949401855, "rollout_time": 0.4456603527069092, "train_time": 0.8480463027954102, "student_train_time": 0.01009988784790039, "throughput": 1533.5534655467247, "inference_time": 0.05489916049191379, "env_time": 0.3907611922149954, "samples": 2000, "teacher_eval_reward": 175.0}
{"epoch": 254, "reward_mean": 31.476190476190474, "student_loss": null, "teacher_policy_loss": -17.71564483642578, "teacher_value_loss": 107.16962432861328, "teacher_entropy": 0.64156574010849, "total_time": 1.3611278533935547, "rollout_time": 0.5878152847290039, "train_time": 0.7604279518127441, "student_train_time": 0.012447595596313477, "throughput": 1469.3696811902082, "inference_time": 0.06350025378560531, "env_time": 0.5243150309433986, "samples": 2000, "teacher_eval_reward": 67.0}
{"epoch": 255, "reward_mean": 33.766666666666666, "student_loss": null, "teacher_policy_loss": -19.94584846496582, "teacher_value_loss": 166.23275756835938, "teacher_entropy": 0.6356111764907837, "total_time": 1.2636501789093018, "rollout_time": 0.4368455410003662, "train_time": 0.8167827129364014, "student_train_time": 0.009620428085327148, "throughput": 1582.7165091894865, "inference_time": 0.05833465656724002, "env_time": 0.3785108844331262, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 256, "reward_mean": 31.242424242424242, "student_loss": null, "teacher_policy_loss": -17.17371940612793, "teacher_value_loss": 93.38819885253906, "teacher_entropy": 0.6291609406471252, "total_time": 1.210585355758667, "rollout_time": 0.4228076934814453, "train_time": 0.7827677726745605, "student_train_time": 0.004625558853149414, "throughput": 1652.0933369019745, "inference_time": 0.05405960252028308, "env_time": 0.36874809096116223, "samples": 2000, "teacher_eval_reward": 403.0}
{"epoch": 257, "reward_mean": 34.35087719298246, "student_loss": null, "teacher_policy_loss": -18.97007942199707, "teacher_value_loss": 107.11308288574219, "teacher_entropy": 0.6382193565368652, "total_time": 1.2114291191101074, "rollout_time": 0.43781542778015137, "train_time": 0.7683124542236328, "student_train_time": 0.004942178726196289, "throughput": 1650.9426498424948, "inference_time": 0.055494186768555664, "env_time": 0.3823212410115957, "samples": 2000, "teacher_eval_reward": 58.0}
{"epoch": 258, "reward_mean": 31.40625, "student_loss": null, "teacher_policy_loss": -18.468778610229492, "teacher_value_loss": 131.40724182128906, "teacher_entropy": 0.6194772720336914, "total_time": 1.2830348014831543, "rollout_time": 0.4508357048034668, "train_time": 0.8245608806610107, "student_train_time": 0.007276296615600586, "throughput": 1558.8041709297775, "inference_time": 0.05631426125364669, "env_time": 0.3945214435498201, "samples": 2000, "teacher_eval_reward": 270.0}
{"epoch": 259, "reward_mean": 31.870967741935484, "student_loss": null, "teacher_policy_loss": -18.134315490722656, "teacher_value_loss": 103.72531127929688, "teacher_entropy": 0.6254327893257141, "total_time": 1.2999684810638428, "rollout_time": 0.4416506290435791, "train_time": 0.8485264778137207, "student_train_time": 0.009436607360839844, "throughput": 1538.4988398820863, "inference_time": 0.05594187131646322, "env_time": 0.3857087577271159, "samples": 2000, "teacher_eval_reward": 131.0}
{"epoch": 260, "reward_mean": 32.114754098360656, "student_loss": null, "teacher_policy_loss": -18.310062408447266, "teacher_value_loss": 141.16152954101562, "teacher_entropy": 0.6292125582695007, "total_time": 1.28959321975708, "rollout_time": 0.4990534782409668, "train_time": 0.7799625396728516, "student_train_time": 0.010209321975708008, "throughput": 1550.8766402918425, "inference_time": 0.055649679499765625, "env_time": 0.44340379874120117, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 261, "reward_mean": 26.615384615384617, "student_loss": null, "teacher_policy_loss": -13.891331672668457, "teacher_value_loss": 103.82778930664062, "teacher_entropy": 0.613960325717926, "total_time": 1.335416555404663, "rollout_time": 0.4448082447052002, "train_time": 0.8816981315612793, "student_train_time": 0.008499860763549805, "throughput": 1497.6600311757797, "inference_time": 0.056437804760207655, "env_time": 0.38837043994499254, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 262, "reward_mean": 29.238805970149254, "student_loss": null, "teacher_policy_loss": -15.88707447052002, "teacher_value_loss": 94.21409606933594, "teacher_entropy": 0.6125874519348145, "total_time": 1.2766928672790527, "rollout_time": 0.45536112785339355, "train_time": 0.8083603382110596, "student_train_time": 0.012575626373291016, "throughput": 1566.5474847231606, "inference_time": 0.05918374330030929, "env_time": 0.39617738455308427, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 263, "reward_mean": 34.59322033898305, "student_loss": null, "teacher_policy_loss": -19.422151565551758, "teacher_value_loss": 157.83383178710938, "teacher_entropy": 0.620455801486969, "total_time": 1.3111119270324707, "rollout_time": 0.4277496337890625, "train_time": 0.8747074604034424, "student_train_time": 0.007943153381347656, "throughput": 1525.4227795232835, "inference_time": 0.052285051004218985, "env_time": 0.3754645827848435, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 264, "reward_mean": 28.651515151515152, "student_loss": null, "teacher_policy_loss": -16.181108474731445, "teacher_value_loss": 73.71678924560547, "teacher_entropy": 0.6272461414337158, "total_time": 1.3187921047210693, "rollout_time": 0.4440596103668213, "train_time": 0.867577314376831, "student_train_time": 0.006787538528442383, "throughput": 1516.5392580379523, "inference_time": 0.05648308667878155, "env_time": 0.38757652368803974, "samples": 2000, "teacher_eval_reward": 58.0}
{"epoch": 265, "reward_mean": 36.35087719298246, "student_loss": null, "teacher_policy_loss": -20.376062393188477, "teacher_value_loss": 162.01756286621094, "teacher_entropy": 0.6366718411445618, "total_time": 1.1796810626983643, "rollout_time": 0.4606587886810303, "train_time": 0.7125060558319092, "student_train_time": 0.006150484085083008, "throughput": 1695.373489700059, "inference_time": 0.05714726374935708, "env_time": 0.4035115249316732, "samples": 2000, "teacher_eval_reward": 55.0}
{"epoch": 266, "reward_mean": 34.310344827586206, "student_loss": null, "teacher_policy_loss": -18.88347816467285, "teacher_value_loss": 130.44189453125, "teacher_entropy": 0.6255988478660583, "total_time": 1.276003122329712, "rollout_time": 0.4296445846557617, "train_time": 0.839296817779541, "student_train_time": 0.006628990173339844, "throughput": 1567.39428376039, "inference_time": 0.05260322849608201, "env_time": 0.3770413561596797, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 267, "reward_mean": 33.54838709677419, "student_loss": null, "teacher_policy_loss": -17.646484375, "teacher_value_loss": 89.69392395019531, "teacher_entropy": 0.630546510219574, "total_time": 1.4268040657043457, "rollout_time": 0.44974231719970703, "train_time": 0.9684672355651855, "student_train_time": 0.008184432983398438, "throughput": 1401.7341610340131, "inference_time": 0.0559342577616917, "env_time": 0.39380805943801533, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 268, "reward_mean": 35.98148148148148, "student_loss": null, "teacher_policy_loss": -21.252357482910156, "teacher_value_loss": 186.30857849121094, "teacher_entropy": 0.638883650302887, "total_time": 1.2468674182891846, "rollout_time": 0.4392282962799072, "train_time": 0.7979021072387695, "student_train_time": 0.009377241134643555, "throughput": 1604.0197784173251, "inference_time": 0.0549280043123872, "env_time": 0.38430029196752, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 269, "reward_mean": 31.333333333333332, "student_loss": null, "teacher_policy_loss": -17.609323501586914, "teacher_value_loss": 135.2558135986328, "teacher_entropy": 0.6125659346580505, "total_time": 1.1983473300933838, "rollout_time": 0.4400317668914795, "train_time": 0.7511279582977295, "student_train_time": 0.006835222244262695, "throughput": 1668.9652071441972, "inference_time": 0.054707904731913004, "env_time": 0.3853238621595665, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 270, "reward_mean": 29.685714285714287, "student_loss": null, "teacher_policy_loss": -15.491654396057129, "teacher_value_loss": 80.8295669555664, "teacher_entropy": 0.6231815814971924, "total_time": 1.3251237869262695, "rollout_time": 0.4513545036315918, "train_time": 0.8658936023712158, "student_train_time": 0.007518291473388672, "throughput": 1509.2929579350166, "inference_time": 0.05390591477043927, "env_time": 0.39744858886115253, "samples": 2000, "teacher_eval_reward": 142.0}
{"epoch": 271, "reward_mean": 30.53125, "student_loss": null, "teacher_policy_loss": -18.557710647583008, "teacher_value_loss": 126.6351547241211, "teacher_entropy": 0.6378907561302185, "total_time": 1.1768980026245117, "rollout_time": 0.4344902038574219, "train_time": 0.735926628112793, "student_train_time": 0.006128072738647461, "throughput": 1699.382610506561, "inference_time": 0.05516379205255362, "env_time": 0.37932641180486826, "samples": 2000, "teacher_eval_reward": 108.0}
{"epoch": 272, "reward_mean": 29.52238805970149, "student_loss": null, "teacher_policy_loss": -16.940216064453125, "teacher_value_loss": 94.80082702636719, "teacher_entropy": 0.6268536448478699, "total_time": 1.2398147583007812, "rollout_time": 0.4465763568878174, "train_time": 0.7839469909667969, "student_train_time": 0.008871078491210938, "throughput": 1613.1442109473555, "inference_time": 0.05502450225503708, "env_time": 0.3915518546327803, "samples": 2000, "teacher_eval_reward": 55.0}
{"epoch": 273, "reward_mean": 34.6271186440678, "student_loss": null, "teacher_policy_loss": -18.103113174438477, "teacher_value_loss": 103.01073455810547, "teacher_entropy": 0.620837926864624, "total_time": 1.1989705562591553, "rollout_time": 0.4413433074951172, "train_time": 0.7518961429595947, "student_train_time": 0.005354881286621094, "throughput": 1668.0976772608115, "inference_time": 0.05733328583301045, "env_time": 0.38401002166210674, "samples": 2000, "teacher_eval_reward": 76.0}
{"epoch": 274, "reward_mean": 32.78688524590164, "student_loss": null, "teacher_policy_loss": -17.585712432861328, "teacher_value_loss": 93.26667022705078, "teacher_entropy": 0.6349368095397949, "total_time": 1.2465472221374512, "rollout_time": 0.436629056930542, "train_time": 0.8021118640899658, "student_train_time": 0.007315397262573242, "throughput": 1604.4317972732756, "inference_time": 0.05582674224569928, "env_time": 0.3808023146848427, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 275, "reward_mean": 30.158730158730158, "student_loss": null, "teacher_policy_loss": -17.327409744262695, "teacher_value_loss": 94.01575469970703, "teacher_entropy": 0.6367936730384827, "total_time": 1.1507327556610107, "rollout_time": 0.42596960067749023, "train_time": 0.7157015800476074, "student_train_time": 0.008702278137207031, "throughput": 1738.0230033090074, "inference_time": 0.05159611227463756, "env_time": 0.37437348840285267, "samples": 2000, "teacher_eval_reward": 102.0}
{"epoch": 276, "reward_mean": 34.31147540983606, "student_loss": null, "teacher_policy_loss": -18.022188186645508, "teacher_value_loss": 124.5638427734375, "teacher_entropy": 0.6266021132469177, "total_time": 1.4504306316375732, "rollout_time": 0.5943162441253662, "train_time": 0.8478622436523438, "student_train_time": 0.007817745208740234, "throughput": 1378.9008287434945, "inference_time": 0.05628234519099351, "env_time": 0.5380338989343727, "samples": 2000, "teacher_eval_reward": 141.0}
{"epoch": 277, "reward_mean": 32.645161290322584, "student_loss": null, "teacher_policy_loss": -16.5347843170166, "teacher_value_loss": 69.51747131347656, "teacher_entropy": 0.6270135045051575, "total_time": 1.243342399597168, "rollout_time": 0.41962170600891113, "train_time": 0.8150029182434082, "student_train_time": 0.008364677429199219, "throughput": 1608.5673589575827, "inference_time": 0.053439023227838334, "env_time": 0.3661826827810728, "samples": 2000, "teacher_eval_reward": 430.0}
{"epoch": 278, "reward_mean": 32.16393442622951, "student_loss": null, "teacher_policy_loss": -18.01008415222168, "teacher_value_loss": 82.66829681396484, "teacher_entropy": 0.6268734931945801, "total_time": 1.2201073169708252, "rollout_time": 0.4251575469970703, "train_time": 0.790163516998291, "student_train_time": 0.004426240921020508, "throughput": 1639.2000705031617, "inference_time": 0.05474835601307859, "env_time": 0.3704091909839917, "samples": 2000, "teacher_eval_reward": 227.0}
{"epoch": 279, "reward_mean": 33.389830508474574, "student_loss": null, "teacher_policy_loss": -19.16217613220215, "teacher_value_loss": 117.21229553222656, "teacher_entropy": 0.6243528723716736, "total_time": 1.1682987213134766, "rollout_time": 0.4302527904510498, "train_time": 0.7266833782196045, "student_train_time": 0.010991334915161133, "throughput": 1711.8909432268072, "inference_time": 0.05626771518655005, "env_time": 0.37398507526449976, "samples": 2000, "teacher_eval_reward": 428.0}
{"epoch": 280, "reward_mean": 32.43333333333333, "student_loss": null, "teacher_policy_loss": -18.841630935668945, "teacher_value_loss": 119.9300537109375, "teacher_entropy": 0.6209749579429626, "total_time": 1.4338433742523193, "rollout_time": 0.4368405342102051, "train_time": 0.9921286106109619, "student_train_time": 0.0045239925384521484, "throughput": 1394.8524894100824, "inference_time": 0.05496120026327844, "env_time": 0.38187933394692664, "samples": 2000, "teacher_eval_reward": 151.0}
{"epoch": 281, "reward_mean": 34.131147540983605, "student_loss": null, "teacher_policy_loss": -18.42546272277832, "teacher_value_loss": 94.6870346069336, "teacher_entropy": 0.620216429233551, "total_time": 1.306851863861084, "rollout_time": 0.4411466121673584, "train_time": 0.8589217662811279, "student_train_time": 0.00641632080078125, "throughput": 1530.3953380691635, "inference_time": 0.05431108027914888, "env_time": 0.3868355318882095, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 282, "reward_mean": 31.75, "student_loss": null, "teacher_policy_loss": -17.249467849731445, "teacher_value_loss": 84.39025115966797, "teacher_entropy": 0.6125036478042603, "total_time": -1.3633458614349365, "rollout_time": 0.44574475288391113, "train_time": -1.8193798065185547, "student_train_time": 0.009870529174804688, "throughput": 200000000000.0, "inference_time": 0.05713848651248554, "env_time": 0.3886062663714256, "samples": 2000, "teacher_eval_reward": 150.0}
{"epoch": 283, "reward_mean": 36.67272727272727, "student_loss": null, "teacher_policy_loss": -19.917543411254883, "teacher_value_loss": 117.17394256591797, "teacher_entropy": 0.6225842237472534, "total_time": 1.1457903385162354, "rollout_time": 0.40998125076293945, "train_time": 0.7281057834625244, "student_train_time": 0.007345676422119141, "throughput": 1745.5200421657778, "inference_time": 0.05272851997324324, "env_time": 0.3572527307896962, "samples": 2000, "teacher_eval_reward": 161.0}
{"epoch": 284, "reward_mean": 35.90909090909091, "student_loss": null, "teacher_policy_loss": -19.494895935058594, "teacher_value_loss": 117.25779724121094, "teacher_entropy": 0.6174793243408203, "total_time": 1.2275078296661377, "rollout_time": 0.4352569580078125, "train_time": 0.7872273921966553, "student_train_time": 0.00466465950012207, "throughput": 1629.3175095624179, "inference_time": 0.055300407719187206, "env_time": 0.3799565502886253, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 285, "reward_mean": 33.98275862068966, "student_loss": null, "teacher_policy_loss": -19.039541244506836, "teacher_value_loss": 132.42498779296875, "teacher_entropy": 0.6203705668449402, "total_time": 1.3546507358551025, "rollout_time": 0.4518158435821533, "train_time": 0.8890211582183838, "student_train_time": 0.013376712799072266, "throughput": 1476.3953150902255, "inference_time": 0.055591614545846824, "env_time": 0.3962242290363065, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 286, "reward_mean": 29.686567164179106, "student_loss": null, "teacher_policy_loss": -16.088499069213867, "teacher_value_loss": 76.85448455810547, "teacher_entropy": 0.6018228530883789, "total_time": 1.3183274269104004, "rollout_time": 0.44116783142089844, "train_time": 0.866971492767334, "student_train_time": 0.00974893569946289, "throughput": 1517.0738006165514, "inference_time": 0.05439083277087775, "env_time": 0.3867769986500207, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 287, "reward_mean": 32.9344262295082, "student_loss": null, "teacher_policy_loss": -17.727968215942383, "teacher_value_loss": 99.23057556152344, "teacher_entropy": 0.6193018555641174, "total_time": 1.1598334312438965, "rollout_time": 0.431931734085083, "train_time": 0.7215776443481445, "student_train_time": 0.005974531173706055, "throughput": 1724.3855420299817, "inference_time": 0.05449882509674353, "env_time": 0.3774329089883395, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 288, "reward_mean": 30.742424242424242, "student_loss": null, "teacher_policy_loss": -15.95572280883789, "teacher_value_loss": 59.4208869934082, "teacher_entropy": 0.6171672344207764, "total_time": 1.4244542121887207, "rollout_time": 0.4375748634338379, "train_time": 0.9790830612182617, "student_train_time": 0.007397890090942383, "throughput": 1404.0465343753901, "inference_time": 0.05372263356548501, "env_time": 0.3838522298683529, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 289, "reward_mean": 35.714285714285715, "student_loss": null, "teacher_policy_loss": -19.591089248657227, "teacher_value_loss": 127.65274810791016, "teacher_entropy": 0.6176286935806274, "total_time": 1.1832618713378906, "rollout_time": 0.43050336837768555, "train_time": 0.74684739112854, "student_train_time": 0.005544185638427734, "throughput": 1690.2429195480117, "inference_time": 0.05622840446449118, "env_time": 0.37427496391319437, "samples": 2000, "teacher_eval_reward": 108.0}
{"epoch": 290, "reward_mean": 32.21666666666667, "student_loss": null, "teacher_policy_loss": -18.254682540893555, "teacher_value_loss": 94.51039123535156, "teacher_entropy": 0.618176281452179, "total_time": 1.2716586589813232, "rollout_time": 0.44992828369140625, "train_time": 0.8133525848388672, "student_train_time": 0.00800943374633789, "throughput": 1572.7490910195374, "inference_time": 0.05535586976657214, "env_time": 0.3945724139248341, "samples": 2000, "teacher_eval_reward": 141.0}
{"epoch": 291, "reward_mean": 32.265625, "student_loss": null, "teacher_policy_loss": -17.769323348999023, "teacher_value_loss": 89.35809326171875, "teacher_entropy": 0.6282699704170227, "total_time": 1.2868988513946533, "rollout_time": 0.4424288272857666, "train_time": 0.8351490497589111, "student_train_time": 0.008911848068237305, "throughput": 1554.1236965380272, "inference_time": 0.054910746974201174, "env_time": 0.3875180803115654, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 292, "reward_mean": 29.850746268656717, "student_loss": null, "teacher_policy_loss": -17.106111526489258, "teacher_value_loss": 97.05184173583984, "teacher_entropy": 0.6229825019836426, "total_time": 1.1999588012695312, "rollout_time": 0.43990087509155273, "train_time": 0.7532227039337158, "student_train_time": 0.006478309631347656, "throughput": 1666.723889090227, "inference_time": 0.05600757399770373, "env_time": 0.383893301093849, "samples": 2000, "teacher_eval_reward": 89.0}
{"epoch": 293, "reward_mean": 31.265625, "student_loss": null, "teacher_policy_loss": -16.895719528198242, "teacher_value_loss": 102.86962127685547, "teacher_entropy": 0.6287370920181274, "total_time": 1.2932016849517822, "rollout_time": 0.4367995262145996, "train_time": 0.8477210998535156, "student_train_time": 0.008330345153808594, "throughput": 1546.549175795863, "inference_time": 0.05294848644371086, "env_time": 0.38385103977088875, "samples": 2000, "teacher_eval_reward": 433.0}
{"epoch": 294, "reward_mean": 31.390625, "student_loss": null, "teacher_policy_loss": -17.279117584228516, "teacher_value_loss": 86.238525390625, "teacher_entropy": 0.6355574131011963, "total_time": 1.2773187160491943, "rollout_time": 0.42400622367858887, "train_time": 0.8446130752563477, "student_train_time": 0.008334159851074219, "throughput": 1565.7799223251752, "inference_time": 0.05351875725318678, "env_time": 0.3704874664254021, "samples": 2000, "teacher_eval_reward": 102.0}
{"epoch": 295, "reward_mean": 32.94827586206897, "student_loss": null, "teacher_policy_loss": -17.623191833496094, "teacher_value_loss": 76.27919006347656, "teacher_entropy": 0.6382039785385132, "total_time": 1.2485249042510986, "rollout_time": 0.4296455383300781, "train_time": 0.8137226104736328, "student_train_time": 0.004656076431274414, "throughput": 1601.890353320311, "inference_time": 0.054508274488398456, "env_time": 0.37513726384167967, "samples": 2000, "teacher_eval_reward": 60.0}
{"epoch": 296, "reward_mean": 31.390625, "student_loss": null, "teacher_policy_loss": -16.76630401611328, "teacher_value_loss": 80.23268127441406, "teacher_entropy": 0.6293778419494629, "total_time": 1.3452866077423096, "rollout_time": 0.4300868511199951, "train_time": 0.906425952911377, "student_train_time": 0.008281707763671875, "throughput": 1486.6720507657808, "inference_time": 0.05418844974883541, "env_time": 0.3758984013711597, "samples": 2000, "teacher_eval_reward": 160.0}
{"epoch": 297, "reward_mean": 40.98, "student_loss": null, "teacher_policy_loss": -20.23584747314453, "teacher_value_loss": 107.81535339355469, "teacher_entropy": 0.6422827839851379, "total_time": 1.1707723140716553, "rollout_time": 0.421616792678833, "train_time": 0.7417101860046387, "student_train_time": 0.007086515426635742, "throughput": 1708.2740819557791, "inference_time": 0.05399966725963168, "env_time": 0.36761712541920133, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 298, "reward_mean": 32.733333333333334, "student_loss": null, "teacher_policy_loss": -17.812088012695312, "teacher_value_loss": 91.32996368408203, "teacher_entropy": 0.6319066286087036, "total_time": -1.2976067066192627, "rollout_time": 0.4288756847381592, "train_time": -1.7347679138183594, "student_train_time": 0.007867097854614258, "throughput": 200000000000.0, "inference_time": 0.0547129589758697, "env_time": 0.3741627257622895, "samples": 2000, "teacher_eval_reward": 95.0}
{"epoch": 299, "reward_mean": 30.64179104477612, "student_loss": null, "teacher_policy_loss": -16.420482635498047, "teacher_value_loss": 89.35591888427734, "teacher_entropy": 0.6245664358139038, "total_time": 1.1434853076934814, "rollout_time": 0.4257023334503174, "train_time": 0.7111396789550781, "student_train_time": 0.006211280822753906, "throughput": 1749.0386509942923, "inference_time": 0.053485530448597274, "env_time": 0.3722168030017201, "samples": 2000, "teacher_eval_reward": 476.0}
{"epoch": 300, "reward_mean": 35.763636363636365, "student_loss": null, "teacher_policy_loss": -18.312267303466797, "teacher_value_loss": 86.08086395263672, "teacher_entropy": 0.6324023008346558, "total_time": 1.2949535846710205, "rollout_time": 0.4190535545349121, "train_time": 0.8667409420013428, "student_train_time": 0.008722782135009766, "throughput": 1544.4569007530063, "inference_time": 0.05249957173145958, "env_time": 0.3665539828034525, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 301, "reward_mean": 35.29824561403509, "student_loss": null, "teacher_policy_loss": -18.5256290435791, "teacher_value_loss": 112.31220245361328, "teacher_entropy": 0.6183376908302307, "total_time": 1.2852284908294678, "rollout_time": 0.45194125175476074, "train_time": 0.8265769481658936, "student_train_time": 0.006331682205200195, "throughput": 1556.1435295518768, "inference_time": 0.05766744099128118, "env_time": 0.39427381076347956, "samples": 2000, "teacher_eval_reward": 168.0}
{"epoch": 302, "reward_mean": 35.482142857142854, "student_loss": null, "teacher_policy_loss": -19.51637077331543, "teacher_value_loss": 114.5950927734375, "teacher_entropy": 0.6110889315605164, "total_time": 1.1874995231628418, "rollout_time": 0.4181520938873291, "train_time": 0.7624528408050537, "student_train_time": 0.006546735763549805, "throughput": 1684.211202605881, "inference_time": 0.05196011797670508, "env_time": 0.366191975910624, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 303, "reward_mean": 33.416666666666664, "student_loss": null, "teacher_policy_loss": -17.727933883666992, "teacher_value_loss": 88.41877746582031, "teacher_entropy": 0.6065798997879028, "total_time": 1.3321404457092285, "rollout_time": 0.43082451820373535, "train_time": 0.8956465721130371, "student_train_time": 0.0052890777587890625, "throughput": 1501.343200292372, "inference_time": 0.055955690524569945, "env_time": 0.3748688276791654, "samples": 2000, "teacher_eval_reward": 133.0}
{"epoch": 304, "reward_mean": 30.848484848484848, "student_loss": null, "teacher_policy_loss": -15.811838150024414, "teacher_value_loss": 86.41326141357422, "teacher_entropy": 0.5903889536857605, "total_time": 1.2732529640197754, "rollout_time": 0.4279446601867676, "train_time": 0.8400344848632812, "student_train_time": 0.004865407943725586, "throughput": 1570.7797715905708, "inference_time": 0.05231514521801728, "env_time": 0.3756295149687503, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 305, "reward_mean": 34.01724137931034, "student_loss": null, "teacher_policy_loss": -18.462718963623047, "teacher_value_loss": 117.46886444091797, "teacher_entropy": 0.5967795252799988, "total_time": 1.1836192607879639, "rollout_time": 0.416623592376709, "train_time": 0.7592685222625732, "student_train_time": 0.007131814956665039, "throughput": 1689.732556961393, "inference_time": 0.05419874094877741, "env_time": 0.36242485142793157, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 306, "reward_mean": 32.516666666666666, "student_loss": null, "teacher_policy_loss": -17.984466552734375, "teacher_value_loss": 115.3594970703125, "teacher_entropy": 0.5944596529006958, "total_time": 1.4005801677703857, "rollout_time": 0.4504530429840088, "train_time": 0.9402406215667725, "student_train_time": 0.009511470794677734, "throughput": 1427.9796658722105, "inference_time": 0.0530646065435576, "env_time": 0.3973884364404512, "samples": 2000, "teacher_eval_reward": 149.0}
{"epoch": 307, "reward_mean": 31.41269841269841, "student_loss": null, "teacher_policy_loss": -17.232566833496094, "teacher_value_loss": 93.9116439819336, "teacher_entropy": 0.5935921669006348, "total_time": 1.2353971004486084, "rollout_time": 0.4288480281829834, "train_time": 0.8011856079101562, "student_train_time": 0.004953861236572266, "throughput": 1618.9126551080153, "inference_time": 0.05452934174172697, "env_time": 0.37431868644125643, "samples": 2000, "teacher_eval_reward": 226.0}
{"epoch": 308, "reward_mean": 33.96774193548387, "student_loss": null, "teacher_policy_loss": -17.536760330200195, "teacher_value_loss": 82.77021789550781, "teacher_entropy": 0.5954644083976746, "total_time": 1.2269527912139893, "rollout_time": 0.44236278533935547, "train_time": 0.7781379222869873, "student_train_time": 0.005960941314697266, "throughput": 1630.054566338393, "inference_time": 0.05424733445397578, "env_time": 0.3881154508853797, "samples": 2000, "teacher_eval_reward": 141.0}
{"epoch": 309, "reward_mean": 36.370370370370374, "student_loss": null, "teacher_policy_loss": -20.25139808654785, "teacher_value_loss": 122.51488494873047, "teacher_entropy": 0.605791449546814, "total_time": 1.35976243019104, "rollout_time": 0.4337189197540283, "train_time": 0.9182705879211426, "student_train_time": 0.0074045658111572266, "throughput": 1470.8451679452635, "inference_time": 0.05509117332439928, "env_time": 0.37862774642962904, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 310, "reward_mean": 38.916666666666664, "student_loss": null, "teacher_policy_loss": -23.24233627319336, "teacher_value_loss": 215.02157592773438, "teacher_entropy": 0.6077314615249634, "total_time": 1.1833250522613525, "rollout_time": 0.4195370674133301, "train_time": 0.7548003196716309, "student_train_time": 0.008596658706665039, "throughput": 1690.1526729092475, "inference_time": 0.05202733051737596, "env_time": 0.3675097368959541, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 311, "reward_mean": 35.71666666666667, "student_loss": null, "teacher_policy_loss": -18.355039596557617, "teacher_value_loss": 106.63401794433594, "teacher_entropy": 0.6111347079277039, "total_time": 1.304776906967163, "rollout_time": 0.441638708114624, "train_time": 0.8523256778717041, "student_train_time": 0.01038813591003418, "throughput": 1532.829090797461, "inference_time": 0.054317128780894564, "env_time": 0.38732157933372946, "samples": 2000, "teacher_eval_reward": 131.0}
{"epoch": 312, "reward_mean": 34.49122807017544, "student_loss": null, "teacher_policy_loss": -19.129173278808594, "teacher_value_loss": 101.61087799072266, "teacher_entropy": 0.6168212294578552, "total_time": 1.1750555038452148, "rollout_time": 0.4190819263458252, "train_time": 0.7468814849853516, "student_train_time": 0.008686304092407227, "throughput": 1702.0472594317994, "inference_time": 0.05340968398922996, "env_time": 0.36567224235659523, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 313, "reward_mean": 34.05172413793103, "student_loss": null, "teacher_policy_loss": -18.232860565185547, "teacher_value_loss": 108.82916259765625, "teacher_entropy": 0.6158820986747742, "total_time": 1.332413673400879, "rollout_time": 0.4518101215362549, "train_time": 0.8696942329406738, "student_train_time": 0.010483741760253906, "throughput": 1501.035331538711, "inference_time": 0.056262562506162794, "env_time": 0.3955475590300921, "samples": 2000, "teacher_eval_reward": 91.0}
{"epoch": 314, "reward_mean": 31.49230769230769, "student_loss": null, "teacher_policy_loss": -17.616880416870117, "teacher_value_loss": 100.96907806396484, "teacher_entropy": 0.6082897782325745, "total_time": 1.2048192024230957, "rollout_time": 0.44028639793395996, "train_time": 0.7582948207855225, "student_train_time": 0.0058786869049072266, "throughput": 1660.0001029014652, "inference_time": 0.056465265039150836, "env_time": 0.3838211328948091, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 315, "reward_mean": 34.63793103448276, "student_loss": null, "teacher_policy_loss": -17.957584381103516, "teacher_value_loss": 81.43035888671875, "teacher_entropy": 0.6191060543060303, "total_time": 1.380903959274292, "rollout_time": 0.4801020622253418, "train_time": 0.8010919094085693, "student_train_time": 0.09932208061218262, "throughput": 1448.3266461565236, "inference_time": 0.05710910350717313, "env_time": 0.42299295871816867, "samples": 2000, "teacher_eval_reward": 173.0}
{"epoch": 316, "reward_mean": 36.67857142857143, "student_loss": null, "teacher_policy_loss": -21.008127212524414, "teacher_value_loss": 223.48443603515625, "teacher_entropy": 0.6266548037528992, "total_time": 1.3545012474060059, "rollout_time": 0.43285346031188965, "train_time": 0.9101560115814209, "student_train_time": 0.011047601699829102, "throughput": 1476.5582562808145, "inference_time": 0.05716045520057378, "env_time": 0.37569300511131587, "samples": 2000, "teacher_eval_reward": 37.0}
{"epoch": 317, "reward_mean": 28.98507462686567, "student_loss": null, "teacher_policy_loss": -15.88271713256836, "teacher_value_loss": 80.12591552734375, "teacher_entropy": 0.6093756556510925, "total_time": 1.332078456878662, "rollout_time": 0.44116759300231934, "train_time": 0.874164342880249, "student_train_time": 0.016135692596435547, "throughput": 1501.4130659288774, "inference_time": 0.05590186074732628, "env_time": 0.38526573225499305, "samples": 2000, "teacher_eval_reward": 50.0}
{"epoch": 318, "reward_mean": 37.35849056603774, "student_loss": null, "teacher_policy_loss": -20.187427520751953, "teacher_value_loss": 169.4204559326172, "teacher_entropy": 0.6218916177749634, "total_time": 1.3948254585266113, "rollout_time": 0.4166696071624756, "train_time": 0.9696500301361084, "student_train_time": 0.008149147033691406, "throughput": 1433.8711612796696, "inference_time": 0.053498647514061304, "env_time": 0.3631709596484143, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 319, "reward_mean": 35.7962962962963, "student_loss": null, "teacher_policy_loss": -19.700252532958984, "teacher_value_loss": 138.36976623535156, "teacher_entropy": 0.6323161125183105, "total_time": 1.2752761840820312, "rollout_time": 0.45361804962158203, "train_time": 0.8107848167419434, "student_train_time": 0.01047372817993164, "throughput": 1568.2877363852278, "inference_time": 0.05543208024209889, "env_time": 0.39818596937948314, "samples": 2000, "teacher_eval_reward": 183.0}
{"epoch": 320, "reward_mean": 35.85964912280702, "student_loss": null, "teacher_policy_loss": -18.2618350982666, "teacher_value_loss": 96.40234375, "teacher_entropy": 0.6388156414031982, "total_time": 1.2592344284057617, "rollout_time": 0.43874382972717285, "train_time": 0.811931848526001, "student_train_time": 0.008060455322265625, "throughput": 1588.266612541777, "inference_time": 0.05391694902391464, "env_time": 0.3848268807032582, "samples": 2000, "teacher_eval_reward": 85.0}
{"epoch": 321, "reward_mean": 32.1875, "student_loss": null, "teacher_policy_loss": -17.650789260864258, "teacher_value_loss": 109.19524383544922, "teacher_entropy": 0.6272341012954712, "total_time": 1.2224922180175781, "rollout_time": 0.43395566940307617, "train_time": 0.7712044715881348, "student_train_time": 0.0169069766998291, "throughput": 1636.0022342254633, "inference_time": 0.05406877329915005, "env_time": 0.3798868961039261, "samples": 2000, "teacher_eval_reward": 69.0}
{"epoch": 322, "reward_mean": 36.129629629629626, "student_loss": null, "teacher_policy_loss": -18.83242416381836, "teacher_value_loss": 87.62870025634766, "teacher_entropy": 0.6235212683677673, "total_time": 1.2698421478271484, "rollout_time": 0.47167325019836426, "train_time": 0.7897500991821289, "student_train_time": 0.008054256439208984, "throughput": 1574.9989110238928, "inference_time": 0.059598729292702046, "env_time": 0.4120745209056622, "samples": 2000, "teacher_eval_reward": 349.0}
{"epoch": 323, "reward_mean": 34.51724137931034, "student_loss": null, "teacher_policy_loss": -17.473834991455078, "teacher_value_loss": 76.26295471191406, "teacher_entropy": 0.6306738257408142, "total_time": 1.3422250747680664, "rollout_time": 0.4472355842590332, "train_time": 0.8649415969848633, "student_train_time": 0.029685497283935547, "throughput": 1490.063058422296, "inference_time": 0.05601819453841017, "env_time": 0.39121738972062303, "samples": 2000, "teacher_eval_reward": 152.0}
{"epoch": 324, "reward_mean": 36.79245283018868, "student_loss": null, "teacher_policy_loss": -18.91584014892578, "teacher_value_loss": 99.63279724121094, "teacher_entropy": 0.6265761256217957, "total_time": 1.2742903232574463, "rollout_time": 0.4430253505706787, "train_time": 0.8236849308013916, "student_train_time": 0.0072247982025146484, "throughput": 1569.5010497195292, "inference_time": 0.05601817242859397, "env_time": 0.38700717814208474, "samples": 2000, "teacher_eval_reward": 198.0}
{"epoch": 325, "reward_mean": 35.728813559322035, "student_loss": null, "teacher_policy_loss": -19.38395881652832, "teacher_value_loss": 147.05430603027344, "teacher_entropy": 0.6160764098167419, "total_time": 1.220625400543213, "rollout_time": 0.4446234703063965, "train_time": 0.7707116603851318, "student_train_time": 0.004931449890136719, "throughput": 1638.504326642673, "inference_time": 0.05499200421763817, "env_time": 0.3896314660887583, "samples": 2000, "teacher_eval_reward": 153.0}
{"epoch": 326, "reward_mean": 32.94915254237288, "student_loss": null, "teacher_policy_loss": -17.678241729736328, "teacher_value_loss": 88.82635498046875, "teacher_entropy": 0.6133530735969543, "total_time": 1.2945990562438965, "rollout_time": 0.450747013092041, "train_time": 0.8361248970031738, "student_train_time": 0.007368326187133789, "throughput": 1544.8798532286348, "inference_time": 0.055556875486217905, "env_time": 0.3951901376058231, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 327, "reward_mean": 33.096774193548384, "student_loss": null, "teacher_policy_loss": -17.635847091674805, "teacher_value_loss": 85.5811538696289, "teacher_entropy": 0.6117781400680542, "total_time": 1.4429166316986084, "rollout_time": 0.4356198310852051, "train_time": 0.9984102249145508, "student_train_time": 0.008506536483764648, "throughput": 1386.0814658748443, "inference_time": 0.05305230622070667, "env_time": 0.3825675248644984, "samples": 2000, "teacher_eval_reward": 88.0}
{"epoch": 328, "reward_mean": 32.459016393442624, "student_loss": null, "teacher_policy_loss": -16.557889938354492, "teacher_value_loss": 61.99341583251953, "teacher_entropy": 0.6079926490783691, "total_time": -1.341500997543335, "rollout_time": 0.4347083568572998, "train_time": -1.7861545085906982, "student_train_time": 0.009578943252563477, "throughput": 200000000000.0, "inference_time": 0.05582459220386227, "env_time": 0.37888376465343754, "samples": 2000, "teacher_eval_reward": 139.0}
{"epoch": 329, "reward_mean": 37.111111111111114, "student_loss": null, "teacher_policy_loss": -19.475522994995117, "teacher_value_loss": 106.17350006103516, "teacher_entropy": 0.616899311542511, "total_time": 1.2429747581481934, "rollout_time": 0.44920969009399414, "train_time": 0.7835178375244141, "student_train_time": 0.009867191314697266, "throughput": 1609.0431337315624, "inference_time": 0.054768990723459865, "env_time": 0.3944406993705343, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 330, "reward_mean": 34.87931034482759, "student_loss": null, "teacher_policy_loss": -18.436307907104492, "teacher_value_loss": 90.50904083251953, "teacher_entropy": 0.6079450845718384, "total_time": 1.1927118301391602, "rollout_time": 0.41868019104003906, "train_time": 0.7689716815948486, "student_train_time": 0.0046656131744384766, "throughput": 1676.850978971718, "inference_time": 0.051715650768528576, "env_time": 0.3669645402715105, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 331, "reward_mean": 39.4, "student_loss": null, "teacher_policy_loss": -22.772489547729492, "teacher_value_loss": 203.20755004882812, "teacher_entropy": 0.6087781190872192, "total_time": 1.1704249382019043, "rollout_time": 0.42838525772094727, "train_time": 0.7355883121490479, "student_train_time": 0.006093025207519531, "throughput": 1708.781088578437, "inference_time": 0.053565649470328935, "env_time": 0.37481960825061833, "samples": 2000, "teacher_eval_reward": 129.0}
{"epoch": 332, "reward_mean": 35.61818181818182, "student_loss": null, "teacher_policy_loss": -19.613140106201172, "teacher_value_loss": 127.74303436279297, "teacher_entropy": 0.6071656942367554, "total_time": 1.210052728652954, "rollout_time": 0.4175112247467041, "train_time": 0.7873971462249756, "student_train_time": 0.004797458648681641, "throughput": 1652.8205363632585, "inference_time": 0.052799675469941576, "env_time": 0.3647115492767625, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 333, "reward_mean": 31.76923076923077, "student_loss": null, "teacher_policy_loss": -16.26974868774414, "teacher_value_loss": 82.32947540283203, "teacher_entropy": 0.6050635576248169, "total_time": 1.3193178176879883, "rollout_time": 0.4158816337585449, "train_time": 0.8942995071411133, "student_train_time": 0.008714437484741211, "throughput": 1515.9349575865347, "inference_time": 0.05189919427903078, "env_time": 0.36398243947951414, "samples": 2000, "teacher_eval_reward": 56.0}
{"epoch": 334, "reward_mean": 34.666666666666664, "student_loss": null, "teacher_policy_loss": -17.479087829589844, "teacher_value_loss": 83.56846618652344, "teacher_entropy": 0.5942995548248291, "total_time": 1.2294201850891113, "rollout_time": 0.4188852310180664, "train_time": 0.8017663955688477, "student_train_time": 0.008390188217163086, "throughput": 1626.783116347675, "inference_time": 0.05445568901086517, "env_time": 0.36442954200720123, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 335, "reward_mean": 35.85454545454545, "student_loss": null, "teacher_policy_loss": -18.047515869140625, "teacher_value_loss": 107.8216781616211, "teacher_entropy": 0.597974956035614, "total_time": 1.2985351085662842, "rollout_time": 0.43656182289123535, "train_time": 0.8560733795166016, "student_train_time": 0.00549769401550293, "throughput": 1540.1970934834446, "inference_time": 0.053491313199629076, "env_time": 0.3830705096916063, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 336, "reward_mean": 33.39344262295082, "student_loss": null, "teacher_policy_loss": -18.09937858581543, "teacher_value_loss": 125.18523406982422, "teacher_entropy": 0.6061909198760986, "total_time": 1.2730886936187744, "rollout_time": 0.43049192428588867, "train_time": 0.83547043800354, "student_train_time": 0.006770133972167969, "throughput": 1570.9824539521821, "inference_time": 0.05524980072914332, "env_time": 0.37524212355674536, "samples": 2000, "teacher_eval_reward": 333.0}
{"epoch": 337, "reward_mean": 34.42857142857143, "student_loss": null, "teacher_policy_loss": -18.336082458496094, "teacher_value_loss": 86.85931396484375, "teacher_entropy": 0.6125872731208801, "total_time": 1.2232732772827148, "rollout_time": 0.43895816802978516, "train_time": 0.774822473526001, "student_train_time": 0.009085893630981445, "throughput": 1634.9576477650571, "inference_time": 0.058294484531870694, "env_time": 0.38066368349791446, "samples": 2000, "teacher_eval_reward": 110.0}
{"epoch": 338, "reward_mean": 34.8, "student_loss": null, "teacher_policy_loss": -19.856908798217773, "teacher_value_loss": 153.04624938964844, "teacher_entropy": 0.6080752611160278, "total_time": 1.1961214542388916, "rollout_time": 0.4291388988494873, "train_time": 0.7579834461212158, "student_train_time": 0.008580684661865234, "throughput": 1672.0710032516115, "inference_time": 0.05330083346962056, "env_time": 0.37583806537986675, "samples": 2000, "teacher_eval_reward": 49.0}
{"epoch": 339, "reward_mean": 37.64150943396226, "student_loss": null, "teacher_policy_loss": -19.240827560424805, "teacher_value_loss": 106.16773223876953, "teacher_entropy": 0.6012031435966492, "total_time": 1.3175175189971924, "rollout_time": 0.49015116691589355, "train_time": 0.8223724365234375, "student_train_time": 0.0046198368072509766, "throughput": 1518.0063803039739, "inference_time": 0.0638752947706962, "env_time": 0.42627587214519735, "samples": 2000, "teacher_eval_reward": 53.0}
{"epoch": 340, "reward_mean": 42.83720930232558, "student_loss": null, "teacher_policy_loss": -22.05620765686035, "teacher_value_loss": 145.60377502441406, "teacher_entropy": 0.624432384967804, "total_time": 1.6364030838012695, "rollout_time": 0.4365062713623047, "train_time": 1.1929795742034912, "student_train_time": 0.006548166275024414, "throughput": 1222.1927591056085, "inference_time": 0.05682607524613559, "env_time": 0.3796801961161691, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 341, "reward_mean": 35.813559322033896, "student_loss": null, "teacher_policy_loss": -17.680187225341797, "teacher_value_loss": 87.67427062988281, "teacher_entropy": 0.6132689118385315, "total_time": 1.285681962966919, "rollout_time": 0.43761491775512695, "train_time": 0.8423609733581543, "student_train_time": 0.005342245101928711, "throughput": 1555.5946630725664, "inference_time": 0.05714671972782526, "env_time": 0.3804681980273017, "samples": 2000, "teacher_eval_reward": 146.0}
{"epoch": 342, "reward_mean": 39.31372549019608, "student_loss": null, "teacher_policy_loss": -20.616228103637695, "teacher_value_loss": 118.60747528076172, "teacher_entropy": 0.6215129494667053, "total_time": 1.2980995178222656, "rollout_time": 0.43476390838623047, "train_time": 0.8544971942901611, "student_train_time": 0.008430957794189453, "throughput": 1540.7139225775738, "inference_time": 0.05583480500354199, "env_time": 0.3789291033826885, "samples": 2000, "teacher_eval_reward": 52.0}
{"epoch": 343, "reward_mean": 37.075471698113205, "student_loss": null, "teacher_policy_loss": -19.386362075805664, "teacher_value_loss": 118.8768081665039, "teacher_entropy": 0.6161432266235352, "total_time": 1.2298893928527832, "rollout_time": 0.44431567192077637, "train_time": 0.7735226154327393, "student_train_time": 0.011632204055786133, "throughput": 1626.1624920277677, "inference_time": 0.0550938857231813, "env_time": 0.38922178619759507, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 344, "reward_mean": 37.925925925925924, "student_loss": null, "teacher_policy_loss": -20.03083038330078, "teacher_value_loss": 156.98776245117188, "teacher_entropy": 0.610620379447937, "total_time": 1.2827396392822266, "rollout_time": 0.43613743782043457, "train_time": 0.8379428386688232, "student_train_time": 0.00830531120300293, "throughput": 1559.1628563993904, "inference_time": 0.053841141971133766, "env_time": 0.3822962958493008, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 345, "reward_mean": 36.872727272727275, "student_loss": null, "teacher_policy_loss": -19.700788497924805, "teacher_value_loss": 126.4563217163086, "teacher_entropy": 0.6188040971755981, "total_time": 1.2169673442840576, "rollout_time": 0.41718173027038574, "train_time": 0.7930014133453369, "student_train_time": 0.006387472152709961, "throughput": 1643.429471952348, "inference_time": 0.05367104279139312, "env_time": 0.3635106874789926, "samples": 2000, "teacher_eval_reward": 144.0}
{"epoch": 346, "reward_mean": 36.5, "student_loss": null, "teacher_policy_loss": -20.008319854736328, "teacher_value_loss": 122.40898132324219, "teacher_entropy": 0.6189819574356079, "total_time": 1.2955834865570068, "rollout_time": 0.44141721725463867, "train_time": 0.84604811668396, "student_train_time": 0.007758378982543945, "throughput": 1543.7059986886443, "inference_time": 0.05766818423398945, "env_time": 0.3837490330206492, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 347, "reward_mean": 36.90909090909091, "student_loss": null, "teacher_policy_loss": -20.477706909179688, "teacher_value_loss": 174.15969848632812, "teacher_entropy": 0.6076676249504089, "total_time": 1.1928558349609375, "rollout_time": 0.4438607692718506, "train_time": 0.7435116767883301, "student_train_time": 0.0050201416015625, "throughput": 1676.648544931244, "inference_time": 0.053565389243885875, "env_time": 0.3902953800279647, "samples": 2000, "teacher_eval_reward": 62.0}
{"epoch": 348, "reward_mean": 37.19230769230769, "student_loss": null, "teacher_policy_loss": -20.94558334350586, "teacher_value_loss": 172.0839385986328, "teacher_entropy": 0.6144670248031616, "total_time": 1.2475802898406982, "rollout_time": 0.437359094619751, "train_time": 0.8008639812469482, "student_train_time": 0.00901484489440918, "throughput": 1603.1032361495365, "inference_time": 0.05681927380828711, "env_time": 0.38053982081146387, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 349, "reward_mean": 33.67213114754098, "student_loss": null, "teacher_policy_loss": -17.082218170166016, "teacher_value_loss": 78.14035034179688, "teacher_entropy": 0.6040903329849243, "total_time": 1.1885969638824463, "rollout_time": 0.44233274459838867, "train_time": 0.7377653121948242, "student_train_time": 0.008131980895996094, "throughput": 1682.65615744733, "inference_time": 0.0564081765805895, "env_time": 0.3859245680177992, "samples": 2000, "teacher_eval_reward": 124.0}
{"epoch": 350, "reward_mean": 36.09090909090909, "student_loss": null, "teacher_policy_loss": -20.398359298706055, "teacher_value_loss": 159.89923095703125, "teacher_entropy": 0.6107692718505859, "total_time": 1.2190768718719482, "rollout_time": 0.4363222122192383, "train_time": 0.7640657424926758, "student_train_time": 0.018344640731811523, "throughput": 1640.585631756682, "inference_time": 0.05594635125453351, "env_time": 0.38037586096470477, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 351, "reward_mean": 35.357142857142854, "student_loss": null, "teacher_policy_loss": -18.254913330078125, "teacher_value_loss": 86.33435821533203, "teacher_entropy": 0.610831081867218, "total_time": 1.2163021564483643, "rollout_time": 0.42683982849121094, "train_time": 0.7735018730163574, "student_train_time": 0.015608549118041992, "throughput": 1644.3282529729743, "inference_time": 0.05422700446433737, "env_time": 0.37261282402687357, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 352, "reward_mean": 41.22, "student_loss": null, "teacher_policy_loss": -21.25699234008789, "teacher_value_loss": 144.6348114013672, "teacher_entropy": 0.6140255928039551, "total_time": 1.2516086101531982, "rollout_time": 0.43491244316101074, "train_time": 0.806859016418457, "student_train_time": 0.009209394454956055, "throughput": 1597.9436253280471, "inference_time": 0.05606906727734895, "env_time": 0.3788433758836618, "samples": 2000, "teacher_eval_reward": 309.0}
{"epoch": 353, "reward_mean": 38.07692307692308, "student_loss": null, "teacher_policy_loss": -20.06778907775879, "teacher_value_loss": 140.46925354003906, "teacher_entropy": 0.6017550826072693, "total_time": 1.2220356464385986, "rollout_time": 0.4507880210876465, "train_time": 0.7590541839599609, "student_train_time": 0.011795759201049805, "throughput": 1636.6134701787444, "inference_time": 0.054366500005926355, "env_time": 0.39642152108172013, "samples": 2000, "teacher_eval_reward": 451.0}
{"epoch": 354, "reward_mean": 36.74074074074074, "student_loss": null, "teacher_policy_loss": -20.01898193359375, "teacher_value_loss": 109.85641479492188, "teacher_entropy": 0.6076068878173828, "total_time": 1.200838565826416, "rollout_time": 0.43250513076782227, "train_time": 0.7591667175292969, "student_train_time": 0.008769989013671875, "throughput": 1665.5028052197856, "inference_time": 0.05415534571875469, "env_time": 0.3783497850490676, "samples": 2000, "teacher_eval_reward": 274.0}
{"epoch": 355, "reward_mean": 35.61818181818182, "student_loss": null, "teacher_policy_loss": -18.828155517578125, "teacher_value_loss": 99.9239730834961, "teacher_entropy": 0.6007905602455139, "total_time": 1.2580761909484863, "rollout_time": 0.44635534286499023, "train_time": 0.7991123199462891, "student_train_time": 0.012253284454345703, "throughput": 1589.7288370843137, "inference_time": 0.055126443307017325, "env_time": 0.3912288995579729, "samples": 2000, "teacher_eval_reward": 139.0}
{"epoch": 356, "reward_mean": 34.724137931034484, "student_loss": null, "teacher_policy_loss": -19.063152313232422, "teacher_value_loss": 147.19203186035156, "teacher_entropy": 0.5964059829711914, "total_time": 1.3383843898773193, "rollout_time": 0.4383387565612793, "train_time": 0.8908984661102295, "student_train_time": 0.00874018669128418, "throughput": 1494.339006885254, "inference_time": 0.05768405924573017, "env_time": 0.38065469731554913, "samples": 2000, "teacher_eval_reward": 128.0}
{"epoch": 357, "reward_mean": 40.35294117647059, "student_loss": null, "teacher_policy_loss": -21.49321174621582, "teacher_value_loss": 195.1455535888672, "teacher_entropy": 0.5992968082427979, "total_time": 1.1842877864837646, "rollout_time": 0.4235689640045166, "train_time": 0.7535293102264404, "student_train_time": 0.006813764572143555, "throughput": 1688.7787097240473, "inference_time": 0.05364694952004356, "env_time": 0.36992201448447304, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 358, "reward_mean": 37.28846153846154, "student_loss": null, "teacher_policy_loss": -19.92431640625, "teacher_value_loss": 118.17830657958984, "teacher_entropy": 0.5936899185180664, "total_time": 1.1873517036437988, "rollout_time": 0.4220261573791504, "train_time": 0.7565183639526367, "student_train_time": 0.00845646858215332, "throughput": 1684.4208787188406, "inference_time": 0.05087998045200948, "env_time": 0.3711461769271409, "samples": 2000, "teacher_eval_reward": 405.0}
{"epoch": 359, "reward_mean": 35.56140350877193, "student_loss": null, "teacher_policy_loss": -18.778074264526367, "teacher_value_loss": 97.7044677734375, "teacher_entropy": 0.5895604491233826, "total_time": -1.3535552024841309, "rollout_time": -2.1359474658966064, "train_time": 0.7769389152526855, "student_train_time": 0.005101442337036133, "throughput": 200000000000.0, "inference_time": 0.05609129353797471, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 142.0}
{"epoch": 360, "reward_mean": 38.61538461538461, "student_loss": null, "teacher_policy_loss": -20.60089111328125, "teacher_value_loss": 129.24925231933594, "teacher_entropy": 0.5920537710189819, "total_time": 1.1978344917297363, "rollout_time": 0.436755895614624, "train_time": 0.7532024383544922, "student_train_time": 0.007518768310546875, "throughput": 1669.6797544307597, "inference_time": 0.05556156948478019, "env_time": 0.38119432612984383, "samples": 2000, "teacher_eval_reward": 120.0}
{"epoch": 361, "reward_mean": 33.016949152542374, "student_loss": null, "teacher_policy_loss": -18.230566024780273, "teacher_value_loss": 84.13834381103516, "teacher_entropy": 0.5879147052764893, "total_time": 1.2638983726501465, "rollout_time": 0.43101930618286133, "train_time": 0.8279783725738525, "student_train_time": 0.00455784797668457, "throughput": 1582.4057086222788, "inference_time": 0.05353559606919589, "env_time": 0.37748371011366544, "samples": 2000, "teacher_eval_reward": 135.0}
{"epoch": 362, "reward_mean": 42.0, "student_loss": null, "teacher_policy_loss": -23.914783477783203, "teacher_value_loss": 252.6769561767578, "teacher_entropy": 0.6106932163238525, "total_time": 1.1718692779541016, "rollout_time": 0.4297215938568115, "train_time": 0.7362592220306396, "student_train_time": 0.005531787872314453, "throughput": 1706.6750000406903, "inference_time": 0.054877614267752506, "env_time": 0.374843979589059, "samples": 2000, "teacher_eval_reward": 81.0}
{"epoch": 363, "reward_mean": 36.19642857142857, "student_loss": null, "teacher_policy_loss": -19.867101669311523, "teacher_value_loss": 118.13835906982422, "teacher_entropy": 0.5974674224853516, "total_time": 1.2282743453979492, "rollout_time": 0.41913819313049316, "train_time": 0.8036348819732666, "student_train_time": 0.005159139633178711, "throughput": 1628.3007192110806, "inference_time": 0.05258403898369579, "env_time": 0.3665541541467974, "samples": 2000, "teacher_eval_reward": 80.0}
{"epoch": 364, "reward_mean": 40.541666666666664, "student_loss": null, "teacher_policy_loss": -20.738014221191406, "teacher_value_loss": 158.5132598876953, "teacher_entropy": 0.5936167240142822, "total_time": 1.1595661640167236, "rollout_time": 0.4334292411804199, "train_time": 0.7107901573181152, "student_train_time": 0.014987945556640625, "throughput": 1724.7829939018084, "inference_time": 0.05302491726615699, "env_time": 0.38040432391426293, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 365, "reward_mean": 37.14545454545455, "student_loss": null, "teacher_policy_loss": -19.417036056518555, "teacher_value_loss": 141.2652587890625, "teacher_entropy": 0.593758761882782, "total_time": 1.293900489807129, "rollout_time": 0.43322205543518066, "train_time": 0.8532383441925049, "student_train_time": 0.007081508636474609, "throughput": 1545.7139213991052, "inference_time": 0.05355426402456942, "env_time": 0.37966779141061124, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 366, "reward_mean": 39.16, "student_loss": null, "teacher_policy_loss": -21.36998176574707, "teacher_value_loss": 124.76002502441406, "teacher_entropy": 0.6052685379981995, "total_time": 1.371260166168213, "rollout_time": 0.4278242588043213, "train_time": 0.9350709915161133, "student_train_time": 0.008012056350708008, "throughput": 1458.5124321001092, "inference_time": 0.052548574189131614, "env_time": 0.3752756846151897, "samples": 2000, "teacher_eval_reward": 97.0}
{"epoch": 367, "reward_mean": 35.49122807017544, "student_loss": null, "teacher_policy_loss": -18.64501953125, "teacher_value_loss": 117.00727844238281, "teacher_entropy": 0.5944837331771851, "total_time": 1.3148224353790283, "rollout_time": 0.43688035011291504, "train_time": 0.8676564693450928, "student_train_time": 0.009919166564941406, "throughput": 1521.117944282304, "inference_time": 0.05479641924102907, "env_time": 0.38208393087188597, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 368, "reward_mean": 37.867924528301884, "student_loss": null, "teacher_policy_loss": -20.331153869628906, "teacher_value_loss": 122.32701110839844, "teacher_entropy": 0.6107600927352905, "total_time": 1.2356541156768799, "rollout_time": 0.4519038200378418, "train_time": 0.7721025943756104, "student_train_time": 0.011292219161987305, "throughput": 1618.5759223602945, "inference_time": 0.06042029891250422, "env_time": 0.3914835211253376, "samples": 2000, "teacher_eval_reward": 491.0}
{"epoch": 369, "reward_mean": 41.36734693877551, "student_loss": null, "teacher_policy_loss": -21.4833984375, "teacher_value_loss": 123.59432983398438, "teacher_entropy": 0.6158696413040161, "total_time": 1.2478818893432617, "rollout_time": 0.4283759593963623, "train_time": 0.8098986148834229, "student_train_time": 0.009245634078979492, "throughput": 1602.715783504611, "inference_time": 0.054083084487501765, "env_time": 0.37429287490886054, "samples": 2000, "teacher_eval_reward": 149.0}
{"epoch": 370, "reward_mean": 38.44230769230769, "student_loss": null, "teacher_policy_loss": -19.548988342285156, "teacher_value_loss": 116.05501556396484, "teacher_entropy": 0.614250123500824, "total_time": 1.3238725662231445, "rollout_time": 0.47667384147644043, "train_time": 0.837561845779419, "student_train_time": 0.0092315673828125, "throughput": 1510.7194234757571, "inference_time": 0.0630695015006495, "env_time": 0.41360433997579094, "samples": 2000, "teacher_eval_reward": 168.0}
{"epoch": 371, "reward_mean": 34.75, "student_loss": null, "teacher_policy_loss": -18.42082977294922, "teacher_value_loss": 88.30337524414062, "teacher_entropy": 0.6077972054481506, "total_time": 1.353783130645752, "rollout_time": 0.4381289482116699, "train_time": 0.9102139472961426, "student_train_time": 0.005076169967651367, "throughput": 1477.3414993330607, "inference_time": 0.05382992450540769, "env_time": 0.38429902370626223, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 372, "reward_mean": 37.236363636363635, "student_loss": null, "teacher_policy_loss": -19.500825881958008, "teacher_value_loss": 121.22773742675781, "teacher_entropy": 0.6115173697471619, "total_time": 1.3100085258483887, "rollout_time": 0.44121432304382324, "train_time": 0.8641097545623779, "student_train_time": 0.004299163818359375, "throughput": 1526.7076210093812, "inference_time": 0.054098458982480224, "env_time": 0.387115864061343, "samples": 2000, "teacher_eval_reward": 220.0}
{"epoch": 373, "reward_mean": 39.11764705882353, "student_loss": null, "teacher_policy_loss": -20.174503326416016, "teacher_value_loss": 103.44004821777344, "teacher_entropy": 0.6074466705322266, "total_time": 1.4341087341308594, "rollout_time": 0.4688870906829834, "train_time": 0.9551796913146973, "student_train_time": 0.009674072265625, "throughput": 1394.5943932989842, "inference_time": 0.062052458204561844, "env_time": 0.40683463247842155, "samples": 2000, "teacher_eval_reward": 152.0}
{"epoch": 374, "reward_mean": 35.05263157894737, "student_loss": null, "teacher_policy_loss": -18.481548309326172, "teacher_value_loss": 80.87425231933594, "teacher_entropy": 0.6042295694351196, "total_time": -1.2220802307128906, "rollout_time": 0.4580533504486084, "train_time": -1.70045804977417, "student_train_time": 0.019953250885009766, "throughput": 200000000000.0, "inference_time": 0.057320608480949886, "env_time": 0.4007327419676585, "samples": 2000, "teacher_eval_reward": 159.0}
{"epoch": 375, "reward_mean": 36.38181818181818, "student_loss": null, "teacher_policy_loss": -19.09687614440918, "teacher_value_loss": 123.71249389648438, "teacher_entropy": 0.599681556224823, "total_time": 1.3383750915527344, "rollout_time": 0.43244099617004395, "train_time": 0.9002211093902588, "student_train_time": 0.005361080169677734, "throughput": 1494.3493887649033, "inference_time": 0.05484352398525516, "env_time": 0.3775974721847888, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 376, "reward_mean": 41.87234042553192, "student_loss": null, "teacher_policy_loss": -20.829404830932617, "teacher_value_loss": 107.36862182617188, "teacher_entropy": 0.6076629757881165, "total_time": 1.4355075359344482, "rollout_time": 0.4246060848236084, "train_time": 1.001225471496582, "student_train_time": 0.00932931900024414, "throughput": 1393.235458494541, "inference_time": 0.053077697009939584, "env_time": 0.3715283878136688, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 377, "reward_mean": 37.870370370370374, "student_loss": null, "teacher_policy_loss": -19.298404693603516, "teacher_value_loss": 96.62963104248047, "teacher_entropy": 0.6024629473686218, "total_time": 1.2724158763885498, "rollout_time": 0.44963669776916504, "train_time": 0.8143913745880127, "student_train_time": 0.006906986236572266, "throughput": 1571.8131446744635, "inference_time": 0.055566006751178065, "env_time": 0.394070691017987, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 378, "reward_mean": 48.666666666666664, "student_loss": null, "teacher_policy_loss": -26.100566864013672, "teacher_value_loss": 204.61483764648438, "teacher_entropy": 0.6066359281539917, "total_time": 1.2090117931365967, "rollout_time": 0.45282864570617676, "train_time": 0.7472624778747559, "student_train_time": 0.008556127548217773, "throughput": 1654.2435825305765, "inference_time": 0.056318566064874176, "env_time": 0.3965100796413026, "samples": 2000, "teacher_eval_reward": 134.0}
{"epoch": 379, "reward_mean": 41.13725490196079, "student_loss": null, "teacher_policy_loss": -21.844133377075195, "teacher_value_loss": 159.81271362304688, "teacher_entropy": 0.5940894484519958, "total_time": 1.251830816268921, "rollout_time": 0.4256892204284668, "train_time": 0.8186657428741455, "student_train_time": 0.00712895393371582, "throughput": 1597.6599824894836, "inference_time": 0.053597914327838225, "env_time": 0.37209130610062857, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 380, "reward_mean": 37.9811320754717, "student_loss": null, "teacher_policy_loss": -19.059362411499023, "teacher_value_loss": 89.57693481445312, "teacher_entropy": 0.587297260761261, "total_time": 1.274775505065918, "rollout_time": 0.428149938583374, "train_time": 0.8387877941131592, "student_train_time": 0.007440090179443359, "throughput": 1568.9036948482792, "inference_time": 0.05411579954306944, "env_time": 0.3740341390403046, "samples": 2000, "teacher_eval_reward": 172.0}
{"epoch": 381, "reward_mean": 36.648148148148145, "student_loss": null, "teacher_policy_loss": -19.039167404174805, "teacher_value_loss": 89.51424407958984, "teacher_entropy": 0.5913419127464294, "total_time": 1.2067677974700928, "rollout_time": 0.4413468837738037, "train_time": 0.7561864852905273, "student_train_time": 0.008872747421264648, "throughput": 1657.3196634786452, "inference_time": 0.05656063545575307, "env_time": 0.38478624831805064, "samples": 2000, "teacher_eval_reward": 400.0}
{"epoch": 382, "reward_mean": 37.22222222222222, "student_loss": null, "teacher_policy_loss": -19.2745418548584, "teacher_value_loss": 115.45423889160156, "teacher_entropy": 0.5815038084983826, "total_time": 1.2656171321868896, "rollout_time": 0.4500608444213867, "train_time": 0.8091716766357422, "student_train_time": 0.0059757232666015625, "throughput": 1580.2567373152992, "inference_time": 0.057040786241486785, "env_time": 0.39302005817989993, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 383, "reward_mean": 39.40816326530612, "student_loss": null, "teacher_policy_loss": -20.535898208618164, "teacher_value_loss": 115.71443176269531, "teacher_entropy": 0.5927814841270447, "total_time": 1.1898219585418701, "rollout_time": 0.43200206756591797, "train_time": 0.7502734661102295, "student_train_time": 0.007148027420043945, "throughput": 1680.9237597623473, "inference_time": 0.055313423990810406, "env_time": 0.37668864357510756, "samples": 2000, "teacher_eval_reward": 125.0}
{"epoch": 384, "reward_mean": 38.24074074074074, "student_loss": null, "teacher_policy_loss": -19.757373809814453, "teacher_value_loss": 101.74321746826172, "teacher_entropy": 0.587785005569458, "total_time": 1.2966184616088867, "rollout_time": 0.43792080879211426, "train_time": 0.8525848388671875, "student_train_time": 0.0057582855224609375, "throughput": 1542.4737956594684, "inference_time": 0.05489031650176912, "env_time": 0.38303049229034514, "samples": 2000, "teacher_eval_reward": 117.0}
{"epoch": 385, "reward_mean": 36.74074074074074, "student_loss": null, "teacher_policy_loss": -18.355621337890625, "teacher_value_loss": 81.00016784667969, "teacher_entropy": 0.589557409286499, "total_time": 1.1681053638458252, "rollout_time": 0.4283638000488281, "train_time": 0.7328915596008301, "student_train_time": 0.006494283676147461, "throughput": 1712.174313980784, "inference_time": 0.0532189470341109, "env_time": 0.37514485301471723, "samples": 2000, "teacher_eval_reward": 116.0}
{"epoch": 386, "reward_mean": 37.15094339622642, "student_loss": null, "teacher_policy_loss": -19.50054359436035, "teacher_value_loss": 91.76393127441406, "teacher_entropy": 0.587049126625061, "total_time": -1.3680205345153809, "rollout_time": 0.4329111576080322, "train_time": -1.8191540241241455, "student_train_time": 0.01787090301513672, "throughput": 200000000000.0, "inference_time": 0.055650574733590474, "env_time": 0.37726058287444175, "samples": 2000, "teacher_eval_reward": 311.0}
{"epoch": 387, "reward_mean": 44.52173913043478, "student_loss": null, "teacher_policy_loss": -23.077604293823242, "teacher_value_loss": 157.36485290527344, "teacher_entropy": 0.5912967324256897, "total_time": 1.3330824375152588, "rollout_time": 0.449770450592041, "train_time": 0.8741018772125244, "student_train_time": 0.008842229843139648, "throughput": 1500.2823109183055, "inference_time": 0.0591671394995501, "env_time": 0.3906033110924909, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 388, "reward_mean": 37.64705882352941, "student_loss": null, "teacher_policy_loss": -19.511327743530273, "teacher_value_loss": 81.29179382324219, "teacher_entropy": 0.5863069295883179, "total_time": 1.27915358543396, "rollout_time": 0.436276912689209, "train_time": 0.8338165283203125, "student_train_time": 0.008652687072753906, "throughput": 1563.5339045869844, "inference_time": 0.05391409447111073, "env_time": 0.38236281821809825, "samples": 2000, "teacher_eval_reward": 87.0}
{"epoch": 389, "reward_mean": 43.91489361702128, "student_loss": null, "teacher_policy_loss": -21.55422592163086, "teacher_value_loss": 129.1239471435547, "teacher_entropy": 0.59641033411026, "total_time": 1.158996343612671, "rollout_time": 0.41936469078063965, "train_time": 0.7338402271270752, "student_train_time": 0.0053446292877197266, "throughput": 1725.6309832400877, "inference_time": 0.053050272470500204, "env_time": 0.36631441831013944, "samples": 2000, "teacher_eval_reward": 140.0}
{"epoch": 390, "reward_mean": 35.82142857142857, "student_loss": null, "teacher_policy_loss": -18.981761932373047, "teacher_value_loss": 100.9508056640625, "teacher_entropy": 0.5868475437164307, "total_time": 1.2249677181243896, "rollout_time": 0.4331846237182617, "train_time": 0.7817256450653076, "student_train_time": 0.009653091430664062, "throughput": 1632.696086932235, "inference_time": 0.05373995049012592, "env_time": 0.3794446732281358, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 391, "reward_mean": 38.24, "student_loss": null, "teacher_policy_loss": -20.32510757446289, "teacher_value_loss": 112.00086975097656, "teacher_entropy": 0.5879269242286682, "total_time": 1.1928794384002686, "rollout_time": 0.427112340927124, "train_time": 0.7553822994232178, "student_train_time": 0.010027170181274414, "throughput": 1676.6153691794154, "inference_time": 0.0558039197785547, "env_time": 0.3713084211485693, "samples": 2000, "teacher_eval_reward": 73.0}
{"epoch": 392, "reward_mean": 36.44827586206897, "student_loss": null, "teacher_policy_loss": -17.920547485351562, "teacher_value_loss": 105.5161361694336, "teacher_entropy": 0.5804242491722107, "total_time": 1.2518467903137207, "rollout_time": 0.4320223331451416, "train_time": 0.8064072132110596, "student_train_time": 0.013066291809082031, "throughput": 1597.6395957358227, "inference_time": 0.052195914035110036, "env_time": 0.37982641911003157, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 393, "reward_mean": 41.333333333333336, "student_loss": null, "teacher_policy_loss": -21.75511360168457, "teacher_value_loss": 172.60986328125, "teacher_entropy": 0.5944249033927917, "total_time": 1.2467172145843506, "rollout_time": 0.44638729095458984, "train_time": 0.7887966632843018, "student_train_time": 0.011144638061523438, "throughput": 1604.2130297100214, "inference_time": 0.057520549515174935, "env_time": 0.3888667414394149, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 394, "reward_mean": 39.83673469387755, "student_loss": null, "teacher_policy_loss": -20.60899543762207, "teacher_value_loss": 120.00205993652344, "teacher_entropy": 0.6003487706184387, "total_time": 1.1899535655975342, "rollout_time": 0.4355204105377197, "train_time": 0.7477545738220215, "student_train_time": 0.006259918212890625, "throughput": 1680.7378521494675, "inference_time": 0.05276423921895912, "env_time": 0.3827561713187606, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 395, "reward_mean": 35.327586206896555, "student_loss": null, "teacher_policy_loss": -18.40712547302246, "teacher_value_loss": 92.8837661743164, "teacher_entropy": 0.5953028798103333, "total_time": 1.18731689453125, "rollout_time": 0.42934346199035645, "train_time": 0.7452137470245361, "student_train_time": 0.012394905090332031, "throughput": 1684.4702616562997, "inference_time": 0.05394981743847893, "env_time": 0.3753936445518775, "samples": 2000, "teacher_eval_reward": 259.0}
{"epoch": 396, "reward_mean": 38.88235294117647, "student_loss": null, "teacher_policy_loss": -20.026498794555664, "teacher_value_loss": 101.3883285522461, "teacher_entropy": 0.598554790019989, "total_time": 1.3693435192108154, "rollout_time": 0.4584238529205322, "train_time": 0.9031074047088623, "student_train_time": 0.007460117340087891, "throughput": 1460.5538872763254, "inference_time": 0.055581608508873614, "env_time": 0.4028422444116586, "samples": 2000, "teacher_eval_reward": 143.0}
{"epoch": 397, "reward_mean": 38.94117647058823, "student_loss": null, "teacher_policy_loss": -20.728151321411133, "teacher_value_loss": 97.8026351928711, "teacher_entropy": 0.5983679294586182, "total_time": 1.181169033050537, "rollout_time": 0.42339253425598145, "train_time": 0.7490320205688477, "student_train_time": 0.008380889892578125, "throughput": 1693.2377534777688, "inference_time": 0.05347180221542658, "env_time": 0.36992073204055487, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 398, "reward_mean": 43.73913043478261, "student_loss": null, "teacher_policy_loss": -21.6774959564209, "teacher_value_loss": 112.93550872802734, "teacher_entropy": 0.5953667759895325, "total_time": 1.5148813724517822, "rollout_time": 0.44672489166259766, "train_time": 1.0576343536376953, "student_train_time": 0.01012563705444336, "throughput": 1320.2353902887262, "inference_time": 0.05615155623854662, "env_time": 0.39057333542405104, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 399, "reward_mean": 38.22222222222222, "student_loss": null, "teacher_policy_loss": -19.857513427734375, "teacher_value_loss": 125.96044158935547, "teacher_entropy": 0.58259117603302, "total_time": 1.1699156761169434, "rollout_time": 0.41957592964172363, "train_time": 0.7452690601348877, "student_train_time": 0.004656076431274414, "throughput": 1709.5249177600406, "inference_time": 0.05343566229748831, "env_time": 0.3661402673442353, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 400, "reward_mean": 43.79545454545455, "student_loss": null, "teacher_policy_loss": -22.79829216003418, "teacher_value_loss": 149.0501708984375, "teacher_entropy": 0.5831430554389954, "total_time": 1.1953442096710205, "rollout_time": 0.4269862174987793, "train_time": 0.7595694065093994, "student_train_time": 0.008385896682739258, "throughput": 1673.1582282482757, "inference_time": 0.05288014845791622, "env_time": 0.3741060690408631, "samples": 2000, "teacher_eval_reward": 236.0}
{"epoch": 401, "reward_mean": 38.36, "student_loss": null, "teacher_policy_loss": -20.324190139770508, "teacher_value_loss": 123.4099349975586, "teacher_entropy": 0.5840268135070801, "total_time": 1.2336061000823975, "rollout_time": 0.428041934967041, "train_time": 0.7975308895111084, "student_train_time": 0.007631778717041016, "throughput": 1621.2630594696411, "inference_time": 0.05440149820424267, "env_time": 0.37364043676279834, "samples": 2000, "teacher_eval_reward": 457.0}
{"epoch": 402, "reward_mean": 39.16981132075472, "student_loss": null, "teacher_policy_loss": -19.381072998046875, "teacher_value_loss": 100.51437377929688, "teacher_entropy": 0.5848679542541504, "total_time": 1.2242767810821533, "rollout_time": 0.4371955394744873, "train_time": 0.7785160541534424, "student_train_time": 0.008217096328735352, "throughput": 1633.6175208943973, "inference_time": 0.05530069629458012, "env_time": 0.3818948431799072, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 403, "reward_mean": 40.86274509803921, "student_loss": null, "teacher_policy_loss": -21.205833435058594, "teacher_value_loss": 112.6299057006836, "teacher_entropy": 0.5954803228378296, "total_time": 1.1386091709136963, "rollout_time": 0.4182901382446289, "train_time": 0.7152307033538818, "student_train_time": 0.004742622375488281, "throughput": 1756.5289750784864, "inference_time": 0.04991545550547016, "env_time": 0.36837468273915874, "samples": 2000, "teacher_eval_reward": 178.0}
{"epoch": 404, "reward_mean": 34.3448275862069, "student_loss": null, "teacher_policy_loss": -19.494266510009766, "teacher_value_loss": 116.25926971435547, "teacher_entropy": 0.5794396996498108, "total_time": 1.167604923248291, "rollout_time": 0.44091320037841797, "train_time": 0.7130758762359619, "student_train_time": 0.013262033462524414, "throughput": 1712.9081594106128, "inference_time": 0.056376816995907575, "env_time": 0.3845363833825104, "samples": 2000, "teacher_eval_reward": 402.0}
{"epoch": 405, "reward_mean": 40.14, "student_loss": null, "teacher_policy_loss": -21.37834358215332, "teacher_value_loss": 140.60243225097656, "teacher_entropy": 0.5861926674842834, "total_time": 1.2057082653045654, "rollout_time": 0.43826913833618164, "train_time": 0.7570128440856934, "student_train_time": 0.010050773620605469, "throughput": 1658.776055163555, "inference_time": 0.054733599308747216, "env_time": 0.3835355390274344, "samples": 2000, "teacher_eval_reward": 112.0}
{"epoch": 406, "reward_mean": 43.355555555555554, "student_loss": null, "teacher_policy_loss": -22.268741607666016, "teacher_value_loss": 151.4261474609375, "teacher_entropy": 0.5937960147857666, "total_time": 1.239516258239746, "rollout_time": 0.44049763679504395, "train_time": 0.7920041084289551, "student_train_time": 0.006659507751464844, "throughput": 1613.53268801833, "inference_time": 0.05515499121611356, "env_time": 0.3853426455789304, "samples": 2000, "teacher_eval_reward": 388.0}
{"epoch": 407, "reward_mean": 42.31818181818182, "student_loss": null, "teacher_policy_loss": -22.378355026245117, "teacher_value_loss": 153.89877319335938, "teacher_entropy": 0.5879296660423279, "total_time": 1.1715824604034424, "rollout_time": 0.4283463954925537, "train_time": 0.7336905002593994, "student_train_time": 0.009145736694335938, "throughput": 1707.0928147142852, "inference_time": 0.05384525376393867, "env_time": 0.37450114172861504, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 408, "reward_mean": 46.630434782608695, "student_loss": null, "teacher_policy_loss": -22.79193687438965, "teacher_value_loss": 177.19776916503906, "teacher_entropy": 0.5918862223625183, "total_time": 1.2554388046264648, "rollout_time": 0.4792954921722412, "train_time": 0.7689995765686035, "student_train_time": 0.006505727767944336, "throughput": 1593.0684893837315, "inference_time": 0.06251901504765556, "env_time": 0.41677647712458565, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 409, "reward_mean": 43.43478260869565, "student_loss": null, "teacher_policy_loss": -23.12405014038086, "teacher_value_loss": 175.12242126464844, "teacher_entropy": 0.5826686024665833, "total_time": 1.202345609664917, "rollout_time": 0.42592811584472656, "train_time": 0.7715139389038086, "student_train_time": 0.004521608352661133, "throughput": 1663.4152309645663, "inference_time": 0.0534663542657654, "env_time": 0.37246176157896116, "samples": 2000, "teacher_eval_reward": 370.0}
{"epoch": 410, "reward_mean": 37.96078431372549, "student_loss": null, "teacher_policy_loss": -19.75349235534668, "teacher_value_loss": 141.21018981933594, "teacher_entropy": 0.5801237225532532, "total_time": 1.247093677520752, "rollout_time": 0.4391453266143799, "train_time": 0.8026852607727051, "student_train_time": 0.004909038543701172, "throughput": 1603.7287623621357, "inference_time": 0.05578323321969947, "env_time": 0.3833620933946804, "samples": 2000, "teacher_eval_reward": 385.0}
{"epoch": 411, "reward_mean": 41.5625, "student_loss": null, "teacher_policy_loss": -22.21566390991211, "teacher_value_loss": 159.50384521484375, "teacher_entropy": 0.5882458686828613, "total_time": 1.1910960674285889, "rollout_time": 0.4361121654510498, "train_time": 0.7484686374664307, "student_train_time": 0.006165504455566406, "throughput": 1679.1256848977114, "inference_time": 0.05299778851076553, "env_time": 0.3831143769402843, "samples": 2000, "teacher_eval_reward": 165.0}
{"epoch": 412, "reward_mean": 37.14545454545455, "student_loss": null, "teacher_policy_loss": -18.250606536865234, "teacher_value_loss": 121.568115234375, "teacher_entropy": 0.5796694159507751, "total_time": 1.2460744380950928, "rollout_time": 0.47432899475097656, "train_time": 0.7644381523132324, "student_train_time": 0.006880760192871094, "throughput": 1605.0405488274466, "inference_time": 0.059043363256932935, "env_time": 0.4152856314940436, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 413, "reward_mean": 39.42, "student_loss": null, "teacher_policy_loss": -20.603199005126953, "teacher_value_loss": 118.41448211669922, "teacher_entropy": 0.595626711845398, "total_time": 1.2359981536865234, "rollout_time": 0.4267542362213135, "train_time": 0.8003616333007812, "student_train_time": 0.008524417877197266, "throughput": 1618.1253944714583, "inference_time": 0.05554998231855279, "env_time": 0.3712042539027607, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 414, "reward_mean": 36.392857142857146, "student_loss": null, "teacher_policy_loss": -18.3173770904541, "teacher_value_loss": 106.42790985107422, "teacher_entropy": 0.59272700548172, "total_time": 1.8202993869781494, "rollout_time": 0.48207950592041016, "train_time": 1.1968860626220703, "student_train_time": 0.140946626663208, "throughput": 1098.7203612259457, "inference_time": 0.06202596526236448, "env_time": 0.4200535406580457, "samples": 2000, "teacher_eval_reward": 162.0}
{"epoch": 415, "reward_mean": 39.32, "student_loss": null, "teacher_policy_loss": -19.00138282775879, "teacher_value_loss": 77.10787963867188, "teacher_entropy": 0.6032018065452576, "total_time": 2.418558120727539, "rollout_time": 0.4756138324737549, "train_time": 1.9255928993225098, "student_train_time": 0.016989707946777344, "throughput": 826.9389860262567, "inference_time": 0.062367951970372815, "env_time": 0.41324588050338207, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 416, "reward_mean": 40.431372549019606, "student_loss": null, "teacher_policy_loss": -20.926401138305664, "teacher_value_loss": 145.35838317871094, "teacher_entropy": 0.6045873165130615, "total_time": 1.2387735843658447, "rollout_time": 0.4453089237213135, "train_time": 0.7876367568969727, "student_train_time": 0.0054700374603271484, "throughput": 1614.5000387813757, "inference_time": 0.0542031484983454, "env_time": 0.3911057752229681, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 417, "reward_mean": 35.61818181818182, "student_loss": null, "teacher_policy_loss": -19.473859786987305, "teacher_value_loss": 127.2927017211914, "teacher_entropy": 0.5996097922325134, "total_time": 1.303802728652954, "rollout_time": 0.44573473930358887, "train_time": 0.8525803089141846, "student_train_time": 0.0051250457763671875, "throughput": 1533.9743935544097, "inference_time": 0.05613793283555424, "env_time": 0.38959680646803463, "samples": 2000, "teacher_eval_reward": 167.0}
{"epoch": 418, "reward_mean": 38.129629629629626, "student_loss": null, "teacher_policy_loss": -19.364330291748047, "teacher_value_loss": 95.60318756103516, "teacher_entropy": 0.6042569875717163, "total_time": 1.367788314819336, "rollout_time": 0.4579811096191406, "train_time": 0.9003264904022217, "student_train_time": 0.009061098098754883, "throughput": 1462.2145680957726, "inference_time": 0.05890724752134702, "env_time": 0.3990738620977936, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 419, "reward_mean": 39.229166666666664, "student_loss": null, "teacher_policy_loss": -21.812925338745117, "teacher_value_loss": 175.14639282226562, "teacher_entropy": 0.600311815738678, "total_time": 1.2793796062469482, "rollout_time": 0.44895267486572266, "train_time": 0.8233113288879395, "student_train_time": 0.0067555904388427734, "throughput": 1563.257683829264, "inference_time": 0.05614164223152329, "env_time": 0.39281103263419936, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 420, "reward_mean": 42.224489795918366, "student_loss": null, "teacher_policy_loss": -21.119152069091797, "teacher_value_loss": 135.91819763183594, "teacher_entropy": 0.5988385677337646, "total_time": 1.4753730297088623, "rollout_time": 0.570486307144165, "train_time": 0.8571619987487793, "student_train_time": 0.047327518463134766, "throughput": 1355.5893728074066, "inference_time": 0.06092623401127639, "env_time": 0.5095600731328886, "samples": 2000, "teacher_eval_reward": 111.0}
{"epoch": 421, "reward_mean": 45.65909090909091, "student_loss": null, "teacher_policy_loss": -22.69628143310547, "teacher_value_loss": 153.03253173828125, "teacher_entropy": 0.6031954288482666, "total_time": 1.2670717239379883, "rollout_time": 0.4514791965484619, "train_time": 0.8094131946563721, "student_train_time": 0.005753993988037109, "throughput": 1578.4426107972101, "inference_time": 0.05327767971721187, "env_time": 0.39820151683125005, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 422, "reward_mean": 41.395833333333336, "student_loss": null, "teacher_policy_loss": -21.260099411010742, "teacher_value_loss": 137.86105346679688, "teacher_entropy": 0.5952346324920654, "total_time": 1.3125293254852295, "rollout_time": 0.4639010429382324, "train_time": 0.8407397270202637, "student_train_time": 0.0075299739837646484, "throughput": 1523.775477748369, "inference_time": 0.0620028517460014, "env_time": 0.401898191192231, "samples": 2000, "teacher_eval_reward": 174.0}
{"epoch": 423, "reward_mean": 43.765957446808514, "student_loss": null, "teacher_policy_loss": -21.879230499267578, "teacher_value_loss": 138.11082458496094, "teacher_entropy": 0.5920241475105286, "total_time": 1.2705309391021729, "rollout_time": 0.4391357898712158, "train_time": 0.8250710964202881, "student_train_time": 0.0059697628021240234, "throughput": 1574.145058925767, "inference_time": 0.054137191213158076, "env_time": 0.38499859865805774, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 424, "reward_mean": 46.214285714285715, "student_loss": null, "teacher_policy_loss": -23.2651309967041, "teacher_value_loss": 143.00192260742188, "teacher_entropy": 0.6006082892417908, "total_time": 1.2126595973968506, "rollout_time": 0.4505155086517334, "train_time": 0.7530429363250732, "student_train_time": 0.008738517761230469, "throughput": 1649.2674484193994, "inference_time": 0.0577755799768056, "env_time": 0.3927399286749278, "samples": 2000, "teacher_eval_reward": 90.0}
{"epoch": 425, "reward_mean": 39.16326530612245, "student_loss": null, "teacher_policy_loss": -20.778705596923828, "teacher_value_loss": 144.9980010986328, "teacher_entropy": 0.5857784152030945, "total_time": 1.2856676578521729, "rollout_time": 0.4617462158203125, "train_time": 0.8189852237701416, "student_train_time": 0.0045621395111083984, "throughput": 1555.6119715581751, "inference_time": 0.05506008319935063, "env_time": 0.40668613262096187, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 426, "reward_mean": 40.11764705882353, "student_loss": null, "teacher_policy_loss": -20.19317626953125, "teacher_value_loss": 111.42449188232422, "teacher_entropy": 0.5900293588638306, "total_time": 1.2106328010559082, "rollout_time": 0.4595201015472412, "train_time": 0.7415721416473389, "student_train_time": 0.009180784225463867, "throughput": 1652.0285905483559, "inference_time": 0.05914664873307629, "env_time": 0.4003734528141649, "samples": 2000, "teacher_eval_reward": 205.0}
{"epoch": 427, "reward_mean": 46.666666666666664, "student_loss": null, "teacher_policy_loss": -22.480684280395508, "teacher_value_loss": 117.21126556396484, "teacher_entropy": 0.5934064984321594, "total_time": 1.3443665504455566, "rollout_time": 0.44285011291503906, "train_time": 0.8909332752227783, "student_train_time": 0.010227680206298828, "throughput": 1487.6894990708822, "inference_time": 0.05449420127843041, "env_time": 0.38835591163660865, "samples": 2000, "teacher_eval_reward": 182.0}
{"epoch": 428, "reward_mean": 41.42307692307692, "student_loss": null, "teacher_policy_loss": -19.869966506958008, "teacher_value_loss": 101.71050262451172, "teacher_entropy": 0.586427628993988, "total_time": 1.208648443222046, "rollout_time": 0.4258544445037842, "train_time": 0.7749695777893066, "student_train_time": 0.007418394088745117, "throughput": 1654.740889475147, "inference_time": 0.055247456972210784, "env_time": 0.3706069875315734, "samples": 2000, "teacher_eval_reward": 135.0}
{"epoch": 429, "reward_mean": 38.64, "student_loss": null, "teacher_policy_loss": -19.338714599609375, "teacher_value_loss": 86.04165649414062, "teacher_entropy": 0.5886144042015076, "total_time": 1.3438560962677002, "rollout_time": 0.45538878440856934, "train_time": 0.8742289543151855, "student_train_time": 0.013870954513549805, "throughput": 1488.25458734355, "inference_time": 0.05411008598275657, "env_time": 0.40127869842581276, "samples": 2000, "teacher_eval_reward": 114.0}
{"epoch": 430, "reward_mean": 38.82692307692308, "student_loss": null, "teacher_policy_loss": -20.538965225219727, "teacher_value_loss": 121.52867889404297, "teacher_entropy": 0.5890303254127502, "total_time": 1.2478609085083008, "rollout_time": 0.43787479400634766, "train_time": 0.8037900924682617, "student_train_time": 0.005726814270019531, "throughput": 1602.7427306708487, "inference_time": 0.05613036426802864, "env_time": 0.381744429738319, "samples": 2000, "teacher_eval_reward": 135.0}
{"epoch": 431, "reward_mean": 41.291666666666664, "student_loss": null, "teacher_policy_loss": -21.20901107788086, "teacher_value_loss": 119.4791259765625, "teacher_entropy": 0.5914955735206604, "total_time": 1.2741138935089111, "rollout_time": 0.44274425506591797, "train_time": 0.8226490020751953, "student_train_time": 0.008356571197509766, "throughput": 1569.7183824689312, "inference_time": 0.05580343500332674, "env_time": 0.38694082006259123, "samples": 2000, "teacher_eval_reward": 136.0}
{"epoch": 432, "reward_mean": 38.3, "student_loss": null, "teacher_policy_loss": -20.769105911254883, "teacher_value_loss": 120.45030212402344, "teacher_entropy": 0.5807121992111206, "total_time": 1.404860258102417, "rollout_time": 0.46591758728027344, "train_time": 0.9314746856689453, "student_train_time": 0.007033586502075195, "throughput": 1423.6291392436815, "inference_time": 0.06267599978673388, "env_time": 0.40324158749353955, "samples": 2000, "teacher_eval_reward": 118.0}
{"epoch": 433, "reward_mean": 47.25, "student_loss": null, "teacher_policy_loss": -22.529193878173828, "teacher_value_loss": 190.09808349609375, "teacher_entropy": 0.5903646945953369, "total_time": 1.4293029308319092, "rollout_time": 0.43305444717407227, "train_time": 0.988532543182373, "student_train_time": 0.00734400749206543, "throughput": 1399.2834946724158, "inference_time": 0.05570037502366176, "env_time": 0.3773540721504105, "samples": 2000, "teacher_eval_reward": 163.0}
{"epoch": 434, "reward_mean": 39.8, "student_loss": null, "teacher_policy_loss": -20.196231842041016, "teacher_value_loss": 96.52626037597656, "teacher_entropy": 0.5860563516616821, "total_time": 1.3214516639709473, "rollout_time": 0.4421083927154541, "train_time": 0.86783766746521, "student_train_time": 0.011138677597045898, "throughput": 1513.4870646649479, "inference_time": 0.055474808479630155, "env_time": 0.38663358423582395, "samples": 2000, "teacher_eval_reward": 156.0}
{"epoch": 435, "reward_mean": 38.72549019607843, "student_loss": null, "teacher_policy_loss": -19.65144157409668, "teacher_value_loss": 87.23673248291016, "teacher_entropy": 0.5837950706481934, "total_time": 1.2453813552856445, "rollout_time": 0.4388563632965088, "train_time": 0.7938580513000488, "student_train_time": 0.01201772689819336, "throughput": 1605.9337900889593, "inference_time": 0.05822161224023148, "env_time": 0.3806347510562773, "samples": 2000, "teacher_eval_reward": 325.0}
{"epoch": 436, "reward_mean": 42.08510638297872, "student_loss": null, "teacher_policy_loss": -21.368003845214844, "teacher_value_loss": 110.28411102294922, "teacher_entropy": 0.5876517295837402, "total_time": 1.2114002704620361, "rollout_time": 0.4287753105163574, "train_time": 0.7746944427490234, "student_train_time": 0.007573604583740234, "throughput": 1650.9819658841473, "inference_time": 0.0546280037942779, "env_time": 0.3741473067220795, "samples": 2000, "teacher_eval_reward": 166.0}
{"epoch": 437, "reward_mean": 36.464285714285715, "student_loss": null, "teacher_policy_loss": -18.498537063598633, "teacher_value_loss": 104.86070251464844, "teacher_entropy": 0.573253870010376, "total_time": 1.2530009746551514, "rollout_time": 0.4405219554901123, "train_time": 0.8064627647399902, "student_train_time": 0.005663871765136719, "throughput": 1596.1679523437213, "inference_time": 0.056886928256062674, "env_time": 0.38363502723404963, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 438, "reward_mean": 46.80952380952381, "student_loss": null, "teacher_policy_loss": -22.910404205322266, "teacher_value_loss": 122.28960418701172, "teacher_entropy": 0.5847945809364319, "total_time": 1.3086223602294922, "rollout_time": 0.4449026584625244, "train_time": 0.85595703125, "student_train_time": 0.006712436676025391, "throughput": 1528.3247946712918, "inference_time": 0.05520690226694569, "env_time": 0.3896957561955787, "samples": 2000, "teacher_eval_reward": 127.0}
{"epoch": 439, "reward_mean": 44.84090909090909, "student_loss": null, "teacher_policy_loss": -21.125051498413086, "teacher_value_loss": 90.0394515991211, "teacher_entropy": 0.5805449485778809, "total_time": 1.2693727016448975, "rollout_time": 0.42711782455444336, "train_time": 0.827094554901123, "student_train_time": 0.01475214958190918, "throughput": 1575.5813855208405, "inference_time": 0.054906951232624124, "env_time": 0.37221087332181924, "samples": 2000, "teacher_eval_reward": 66.0}
{"epoch": 440, "reward_mean": 40.09615384615385, "student_loss": null, "teacher_policy_loss": -18.860429763793945, "teacher_value_loss": 93.44538879394531, "teacher_entropy": 0.5695973038673401, "total_time": 1.2435767650604248, "rollout_time": 0.4387941360473633, "train_time": 0.7961039543151855, "student_train_time": 0.008327245712280273, "throughput": 1608.264207077575, "inference_time": 0.05536660924553871, "env_time": 0.38342752680182457, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 441, "reward_mean": 41.47826086956522, "student_loss": null, "teacher_policy_loss": -21.695133209228516, "teacher_value_loss": 131.3262939453125, "teacher_entropy": 0.575590968132019, "total_time": 1.2275292873382568, "rollout_time": 0.4232051372528076, "train_time": 0.7883162498474121, "student_train_time": 0.015654802322387695, "throughput": 1629.2890284815517, "inference_time": 0.0556925634828076, "env_time": 0.36751257377, "samples": 2000, "teacher_eval_reward": 214.0}
{"epoch": 442, "reward_mean": 48.95454545454545, "student_loss": null, "teacher_policy_loss": -22.676136016845703, "teacher_value_loss": 134.82057189941406, "teacher_entropy": 0.5882678031921387, "total_time": 1.2777621746063232, "rollout_time": 0.47299671173095703, "train_time": 0.7896788120269775, "student_train_time": 0.014734029769897461, "throughput": 1565.2365046853865, "inference_time": 0.0623160774975986, "env_time": 0.41068063423335843, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 443, "reward_mean": 44.61363636363637, "student_loss": null, "teacher_policy_loss": -23.412473678588867, "teacher_value_loss": 172.4818572998047, "teacher_entropy": 0.5818910598754883, "total_time": 1.1796321868896484, "rollout_time": 0.4309077262878418, "train_time": 0.741466760635376, "student_train_time": 0.006902217864990234, "throughput": 1695.4437342655308, "inference_time": 0.05169552777988429, "env_time": 0.3792121985079575, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 444, "reward_mean": 40.42857142857143, "student_loss": null, "teacher_policy_loss": -20.665157318115234, "teacher_value_loss": 129.0212860107422, "teacher_entropy": 0.5807229280471802, "total_time": 1.2046892642974854, "rollout_time": 0.4350106716156006, "train_time": 0.7616579532623291, "student_train_time": 0.0076563358306884766, "throughput": 1660.1791509832208, "inference_time": 0.056202581256002304, "env_time": 0.3788080903595983, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 445, "reward_mean": 39.96, "student_loss": null, "teacher_policy_loss": -21.18075942993164, "teacher_value_loss": 152.966064453125, "teacher_entropy": 0.5744699835777283, "total_time": 1.335676908493042, "rollout_time": 0.42987847328186035, "train_time": 0.8970146179199219, "student_train_time": 0.00834035873413086, "throughput": 1497.3681039799294, "inference_time": 0.054269761758405366, "env_time": 0.375608711523455, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 446, "reward_mean": 42.43478260869565, "student_loss": null, "teacher_policy_loss": -21.380144119262695, "teacher_value_loss": 119.72457885742188, "teacher_entropy": 0.5851269364356995, "total_time": 1.4039194583892822, "rollout_time": 0.43539977073669434, "train_time": 0.9556055068969727, "student_train_time": 0.01244664192199707, "throughput": 1424.583146881233, "inference_time": 0.05493929426120303, "env_time": 0.3804604764754913, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 447, "reward_mean": 43.82608695652174, "student_loss": null, "teacher_policy_loss": -20.992361068725586, "teacher_value_loss": 102.95299530029297, "teacher_entropy": 0.5812557339668274, "total_time": 1.2207450866699219, "rollout_time": 0.43204808235168457, "train_time": 0.7734591960906982, "student_train_time": 0.014505624771118164, "throughput": 1638.3436819359335, "inference_time": 0.05593832698832557, "env_time": 0.376109755363359, "samples": 2000, "teacher_eval_reward": 179.0}
{"epoch": 448, "reward_mean": 43.78260869565217, "student_loss": null, "teacher_policy_loss": -20.91236686706543, "teacher_value_loss": 103.74447631835938, "teacher_entropy": 0.5842307209968567, "total_time": 1.1895925998687744, "rollout_time": 0.4293944835662842, "train_time": 0.7523133754730225, "student_train_time": 0.00751948356628418, "throughput": 1681.247849238994, "inference_time": 0.0556227143133583, "env_time": 0.3737717692529259, "samples": 2000, "teacher_eval_reward": 177.0}
{"epoch": 449, "reward_mean": 46.42857142857143, "student_loss": null, "teacher_policy_loss": -24.295000076293945, "teacher_value_loss": 162.5941162109375, "teacher_entropy": 0.5848901271820068, "total_time": 1.4320542812347412, "rollout_time": 0.4235234260559082, "train_time": 0.9991645812988281, "student_train_time": 0.009008169174194336, "throughput": 1396.5951055120386, "inference_time": 0.054280621492580394, "env_time": 0.3692428045633278, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 450, "reward_mean": 41.47826086956522, "student_loss": null, "teacher_policy_loss": -22.705156326293945, "teacher_value_loss": 158.02444458007812, "teacher_entropy": 0.5741255879402161, "total_time": 1.2805685997009277, "rollout_time": 0.43804454803466797, "train_time": 0.8292267322540283, "student_train_time": 0.012858152389526367, "throughput": 1561.8062167595651, "inference_time": 0.05791882249468472, "env_time": 0.38012572553998325, "samples": 2000, "teacher_eval_reward": 191.0}
{"epoch": 451, "reward_mean": 47.97727272727273, "student_loss": null, "teacher_policy_loss": -24.719741821289062, "teacher_value_loss": 196.11166381835938, "teacher_entropy": 0.5808115005493164, "total_time": 1.2737183570861816, "rollout_time": 0.4200599193572998, "train_time": 0.8445372581481934, "student_train_time": 0.008771181106567383, "throughput": 1570.2058377923472, "inference_time": 0.05454828074653051, "env_time": 0.3655116386107693, "samples": 2000, "teacher_eval_reward": 150.0}
{"epoch": 452, "reward_mean": 40.916666666666664, "student_loss": null, "teacher_policy_loss": -21.578462600708008, "teacher_value_loss": 101.11515045166016, "teacher_entropy": 0.5872145891189575, "total_time": 1.220536231994629, "rollout_time": 0.4320530891418457, "train_time": 0.7812187671661377, "student_train_time": 0.006902933120727539, "throughput": 1638.6240306291875, "inference_time": 0.05500959274286288, "env_time": 0.3770434963989828, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 453, "reward_mean": 41.09803921568628, "student_loss": null, "teacher_policy_loss": -19.41493797302246, "teacher_value_loss": 92.20235443115234, "teacher_entropy": 0.5786584615707397, "total_time": 1.2849786281585693, "rollout_time": 0.4429013729095459, "train_time": 0.8362271785736084, "student_train_time": 0.0054972171783447266, "throughput": 1556.4461199374869, "inference_time": 0.05666471418226138, "env_time": 0.3862366587272845, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 454, "reward_mean": 47.76190476190476, "student_loss": null, "teacher_policy_loss": -22.261253356933594, "teacher_value_loss": 110.94895935058594, "teacher_entropy": 0.5911805629730225, "total_time": 1.2332258224487305, "rollout_time": 0.43549180030822754, "train_time": 0.7878074645996094, "student_train_time": 0.009521722793579102, "throughput": 1621.7629923031773, "inference_time": 0.0558672929637396, "env_time": 0.37962450734448794, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 455, "reward_mean": 38.88461538461539, "student_loss": null, "teacher_policy_loss": -22.261919021606445, "teacher_value_loss": 168.181640625, "teacher_entropy": 0.573371946811676, "total_time": 1.2858514785766602, "rollout_time": 0.44150233268737793, "train_time": 0.8385167121887207, "student_train_time": 0.005476713180541992, "throughput": 1555.3895868392576, "inference_time": 0.05648815497443138, "env_time": 0.38501417771294655, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 456, "reward_mean": 39.7, "student_loss": null, "teacher_policy_loss": -20.384435653686523, "teacher_value_loss": 111.5210952758789, "teacher_entropy": 0.585049569606781, "total_time": 1.3287615776062012, "rollout_time": 0.4533982276916504, "train_time": 0.8701350688934326, "student_train_time": 0.004818439483642578, "throughput": 1505.160921045785, "inference_time": 0.05740690554557659, "env_time": 0.3959913221460738, "samples": 2000, "teacher_eval_reward": 188.0}
{"epoch": 457, "reward_mean": 44.0, "student_loss": null, "teacher_policy_loss": -21.981351852416992, "teacher_value_loss": 126.56610870361328, "teacher_entropy": 0.5800143480300903, "total_time": 1.243689775466919, "rollout_time": 0.4535238742828369, "train_time": 0.7748534679412842, "student_train_time": 0.014903068542480469, "throughput": 1608.1180688722309, "inference_time": 0.05602329502835346, "env_time": 0.39750057925448345, "samples": 2000, "teacher_eval_reward": 133.0}
{"epoch": 458, "reward_mean": 42.48936170212766, "student_loss": null, "teacher_policy_loss": -21.626251220703125, "teacher_value_loss": 118.13136291503906, "teacher_entropy": 0.572753369808197, "total_time": 1.2855453491210938, "rollout_time": 0.46056222915649414, "train_time": 0.8170006275177002, "student_train_time": 0.007569789886474609, "throughput": 1555.7599748366458, "inference_time": 0.05729047749264282, "env_time": 0.4032717516638513, "samples": 2000, "teacher_eval_reward": 106.0}
{"epoch": 459, "reward_mean": 45.77777777777778, "student_loss": null, "teacher_policy_loss": -24.073471069335938, "teacher_value_loss": 186.04693603515625, "teacher_entropy": 0.576195240020752, "total_time": 1.2488787174224854, "rollout_time": 0.432222843170166, "train_time": 0.8089923858642578, "student_train_time": 0.007306575775146484, "throughput": 1601.4365303043405, "inference_time": 0.05469443853144185, "env_time": 0.37752840463872417, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 460, "reward_mean": 42.891304347826086, "student_loss": null, "teacher_policy_loss": -22.929000854492188, "teacher_value_loss": 170.60357666015625, "teacher_entropy": 0.567389726638794, "total_time": 1.2504620552062988, "rollout_time": 0.44120097160339355, "train_time": 0.7999193668365479, "student_train_time": 0.008919715881347656, "throughput": 1599.4087878740502, "inference_time": 0.053365400732218404, "env_time": 0.38783557087117515, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 461, "reward_mean": 38.53191489361702, "student_loss": null, "teacher_policy_loss": -23.72039031982422, "teacher_value_loss": 202.73934936523438, "teacher_entropy": 0.5655972361564636, "total_time": 1.2832648754119873, "rollout_time": 0.4266815185546875, "train_time": 0.8489444255828857, "student_train_time": 0.007254838943481445, "throughput": 1558.5246961255039, "inference_time": 0.05314942904624331, "env_time": 0.3735320895084442, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 462, "reward_mean": 51.642857142857146, "student_loss": null, "teacher_policy_loss": -25.698501586914062, "teacher_value_loss": 259.7082214355469, "teacher_entropy": 0.570448637008667, "total_time": 1.39255690574646, "rollout_time": 0.4163661003112793, "train_time": 0.9678483009338379, "student_train_time": 0.007947444915771484, "throughput": 1436.2070172837418, "inference_time": 0.051617420480397413, "env_time": 0.3647486798308819, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 463, "reward_mean": 40.6, "student_loss": null, "teacher_policy_loss": -21.866382598876953, "teacher_value_loss": 179.94668579101562, "teacher_entropy": 0.5601335763931274, "total_time": 1.452049970626831, "rollout_time": 0.5976591110229492, "train_time": 0.8441934585571289, "student_train_time": 0.009788036346435547, "throughput": 1377.363066325208, "inference_time": 0.06834755402815063, "env_time": 0.5293115569947986, "samples": 2000, "teacher_eval_reward": 143.0}
{"epoch": 464, "reward_mean": 42.354166666666664, "student_loss": null, "teacher_policy_loss": -22.54535484313965, "teacher_value_loss": 142.36456298828125, "teacher_entropy": 0.5645656585693359, "total_time": 1.2786920070648193, "rollout_time": 0.4290921688079834, "train_time": 0.8440260887145996, "student_train_time": 0.004685401916503906, "throughput": 1564.0983043218603, "inference_time": 0.053081124990058015, "env_time": 0.3760110438179254, "samples": 2000, "teacher_eval_reward": 137.0}
{"epoch": 465, "reward_mean": 41.59574468085106, "student_loss": null, "teacher_policy_loss": -20.813444137573242, "teacher_value_loss": 100.17866516113281, "teacher_entropy": 0.5715091824531555, "total_time": 1.299332618713379, "rollout_time": 0.45131731033325195, "train_time": 0.8360354900360107, "student_train_time": 0.011617660522460938, "throughput": 1539.2517444689672, "inference_time": 0.05626572774235683, "env_time": 0.3950515825908951, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 466, "reward_mean": 46.5, "student_loss": null, "teacher_policy_loss": -24.322708129882812, "teacher_value_loss": 165.8228302001953, "teacher_entropy": 0.5753015279769897, "total_time": 1.220263957977295, "rollout_time": 0.4256289005279541, "train_time": 0.7844264507293701, "student_train_time": 0.009847402572631836, "throughput": 1638.9896521365695, "inference_time": 0.05357328574973508, "env_time": 0.372055614778219, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 467, "reward_mean": 40.666666666666664, "student_loss": null, "teacher_policy_loss": -22.152122497558594, "teacher_value_loss": 171.8465118408203, "teacher_entropy": 0.5695656538009644, "total_time": 1.2937593460083008, "rollout_time": 0.44948840141296387, "train_time": 0.8356289863586426, "student_train_time": 0.008174657821655273, "throughput": 1545.8825524010306, "inference_time": 0.05262997123281821, "env_time": 0.39685843018014566, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 468, "reward_mean": 46.857142857142854, "student_loss": null, "teacher_policy_loss": -23.35859489440918, "teacher_value_loss": 157.680419921875, "teacher_entropy": 0.579054057598114, "total_time": 1.2802786827087402, "rollout_time": 0.4319338798522949, "train_time": 0.8417654037475586, "student_train_time": 0.006222724914550781, "throughput": 1562.1598851966469, "inference_time": 0.05644849445525324, "env_time": 0.3754853853970417, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 469, "reward_mean": 42.680851063829785, "student_loss": null, "teacher_policy_loss": -22.312053680419922, "teacher_value_loss": 199.39501953125, "teacher_entropy": 0.5740811228752136, "total_time": 1.2428102493286133, "rollout_time": 0.4327206611633301, "train_time": 0.8001089096069336, "student_train_time": 0.009627342224121094, "throughput": 1609.2561202166085, "inference_time": 0.056682951289985795, "env_time": 0.3760377098733443, "samples": 2000, "teacher_eval_reward": 132.0}
{"epoch": 470, "reward_mean": 43.32608695652174, "student_loss": null, "teacher_policy_loss": -21.05430793762207, "teacher_value_loss": 104.14237213134766, "teacher_entropy": 0.5807366371154785, "total_time": -1.380338191986084, "rollout_time": 0.4350724220275879, "train_time": -1.824512243270874, "student_train_time": 0.008702754974365234, "throughput": 200000000000.0, "inference_time": 0.05493036229381687, "env_time": 0.380142059733771, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 471, "reward_mean": 41.775510204081634, "student_loss": null, "teacher_policy_loss": -20.152406692504883, "teacher_value_loss": 117.51762390136719, "teacher_entropy": 0.573524534702301, "total_time": 1.1782312393188477, "rollout_time": 0.43456339836120605, "train_time": 0.7376041412353516, "student_train_time": 0.005717277526855469, "throughput": 1697.4596609373798, "inference_time": 0.0547507789779047, "env_time": 0.37981261938330135, "samples": 2000, "teacher_eval_reward": 164.0}
{"epoch": 472, "reward_mean": 41.46808510638298, "student_loss": null, "teacher_policy_loss": -23.93511962890625, "teacher_value_loss": 217.77159118652344, "teacher_entropy": 0.582912266254425, "total_time": 1.4018948078155518, "rollout_time": 0.43901968002319336, "train_time": 0.9550180435180664, "student_train_time": 0.0074901580810546875, "throughput": 1426.6405645059936, "inference_time": 0.05744697326190362, "env_time": 0.38157270676128974, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 473, "reward_mean": 50.275, "student_loss": null, "teacher_policy_loss": -25.03974723815918, "teacher_value_loss": 187.7801513671875, "teacher_entropy": 0.57941073179245, "total_time": 1.315636396408081, "rollout_time": 0.4602785110473633, "train_time": 0.8404934406280518, "student_train_time": 0.014503002166748047, "throughput": 1520.1768554445225, "inference_time": 0.05897908920996997, "env_time": 0.4012994218373933, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 474, "reward_mean": 42.229166666666664, "student_loss": null, "teacher_policy_loss": -22.648324966430664, "teacher_value_loss": 132.1805877685547, "teacher_entropy": 0.5784751772880554, "total_time": 1.2345921993255615, "rollout_time": 0.4323558807373047, "train_time": 0.7932591438293457, "student_train_time": 0.00861668586730957, "throughput": 1619.9681166725084, "inference_time": 0.05536804445000598, "env_time": 0.3769878362872987, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 475, "reward_mean": 44.55555555555556, "student_loss": null, "teacher_policy_loss": -24.211862564086914, "teacher_value_loss": 199.04241943359375, "teacher_entropy": 0.578244149684906, "total_time": 1.3835699558258057, "rollout_time": 0.44948720932006836, "train_time": 0.924856424331665, "student_train_time": 0.00885915756225586, "throughput": 1445.5358701441794, "inference_time": 0.061216465448524104, "env_time": 0.38827074387154425, "samples": 2000, "teacher_eval_reward": 139.0}
{"epoch": 476, "reward_mean": 42.02173913043478, "student_loss": null, "teacher_policy_loss": -21.619911193847656, "teacher_value_loss": 144.41357421875, "teacher_entropy": 0.5747418403625488, "total_time": 1.41215181350708, "rollout_time": 0.4433770179748535, "train_time": 0.960716724395752, "student_train_time": 0.007699728012084961, "throughput": 1416.2783214029932, "inference_time": 0.054824899199957144, "env_time": 0.38855211877489637, "samples": 2000, "teacher_eval_reward": 123.0}
{"epoch": 477, "reward_mean": 46.93181818181818, "student_loss": null, "teacher_policy_loss": -22.834754943847656, "teacher_value_loss": 135.1346435546875, "teacher_entropy": 0.5796223878860474, "total_time": 1.2764124870300293, "rollout_time": 0.4395122528076172, "train_time": 0.8277740478515625, "student_train_time": 0.008770942687988281, "throughput": 1566.8915968172814, "inference_time": 0.056694081984460354, "env_time": 0.38281817082315683, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 478, "reward_mean": 45.333333333333336, "student_loss": null, "teacher_policy_loss": -23.882843017578125, "teacher_value_loss": 169.00408935546875, "teacher_entropy": 0.5757784247398376, "total_time": 1.2361750602722168, "rollout_time": 0.4370763301849365, "train_time": 0.7863137722015381, "student_train_time": 0.012411832809448242, "throughput": 1617.8938277233826, "inference_time": 0.053500539495871635, "env_time": 0.3835757906890649, "samples": 2000, "teacher_eval_reward": 119.0}
{"epoch": 479, "reward_mean": 40.02040816326531, "student_loss": null, "teacher_policy_loss": -19.88790512084961, "teacher_value_loss": 86.46118927001953, "teacher_entropy": 0.5639690160751343, "total_time": 1.3267745971679688, "rollout_time": 0.4534926414489746, "train_time": 0.856816291809082, "student_train_time": 0.01606011390686035, "throughput": 1507.4150532193235, "inference_time": 0.05671400430401263, "env_time": 0.396778637144962, "samples": 2000, "teacher_eval_reward": 92.0}
{"epoch": 480, "reward_mean": 41.06122448979592, "student_loss": null, "teacher_policy_loss": -19.825542449951172, "teacher_value_loss": 78.33492279052734, "teacher_entropy": 0.5651904344558716, "total_time": 1.2682111263275146, "rollout_time": 0.4545161724090576, "train_time": 0.8050947189331055, "student_train_time": 0.008168458938598633, "throughput": 1577.024486286916, "inference_time": 0.06026670293613279, "env_time": 0.39424946947292483, "samples": 2000, "teacher_eval_reward": 171.0}
{"epoch": 481, "reward_mean": 45.95348837209303, "student_loss": null, "teacher_policy_loss": -24.139789581298828, "teacher_value_loss": 186.9292755126953, "teacher_entropy": 0.5818386077880859, "total_time": 1.2542498111724854, "rollout_time": 0.43018102645874023, "train_time": 0.8158483505249023, "student_train_time": 0.007828950881958008, "throughput": 1594.5786733907337, "inference_time": 0.05468073644624383, "env_time": 0.3755002900124964, "samples": 2000, "teacher_eval_reward": 65.0}
{"epoch": 482, "reward_mean": 46.857142857142854, "student_loss": null, "teacher_policy_loss": -22.851444244384766, "teacher_value_loss": 151.06719970703125, "teacher_entropy": 0.5700919032096863, "total_time": 1.2858459949493408, "rollout_time": 0.4460334777832031, "train_time": 0.8305604457855225, "student_train_time": 0.008846759796142578, "throughput": 1555.3962199639584, "inference_time": 0.05599366803471639, "env_time": 0.39003980974848673, "samples": 2000, "teacher_eval_reward": 63.0}
{"epoch": 483, "reward_mean": 49.285714285714285, "student_loss": null, "teacher_policy_loss": -22.821203231811523, "teacher_value_loss": 151.15139770507812, "teacher_entropy": 0.5758379101753235, "total_time": -1.4031553268432617, "rollout_time": -2.1662650108337402, "train_time": 0.754084587097168, "student_train_time": 0.008634328842163086, "throughput": 200000000000.0, "inference_time": 0.05409807049363735, "env_time": 0.0, "samples": 2000, "teacher_eval_reward": 64.0}
{"epoch": 484, "reward_mean": 51.1025641025641, "student_loss": null, "teacher_policy_loss": -25.90321159362793, "teacher_value_loss": 245.89306640625, "teacher_entropy": 0.5731664896011353, "total_time": 1.2439956665039062, "rollout_time": 0.4299030303955078, "train_time": 0.803840160369873, "student_train_time": 0.009897470474243164, "throughput": 1607.7226423310212, "inference_time": 0.05362152752604743, "env_time": 0.3762815028694604, "samples": 2000, "teacher_eval_reward": 128.0}
{"epoch": 485, "reward_mean": 47.58536585365854, "student_loss": null, "teacher_policy_loss": -26.02174186706543, "teacher_value_loss": 246.69143676757812, "teacher_entropy": 0.5799353122711182, "total_time": 1.1815643310546875, "rollout_time": 0.4341580867767334, "train_time": 0.7400872707366943, "student_train_time": 0.006958723068237305, "throughput": 1692.6712726803125, "inference_time": 0.0544731815753039, "env_time": 0.3796849052014295, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 486, "reward_mean": 48.16279069767442, "student_loss": null, "teacher_policy_loss": -22.683961868286133, "teacher_value_loss": 144.09988403320312, "teacher_entropy": 0.5794908404350281, "total_time": 1.2508585453033447, "rollout_time": 0.4547257423400879, "train_time": 0.7906649112701416, "student_train_time": 0.005115032196044922, "throughput": 1598.901816284096, "inference_time": 0.055787059529393446, "env_time": 0.39893868281069444, "samples": 2000, "teacher_eval_reward": 216.0}
{"epoch": 487, "reward_mean": 45.58536585365854, "student_loss": null, "teacher_policy_loss": -24.090171813964844, "teacher_value_loss": 145.0703125, "teacher_entropy": 0.5874453783035278, "total_time": 1.231234073638916, "rollout_time": 0.44483423233032227, "train_time": 0.7806470394134521, "student_train_time": 0.005280971527099609, "throughput": 1624.3864938605816, "inference_time": 0.056136003013307345, "env_time": 0.3886982293170149, "samples": 2000, "teacher_eval_reward": 75.0}
{"epoch": 488, "reward_mean": 48.61904761904762, "student_loss": null, "teacher_policy_loss": -23.06348991394043, "teacher_value_loss": 145.66738891601562, "teacher_entropy": 0.5772222280502319, "total_time": 1.2493314743041992, "rollout_time": 0.44593214988708496, "train_time": 0.7961993217468262, "student_train_time": 0.006840944290161133, "throughput": 1600.8561707883625, "inference_time": 0.05493066524468304, "env_time": 0.3910014846424019, "samples": 2000, "teacher_eval_reward": 79.0}
{"epoch": 489, "reward_mean": 50.55, "student_loss": null, "teacher_policy_loss": -23.890331268310547, "teacher_value_loss": 152.46292114257812, "teacher_entropy": 0.5775691270828247, "total_time": 1.3395864963531494, "rollout_time": 0.4357490539550781, "train_time": 0.8982205390930176, "student_train_time": 0.005255937576293945, "throughput": 1492.9980299478539, "inference_time": 0.05466961696765793, "env_time": 0.3810794369874202, "samples": 2000, "teacher_eval_reward": 74.0}
{"epoch": 490, "reward_mean": 49.36585365853659, "student_loss": null, "teacher_policy_loss": -23.74203109741211, "teacher_value_loss": 160.23876953125, "teacher_entropy": 0.57292240858078, "total_time": 1.4179842472076416, "rollout_time": 0.42957544326782227, "train_time": 0.9835507869720459, "student_train_time": 0.004506587982177734, "throughput": 1410.4529044934668, "inference_time": 0.05619090001891891, "env_time": 0.37338454324890336, "samples": 2000, "teacher_eval_reward": 138.0}
{"epoch": 491, "reward_mean": 49.375, "student_loss": null, "teacher_policy_loss": -24.22100067138672, "teacher_value_loss": 133.96348571777344, "teacher_entropy": 0.579679012298584, "total_time": 1.2882747650146484, "rollout_time": 0.4391329288482666, "train_time": 0.8316090106964111, "student_train_time": 0.017165660858154297, "throughput": 1552.4638487949105, "inference_time": 0.053078918768733274, "env_time": 0.3860540100795333, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 492, "reward_mean": 42.791666666666664, "student_loss": null, "teacher_policy_loss": -21.329452514648438, "teacher_value_loss": 127.78701782226562, "teacher_entropy": 0.5782877206802368, "total_time": 1.3184282779693604, "rollout_time": 0.4307882785797119, "train_time": 0.8823118209838867, "student_train_time": 0.004914045333862305, "throughput": 1516.9577544865729, "inference_time": 0.05503594599395001, "env_time": 0.3757523325857619, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 493, "reward_mean": 45.627906976744185, "student_loss": null, "teacher_policy_loss": -23.582035064697266, "teacher_value_loss": 155.49485778808594, "teacher_entropy": 0.5817387104034424, "total_time": 1.2768280506134033, "rollout_time": 0.44055867195129395, "train_time": 0.8273804187774658, "student_train_time": 0.00847315788269043, "throughput": 1566.3816275333052, "inference_time": 0.05592562370475207, "env_time": 0.3846330482465419, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 494, "reward_mean": 41.708333333333336, "student_loss": null, "teacher_policy_loss": -20.582529067993164, "teacher_value_loss": 97.41911315917969, "teacher_entropy": 0.5823125243186951, "total_time": 1.1858315467834473, "rollout_time": 0.4177367687225342, "train_time": 0.7507712841033936, "student_train_time": 0.016972780227661133, "throughput": 1686.5801938099676, "inference_time": 0.054272974743071245, "env_time": 0.36346379397946293, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 495, "reward_mean": 47.26190476190476, "student_loss": null, "teacher_policy_loss": -22.634464263916016, "teacher_value_loss": 128.46595764160156, "teacher_entropy": 0.5869457721710205, "total_time": 1.239905834197998, "rollout_time": 0.43173861503601074, "train_time": 0.8025150299072266, "student_train_time": 0.00529932975769043, "throughput": 1613.0257192423405, "inference_time": 0.055274962265684735, "env_time": 0.376463652770326, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 496, "reward_mean": 43.977777777777774, "student_loss": null, "teacher_policy_loss": -22.838027954101562, "teacher_value_loss": 153.23460388183594, "teacher_entropy": 0.5779394507408142, "total_time": 1.3852992057800293, "rollout_time": 0.4617753028869629, "train_time": 0.9091331958770752, "student_train_time": 0.01399374008178711, "throughput": 1443.7314275899314, "inference_time": 0.060960193990467815, "env_time": 0.4008151088964951, "samples": 2000, "teacher_eval_reward": 174.0}
{"epoch": 497, "reward_mean": 54.68421052631579, "student_loss": null, "teacher_policy_loss": -25.300474166870117, "teacher_value_loss": 172.27731323242188, "teacher_entropy": 0.5857737064361572, "total_time": 1.296581745147705, "rollout_time": 0.4443967342376709, "train_time": 0.8447213172912598, "student_train_time": 0.0071086883544921875, "throughput": 1542.5174752650573, "inference_time": 0.05799614524948993, "env_time": 0.38640058898818097, "samples": 2000, "teacher_eval_reward": 94.0}
{"epoch": 498, "reward_mean": 41.45652173913044, "student_loss": null, "teacher_policy_loss": -21.5925350189209, "teacher_value_loss": 100.36257934570312, "teacher_entropy": 0.5708898901939392, "total_time": 1.2990639209747314, "rollout_time": 0.43163418769836426, "train_time": 0.8571569919586182, "student_train_time": 0.009847640991210938, "throughput": 1539.570122538183, "inference_time": 0.053959097733240924, "env_time": 0.37767508996512333, "samples": 2000, "teacher_eval_reward": 91.0}
{"epoch": 499, "reward_mean": 41.06122448979592, "student_loss": null, "teacher_policy_loss": -19.982759475708008, "teacher_value_loss": 92.26556396484375, "teacher_entropy": 0.5730871558189392, "total_time": 1.1903750896453857, "rollout_time": 0.4321012496948242, "train_time": 0.7517766952514648, "student_train_time": 0.006139278411865234, "throughput": 1680.142685609964, "inference_time": 0.053526185740338406, "env_time": 0.3785750639544858, "samples": 2000, "teacher_eval_reward": 500.0}
{"epoch": 500, "reward_mean": 49.12820512820513, "student_loss": null, "teacher_policy_loss": -25.38454246520996, "teacher_value_loss": 157.68150329589844, "teacher_entropy": 0.5823328495025635, "total_time": 1.2922556400299072, "rollout_time": 0.41841864585876465, "train_time": 0.8662130832672119, "student_train_time": 0.007249116897583008, "throughput": 1547.6813859784843, "inference_time": 0.05391490924193931, "env_time": 0.36450373661682534, "samples": 2000, "teacher_eval_reward": 119.0}
